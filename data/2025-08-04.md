<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 46]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 8]
- [cs.AI](#cs.AI) [Total: 25]
- [math.NA](#math.NA) [Total: 8]
- [cs.LG](#cs.LG) [Total: 62]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Quality-Guided Mixture of Score-Fusion Experts Framework for Human Recognition](https://arxiv.org/abs/2508.00053)
*Jie Zhu,Yiyang Su,Minchul Kim,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: 提出了一种基于质量引导的专家混合（QME）框架，用于提升多模态生物识别的性能。


<details>
  <summary>Details</summary>
Motivation: 传统多模态生物识别方法忽略了各模态分数分布的差异，限制了性能提升。

Method: 采用可学习的分数融合策略，结合质量估计器和分数三元组损失。

Result: 在多个数据集上取得最优性能，解决了模型对齐和数据质量变化问题。

Conclusion: QME框架在多模态生物识别中表现出色，具有广泛适用性。

Abstract: Whole-body biometric recognition is a challenging multimodal task that
integrates various biometric modalities, including face, gait, and body. This
integration is essential for overcoming the limitations of unimodal systems.
Traditionally, whole-body recognition involves deploying different models to
process multiple modalities, achieving the final outcome by score-fusion (e.g.,
weighted averaging of similarity matrices from each model). However, these
conventional methods may overlook the variations in score distributions of
individual modalities, making it challenging to improve final performance. In
this work, we present \textbf{Q}uality-guided \textbf{M}ixture of score-fusion
\textbf{E}xperts (QME), a novel framework designed for improving whole-body
biometric recognition performance through a learnable score-fusion strategy
using a Mixture of Experts (MoE). We introduce a novel pseudo-quality loss for
quality estimation with a modality-specific Quality Estimator (QE), and a score
triplet loss to improve the metric performance. Extensive experiments on
multiple whole-body biometric datasets demonstrate the effectiveness of our
proposed approach, achieving state-of-the-art results across various metrics
compared to baseline methods. Our method is effective for multimodal and
multi-model, addressing key challenges such as model misalignment in the
similarity score domain and variability in data quality.

</details>


### [2] [Punching Bag vs. Punching Person: Motion Transferability in Videos](https://arxiv.org/abs/2508.00085)
*Raiyaan Abdullah,Jared Claypoole,Michael Cogswell,Ajay Divakaran,Yogesh Rawat*

Main category: cs.CV

TL;DR: 论文研究了动作识别模型在跨多样上下文中的高级运动概念迁移能力，发现模型在识别新情境中的高级动作时性能显著下降，并提出了改进方法。


<details>
  <summary>Details</summary>
Motivation: 探索动作识别模型是否能有效迁移高级运动概念到不同上下文，特别是在类似分布中。

Method: 引入一个运动迁移性框架，使用三个数据集（Syn-TA、Kinetics400-TA、Something-Something-v2-TA）评估13个先进模型。

Result: 模型在新情境中识别高级动作时性能显著下降，且多模态模型在细粒度未知动作上表现更差。

Conclusion: 研究为评估动作识别中的运动迁移性提供了重要基准，并提出了改进方向。

Abstract: Action recognition models demonstrate strong generalization, but can they
effectively transfer high-level motion concepts across diverse contexts, even
within similar distributions? For example, can a model recognize the broad
action "punching" when presented with an unseen variation such as "punching
person"? To explore this, we introduce a motion transferability framework with
three datasets: (1) Syn-TA, a synthetic dataset with 3D object motions; (2)
Kinetics400-TA; and (3) Something-Something-v2-TA, both adapted from natural
video datasets. We evaluate 13 state-of-the-art models on these benchmarks and
observe a significant drop in performance when recognizing high-level actions
in novel contexts. Our analysis reveals: 1) Multimodal models struggle more
with fine-grained unknown actions than with coarse ones; 2) The bias-free
Syn-TA proves as challenging as real-world datasets, with models showing
greater performance drops in controlled settings; 3) Larger models improve
transferability when spatial cues dominate but struggle with intensive temporal
reasoning, while reliance on object and background cues hinders generalization.
We further explore how disentangling coarse and fine motions can improve
recognition in temporally challenging datasets. We believe this study
establishes a crucial benchmark for assessing motion transferability in action
recognition. Datasets and relevant code:
https://github.com/raiyaan-abdullah/Motion-Transfer.

</details>


### [3] [The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking](https://arxiv.org/abs/2508.00088)
*Mateo de Mayo,Daniel Cremers,Taihú Pire*

Main category: cs.CV

TL;DR: 论文介绍了Monado SLAM数据集，旨在解决现有VIO/SLAM系统在头戴设备使用场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有VIO/SLAM系统在头戴设备的高强度运动、动态遮挡等复杂场景中表现不佳，缺乏相关数据集。

Method: 提出Monado SLAM数据集，包含多款虚拟现实头戴设备的真实序列数据。

Result: 数据集以CC BY 4.0许可发布，推动VIO/SLAM研究发展。

Conclusion: Monado SLAM数据集填补了现有研究的空白，有助于解决实际应用中的挑战。

Abstract: Humanoid robots and mixed reality headsets benefit from the use of
head-mounted sensors for tracking. While advancements in visual-inertial
odometry (VIO) and simultaneous localization and mapping (SLAM) have produced
new and high-quality state-of-the-art tracking systems, we show that these are
still unable to gracefully handle many of the challenging settings presented in
the head-mounted use cases. Common scenarios like high-intensity motions,
dynamic occlusions, long tracking sessions, low-textured areas, adverse
lighting conditions, saturation of sensors, to name a few, continue to be
covered poorly by existing datasets in the literature. In this way, systems may
inadvertently overlook these essential real-world issues. To address this, we
present the Monado SLAM dataset, a set of real sequences taken from multiple
virtual reality headsets. We release the dataset under a permissive CC BY 4.0
license, to drive advancements in VIO/SLAM research and development.

</details>


### [4] [Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images](https://arxiv.org/abs/2508.00135)
*Basna Mohammed Salih Hasan,Ramadhan J. Mstafa*

Main category: cs.CV

TL;DR: 论文提出了一种基于卷积神经网络（CNN）的模型，利用眼周区域的颜色图像进行性别分类，在CVBL和（Female and Male）数据集上分别达到99%和96%的准确率。


<details>
  <summary>Details</summary>
Motivation: 性别分类在安全、人机交互等领域至关重要，但化妆品和伪装等因素会影响分类准确性，因此研究专注于眼周区域的性别分类。

Method: 使用CNN模型分析眼周区域的颜色图像，提取关键特征进行分类，并在两个数据集上进行验证。

Result: 模型在CVBL数据集上达到99%准确率，在（Female and Male）数据集上达到96%准确率，且参数较少（7,235,089）。

Conclusion: 模型表现优异，适用于安全和监控等实际应用。

Abstract: Gender classification has emerged as a crucial aspect in various fields,
including security, human-machine interaction, surveillance, and advertising.
Nonetheless, the accuracy of this classification can be influenced by factors
such as cosmetics and disguise. Consequently, our study is dedicated to
addressing this concern by concentrating on gender classification using color
images of the periocular region. The periocular region refers to the area
surrounding the eye, including the eyelids, eyebrows, and the region between
them. It contains valuable visual cues that can be used to extract key features
for gender classification. This paper introduces a sophisticated Convolutional
Neural Network (CNN) model that utilizes color image databases to evaluate the
effectiveness of the periocular region for gender classification. To validate
the model's performance, we conducted tests on two eye datasets, namely CVBL
and (Female and Male). The recommended architecture achieved an outstanding
accuracy of 99% on the previously unused CVBL dataset while attaining a
commendable accuracy of 96% with a small number of learnable parameters
(7,235,089) on the (Female and Male) dataset. To ascertain the effectiveness of
our proposed model for gender classification using the periocular region, we
evaluated its performance through an extensive range of metrics and compared it
with other state-of-the-art approaches. The results unequivocally demonstrate
the efficacy of our model, thereby suggesting its potential for practical
application in domains such as security and surveillance.

</details>


### [5] [World Consistency Score: A Unified Metric for Video Generation Quality](https://arxiv.org/abs/2508.00144)
*Akshat Rakheja,Aarsh Ashdhir,Aryan Bhattacharjee,Vanshika Sharma*

Main category: cs.CV

TL;DR: World Consistency Score (WCS) 是一种新的统一评估指标，用于衡量生成视频模型的内部世界一致性。它整合了四个可解释的子组件，并通过学习权重公式生成一致性分数。


<details>
  <summary>Details</summary>
Motivation: 现有视频评估指标主要关注视觉保真度或提示对齐，而忽略了时间与物理一致性。WCS旨在填补这一空白。

Method: WCS结合了四个子指标（物体持久性、关系稳定性、因果合规性和闪烁惩罚），并通过开源工具计算。权重通过人类偏好数据训练。

Result: WCS在多个基准测试中验证了与人类评价的相关性，并与其他指标（如FVD、CLIPScore）进行了比较。

Conclusion: WCS提供了一个全面且可解释的框架，用于评估视频生成模型在时间与物理一致性方面的表现。

Abstract: We introduce World Consistency Score (WCS), a novel unified evaluation metric
for generative video models that emphasizes internal world consistency of the
generated videos. WCS integrates four interpretable sub-components - object
permanence, relation stability, causal compliance, and flicker penalty - each
measuring a distinct aspect of temporal and physical coherence in a video.
These submetrics are combined via a learned weighted formula to produce a
single consistency score that aligns with human judgments. We detail the
motivation for WCS in the context of existing video evaluation metrics,
formalize each submetric and how it is computed with open-source tools
(trackers, action recognizers, CLIP embeddings, optical flow), and describe how
the weights of the WCS combination are trained using human preference data. We
also outline an experimental validation blueprint: using benchmarks like
VBench-2.0, EvalCrafter, and LOVE to test WCS's correlation with human
evaluations, performing sensitivity analyses, and comparing WCS against
established metrics (FVD, CLIPScore, VBench, FVMD). The proposed WCS offers a
comprehensive and interpretable framework for evaluating video generation
models on their ability to maintain a coherent "world" over time, addressing
gaps left by prior metrics focused only on visual fidelity or prompt alignment.

</details>


### [6] [GeoExplorer: Active Geo-localization with Curiosity-Driven Exploration](https://arxiv.org/abs/2508.00152)
*Li Mi,Manon Bechaz,Zeming Chen,Antoine Bosselut,Devis Tuia*

Main category: cs.CV

TL;DR: GeoExplorer通过好奇心驱动的探索提升主动地理定位（AGL）的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有AGL方法依赖距离奖励，在目标或环境未知时表现不佳，缺乏鲁棒性和泛化能力。

Method: 提出GeoExplorer，引入好奇心驱动的内在奖励，实现目标无关的多样化探索。

Result: 在四个AGL基准测试中验证了GeoExplorer的有效性，尤其在陌生目标和环境中表现优异。

Conclusion: 好奇心驱动的探索策略显著提升了AGL任务的鲁棒性和泛化能力。

Abstract: Active Geo-localization (AGL) is the task of localizing a goal, represented
in various modalities (e.g., aerial images, ground-level images, or text),
within a predefined search area. Current methods approach AGL as a
goal-reaching reinforcement learning (RL) problem with a distance-based reward.
They localize the goal by implicitly learning to minimize the relative distance
from it. However, when distance estimation becomes challenging or when
encountering unseen targets and environments, the agent exhibits reduced
robustness and generalization ability due to the less reliable exploration
strategy learned during training. In this paper, we propose GeoExplorer, an AGL
agent that incorporates curiosity-driven exploration through intrinsic rewards.
Unlike distance-based rewards, our curiosity-driven reward is goal-agnostic,
enabling robust, diverse, and contextually relevant exploration based on
effective environment modeling. These capabilities have been proven through
extensive experiments across four AGL benchmarks, demonstrating the
effectiveness and generalization ability of GeoExplorer in diverse settings,
particularly in localizing unfamiliar targets and environments.

</details>


### [7] [Robust 3D Object Detection using Probabilistic Point Clouds from Single-Photon LiDARs](https://arxiv.org/abs/2508.00169)
*Bhavya Goyal,Felipe Gutierrez-Barragan,Wei Lin,Andreas Velten,Yin Li,Mohit Gupta*

Main category: cs.CV

TL;DR: 论文提出了一种名为概率点云（PPC）的新型3D场景表示方法，通过为每个点添加概率属性来封装原始数据中的测量不确定性，从而提升3D物体检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代LiDAR在长距离或低反射率物体等场景中会产生稀疏或错误的点云，而传统3D处理流程未保留原始测量中的不确定性信息，导致下游感知模型精度下降。

Method: 提出PPC方法，为点云中的每个点添加概率属性，并设计基于PPC的推理方法，作为轻量级模块嵌入3D推理流程。

Result: 通过仿真和实际数据验证，PPC方法在室内外场景中优于LiDAR和相机-LiDAR融合模型，尤其在处理小、远、低反射率物体及强环境光时表现突出。

Conclusion: PPC通过引入概率属性有效提升了3D物体检测的鲁棒性，适用于多种挑战性场景。

Abstract: LiDAR-based 3D sensors provide point clouds, a canonical 3D representation
used in various scene understanding tasks. Modern LiDARs face key challenges in
several real-world scenarios, such as long-distance or low-albedo objects,
producing sparse or erroneous point clouds. These errors, which are rooted in
the noisy raw LiDAR measurements, get propagated to downstream perception
models, resulting in potentially severe loss of accuracy. This is because
conventional 3D processing pipelines do not retain any uncertainty information
from the raw measurements when constructing point clouds.
  We propose Probabilistic Point Clouds (PPC), a novel 3D scene representation
where each point is augmented with a probability attribute that encapsulates
the measurement uncertainty (or confidence) in the raw data. We further
introduce inference approaches that leverage PPC for robust 3D object
detection; these methods are versatile and can be used as computationally
lightweight drop-in modules in 3D inference pipelines. We demonstrate, via both
simulations and real captures, that PPC-based 3D inference methods outperform
several baselines using LiDAR as well as camera-LiDAR fusion models, across
challenging indoor and outdoor scenarios involving small, distant, and
low-albedo objects, as well as strong ambient light.
  Our project webpage is at https://bhavyagoyal.github.io/ppc .

</details>


### [8] [Graph Lineages and Skeletal Graph Products](https://arxiv.org/abs/2508.00197)
*Eric Mjolsness,Cory B. Scott*

Main category: cs.CV

TL;DR: 论文定义了结构化的图“谱系”（按层级排序），以分层方式增长，支持高效的代数操作和类型构造器，适用于分层模型架构和局部算法。


<details>
  <summary>Details</summary>
Motivation: 为机器学习和计算科学等领域的分层模型架构提供数学基础，支持高效的图操作和构造。

Method: 定义图谱系及其增长规则，引入“分级图”类别，推导低成本的“骨架”代数操作和类型构造器。

Result: 实现了对分级图和图谱系的高效操作，并展示了在深度神经网络和多网格数值方法中的应用。

Conclusion: 该方法为分层模型架构和局部算法提供了有效的数学工具，具有广泛的应用潜力。

Abstract: Graphs, and sequences of growing graphs, can be used to specify the
architecture of mathematical models in many fields including machine learning
and computational science. Here we define structured graph "lineages" (ordered
by level number) that grow in a hierarchical fashion, so that: (1) the number
of graph vertices and edges increases exponentially in level number; (2)
bipartite graphs connect successive levels within a graph lineage and, as in
multigrid methods, can constrain matrices relating successive levels; (3) using
prolongation maps within a graph lineage, process-derived distance measures
between graphs at successive levels can be defined; (4) a category of "graded
graphs" can be defined, and using it low-cost "skeletal" variants of standard
algebraic graph operations and type constructors (cross product, box product,
disjoint sum, and function types) can be derived for graded graphs and hence
hierarchical graph lineages; (5) these skeletal binary operators have similar
but not identical algebraic and category-theoretic properties to their standard
counterparts; (6) graph lineages and their skeletal product constructors can
approach continuum limit objects. Additional space-efficient unary operators on
graded graphs are also derived: thickening, which creates a graph lineage of
multiscale graphs, and escalation to a graph lineage of search frontiers
(useful as a generalization of adaptive grids and in defining "skeletal"
functions). The result is an algebraic type theory for graded graphs and
(hierarchical) graph lineages. The approach is expected to be well suited to
defining hierarchical model architectures - "hierarchitectures" - and local
sampling, search, or optimization algorithms on them. We demonstrate such
application to deep neural networks (including visual and feature scale spaces)
and to multigrid numerical methods.

</details>


### [9] [On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI](https://arxiv.org/abs/2508.00171)
*David Restrepo,Ira Ktena,Maria Vakalopoulou,Stergios Christodoulidis,Enzo Ferrante*

Main category: cs.CV

TL;DR: 论文提出了一种名为选择性模态转移（SMS）的方法，用于量化视觉语言模型（VLMs）在二元分类任务中对不同模态的依赖程度，揭示了模型对文本输入的显著依赖。


<details>
  <summary>Details</summary>
Motivation: 临床决策依赖于医学图像和相关临床报告的综合分析，但现有视觉语言模型可能偏向某一模态（如文本），忽视关键的视觉信息。

Method: 通过选择性模态转移（SMS）方法，系统地交换样本中的图像或文本，以暴露模态特异性偏差，并在两个医学影像数据集上评估了六种开源VLM模型。

Result: 研究发现模型在未扰动和扰动设置下均表现出对文本输入的显著依赖，视觉信息常被文本细节掩盖。

Conclusion: 强调了设计和评估真正整合视觉与文本线索的多模态医学模型的重要性。

Abstract: Clinical decision-making relies on the integrated analysis of medical images
and the associated clinical reports. While Vision-Language Models (VLMs) can
offer a unified framework for such tasks, they can exhibit strong biases toward
one modality, frequently overlooking critical visual cues in favor of textual
information. In this work, we introduce Selective Modality Shifting (SMS), a
perturbation-based approach to quantify a model's reliance on each modality in
binary classification tasks. By systematically swapping images or text between
samples with opposing labels, we expose modality-specific biases. We assess six
open-source VLMs-four generalist models and two fine-tuned for medical data-on
two medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray)
and FairVLMed (scanning laser ophthalmoscopy). By assessing model performance
and the calibration of every model in both unperturbed and perturbed settings,
we reveal a marked dependency on text input, which persists despite the
presence of complementary visual information. We also perform a qualitative
attention-based analysis which further confirms that image content is often
overshadowed by text details. Our findings highlight the importance of
designing and evaluating multimodal medical models that genuinely integrate
visual and textual cues, rather than relying on single-modality signals.

</details>


### [10] [Learning Personalised Human Internal Cognition from External Expressive Behaviours for Real Personality Recognition](https://arxiv.org/abs/2508.00205)
*Xiangyu Kong,Hengde Zhu,Haoqin Sun,Zhihao Guo,Jiayan Gu,Xinyi Ni,Wei Zhang,Shizhe Liu,Siyang Song*

Main category: cs.CV

TL;DR: 提出了一种基于个性化内部认知的自动真实人格识别方法，通过模拟目标个体的内部认知来提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常作为外部观察者推断人格印象，与真实人格偏差较大，性能较差。

Method: 模拟个性化内部认知，构建二维图表示，并使用2D-GNN进行人格识别。

Result: 通过端到端训练方法，实现了更高效的真实人格识别。

Conclusion: 该方法通过模拟内部认知，显著提升了真实人格识别的准确性。

Abstract: Automatic real personality recognition (RPR) aims to evaluate human real
personality traits from their expressive behaviours. However, most existing
solutions generally act as external observers to infer observers' personality
impressions based on target individuals' expressive behaviours, which
significantly deviate from their real personalities and consistently lead to
inferior recognition performance. Inspired by the association between real
personality and human internal cognition underlying the generation of
expressive behaviours, we propose a novel RPR approach that efficiently
simulates personalised internal cognition from easy-accessible external short
audio-visual behaviours expressed by the target individual. The simulated
personalised cognition, represented as a set of network weights that enforce
the personalised network to reproduce the individual-specific facial reactions,
is further encoded as a novel graph containing two-dimensional node and edge
feature matrices, with a novel 2D Graph Neural Network (2D-GNN) proposed for
inferring real personality traits from it. To simulate real personality-related
cognition, an end-to-end strategy is designed to jointly train our cognition
simulation, 2D graph construction, and personality recognition modules.

</details>


### [11] [SAM-PTx: Text-Guided Fine-Tuning of SAM with Parameter-Efficient, Parallel-Text Adapters](https://arxiv.org/abs/2508.00213)
*Shayan Jalilian,Abdul Bais*

Main category: cs.CV

TL;DR: SAM-PTx通过轻量级适配器设计，将CLIP文本嵌入作为语义引导注入SAM，提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 探索语义文本提示在分割任务中的潜力，弥补传统空间提示的不足。

Method: 提出Parallel-Text适配器，将冻结的CLIP文本嵌入注入SAM的图像编码器，仅修改MLP分支。

Result: 在COD10K、COCO和ADE20K数据集上，语义提示优于纯空间提示基线。

Conclusion: 语义条件集成是高效适配SAM的可行路径，计算复杂度低。

Abstract: The Segment Anything Model (SAM) has demonstrated impressive generalization
in prompt-based segmentation. Yet, the potential of semantic text prompts
remains underexplored compared to traditional spatial prompts like points and
boxes. This paper introduces SAM-PTx, a parameter-efficient approach for
adapting SAM using frozen CLIP-derived text embeddings as class-level semantic
guidance. Specifically, we propose a lightweight adapter design called
Parallel-Text that injects text embeddings into SAM's image encoder, enabling
semantics-guided segmentation while keeping most of the original architecture
frozen. Our adapter modifies only the MLP-parallel branch of each transformer
block, preserving the attention pathway for spatial reasoning. Through
supervised experiments and ablations on the COD10K dataset as well as low-data
subsets of COCO and ADE20K, we show that incorporating fixed text embeddings as
input improves segmentation performance over purely spatial prompt baselines.
To our knowledge, this is the first work to use text prompts for segmentation
on the COD10K dataset. These results suggest that integrating semantic
conditioning into SAM's architecture offers a practical and scalable path for
efficient adaptation with minimal computational complexity.

</details>


### [12] [Object-Centric Cropping for Visual Few-Shot Classification](https://arxiv.org/abs/2508.00218)
*Aymane Abdali,Bartosz Boguslawski,Lucas Drumetz,Vincent Gripon*

Main category: cs.CV

TL;DR: 在少样本图像分类中，通过引入物体局部位置信息和使用Segment Anything Model，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决少样本图像分类中因图像模糊或多物体背景导致的性能下降问题。

Method: 利用物体局部位置信息，结合Segment Anything Model或无监督前景物体提取方法。

Result: 在基准测试中显著提升了分类性能。

Conclusion: 局部位置信息和简单标注或无监督方法可有效提升少样本分类效果。

Abstract: In the domain of Few-Shot Image Classification, operating with as little as
one example per class, the presence of image ambiguities stemming from multiple
objects or complex backgrounds can significantly deteriorate performance. Our
research demonstrates that incorporating additional information about the local
positioning of an object within its image markedly enhances classification
across established benchmarks. More importantly, we show that a significant
fraction of the improvement can be achieved through the use of the Segment
Anything Model, requiring only a pixel of the object of interest to be pointed
out, or by employing fully unsupervised foreground object extraction methods.

</details>


### [13] [Guided Depth Map Super-Resolution via Multi-Scale Fusion U-shaped Mamba Network](https://arxiv.org/abs/2508.00248)
*Chenggang Guo,Hao Xu,XianMing Wan*

Main category: cs.CV

TL;DR: 提出了一种多尺度融合U形Mamba（MSF-UM）模型，用于深度图超分辨率，结合了Mamba的高效状态空间建模能力和多尺度U形结构，显著提升了重建精度并减少了参数数量。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络在长距离依赖和全局上下文建模方面存在局限，而Transformer的计算复杂度和内存消耗较高，限制了其在高分辨率深度图处理中的应用。

Method: 设计了结合残差密集通道注意力块和Mamba状态空间模块的结构，利用多尺度跨模态融合策略，通过彩色图像的高频纹理信息指导深度图超分辨率。

Result: 在多个公开数据集上的实验表明，MSF-UM在减少参数数量的同时，显著提升了重建精度，并展现出优异的泛化能力。

Conclusion: MSF-UM模型在深度图超分辨率任务中表现出色，尤其在处理大规模深度图时具有显著优势。

Abstract: Depth map super-resolution technology aims to improve the spatial resolution
of low-resolution depth maps and effectively restore high-frequency detail
information. Traditional convolutional neural network has limitations in
dealing with long-range dependencies and are unable to fully model the global
contextual information in depth maps. Although transformer can model global
dependencies, its computational complexity and memory consumption are
quadratic, which significantly limits its ability to process high-resolution
depth maps. In this paper, we propose a multi-scale fusion U-shaped Mamba
(MSF-UM) model, a novel guided depth map super-resolution framework. The core
innovation of this model is to integrate Mamba's efficient state-space modeling
capabilities into a multi-scale U-shaped fusion structure guided by a color
image. The structure combining the residual dense channel attention block and
the Mamba state space module is designed, which combines the local feature
extraction capability of the convolutional layer with the modeling advantage of
the state space model for long-distance dependencies. At the same time, the
model adopts a multi-scale cross-modal fusion strategy to make full use of the
high-frequency texture information from the color image to guide the
super-resolution process of the depth map. Compared with existing mainstream
methods, the proposed MSF-UM significantly reduces the number of model
parameters while achieving better reconstruction accuracy. Extensive
experiments on multiple publicly available datasets validate the effectiveness
of the model, especially showing excellent generalization ability in the task
of large-scale depth map super-resolution.

</details>


### [14] [PointGauss: Point Cloud-Guided Multi-Object Segmentation for Gaussian Splatting](https://arxiv.org/abs/2508.00259)
*Wentao Sun,Hanqing Xu,Quanyun Wu,Dedong Zhang,Yiping Chen,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: PointGauss提出了一种基于点云引导的高斯泼溅表示实时多目标分割框架，显著提升了多视角一致性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在初始化时间长和多视角一致性不足的问题，PointGauss旨在通过点云分割驱动流程高效实现3D分割。

Method: 采用点云高斯基元解码器和GPU加速的2D掩码渲染系统，快速生成3D实例掩码并确保多视角一致性。

Result: 实验表明，PointGauss在多视角mIoU上性能提升1.89%至31.78%，同时保持高效计算。

Conclusion: PointGauss在效率和性能上优于现有方法，并提出了新数据集DesktopObjects-360以解决当前基准的局限性。

Abstract: We introduce PointGauss, a novel point cloud-guided framework for real-time
multi-object segmentation in Gaussian Splatting representations. Unlike
existing methods that suffer from prolonged initialization and limited
multi-view consistency, our approach achieves efficient 3D segmentation by
directly parsing Gaussian primitives through a point cloud segmentation-driven
pipeline. The key innovation lies in two aspects: (1) a point cloud-based
Gaussian primitive decoder that generates 3D instance masks within 1 minute,
and (2) a GPU-accelerated 2D mask rendering system that ensures multi-view
consistency. Extensive experiments demonstrate significant improvements over
previous state-of-the-art methods, achieving performance gains of 1.89 to
31.78% in multi-view mIoU, while maintaining superior computational efficiency.
To address the limitations of current benchmarks (single-object focus,
inconsistent 3D evaluation, small scale, and partial coverage), we present
DesktopObjects-360, a novel comprehensive dataset for 3D segmentation in
radiance fields, featuring: (1) complex multi-object scenes, (2) globally
consistent 2D annotations, (3) large-scale training data (over 27 thousand 2D
masks), (4) full 360{\deg} coverage, and (5) 3D evaluation masks.

</details>


### [15] [Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models](https://arxiv.org/abs/2508.00260)
*Hyundong Jin,Hyung Jin Chang,Eunwoo Kim*

Main category: cs.CV

TL;DR: 本文提出了一种新框架，通过混合视觉投影器和专家推荐策略，解决生成式视觉语言模型在持续学习中忽视语言指令的问题，提升了任务适应性和响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在持续学习中可能过度关注视觉输入而忽视语言指令，特别是在重复文本指令的任务中。本文旨在解决这一问题。

Method: 提出混合视觉投影器框架，每个投影器作为基于指令上下文的视觉到语言翻译专家；引入专家推荐策略和专家剪枝以减少干扰。

Result: 实验表明，该方法在多样化视觉语言任务中优于现有持续学习方法，生成更符合指令的响应。

Conclusion: 通过结合混合投影器和优化策略，本文方法有效提升了模型对语言指令的关注和任务适应性。

Abstract: Continual learning enables pre-trained generative vision-language models
(VLMs) to incorporate knowledge from new tasks without retraining data from
previous ones. Recent methods update a visual projector to translate visual
information for new tasks, connecting pre-trained vision encoders with large
language models. However, such adjustments may cause the models to prioritize
visual inputs over language instructions, particularly learning tasks with
repetitive types of textual instructions. To address the neglect of language
instructions, we propose a novel framework that grounds the translation of
visual information on instructions for language models. We introduce a mixture
of visual projectors, each serving as a specialized visual-to-language
translation expert based on the given instruction context to adapt to new
tasks. To avoid using experts for irrelevant instruction contexts, we propose
an expert recommendation strategy that reuses experts for tasks similar to
those previously learned. Additionally, we introduce expert pruning to
alleviate interference from the use of experts that cumulatively activated in
previous tasks. Extensive experiments on diverse vision-language tasks
demonstrate that our method outperforms existing continual learning approaches
by generating instruction-following responses.

</details>


### [16] [Multimodal Referring Segmentation: A Survey](https://arxiv.org/abs/2508.00265)
*Henghui Ding,Song Tang,Shuting He,Chang Liu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 本文综述了多模态指代分割任务，涵盖其背景、方法、性能比较及应用，并提供了相关资源链接。


<details>
  <summary>Details</summary>
Motivation: 多模态指代分割在基于用户指令的精确对象感知应用中至关重要，近年来因深度学习的进步而备受关注。

Method: 文章提出统一的元架构，并回顾了图像、视频和3D场景中的代表性方法，还讨论了广义指代表达（GREx）方法。

Result: 提供了标准基准上的性能比较，并持续跟踪相关研究进展。

Conclusion: 多模态指代分割是一个快速发展的领域，未来仍需解决真实世界复杂性的挑战。

Abstract: Multimodal referring segmentation aims to segment target objects in visual
scenes, such as images, videos, and 3D scenes, based on referring expressions
in text or audio format. This task plays a crucial role in practical
applications requiring accurate object perception based on user instructions.
Over the past decade, it has gained significant attention in the multimodal
community, driven by advances in convolutional neural networks, transformers,
and large language models, all of which have substantially improved multimodal
perception capabilities. This paper provides a comprehensive survey of
multimodal referring segmentation. We begin by introducing this field's
background, including problem definitions and commonly used datasets. Next, we
summarize a unified meta architecture for referring segmentation and review
representative methods across three primary visual scenes, including images,
videos, and 3D scenes. We further discuss Generalized Referring Expression
(GREx) methods to address the challenges of real-world complexity, along with
related tasks and practical applications. Extensive performance comparisons on
standard benchmarks are also provided. We continually track related works at
https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation.

</details>


### [17] [Towards Robust Semantic Correspondence: A Benchmark and Insights](https://arxiv.org/abs/2508.00272)
*Wenyue Chong*

Main category: cs.CV

TL;DR: 论文提出了一种评估语义对应在恶劣条件下鲁棒性的新基准，发现现有方法在挑战性场景中表现下降，大规模视觉模型能提升鲁棒性，但微调会降低相对鲁棒性。DINO模型在相对鲁棒性上优于Stable Diffusion，融合两者可提升绝对鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 语义对应是计算机视觉中的基础任务，但在恶劣条件下的鲁棒性研究不足。本文旨在填补这一空白，通过建立新基准评估语义对应在挑战性场景中的表现。

Method: 建立包含14种常见成像问题的基准数据集，评估现有语义对应方法的鲁棒性，并分析大规模视觉模型和融合策略的效果。

Result: 现有方法在恶劣条件下表现显著下降；大规模视觉模型能提升鲁棒性，但微调会降低相对鲁棒性；DINO模型优于Stable Diffusion，融合两者效果更好。

Conclusion: 语义对应在恶劣条件下的鲁棒性仍需改进，任务特定的增强策略比通用数据增强更有效。

Abstract: Semantic correspondence aims to identify semantically meaningful
relationships between different images and is a fundamental challenge in
computer vision. It forms the foundation for numerous tasks such as 3D
reconstruction, object tracking, and image editing. With the progress of
large-scale vision models, semantic correspondence has achieved remarkable
performance in controlled and high-quality conditions. However, the robustness
of semantic correspondence in challenging scenarios is much less investigated.
In this work, we establish a novel benchmark for evaluating semantic
correspondence in adverse conditions. The benchmark dataset comprises 14
distinct challenging scenarios that reflect commonly encountered imaging
issues, including geometric distortion, image blurring, digital artifacts, and
environmental occlusion. Through extensive evaluations, we provide several key
insights into the robustness of semantic correspondence approaches: (1) All
existing methods suffer from noticeable performance drops under adverse
conditions; (2) Using large-scale vision models can enhance overall robustness,
but fine-tuning on these models leads to a decline in relative robustness; (3)
The DINO model outperforms the Stable Diffusion in relative robustness, and
their fusion achieves better absolute robustness; Moreover, We evaluate common
robustness enhancement strategies for semantic correspondence and find that
general data augmentations are ineffective, highlighting the need for
task-specific designs. These results are consistent across both our dataset and
real-world benchmarks.

</details>


### [18] [Privacy-Preserving Driver Drowsiness Detection with Spatial Self-Attention and Federated Learning](https://arxiv.org/abs/2508.00287)
*Tran Viet Khoa,Do Hai Son,Mohammad Abu Alsheikh,Yibeltal F Alem,Dinh Thai Hoang*

Main category: cs.CV

TL;DR: 提出了一种基于空间自注意力机制和LSTM的驾驶员疲劳检测框架，支持联邦学习，准确率达89.9%。


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是交通事故的主要原因之一，但在分散和多样化的真实数据中准确检测仍具挑战性。

Method: 结合空间自注意力机制与LSTM提取关键面部特征，采用梯度相似性比较优化联邦学习模型聚合。

Result: 在联邦学习设置下达到89.9%的检测准确率，优于现有方法。

Conclusion: 该框架能有效处理真实数据多样性，有望应用于智能交通系统提升道路安全。

Abstract: Driver drowsiness is one of the main causes of road accidents and is
recognized as a leading contributor to traffic-related fatalities. However,
detecting drowsiness accurately remains a challenging task, especially in
real-world settings where facial data from different individuals is
decentralized and highly diverse. In this paper, we propose a novel framework
for drowsiness detection that is designed to work effectively with
heterogeneous and decentralized data. Our approach develops a new Spatial
Self-Attention (SSA) mechanism integrated with a Long Short-Term Memory (LSTM)
network to better extract key facial features and improve detection
performance. To support federated learning, we employ a Gradient Similarity
Comparison (GSC) that selects the most relevant trained models from different
operators before aggregation. This improves the accuracy and robustness of the
global model while preserving user privacy. We also develop a customized tool
that automatically processes video data by extracting frames, detecting and
cropping faces, and applying data augmentation techniques such as rotation,
flipping, brightness adjustment, and zooming. Experimental results show that
our framework achieves a detection accuracy of 89.9% in the federated learning
settings, outperforming existing methods under various deployment scenarios.
The results demonstrate the effectiveness of our approach in handling
real-world data variability and highlight its potential for deployment in
intelligent transportation systems to enhance road safety through early and
reliable drowsiness detection.

</details>


### [19] [TITAN-Guide: Taming Inference-Time AligNment for Guided Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.00289)
*Christian Simon,Masato Ishii,Akio Hayakawa,Zhi Zhong,Shusuke Takahashi,Takashi Shibuya,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 提出了一种名为TITAN-Guide的训练自由指导框架，解决了现有方法在内存需求和控制效果上的不足，特别适用于计算密集型的文本到视频扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有训练自由指导框架要么内存需求高，要么控制效果不佳，限制了其在计算密集型任务（如文本到视频扩散模型）中的应用。

Method: 开发了一种无需反向传播的高效扩散潜在优化方法，研究了前向梯度下降与多种方向指令的结合。

Result: 实验表明，该方法在内存管理和潜在优化上优于现有方法，显著提升了文本到视频扩散模型的性能。

Conclusion: TITAN-Guide不仅降低了内存需求，还在多个扩散指导基准测试中表现出色。

Abstract: In the recent development of conditional diffusion models still require heavy
supervised fine-tuning for performing control on a category of tasks.
Training-free conditioning via guidance with off-the-shelf models is a
favorable alternative to avoid further fine-tuning on the base model. However,
the existing training-free guidance frameworks either have heavy memory
requirements or offer sub-optimal control due to rough estimation. These
shortcomings limit the applicability to control diffusion models that require
intense computation, such as Text-to-Video (T2V) diffusion models. In this
work, we propose Taming Inference Time Alignment for Guided Text-to-Video
Diffusion Model, so-called TITAN-Guide, which overcomes memory space issues,
and provides more optimal control in the guidance process compared to the
counterparts. In particular, we develop an efficient method for optimizing
diffusion latents without backpropagation from a discriminative guiding model.
In particular, we study forward gradient descents for guided diffusion tasks
with various options on directional directives. In our experiments, we
demonstrate the effectiveness of our approach in efficiently managing memory
during latent optimization, while previous methods fall short. Our proposed
approach not only minimizes memory requirements but also significantly enhances
T2V performance across a range of diffusion guidance benchmarks. Code, models,
and demo are available at https://titanguide.github.io.

</details>


### [20] [AniMer+: Unified Pose and Shape Estimation Across Mammalia and Aves via Family-Aware Transformer](https://arxiv.org/abs/2508.00298)
*Jin Lyu,Liang An,Li Lin,Pujin Cheng,Yebin Liu,Xiaoying Tang*

Main category: cs.CV

TL;DR: AniMer+ 是一个扩展的框架，通过高容量的 ViT 和 MoE 设计，实现了对哺乳动物和鸟类的统一姿态与形状重建，并利用扩散模型生成合成数据集以解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 在基础模型时代，通过单一网络实现对不同动态对象的统一理解具有重要意义，同时准确的动物姿态与形状估计对生物学研究至关重要。然而，现有方法网络容量有限且缺乏多物种数据集。

Method: AniMer+ 采用高容量、家族感知的 ViT 和 MoE 设计，将网络层分为物种特定和共享部分，并引入扩散模型生成合成数据集 CtrlAni3D 和 CtrlAVES3D。

Result: 在 41.3k 哺乳动物和 12.4k 鸟类图像（真实与合成数据）上训练后，AniMer+ 在多个基准测试中表现优于现有方法，包括具有挑战性的 Animal Kingdom 数据集。

Conclusion: AniMer+ 的网络架构和合成数据集显著提升了实际应用性能，为多物种姿态与形状重建提供了有效解决方案。

Abstract: In the era of foundation models, achieving a unified understanding of
different dynamic objects through a single network has the potential to empower
stronger spatial intelligence. Moreover, accurate estimation of animal pose and
shape across diverse species is essential for quantitative analysis in
biological research. However, this topic remains underexplored due to the
limited network capacity of previous methods and the scarcity of comprehensive
multi-species datasets. To address these limitations, we introduce AniMer+, an
extended version of our scalable AniMer framework. In this paper, we focus on a
unified approach for reconstructing mammals (mammalia) and birds (aves). A key
innovation of AniMer+ is its high-capacity, family-aware Vision Transformer
(ViT) incorporating a Mixture-of-Experts (MoE) design. Its architecture
partitions network layers into taxa-specific components (for mammalia and aves)
and taxa-shared components, enabling efficient learning of both distinct and
common anatomical features within a single model. To overcome the critical
shortage of 3D training data, especially for birds, we introduce a
diffusion-based conditional image generation pipeline. This pipeline produces
two large-scale synthetic datasets: CtrlAni3D for quadrupeds and CtrlAVES3D for
birds. To note, CtrlAVES3D is the first large-scale, 3D-annotated dataset for
birds, which is crucial for resolving single-view depth ambiguities. Trained on
an aggregated collection of 41.3k mammalian and 12.4k avian images (combining
real and synthetic data), our method demonstrates superior performance over
existing approaches across a wide range of benchmarks, including the
challenging out-of-domain Animal Kingdom dataset. Ablation studies confirm the
effectiveness of both our novel network architecture and the generated
synthetic datasets in enhancing real-world application performance.

</details>


### [21] [Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence](https://arxiv.org/abs/2508.00299)
*Danzhen Fu,Jiagao Hu,Daiguo Zhou,Fei Wang,Zepeng Wang,Wenhua Liao*

Main category: cs.CV

TL;DR: 提出了一种多视角行人视频编辑框架，通过视频修复和动作控制技术增强自动驾驶训练数据的多样性。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶系统中行人检测模型因训练数据缺乏危险场景而鲁棒性不足的问题。

Method: 识别多视角行人区域，扩展边界框并拼接为统一画布，通过姿态序列控制进行行人编辑（插入、替换、移除）。

Result: 实验表明，该方法能高质量完成行人编辑，具有视觉真实性、时空一致性和多视角一致性。

Conclusion: 该方法为自动驾驶数据增强和场景模拟提供了灵活高效的解决方案。

Abstract: Pedestrian detection models in autonomous driving systems often lack
robustness due to insufficient representation of dangerous pedestrian scenarios
in training datasets. To address this limitation, we present a novel framework
for controllable pedestrian video editing in multi-view driving scenarios by
integrating video inpainting and human motion control techniques. Our approach
begins by identifying pedestrian regions of interest across multiple camera
views, expanding detection bounding boxes with a fixed ratio, and resizing and
stitching these regions into a unified canvas while preserving cross-view
spatial relationships. A binary mask is then applied to designate the editable
area, within which pedestrian editing is guided by pose sequence control
conditions. This enables flexible editing functionalities, including pedestrian
insertion, replacement, and removal. Extensive experiments demonstrate that our
framework achieves high-quality pedestrian editing with strong visual realism,
spatiotemporal coherence, and cross-view consistency. These results establish
the proposed method as a robust and versatile solution for multi-view
pedestrian video generation, with broad potential for applications in data
augmentation and scenario simulation in autonomous driving.

</details>


### [22] [Exploring Fourier Prior and Event Collaboration for Low-Light Image Enhancement](https://arxiv.org/abs/2508.00308)
*Chunyan She,Fujun Han,Chengyu Fang,Shukai Duan,Lidan Wang*

Main category: cs.CV

TL;DR: 论文提出了一种基于事件相机的低光图像增强方法，通过解耦增强流程为可见性恢复和结构细化两阶段，结合动态对齐和对比损失，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分利用事件相机和帧相机的模态优势，限制了性能提升。

Method: 将增强流程分为可见性恢复和结构细化两阶段，设计了基于傅里叶空间的振幅-相位纠缠网络和动态对齐融合策略，并引入对比损失。

Result: 实验表明，该方法优于现有最优模型。

Conclusion: 通过解耦增强流程和动态对齐策略，有效提升了低光图像增强的性能。

Abstract: The event camera, benefiting from its high dynamic range and low latency,
provides performance gain for low-light image enhancement. Unlike frame-based
cameras, it records intensity changes with extremely high temporal resolution,
capturing sufficient structure information. Currently, existing event-based
methods feed a frame and events directly into a single model without fully
exploiting modality-specific advantages, which limits their performance.
Therefore, by analyzing the role of each sensing modality, the enhancement
pipeline is decoupled into two stages: visibility restoration and structure
refinement. In the first stage, we design a visibility restoration network with
amplitude-phase entanglement by rethinking the relationship between amplitude
and phase components in Fourier space. In the second stage, a fusion strategy
with dynamic alignment is proposed to mitigate the spatial mismatch caused by
the temporal resolution discrepancy between two sensing modalities, aiming to
refine the structure information of the image enhanced by the visibility
restoration network. In addition, we utilize spatial-frequency interpolation to
simulate negative samples with diverse illumination, noise and artifact
degradations, thereby developing a contrastive loss that encourages the model
to learn discriminative representations. Experiments demonstrate that the
proposed method outperforms state-of-the-art models.

</details>


### [23] [DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios](https://arxiv.org/abs/2508.00311)
*Yufeng Zhong,Zhixiong Zeng,Lei Chen,Longrong Yang,Liming Zheng,Jing Huang,Siqi Yang,Lin Ma*

Main category: cs.CV

TL;DR: DocTron-Formula是一个基于通用视觉语言模型的统一框架，用于数学公式OCR，无需专用架构，并在CSFormula数据集上取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 数学公式OCR在科学文献智能分析中至关重要，但现有模型难以处理其结构多样性和复杂性。

Method: 通过通用视觉语言模型构建统一框架，并引入大规模多学科数据集CSFormula，进行监督微调。

Result: 在多种风格、科学领域和复杂布局中达到最优性能，超越专用模型。

Conclusion: DocTron-Formula为复杂科学文档的自动理解提供了新范式。

Abstract: Optical Character Recognition (OCR) for mathematical formula is essential for
the intelligent analysis of scientific literature. However, both task-specific
and general vision-language models often struggle to handle the structural
diversity, complexity, and real-world variability inherent in mathematical
content. In this work, we present DocTron-Formula, a unified framework built
upon general vision-language models, thereby eliminating the need for
specialized architectures. Furthermore, we introduce CSFormula, a large-scale
and challenging dataset that encompasses multidisciplinary and structurally
complex formulas at the line, paragraph, and page levels. Through
straightforward supervised fine-tuning, our approach achieves state-of-the-art
performance across a variety of styles, scientific domains, and complex
layouts. Experimental results demonstrate that our method not only surpasses
specialized models in terms of accuracy and robustness, but also establishes a
new paradigm for the automated understanding of complex scientific documents.

</details>


### [24] [GV-VAD : Exploring Video Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.00312)
*Suhang Cai,Xiaohao Peng,Chong Wang,Xiaojie Cai,Jiangbo Qian*

Main category: cs.CV

TL;DR: 提出了一种基于生成视频增强的弱监督视频异常检测框架（GV-VAD），通过文本条件视频生成模型生成可控且合理的合成视频，低成本扩充训练数据，并采用合成样本损失缩放策略优化训练效果。


<details>
  <summary>Details</summary>
Motivation: 真实世界异常数据稀缺、不可预测且标注成本高，限制了现有模型的性能和泛化能力。

Method: 利用文本条件视频生成模型生成可控且合理的合成视频，结合合成样本损失缩放策略优化训练。

Result: 在UCF-Crime数据集上表现优于现有最优方法。

Conclusion: GV-VAD框架通过低成本生成合成视频有效提升了异常检测性能。

Abstract: Video anomaly detection (VAD) plays a critical role in public safety
applications such as intelligent surveillance. However, the rarity,
unpredictability, and high annotation cost of real-world anomalies make it
difficult to scale VAD datasets, which limits the performance and
generalization ability of existing models. To address this challenge, we
propose a generative video-enhanced weakly-supervised video anomaly detection
(GV-VAD) framework that leverages text-conditioned video generation models to
produce semantically controllable and physically plausible synthetic videos.
These virtual videos are used to augment training data at low cost. In
addition, a synthetic sample loss scaling strategy is utilized to control the
influence of generated synthetic samples for efficient training. The
experiments show that the proposed framework outperforms state-of-the-art
methods on UCF-Crime datasets. The code is available at
https://github.com/Sumutan/GV-VAD.git.

</details>


### [25] [Steering Guidance for Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.00319)
*Sunghyun Park,Seokeon Choi,Hyoungwoo Park,Sungrack Yun*

Main category: cs.CV

TL;DR: 提出了一种个性化引导方法，通过未学习的弱模型和动态权重插值，平衡目标分布对齐与文本编辑能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CFG和AG）无法有效平衡目标分布对齐与文本编辑能力，需要一种更优的解决方案。

Method: 利用未学习的弱模型和动态权重插值，在推理时控制未学习程度，实现平衡输出。

Result: 实验表明，该方法能提升文本对齐和目标分布保真度，且无需额外计算开销。

Conclusion: 提出的方法有效解决了现有引导方法的局限性，实现了更好的平衡性能。

Abstract: Personalizing text-to-image diffusion models is crucial for adapting the
pre-trained models to specific target concepts, enabling diverse image
generation. However, fine-tuning with few images introduces an inherent
trade-off between aligning with the target distribution (e.g., subject
fidelity) and preserving the broad knowledge of the original model (e.g., text
editability). Existing sampling guidance methods, such as classifier-free
guidance (CFG) and autoguidance (AG), fail to effectively guide the output
toward well-balanced space: CFG restricts the adaptation to the target
distribution, while AG compromises text alignment. To address these
limitations, we propose personalization guidance, a simple yet effective method
leveraging an unlearned weak model conditioned on a null text prompt. Moreover,
our method dynamically controls the extent of unlearning in a weak model
through weight interpolation between pre-trained and fine-tuned models during
inference. Unlike existing guidance methods, which depend solely on guidance
scales, our method explicitly steers the outputs toward a balanced latent space
without additional computational overhead. Experimental results demonstrate
that our proposed guidance can improve text alignment and target distribution
fidelity, integrating seamlessly with various fine-tuning strategies.

</details>


### [26] [Spectral Sensitivity Estimation with an Uncalibrated Diffraction Grating](https://arxiv.org/abs/2508.00330)
*Lilika Makabe,Hiroaki Santo,Fumio Okura,Michael S. Brown,Yasuyuki Matsushita*

Main category: cs.CV

TL;DR: 提出一种基于衍射光栅的相机光谱灵敏度校准方法，无需专用设备，仅需普通光栅片即可实现高精度校准。


<details>
  <summary>Details</summary>
Motivation: 相机光谱灵敏度的准确校准对计算机视觉任务至关重要，但现有方法依赖专用设备或已知光谱反射率的目标。

Method: 通过捕捉直接照明及其通过光栅片的衍射图案图像，以闭式方法同时估计相机光谱灵敏度和光栅参数。

Result: 在合成和真实数据实验中，该方法优于传统基于参考目标的方法。

Conclusion: 该方法高效实用，为相机光谱灵敏度校准提供了新思路。

Abstract: This paper introduces a practical and accurate calibration method for camera
spectral sensitivity using a diffraction grating. Accurate calibration of
camera spectral sensitivity is crucial for various computer vision tasks,
including color correction, illumination estimation, and material analysis.
Unlike existing approaches that require specialized narrow-band filters or
reference targets with known spectral reflectances, our method only requires an
uncalibrated diffraction grating sheet, readily available off-the-shelf. By
capturing images of the direct illumination and its diffracted pattern through
the grating sheet, our method estimates both the camera spectral sensitivity
and the diffraction grating parameters in a closed-form manner. Experiments on
synthetic and real-world data demonstrate that our method outperforms
conventional reference target-based methods, underscoring its effectiveness and
practicality.

</details>


### [27] [Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning](https://arxiv.org/abs/2508.00356)
*Angelos Vlachos,Giorgos Filandrianos,Maria Lymperaiou,Nikolaos Spanos,Ilias Mitsouras,Vasileios Karampinis,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 提出了一种基于协作代理的多图像推理框架，通过语言和视觉代理实现自动化、模块化且无需训练的多任务推理。


<details>
  <summary>Details</summary>
Motivation: 解决跨数据集和任务格式的多模态推理挑战。

Method: 采用双代理系统：语言代理生成任务提示，视觉代理进行推理。

Result: 在18个数据集上表现优异，Claude 3.7在多项任务中接近天花板性能。

Conclusion: 提示引导下的大视觉语言模型能有效进行多图像推理。

Abstract: We present a Collaborative Agent-Based Framework for Multi-Image Reasoning.
Our approach tackles the challenge of interleaved multimodal reasoning across
diverse datasets and task formats by employing a dual-agent system: a
language-based PromptEngineer, which generates context-aware, task-specific
prompts, and a VisionReasoner, a large vision-language model (LVLM) responsible
for final inference. The framework is fully automated, modular, and
training-free, enabling generalization across classification, question
answering, and free-form generation tasks involving one or multiple input
images. We evaluate our method on 18 diverse datasets from the 2025 MIRAGE
Challenge (Track A), covering a broad spectrum of visual reasoning tasks
including document QA, visual comparison, dialogue-based understanding, and
scene-level inference. Our results demonstrate that LVLMs can effectively
reason over multiple images when guided by informative prompts. Notably, Claude
3.7 achieves near-ceiling performance on challenging tasks such as TQA (99.13%
accuracy), DocVQA (96.87%), and MMCoQA (75.28 ROUGE-L). We also explore how
design choices-such as model selection, shot count, and input length-influence
the reasoning performance of different LVLMs.

</details>


### [28] [Stable at Any Speed: Speed-Driven Multi-Object Tracking with Learnable Kalman Filtering](https://arxiv.org/abs/2508.00358)
*Yan Gong,Mengjun Chen,Hao Liu,Gao Yongsheng,Lei Yang,Naibang Wang,Ziying Song,Haoqun Ma*

Main category: cs.CV

TL;DR: 论文提出了一种基于速度引导的可学习卡尔曼滤波器（SG-LKF），通过动态调整不确定性建模以适应车辆速度，显著提高了动态场景下的多目标跟踪稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统多目标跟踪方法依赖静态坐标变换，忽略了车辆速度对观测噪声和参考系变化的影响，导致在高动态场景中跟踪性能下降。

Method: 提出了SG-LKF，结合MotionScaleNet（MSNet）动态预测关键参数，并引入自监督轨迹一致性损失以增强帧间关联和轨迹连续性。

Result: SG-LKF在KITTI 2D MOT上以79.59% HOTA排名第一，在KITTI 3D MOT上达到82.03% HOTA，并在nuScenes 3D MOT上优于SimpleTrack 2.2% AMOTA。

Conclusion: SG-LKF通过动态适应车辆速度，显著提升了多目标跟踪在高动态场景中的性能。

Abstract: Multi-object tracking (MOT) enables autonomous vehicles to continuously
perceive dynamic objects, supplying essential temporal cues for prediction,
behavior understanding, and safe planning. However, conventional
tracking-by-detection methods typically rely on static coordinate
transformations based on ego-vehicle poses, disregarding ego-vehicle
speed-induced variations in observation noise and reference frame changes,
which degrades tracking stability and accuracy in dynamic, high-speed
scenarios. In this paper, we investigate the critical role of ego-vehicle speed
in MOT and propose a Speed-Guided Learnable Kalman Filter (SG-LKF) that
dynamically adapts uncertainty modeling to ego-vehicle speed, significantly
improving stability and accuracy in highly dynamic scenarios. Central to SG-LKF
is MotionScaleNet (MSNet), a decoupled token-mixing and channel-mixing MLP that
adaptively predicts key parameters of SG-LKF. To enhance inter-frame
association and trajectory continuity, we introduce a self-supervised
trajectory consistency loss jointly optimized with semantic and positional
constraints. Extensive experiments show that SG-LKF ranks first among all
vision-based methods on KITTI 2D MOT with 79.59% HOTA, delivers strong results
on KITTI 3D MOT with 82.03% HOTA, and outperforms SimpleTrack by 2.2% AMOTA on
nuScenes 3D MOT.

</details>


### [29] [CoST: Efficient Collaborative Perception From Unified Spatiotemporal Perspective](https://arxiv.org/abs/2508.00359)
*Zongheng Tang,Yi Liu,Yifan Sun,Yulu Gao,Jinyu Chen,Runsheng Xu,Si Liu*

Main category: cs.CV

TL;DR: 论文提出了一种高效的协作感知方法CoST，通过统一时空空间同时聚合多智能体和多时间观测，提升了传输效率和感知性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法将多智能体融合和多时间融合分离的问题，提升协作感知的效率和准确性。

Method: 提出协作感知时空变换器（CoST），统一时空空间进行特征传输和融合。

Result: CoST在效率和准确性上均有提升，且兼容多数现有方法。

Conclusion: CoST通过统一时空空间实现了高效的协作感知，适用于多种场景。

Abstract: Collaborative perception shares information among different agents and helps
solving problems that individual agents may face, e.g., occlusions and small
sensing range. Prior methods usually separate the multi-agent fusion and
multi-time fusion into two consecutive steps. In contrast, this paper proposes
an efficient collaborative perception that aggregates the observations from
different agents (space) and different times into a unified spatio-temporal
space simultanesouly. The unified spatio-temporal space brings two benefits,
i.e., efficient feature transmission and superior feature fusion. 1) Efficient
feature transmission: each static object yields a single observation in the
spatial temporal space, and thus only requires transmission only once (whereas
prior methods re-transmit all the object features multiple times). 2) superior
feature fusion: merging the multi-agent and multi-time fusion into a unified
spatial-temporal aggregation enables a more holistic perspective, thereby
enhancing perception performance in challenging scenarios. Consequently, our
Collaborative perception with Spatio-temporal Transformer (CoST) gains
improvement in both efficiency and accuracy. Notably, CoST is not tied to any
specific method and is compatible with a majority of previous methods,
enhancing their accuracy while reducing the transmission bandwidth.

</details>


### [30] [Honey Classification using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2508.00361)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.CV

TL;DR: 提出了一种基于机器学习的蜂蜜植物来源自动分类方法，通过数据集准备、特征提取和分类三个步骤实现，使用LDA和SVM/KNN模型，在标准数据集上取得了最高95.13%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 解决蜂蜜植物来源分类问题，提高分类准确性和效率。

Method: 1. 数据集准备：采用类转换方法增强类别可分性；2. 特征提取：使用LDA降维；3. 分类：采用SVM和KNN模型。

Result: 在标准HSI数据集上，分类准确率最高达95.13%（图像分类）和92.80%（实例分类）。

Conclusion: 该方法在蜂蜜植物来源分类中表现优异，达到了当前最佳水平。

Abstract: In this paper, we propose a machine learning-based method for automatically
classifying honey botanical origins. Dataset preparation, feature extraction,
and classification are the three main steps of the proposed method. We use a
class transformation method in the dataset preparation phase to maximize the
separability across classes. The feature extraction phase employs the Linear
Discriminant Analysis (LDA) technique for extracting relevant features and
reducing the number of dimensions. In the classification phase, we use Support
Vector Machines (SVM) and K-Nearest Neighbors (KNN) models to classify the
extracted features of honey samples into their botanical origins. We evaluate
our system using a standard honey hyperspectral imaging (HSI) dataset.
Experimental findings demonstrate that the proposed system produces
state-of-the-art results on this dataset, achieving the highest classification
accuracy of 95.13% for hyperspectral image-based classification and 92.80% for
hyperspectral instance-based classification.

</details>


### [31] [SparseRecon: Neural Implicit Surface Reconstruction from Sparse Views with Feature and Depth Consistencies](https://arxiv.org/abs/2508.00366)
*Liang Han,Xu Zhang,Haichuan Song,Kanle Shi,Yu-Shen Liu,Zhizhong Han*

Main category: cs.CV

TL;DR: SparseRecon是一种新的神经隐式重建方法，通过体积渲染特征一致性和不确定性引导深度约束，解决了稀疏视图重建中泛化性和重建质量的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（泛化性和过拟合性）在稀疏视图重建中存在泛化能力不足或重建质量受限的问题。

Method: 提出特征一致性损失和不确定性引导深度约束，分别解决视图一致性不足和几何细节恢复问题。

Result: 实验表明，SparseRecon在稀疏视图输入下优于现有方法，尤其是在小重叠视图场景中。

Conclusion: SparseRecon通过结合特征一致性和深度约束，显著提升了稀疏视图重建的质量和泛化能力。

Abstract: Surface reconstruction from sparse views aims to reconstruct a 3D shape or
scene from few RGB images. The latest methods are either generalization-based
or overfitting-based. However, the generalization-based methods do not
generalize well on views that were unseen during training, while the
reconstruction quality of overfitting-based methods is still limited by the
limited geometry clues. To address this issue, we propose SparseRecon, a novel
neural implicit reconstruction method for sparse views with volume
rendering-based feature consistency and uncertainty-guided depth constraint.
Firstly, we introduce a feature consistency loss across views to constrain the
neural implicit field. This design alleviates the ambiguity caused by
insufficient consistency information of views and ensures completeness and
smoothness in the reconstruction results. Secondly, we employ an
uncertainty-guided depth constraint to back up the feature consistency loss in
areas with occlusion and insignificant features, which recovers geometry
details for better reconstruction quality. Experimental results demonstrate
that our method outperforms the state-of-the-art methods, which can produce
high-quality geometry with sparse-view input, especially in the scenarios with
small overlapping views. Project page: https://hanl2010.github.io/SparseRecon/.

</details>


### [32] [Representation Shift: Unifying Token Compression with FlashAttention](https://arxiv.org/abs/2508.00367)
*Joonmyung Choi,Sanghyeok Lee,Byungoh Ko,Eunseo Kim,Jihyung Kil,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 提出了一种名为Representation Shift的训练无关、模型无关的度量方法，用于衡量令牌表示的变化程度，从而与FlashAttention兼容，实现令牌压缩。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂度的增加，Transformer模型和令牌数量增加，导致自注意力的二次计算成本和GPU内存访问开销上升。现有令牌压缩方法依赖注意力图，与FlashAttention不兼容。

Method: 提出Representation Shift度量方法，无需训练或注意力图，直接测量令牌表示的变化程度，实现与FlashAttention兼容的令牌压缩。

Result: 实验表明，该方法在视频-文本检索和视频问答任务中分别实现了5.5%和4.4%的速度提升。

Conclusion: Representation Shift是一种高效且通用的令牌压缩方法，适用于多种模型，并与FlashAttention无缝集成。

Abstract: Transformers have demonstrated remarkable success across vision, language,
and video. Yet, increasing task complexity has led to larger models and more
tokens, raising the quadratic cost of self-attention and the overhead of GPU
memory access. To reduce the computation cost of self-attention, prior work has
proposed token compression techniques that drop redundant or less informative
tokens. Meanwhile, fused attention kernels such as FlashAttention have been
developed to alleviate memory overhead by avoiding attention map construction
and its associated I/O to HBM. This, however, makes it incompatible with most
training-free token compression methods, which rely on attention maps to
determine token importance. Here, we propose Representation Shift, a
training-free, model-agnostic metric that measures the degree of change in each
token's representation. This seamlessly integrates token compression with
FlashAttention, without attention maps or retraining. Our method further
generalizes beyond Transformers to CNNs and state space models. Extensive
experiments show that Representation Shift enables effective token compression
compatible with FlashAttention, yielding significant speedups of up to 5.5% and
4.4% in video-text retrieval and video QA, respectively. Code is available at
https://github.com/mlvlab/Representation-Shift.

</details>


### [33] [Bidirectional Action Sequence Learning for Long-term Action Anticipation with Large Language Models](https://arxiv.org/abs/2508.00374)
*Yuji Sato,Yasunori Ishii,Takayoshi Yamashita*

Main category: cs.CV

TL;DR: BiAnt结合前向和后向预测，利用大语言模型提升视频长期动作预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法因单向性限制性能，难以捕捉场景中的语义子动作。

Method: 结合前向和后向预测，使用大语言模型。

Result: 在Ego4D上实验，BiAnt在编辑距离上优于基线方法。

Conclusion: BiAnt通过双向预测有效提升长期动作预测性能。

Abstract: Video-based long-term action anticipation is crucial for early risk detection
in areas such as automated driving and robotics. Conventional approaches
extract features from past actions using encoders and predict future events
with decoders, which limits performance due to their unidirectional nature.
These methods struggle to capture semantically distinct sub-actions within a
scene. The proposed method, BiAnt, addresses this limitation by combining
forward prediction with backward prediction using a large language model.
Experimental results on Ego4D demonstrate that BiAnt improves performance in
terms of edit distance compared to baseline methods.

</details>


### [34] [Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis](https://arxiv.org/abs/2508.00381)
*Kamal Basha S,Athira Nambiar*

Main category: cs.CV

TL;DR: 提出Adapt-WeldNet框架，结合预训练架构、迁移学习和自适应优化器，优化焊接缺陷检测性能，并引入DDIA框架增强系统透明度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统无损检测方法难以检测细微或内部缺陷，现有神经网络方法缺乏可解释性，存在安全隐患。

Method: Adapt-WeldNet系统评估预训练架构、迁移学习策略和自适应优化器；DDIA框架结合XAI技术和专家验证。

Result: 提升缺陷检测性能和系统透明度，增强信任和可靠性。

Conclusion: 该工作通过性能优化和可解释性增强，支持海洋和离岸环境中的关键操作。

Abstract: Weld defect detection is crucial for ensuring the safety and reliability of
piping systems in the oil and gas industry, especially in challenging marine
and offshore environments. Traditional non-destructive testing (NDT) methods
often fail to detect subtle or internal defects, leading to potential failures
and costly downtime. Furthermore, existing neural network-based approaches for
defect classification frequently rely on arbitrarily selected pretrained
architectures and lack interpretability, raising safety concerns for
deployment. To address these challenges, this paper introduces
``Adapt-WeldNet", an adaptive framework for welding defect detection that
systematically evaluates various pre-trained architectures, transfer learning
strategies, and adaptive optimizers to identify the best-performing model and
hyperparameters, optimizing defect detection and providing actionable insights.
Additionally, a novel Defect Detection Interpretability Analysis (DDIA)
framework is proposed to enhance system transparency. DDIA employs Explainable
AI (XAI) techniques, such as Grad-CAM and LIME, alongside domain-specific
evaluations validated by certified ASNT NDE Level II professionals.
Incorporating a Human-in-the-Loop (HITL) approach and aligning with the
principles of Trustworthy AI, DDIA ensures the reliability, fairness, and
accountability of the defect detection system, fostering confidence in
automated decisions through expert validation. By improving both performance
and interpretability, this work enhances trust, safety, and reliability in
welding defect detection systems, supporting critical operations in offshore
and marine environments.

</details>


### [35] [$MV_{Hybrid}$: Improving Spatial Transcriptomics Prediction with Hybrid State Space-Vision Transformer Backbone in Pathology Vision Foundation Models](https://arxiv.org/abs/2508.00383)
*Won June Cho,Hongjun Yoon,Daeky Jeong,Hyeongyeol Lim,Yosep Chong*

Main category: cs.CV

TL;DR: 论文提出了一种混合架构$MV_{Hybrid}$，结合状态空间模型（SSMs）和ViT，用于从病理图像预测空间基因表达，性能优于现有ViT模型。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学成本高且技术复杂，限制了临床应用。从常规病理图像预测基因表达是一种实用替代方案，但现有ViT模型性能不足。

Method: 提出$MV_{Hybrid}$架构，结合SSMs和ViT，利用负实特征值初始化状态空间模型以增强低频模式捕捉能力。

Result: $MV_{Hybrid}$在基因表达预测中比ViT性能提升57%，且在分类、检索和生存预测任务中表现相当或更好。

Conclusion: $MV_{Hybrid}$是一种有前景的下一代病理视觉基础模型架构。

Abstract: Spatial transcriptomics reveals gene expression patterns within tissue
context, enabling precision oncology applications such as treatment response
prediction, but its high cost and technical complexity limit clinical adoption.
Predicting spatial gene expression (biomarkers) from routine histopathology
images offers a practical alternative, yet current vision foundation models
(VFMs) in pathology based on Vision Transformer (ViT) backbones perform below
clinical standards. Given that VFMs are already trained on millions of diverse
whole slide images, we hypothesize that architectural innovations beyond ViTs
may better capture the low-frequency, subtle morphological patterns correlating
with molecular phenotypes. By demonstrating that state space models initialized
with negative real eigenvalues exhibit strong low-frequency bias, we introduce
$MV_{Hybrid}$, a hybrid backbone architecture combining state space models
(SSMs) with ViT. We compare five other different backbone architectures for
pathology VFMs, all pretrained on identical colorectal cancer datasets using
the DINOv2 self-supervised learning method. We evaluate all pretrained models
using both random split and leave-one-study-out (LOSO) settings of the same
biomarker dataset. In LOSO evaluation, $MV_{Hybrid}$ achieves 57% higher
correlation than the best-performing ViT and shows 43% smaller performance
degradation compared to random split in gene expression prediction,
demonstrating superior performance and robustness, respectively. Furthermore,
$MV_{Hybrid}$ shows equal or better downstream performance in classification,
patch retrieval, and survival prediction tasks compared to that of ViT, showing
its promise as a next-generation pathology VFM backbone. Our code is publicly
available at: https://github.com/deepnoid-ai/MVHybrid.

</details>


### [36] [Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition](https://arxiv.org/abs/2508.00391)
*Guanjie Huang,Danny H. K. Tsang,Shan Yang,Guangzhi Lei,Li Liu*

Main category: cs.CV

TL;DR: 提出了一种名为Cued-Agent的多智能体系统，用于自动识别Cued Speech（CS），通过四个子智能体协作处理手部和唇部动作，解决了传统方法中多模态融合和数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在CS识别中因手部和唇部动作的异步性及数据不足导致性能不佳，多智能体系统在有限数据下表现优异，因此提出Cued-Agent。

Method: Cued-Agent包含四个子智能体：基于多模态大语言模型的手部识别、基于Transformer的唇部识别、动态整合手部提示的推理代理，以及首次实现音素到自然语言转换的自校正代理。

Result: 实验表明，Cued-Agent在正常和听力受损场景下均优于现有方法。

Conclusion: Cued-Agent通过多智能体协作有效解决了CS识别中的多模态融合和数据不足问题，性能显著提升。

Abstract: Cued Speech (CS) is a visual communication system that combines lip-reading
with hand coding to facilitate communication for individuals with hearing
impairments. Automatic CS Recognition (ACSR) aims to convert CS hand gestures
and lip movements into text via AI-driven methods. Traditionally, the temporal
asynchrony between hand and lip movements requires the design of complex
modules to facilitate effective multimodal fusion. However, constrained by
limited data availability, current methods demonstrate insufficient capacity
for adequately training these fusion mechanisms, resulting in suboptimal
performance. Recently, multi-agent systems have shown promising capabilities in
handling complex tasks with limited data availability. To this end, we propose
the first collaborative multi-agent system for ACSR, named Cued-Agent. It
integrates four specialized sub-agents: a Multimodal Large Language Model-based
Hand Recognition agent that employs keyframe screening and CS expert prompt
strategies to decode hand movements, a pretrained Transformer-based Lip
Recognition agent that extracts lip features from the input video, a Hand
Prompt Decoding agent that dynamically integrates hand prompts with lip
features during inference in a training-free manner, and a Self-Correction
Phoneme-to-Word agent that enables post-process and end-to-end conversion from
phoneme sequences to natural language sentences for the first time through
semantic refinement. To support this study, we expand the existing Mandarin CS
dataset by collecting data from eight hearing-impaired cuers, establishing a
mixed dataset of fourteen subjects. Extensive experiments demonstrate that our
Cued-Agent performs superbly in both normal and hearing-impaired scenarios
compared with state-of-the-art methods. The implementation is available at
https://github.com/DennisHgj/Cued-Agent.

</details>


### [37] [Decouple before Align: Visual Disentanglement Enhances Prompt Tuning](https://arxiv.org/abs/2508.00395)
*Fei Zhang,Tianfei Zhou,Jiangchao Yao,Ya Zhang,Ivor W. Tsang,Yanfeng Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为DAPT的提示调优框架，通过解耦视觉模态的前景和背景表示，并分别对齐文本模态，解决了视觉-语言模型中信息不对称的问题，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究发现提示调优中存在视觉模态与文本模态信息不对称的问题，导致模型注意力偏向于上下文区域，而非目标对象。

Method: 提出DAPT框架，首先通过视觉分割线索解耦视觉模态为前景和背景表示，再分别与文本模态对齐，并引入视觉拉推正则化以增强注意力。

Result: 在少样本学习、基础到新类别的泛化以及数据高效学习中，DAPT在多个基准测试中表现优异。

Conclusion: DAPT通过解耦和对齐策略有效解决了信息不对称问题，提升了视觉-语言模型的性能。

Abstract: Prompt tuning (PT), as an emerging resource-efficient fine-tuning paradigm,
has showcased remarkable effectiveness in improving the task-specific
transferability of vision-language models. This paper delves into a previously
overlooked information asymmetry issue in PT, where the visual modality mostly
conveys more context than the object-oriented textual modality.
Correspondingly, coarsely aligning these two modalities could result in the
biased attention, driving the model to merely focus on the context area. To
address this, we propose DAPT, an effective PT framework based on an intuitive
decouple-before-align concept. First, we propose to explicitly decouple the
visual modality into the foreground and background representation via
exploiting coarse-and-fine visual segmenting cues, and then both of these
decoupled patterns are aligned with the original foreground texts and the
hand-crafted background classes, thereby symmetrically strengthening the modal
alignment. To further enhance the visual concentration, we propose a visual
pull-push regularization tailored for the foreground-background patterns,
directing the original visual representation towards unbiased attention on the
region-of-interest object. We demonstrate the power of architecture-free DAPT
through few-shot learning, base-to-novel generalization, and data-efficient
learning, all of which yield superior performance across prevailing benchmarks.
Our code will be released at https://github.com/Ferenas/DAPT.

</details>


### [38] [Video Forgery Detection with Optical Flow Residuals and Spatial-Temporal Consistency](https://arxiv.org/abs/2508.00397)
*Xi Xue,Kunio Suzuki,Nabarun Goswami,Takuya Shintate*

Main category: cs.CV

TL;DR: 提出了一种基于RGB外观特征和光流残差的双分支框架，用于检测AI生成视频中的伪造内容。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型生成的视频越来越逼真，现有方法难以捕捉时间不一致性，尤其是在高保真视频中。

Method: 采用双分支架构，分别分析RGB帧和光流残差，以检测外观和运动异常。

Result: 在多种生成模型上的实验表明，该方法具有鲁棒性和强泛化能力。

Conclusion: 通过结合空间和时间特征，该方法能有效检测多种伪造视频。

Abstract: The rapid advancement of diffusion-based video generation models has led to
increasingly realistic synthetic content, presenting new challenges for video
forgery detection. Existing methods often struggle to capture fine-grained
temporal inconsistencies, particularly in AI-generated videos with high visual
fidelity and coherent motion. In this work, we propose a detection framework
that leverages spatial-temporal consistency by combining RGB appearance
features with optical flow residuals. The model adopts a dual-branch
architecture, where one branch analyzes RGB frames to detect appearance-level
artifacts, while the other processes flow residuals to reveal subtle motion
anomalies caused by imperfect temporal synthesis. By integrating these
complementary features, the proposed method effectively detects a wide range of
forged videos. Extensive experiments on text-to-video and image-to-video tasks
across ten diverse generative models demonstrate the robustness and strong
generalization ability of the proposed approach.

</details>


### [39] [iSafetyBench: A video-language benchmark for safety in industrial environment](https://arxiv.org/abs/2508.00399)
*Raiyaan Abdullah,Yogesh Singh Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: iSafetyBench是一个新的视频语言基准测试，用于评估视觉语言模型在工业环境中的性能，特别是在常规和危险场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在高风险的工业领域中识别常规操作和安全关键异常的能力尚未充分探索。

Method: 构建了包含1,100个工业视频片段的iSafetyBench数据集，标注了98个常规和67个危险动作类别，并设计了多标签和多选题评估。

Result: 评估了8个最先进的视频语言模型，发现它们在危险活动识别和多标签场景中表现不佳。

Conclusion: iSafetyBench揭示了现有模型的性能差距，推动了更鲁棒、安全感知的多模态模型的发展。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive
generalization across diverse video understanding tasks under zero-shot
settings. However, their capabilities in high-stakes industrial domains-where
recognizing both routine operations and safety-critical anomalies is
essential-remain largely underexplored. To address this gap, we introduce
iSafetyBench, a new video-language benchmark specifically designed to evaluate
model performance in industrial environments across both normal and hazardous
scenarios. iSafetyBench comprises 1,100 video clips sourced from real-world
industrial settings, annotated with open-vocabulary, multi-label action tags
spanning 98 routine and 67 hazardous action categories. Each clip is paired
with multiple-choice questions for both single-label and multi-label
evaluation, enabling fine-grained assessment of VLMs in both standard and
safety-critical contexts. We evaluate eight state-of-the-art video-language
models under zero-shot conditions. Despite their strong performance on existing
video benchmarks, these models struggle with iSafetyBench-particularly in
recognizing hazardous activities and in multi-label scenarios. Our results
reveal significant performance gaps, underscoring the need for more robust,
safety-aware multimodal models for industrial applications. iSafetyBench
provides a first-of-its-kind testbed to drive progress in this direction. The
dataset is available at: https://github.com/raiyaan-abdullah/iSafety-Bench.

</details>


### [40] [Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents](https://arxiv.org/abs/2508.00400)
*Janika Deborah Gajo,Gerarld Paul Merales,Jerome Escarcha,Brenden Ashley Molina,Gian Nartea,Emmanuel G. Maminta,Juan Carlos Roldan,Rowel O. Atienza*

Main category: cs.CV

TL;DR: Sari Sandbox是一个高保真、逼真的3D零售店模拟环境，用于评估具身代理在购物任务中与人类表现的对比。


<details>
  <summary>Details</summary>
Motivation: 解决零售领域缺乏专门用于具身代理训练的模拟环境的问题。

Method: 提供包含250多种交互式杂货商品的三种商店配置，支持VR和VLM驱动的具身代理，并引入SariBench数据集。

Result: 具身代理能够导航、检查和操作零售商品，并与人类表现进行基准对比。

Conclusion: 提出了性能分析和改进建议，源代码已开源。

Abstract: We present Sari Sandbox, a high-fidelity, photorealistic 3D retail store
simulation for benchmarking embodied agents against human performance in
shopping tasks. Addressing a gap in retail-specific sim environments for
embodied agent training, Sari Sandbox features over 250 interactive grocery
items across three store configurations, controlled via an API. It supports
both virtual reality (VR) for human interaction and a vision language model
(VLM)-powered embodied agent. We also introduce SariBench, a dataset of
annotated human demonstrations across varied task difficulties. Our sandbox
enables embodied agents to navigate, inspect, and manipulate retail items,
providing baselines against human performance. We conclude with benchmarks,
performance analysis, and recommendations for enhancing realism and
scalability. The source code can be accessed via
https://github.com/upeee/sari-sandbox-env.

</details>


### [41] [PMR: Physical Model-Driven Multi-Stage Restoration of Turbulent Dynamic Videos](https://arxiv.org/abs/2508.00406)
*Tao Wu,Jingyuan Ye,Ying Fu*

Main category: cs.CV

TL;DR: 论文提出了一种动态效率指数（DEI）和多阶段视频恢复框架（PMR），用于解决大气湍流导致的视频质量下降问题，尤其在强湍流和复杂动态场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 大气湍流引起的几何畸变和模糊降低了远距离动态场景视频的质量，现有方法难以恢复边缘细节和消除混合失真。

Method: 提出动态效率指数（DEI）量化视频动态强度，并设计多阶段视频恢复框架（PMR），包括几何稳定、动态区域增强和去模糊三个阶段。

Result: 实验表明，PMR能有效抑制运动拖尾伪影，恢复边缘细节，并在高湍流和复杂动态场景中表现出强泛化能力。

Conclusion: 该方法在视频恢复领域具有高效性和高质量，代码和数据集将公开。

Abstract: Geometric distortions and blurring caused by atmospheric turbulence degrade
the quality of long-range dynamic scene videos. Existing methods struggle with
restoring edge details and eliminating mixed distortions, especially under
conditions of strong turbulence and complex dynamics. To address these
challenges, we introduce a Dynamic Efficiency Index ($DEI$), which combines
turbulence intensity, optical flow, and proportions of dynamic regions to
accurately quantify video dynamic intensity under varying turbulence conditions
and provide a high-dynamic turbulence training dataset. Additionally, we
propose a Physical Model-Driven Multi-Stage Video Restoration ($PMR$) framework
that consists of three stages: \textbf{de-tilting} for geometric stabilization,
\textbf{motion segmentation enhancement} for dynamic region refinement, and
\textbf{de-blurring} for quality restoration. $PMR$ employs lightweight
backbones and stage-wise joint training to ensure both efficiency and high
restoration quality. Experimental results demonstrate that the proposed method
effectively suppresses motion trailing artifacts, restores edge details and
exhibits strong generalization capability, especially in real-world scenarios
characterized by high-turbulence and complex dynamics. We will make the code
and datasets openly available.

</details>


### [42] [Sortblock: Similarity-Aware Feature Reuse for Diffusion Model](https://arxiv.org/abs/2508.00412)
*Hanqi Chen,Xu Zhang,Xiaoliu Guan,Lielin Jiang,Guanzhong Wang,Zeyu Chen,Yi Liu*

Main category: cs.CV

TL;DR: Sortblock是一种无需训练的推理加速框架，通过动态缓存块级特征和选择性跳过冗余计算，显著提升Diffusion Transformers的推理速度。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers（DiTs）因其顺序去噪过程导致高推理延迟，限制了实时应用。现有加速方法未考虑去噪阶段和Transformer块的语义变化。

Method: 提出Sortblock框架，动态缓存相邻时间步的块级特征，通过残差演化排序自适应确定重计算比例，并结合轻量级线性预测减少误差。

Result: 实验表明，Sortblock在多种任务和DiT架构上实现2倍以上的推理加速，且生成质量几乎无损。

Conclusion: Sortblock为扩散生成模型提供了一种高效且通用的加速解决方案。

Abstract: Diffusion Transformers (DiTs) have demonstrated remarkable generative
capabilities, particularly benefiting from Transformer architectures that
enhance visual and artistic fidelity. However, their inherently sequential
denoising process results in high inference latency, limiting their deployment
in real-time scenarios. Existing training-free acceleration approaches
typically reuse intermediate features at fixed timesteps or layers, overlooking
the evolving semantic focus across denoising stages and Transformer blocks.To
address this, we propose Sortblock, a training-free inference acceleration
framework that dynamically caches block-wise features based on their similarity
across adjacent timesteps. By ranking the evolution of residuals, Sortblock
adaptively determines a recomputation ratio, selectively skipping redundant
computations while preserving generation quality. Furthermore, we incorporate a
lightweight linear prediction mechanism to reduce accumulated errors in skipped
blocks.Extensive experiments across various tasks and DiT architectures
demonstrate that Sortblock achieves over 2$\times$ inference speedup with
minimal degradation in output quality, offering an effective and generalizable
solution for accelerating diffusion-based generative models.

</details>


### [43] [DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space](https://arxiv.org/abs/2508.00413)
*Junyu Chen,Dongyun Zou,Wenkun He,Junsong Chen,Enze Xie,Song Han,Han Cai*

Main category: cs.CV

TL;DR: DC-AE 1.5是一种新型深度压缩自编码器，通过结构化潜在空间和增强扩散训练，解决了高分辨率扩散模型中潜在通道增加导致的收敛慢问题，提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 潜在通道数增加虽能提升重建质量，但会导致扩散模型收敛慢，限制了潜在扩散模型的质量上限。

Method: 引入结构化潜在空间（训练时对潜在空间施加通道结构）和增强扩散训练（在对象潜在通道上添加扩散训练目标）。

Result: DC-AE 1.5在ImageNet 512x512上生成质量优于DC-AE，且速度快4倍。

Conclusion: DC-AE 1.5通过创新方法解决了潜在通道增加带来的问题，显著提升了扩散模型的性能。

Abstract: We present DC-AE 1.5, a new family of deep compression autoencoders for
high-resolution diffusion models. Increasing the autoencoder's latent channel
number is a highly effective approach for improving its reconstruction quality.
However, it results in slow convergence for diffusion models, leading to poorer
generation quality despite better reconstruction quality. This issue limits the
quality upper bound of latent diffusion models and hinders the employment of
autoencoders with higher spatial compression ratios. We introduce two key
innovations to address this challenge: i) Structured Latent Space, a
training-based approach to impose a desired channel-wise structure on the
latent space with front latent channels capturing object structures and latter
latent channels capturing image details; ii) Augmented Diffusion Training, an
augmented diffusion training strategy with additional diffusion training
objectives on object latent channels to accelerate convergence. With these
techniques, DC-AE 1.5 delivers faster convergence and better diffusion scaling
results than DC-AE. On ImageNet 512x512, DC-AE-1.5-f64c128 delivers better
image generation quality than DC-AE-f32c32 while being 4x faster. Code:
https://github.com/dc-ai-projects/DC-Gen.

</details>


### [44] [IN2OUT: Fine-Tuning Video Inpainting Model for Video Outpainting Using Hierarchical Discriminator](https://arxiv.org/abs/2508.00418)
*Sangwoo Youn,Minji Lee,Nokap Tony Park,Yeonggyoo Jeon,Taeyoung Na*

Main category: cs.CV

TL;DR: 论文提出了一种基于视频修复模型的视频外绘方法，通过改进判别器设计和引入分层对抗训练目标，解决了现有方法在扩展视频边界时模糊的问题。


<details>
  <summary>Details</summary>
Motivation: 视频外绘需要扩展边界并保持内容一致性，但现有方法仅生成背景效果不佳。

Method: 使用视频修复模型，设计分层判别器，并引入专门的外绘损失函数。

Result: 方法在定量和定性上均优于现有技术。

Conclusion: 通过改进判别器和损失函数，实现了视觉吸引且全局一致的视频外绘效果。

Abstract: Video outpainting presents a unique challenge of extending the borders while
maintaining consistency with the given content. In this paper, we suggest the
use of video inpainting models that excel in object flow learning and
reconstruction in outpainting rather than solely generating the background as
in existing methods. However, directly applying or fine-tuning inpainting
models to outpainting has shown to be ineffective, often leading to blurry
results. Our extensive experiments on discriminator designs reveal that a
critical component missing in the outpainting fine-tuning process is a
discriminator capable of effectively assessing the perceptual quality of the
extended areas. To tackle this limitation, we differentiate the objectives of
adversarial training into global and local goals and introduce a hierarchical
discriminator that meets both objectives. Additionally, we develop a
specialized outpainting loss function that leverages both local and global
features of the discriminator. Fine-tuning on this adversarial loss function
enhances the generator's ability to produce both visually appealing and
globally coherent outpainted scenes. Our proposed method outperforms
state-of-the-art methods both quantitatively and qualitatively. Supplementary
materials including the demo video and the code are available in SigPort.

</details>


### [45] [UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via Dynamic Tree Scan and Hidden State Weaken](https://arxiv.org/abs/2508.00421)
*Runmin Cong,Zongji Yu,Hao Fang,Haoyan Sun,Sam Kwong*

Main category: cs.CV

TL;DR: 提出首个基于Mamba的水下实例分割模型UIS-Mamba，通过动态树扫描（DTS）和隐藏状态弱化（HSW）模块解决水下场景的特殊挑战，实现高性能。


<details>
  <summary>Details</summary>
Motivation: 水下实例分割任务因水下场景的特殊性（如颜色失真和边界模糊）面临挑战，现有固定补丁扫描机制无法保持实例连续性。

Method: 设计DTS模块动态调整补丁偏移和缩放，保持实例内部特征连续性；HSW模块通过Ncut机制弱化背景干扰，聚焦实例信息流。

Result: 在UIIS和USIS10K数据集上达到最优性能，同时保持低参数和计算复杂度。

Conclusion: UIS-Mamba成功将Mamba迁移至水下任务，为水下实例分割提供了高效解决方案。

Abstract: Underwater Instance Segmentation (UIS) tasks are crucial for underwater
complex scene detection. Mamba, as an emerging state space model with
inherently linear complexity and global receptive fields, is highly suitable
for processing image segmentation tasks with long sequence features. However,
due to the particularity of underwater scenes, there are many challenges in
applying Mamba to UIS. The existing fixed-patch scanning mechanism cannot
maintain the internal continuity of scanned instances in the presence of
severely underwater color distortion and blurred instance boundaries, and the
hidden state of the complex underwater background can also inhibit the
understanding of instance objects. In this work, we propose the first
Mamba-based underwater instance segmentation model UIS-Mamba, and design two
innovative modules, Dynamic Tree Scan (DTS) and Hidden State Weaken (HSW), to
migrate Mamba to the underwater task. DTS module maintains the continuity of
the internal features of the instance objects by allowing the patches to
dynamically offset and scale, thereby guiding the minimum spanning tree and
providing dynamic local receptive fields. HSW module suppresses the
interference of complex backgrounds and effectively focuses the information
flow of state propagation to the instances themselves through the Ncut-based
hidden state weakening mechanism. Experimental results show that UIS-Mamba
achieves state-of-the-art performance on both UIIS and USIS10K datasets, while
maintaining a low number of parameters and computational complexity. Code is
available at https://github.com/Maricalce/UIS-Mamba.

</details>


### [46] [Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional Inpainting](https://arxiv.org/abs/2508.00427)
*Seunggeun Chi,Enna Sachdeva,Pin-Hao Huang,Kwonjoon Lee*

Main category: cs.CV

TL;DR: 提出了一种结合物理先验知识和多区域修复技术的新方法，用于动态场景中的遮挡物体补全，显著提升了人机交互场景下的补全效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态场景中因对人机交互理解有限而难以生成合理的补全结果。

Method: 利用人类拓扑和接触信息的物理约束，定义主次区域，并在扩散模型中采用定制化的去噪策略。

Result: 实验表明，该方法在人机交互场景中显著优于现有方法，且无需真实接触标注仍具鲁棒性。

Conclusion: 该方法提升了动态环境中机器感知的准确性，适用于3D重建和新视角合成等任务。

Abstract: Amodal completion, which is the process of inferring the full appearance of
objects despite partial occlusions, is crucial for understanding complex
human-object interactions (HOI) in computer vision and robotics. Existing
methods, such as those that use pre-trained diffusion models, often struggle to
generate plausible completions in dynamic scenarios because they have a limited
understanding of HOI. To solve this problem, we've developed a new approach
that uses physical prior knowledge along with a specialized multi-regional
inpainting technique designed for HOI. By incorporating physical constraints
from human topology and contact information, we define two distinct regions:
the primary region, where occluded object parts are most likely to be, and the
secondary region, where occlusions are less probable. Our multi-regional
inpainting method uses customized denoising strategies across these regions
within a diffusion model. This improves the accuracy and realism of the
generated completions in both their shape and visual detail. Our experimental
results show that our approach significantly outperforms existing methods in
HOI scenarios, moving machine perception closer to a more human-like
understanding of dynamic environments. We also show that our pipeline is robust
even without ground-truth contact annotations, which broadens its applicability
to tasks like 3D reconstruction and novel view/pose synthesis.

</details>


### [47] [Reducing the gap between general purpose data and aerial images in concentrated solar power plants](https://arxiv.org/abs/2508.00440)
*M. A. Pérez-Cutiño,J. Valverde,J. Capitán,J. M. Díaz-Báñez*

Main category: cs.CV

TL;DR: 论文提出AerialCSP，一种模拟CSP工厂航拍图像的虚拟数据集，以减少实际数据标注需求并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: CSP工厂的航拍图像具有高反射性和特定领域元素，通用数据集训练的模型难以泛化，而实际数据标注成本高。

Method: 创建AerialCSP虚拟数据集，模拟真实CSP工厂图像，用于模型预训练。

Result: AerialCSP显著提升实际缺陷检测性能，尤其是对小而罕见缺陷的检测。

Conclusion: AerialCSP为CSP相关视觉任务提供了高质量合成数据，减少了对实际标注数据的依赖。

Abstract: In the context of Concentrated Solar Power (CSP) plants, aerial images
captured by drones present a unique set of challenges. Unlike urban or natural
landscapes commonly found in existing datasets, solar fields contain highly
reflective surfaces, and domain-specific elements that are uncommon in
traditional computer vision benchmarks. As a result, machine learning models
trained on generic datasets struggle to generalize to this setting without
extensive retraining and large volumes of annotated data. However, collecting
and labeling such data is costly and time-consuming, making it impractical for
rapid deployment in industrial applications.
  To address this issue, we propose a novel approach: the creation of
AerialCSP, a virtual dataset that simulates aerial imagery of CSP plants. By
generating synthetic data that closely mimic real-world conditions, our
objective is to facilitate pretraining of models before deployment,
significantly reducing the need for extensive manual labeling. Our main
contributions are threefold: (1) we introduce AerialCSP, a high-quality
synthetic dataset for aerial inspection of CSP plants, providing annotated data
for object detection and image segmentation; (2) we benchmark multiple models
on AerialCSP, establishing a baseline for CSP-related vision tasks; and (3) we
demonstrate that pretraining on AerialCSP significantly improves real-world
fault detection, particularly for rare and small defects, reducing the need for
extensive manual labeling. AerialCSP is made publicly available at
https://mpcutino.github.io/aerialcsp/.

</details>


### [48] [TopoTTA: Topology-Enhanced Test-Time Adaptation for Tubular Structure Segmentation](https://arxiv.org/abs/2508.00442)
*Jiale Zhou,Wenhan Wang,Shikun Li,Xiaolei Qu,Xin Guo,Yizhong Liu,Wenzhong Tang,Xun Lin,Yefeng Zheng*

Main category: cs.CV

TL;DR: 论文提出了一种针对管状结构分割（TSS）的测试时适应框架TopoTTA，通过两阶段方法解决域偏移问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 管状结构分割对域偏移特别敏感，传统方法在未见目标域中性能下降明显，因此需要专门的方法来应对拓扑结构变化和局部特征差异。

Method: TopoTTA分为两阶段：第一阶段使用TopoMDCs适应跨域拓扑差异；第二阶段通过TopoHG生成硬样本并利用伪标签优化拓扑连续性。

Result: 在四个场景和十个数据集上的实验表明，TopoTTA平均提升了31.81%的clDice分数，且可作为CNN-based TSS模型的即插即用方案。

Conclusion: TopoTTA有效解决了TSS中的域偏移问题，显著提升了分割性能，具有广泛的应用潜力。

Abstract: Tubular structure segmentation (TSS) is important for various applications,
such as hemodynamic analysis and route navigation. Despite significant progress
in TSS, domain shifts remain a major challenge, leading to performance
degradation in unseen target domains. Unlike other segmentation tasks, TSS is
more sensitive to domain shifts, as changes in topological structures can
compromise segmentation integrity, and variations in local features
distinguishing foreground from background (e.g., texture and contrast) may
further disrupt topological continuity. To address these challenges, we propose
Topology-enhanced Test-Time Adaptation (TopoTTA), the first test-time
adaptation framework designed specifically for TSS. TopoTTA consists of two
stages: Stage 1 adapts models to cross-domain topological discrepancies using
the proposed Topological Meta Difference Convolutions (TopoMDCs), which enhance
topological representation without altering pre-trained parameters; Stage 2
improves topological continuity by a novel Topology Hard sample Generation
(TopoHG) strategy and prediction alignment on hard samples with pseudo-labels
in the generated pseudo-break regions. Extensive experiments across four
scenarios and ten datasets demonstrate TopoTTA's effectiveness in handling
topological distribution shifts, achieving an average improvement of 31.81% in
clDice. TopoTTA also serves as a plug-and-play TTA solution for CNN-based TSS
models.

</details>


### [49] [SDMatte: Grafting Diffusion Models for Interactive Matting](https://arxiv.org/abs/2508.00443)
*Longfei Huang,Yu Liang,Hao Zhang,Jinwei Chen,Wei Dong,Lunde Chen,Wanyu Liu,Bo Li,Pengtao Jiang*

Main category: cs.CV

TL;DR: SDMatte是一种基于扩散模型的交互式抠图方法，通过视觉提示驱动交互，结合坐标嵌入和掩码自注意力机制，显著提升了边缘细节的提取能力。


<details>
  <summary>Details</summary>
Motivation: 现有交互式抠图方法在边缘细节提取上表现不足，而扩散模型因其强大的数据分布建模和纹理细节合成能力，成为解决这一问题的理想选择。

Method: 提出SDMatte模型，利用扩散模型的先验知识，将文本驱动交互能力转化为视觉提示驱动交互能力，并引入坐标嵌入和掩码自注意力机制。

Result: 在多个数据集上的实验表明，SDMatte在交互式抠图中表现出色，尤其是在边缘细节提取上。

Conclusion: SDMatte通过扩散模型和视觉提示驱动的交互能力，显著提升了交互式抠图的性能，为精细边缘处理提供了有效解决方案。

Abstract: Recent interactive matting methods have shown satisfactory performance in
capturing the primary regions of objects, but they fall short in extracting
fine-grained details in edge regions. Diffusion models trained on billions of
image-text pairs, demonstrate exceptional capability in modeling highly complex
data distributions and synthesizing realistic texture details, while exhibiting
robust text-driven interaction capabilities, making them an attractive solution
for interactive matting. To this end, we propose SDMatte, a diffusion-driven
interactive matting model, with three key contributions. First, we exploit the
powerful priors of diffusion models and transform the text-driven interaction
capability into visual prompt-driven interaction capability to enable
interactive matting. Second, we integrate coordinate embeddings of visual
prompts and opacity embeddings of target objects into U-Net, enhancing
SDMatte's sensitivity to spatial position information and opacity information.
Third, we propose a masked self-attention mechanism that enables the model to
focus on areas specified by visual prompts, leading to better performance.
Extensive experiments on multiple datasets demonstrate the superior performance
of our method, validating its effectiveness in interactive matting. Our code
and model are available at https://github.com/vivoCameraResearch/SDMatte.

</details>


### [50] [AutoDebias: Automated Framework for Debiasing Text-to-Image Models](https://arxiv.org/abs/2508.00445)
*Hongyi Cai,Mohammad Mahdinur Rahman,Mingkang Dong,Jie Li,Muxin Pu,Zhili Fang,Yinan Peng,Hanjun Luo,Yang Liu*

Main category: cs.CV

TL;DR: AutoDebias是一个自动识别并减轻文本到图像（T2I）模型中有害偏见的框架，无需预先了解具体偏见类型。


<details>
  <summary>Details</summary>
Motivation: T2I模型在生成高质量图像时常常表现出未提及的社会偏见（如性别或种族刻板印象），现有方法难以处理复杂或重叠的偏见。

Method: AutoDebias利用视觉语言模型检测偏见模式，并通过生成包容性替代提示构建公平指南，驱动CLIP引导的训练过程。

Result: 在覆盖25种以上偏见场景的基准测试中，AutoDebias以91.6%的准确率检测有害模式，将偏见输出从90%降至可忽略水平，同时保持图像质量。

Conclusion: AutoDebias能有效处理复杂和重叠的偏见，同时保持模型的图像质量和多样性。

Abstract: Text-to-Image (T2I) models generate high-quality images from text prompts but
often exhibit unintended social biases, such as gender or racial stereotypes,
even when these attributes are not mentioned. Existing debiasing methods work
well for simple or well-known cases but struggle with subtle or overlapping
biases. We propose AutoDebias, a framework that automatically identifies and
mitigates harmful biases in T2I models without prior knowledge of specific bias
types. Specifically, AutoDebias leverages vision-language models to detect
biased visual patterns and constructs fairness guides by generating inclusive
alternative prompts that reflect balanced representations. These guides drive a
CLIP-guided training process that promotes fairer outputs while preserving the
original model's image quality and diversity. Unlike existing methods,
AutoDebias effectively addresses both subtle stereotypes and multiple
interacting biases. We evaluate the framework on a benchmark covering over 25
bias scenarios, including challenging cases where multiple biases occur
simultaneously. AutoDebias detects harmful patterns with 91.6% accuracy and
reduces biased outputs from 90% to negligible levels, while preserving the
visual fidelity of the original model.

</details>


### [51] [CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text](https://arxiv.org/abs/2508.00447)
*Anju Rani,Daniel Ortiz-Arroyo,Petar Durdevic*

Main category: cs.CV

TL;DR: CLIPTime是一个基于CLIP架构的多模态多任务框架，旨在通过图像和文本输入预测真菌生长的发育阶段和时间戳，无需显式时间输入。


<details>
  <summary>Details</summary>
Motivation: 理解生物生长的时间动态在微生物学、农业和生物降解研究中至关重要，但现有视觉语言模型在捕捉时间进展方面效果有限。

Method: CLIPTime基于CLIP架构，学习联合视觉-文本嵌入，支持时间感知推理，并引入合成真菌生长数据集进行训练和评估。

Result: 实验表明，CLIPTime能有效建模生物进展，并生成可解释的时间相关输出。

Conclusion: CLIPTime展示了视觉语言模型在现实生物监测应用中的潜力。

Abstract: Understanding the temporal dynamics of biological growth is critical across
diverse fields such as microbiology, agriculture, and biodegradation research.
Although vision-language models like Contrastive Language Image Pretraining
(CLIP) have shown strong capabilities in joint visual-textual reasoning, their
effectiveness in capturing temporal progression remains limited. To address
this, we propose CLIPTime, a multimodal, multitask framework designed to
predict both the developmental stage and the corresponding timestamp of fungal
growth from image and text inputs. Built upon the CLIP architecture, our model
learns joint visual-textual embeddings and enables time-aware inference without
requiring explicit temporal input during testing. To facilitate training and
evaluation, we introduce a synthetic fungal growth dataset annotated with
aligned timestamps and categorical stage labels. CLIPTime jointly performs
classification and regression, predicting discrete growth stages alongside
continuous timestamps. We also propose custom evaluation metrics, including
temporal accuracy and regression error, to assess the precision of time-aware
predictions. Experimental results demonstrate that CLIPTime effectively models
biological progression and produces interpretable, temporally grounded outputs,
highlighting the potential of vision-language models in real-world biological
monitoring applications.

</details>


### [52] [PIF-Net: Ill-Posed Prior Guided Multispectral and Hyperspectral Image Fusion via Invertible Mamba and Fusion-Aware LoRA](https://arxiv.org/abs/2508.00453)
*Baisong Li,Xingwang Wang,Haixiao Xu*

Main category: cs.CV

TL;DR: PIF-Net提出了一种融合多光谱和高光谱图像的框架，通过引入病态先验和可逆Mamba架构，平衡光谱建模与计算效率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多光谱和高光谱图像融合（MHIF）任务由于光谱与空间信息的固有权衡和数据不对齐问题，具有病态性，现有方法未能有效解决。

Method: 提出PIF-Net框架，结合病态先验和可逆Mamba架构，设计Fusion-Aware Low-Rank Adaptation模块动态校准特征。

Result: 在多个基准数据集上，PIF-Net显著优于当前最优方法，同时保持模型高效性。

Conclusion: PIF-Net通过创新架构和模块设计，有效解决了MHIF的病态性问题，提升了图像恢复性能。

Abstract: The goal of multispectral and hyperspectral image fusion (MHIF) is to
generate high-quality images that simultaneously possess rich spectral
information and fine spatial details. However, due to the inherent trade-off
between spectral and spatial information and the limited availability of
observations, this task is fundamentally ill-posed. Previous studies have not
effectively addressed the ill-posed nature caused by data misalignment. To
tackle this challenge, we propose a fusion framework named PIF-Net, which
explicitly incorporates ill-posed priors to effectively fuse multispectral
images and hyperspectral images. To balance global spectral modeling with
computational efficiency, we design a method based on an invertible Mamba
architecture that maintains information consistency during feature
transformation and fusion, ensuring stable gradient flow and process
reversibility. Furthermore, we introduce a novel fusion module called the
Fusion-Aware Low-Rank Adaptation module, which dynamically calibrates spectral
and spatial features while keeping the model lightweight. Extensive experiments
on multiple benchmark datasets demonstrate that PIF-Net achieves significantly
better image restoration performance than current state-of-the-art methods
while maintaining model efficiency.

</details>


### [53] [Semantic and Temporal Integration in Latent Diffusion Space for High-Fidelity Video Super-Resolution](https://arxiv.org/abs/2508.00471)
*Yiwen Wang,Xinning Chai,Yuhong Zhang,Zhengxue Cheng,Jun Zhao,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: SeTe-VSR是一种结合语义和时间指导的视频超分辨率方法，通过潜在扩散空间实现高保真对齐和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频超分辨率模型在控制生成过程和保持时间一致性方面存在挑战。

Method: 提出SeTe-VSR方法，结合高级语义信息和时空指导，在潜在扩散空间中平衡细节恢复和时间一致性。

Result: 实验表明，SeTe-VSR在细节恢复和感知质量上优于现有方法。

Conclusion: SeTe-VSR有效解决了复杂视频超分辨率任务中的挑战。

Abstract: Recent advancements in video super-resolution (VSR) models have demonstrated
impressive results in enhancing low-resolution videos. However, due to
limitations in adequately controlling the generation process, achieving high
fidelity alignment with the low-resolution input while maintaining temporal
consistency across frames remains a significant challenge. In this work, we
propose Semantic and Temporal Guided Video Super-Resolution (SeTe-VSR), a novel
approach that incorporates both semantic and temporal-spatio guidance in the
latent diffusion space to address these challenges. By incorporating high-level
semantic information and integrating spatial and temporal information, our
approach achieves a seamless balance between recovering intricate details and
ensuring temporal coherence. Our method not only preserves high-reality visual
content but also significantly enhances fidelity. Extensive experiments
demonstrate that SeTe-VSR outperforms existing methods in terms of detail
recovery and perceptual quality, highlighting its effectiveness for complex
video super-resolution tasks.

</details>


### [54] [Fine-grained Spatiotemporal Grounding on Egocentric Videos](https://arxiv.org/abs/2508.00518)
*Shuo Liang,Yiwu Zhong,Zi-Yuan Hu,Yeyao Tao,Liwei Wang*

Main category: cs.CV

TL;DR: 论文提出了EgoMask，首个用于自我中心视频的像素级时空定位基准，揭示了自我中心与外部中心视频的关键差异，并提供了大规模训练数据集EgoMask-Train。


<details>
  <summary>Details</summary>
Motivation: 自我中心视频在增强现实和机器人等应用中日益重要，但相关研究较少，现有方法在此类视频中表现不佳。

Method: 通过自动标注管道构建EgoMask基准，并创建EgoMask-Train训练数据集，用于模型开发和评估。

Result: 实验表明，现有先进模型在EgoMask上表现不佳，但在EgoMask-Train上微调后性能显著提升。

Conclusion: 研究为自我中心视频理解提供了关键资源和见解，推动了该领域的发展。

Abstract: Spatiotemporal video grounding aims to localize target entities in videos
based on textual queries. While existing research has made significant progress
in exocentric videos, the egocentric setting remains relatively underexplored,
despite its growing importance in applications such as augmented reality and
robotics. In this work, we conduct a systematic analysis of the discrepancies
between egocentric and exocentric videos, revealing key challenges such as
shorter object durations, sparser trajectories, smaller object sizes, and
larger positional shifts. To address these challenges, we introduce EgoMask,
the first pixel-level benchmark for fine-grained spatiotemporal grounding in
egocentric videos. It is constructed by our proposed automatic annotation
pipeline, which annotates referring expressions and object masks across short-,
medium-, and long-term videos. Additionally, we create EgoMask-Train, a
large-scale training dataset to facilitate model development. Experiments
demonstrate that the state-of-the-art spatiotemporal grounding models perform
poorly on our benchmark EgoMask, but fine-tuning on EgoMask-Train yields
significant improvements, while preserving performance on exocentric datasets.
Our work thus provides essential resources and insights for advancing
egocentric video understanding. Our code is available at
https://github.com/LaVi-Lab/EgoMask .

</details>


### [55] [HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection](https://arxiv.org/abs/2508.00473)
*Jiaping Cao,Kangkang Zhou,Juan Du*

Main category: cs.CV

TL;DR: 提出了一种名为HyPCV-Former的双曲时空变换器，用于3D点云视频中的异常检测，通过双曲空间建模事件的分层结构和时空连续性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在RGB或深度域中使用欧几里得表示，难以捕捉事件的分层结构和时空连续性，因此提出双曲空间建模以解决这一问题。

Method: 首先从点云序列中提取每帧空间特征，并将其嵌入到洛伦兹双曲空间；随后通过双曲多头自注意力机制（HMHA）建模时间动态，直接在双曲空间中进行特征变换和异常评分。

Result: 在多个异常类别上实现了最先进的性能，TIMo数据集上提升7%，DAD数据集上提升5.6%。

Conclusion: HyPCV-Former通过双曲空间建模显著提升了异常检测性能，为视频监控领域提供了新的解决方案。

Abstract: Video anomaly detection is a fundamental task in video surveillance, with
broad applications in public safety and intelligent monitoring systems.
Although previous methods leverage Euclidean representations in RGB or depth
domains, such embeddings are inherently limited in capturing hierarchical event
structures and spatio-temporal continuity. To address these limitations, we
propose HyPCV-Former, a novel hyperbolic spatio-temporal transformer for
anomaly detection in 3D point cloud videos. Our approach first extracts
per-frame spatial features from point cloud sequences via point cloud
extractor, and then embeds them into Lorentzian hyperbolic space, which better
captures the latent hierarchical structure of events. To model temporal
dynamics, we introduce a hyperbolic multi-head self-attention (HMHA) mechanism
that leverages Lorentzian inner products and curvature-aware softmax to learn
temporal dependencies under non-Euclidean geometry. Our method performs all
feature transformations and anomaly scoring directly within full Lorentzian
space rather than via tangent space approximation. Extensive experiments
demonstrate that HyPCV-Former achieves state-of-the-art performance across
multiple anomaly categories, with a 7\% improvement on the TIMo dataset and a
5.6\% gain on the DAD dataset compared to benchmarks. The code will be released
upon paper acceptance.

</details>


### [56] [LesiOnTime -- Joint Temporal and Clinical Modeling for Small Breast Lesion Segmentation in Longitudinal DCE-MRI](https://arxiv.org/abs/2508.00496)
*Mohammed Kamran,Maria Bernathova,Raoul Varga,Christian Singer,Zsuzsanna Bago-Horvath,Thomas Helbich,Georg Langs,Philipp Seeböck*

Main category: cs.CV

TL;DR: LesiOnTime是一种新的3D分割方法，结合纵向影像和BI-RADS评分，显著提升了小病灶分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法主要针对大病灶，忽略了纵向和临床信息，而早期癌症检测需要这些信息。

Method: 提出Temporal Prior Attention (TPA)块和BI-RADS Consistency Regularization (BCR)损失函数，整合纵向数据和临床评分。

Result: 在DCE-MRI数据集上，Dice分数比现有方法高5%，TPA和BCR均贡献显著。

Conclusion: 结合时间和临床背景对乳腺癌筛查中的早期病灶分割至关重要。

Abstract: Accurate segmentation of small lesions in Breast Dynamic Contrast-Enhanced
MRI (DCE-MRI) is critical for early cancer detection, especially in high-risk
patients. While recent deep learning methods have advanced lesion segmentation,
they primarily target large lesions and neglect valuable longitudinal and
clinical information routinely used by radiologists. In real-world screening,
detecting subtle or emerging lesions requires radiologists to compare across
timepoints and consider previous radiology assessments, such as the BI-RADS
score. We propose LesiOnTime, a novel 3D segmentation approach that mimics
clinical diagnostic workflows by jointly leveraging longitudinal imaging and
BIRADS scores. The key components are: (1) a Temporal Prior Attention (TPA)
block that dynamically integrates information from previous and current scans;
and (2) a BI-RADS Consistency Regularization (BCR) loss that enforces latent
space alignment for scans with similar radiological assessments, thus embedding
domain knowledge into the training process. Evaluated on a curated in-house
longitudinal dataset of high-risk patients with DCE-MRI, our approach
outperforms state-of-the-art single-timepoint and longitudinal baselines by 5%
in terms of Dice. Ablation studies demonstrate that both TPA and BCR contribute
complementary performance gains. These results highlight the importance of
incorporating temporal and clinical context for reliable early lesion
segmentation in real-world breast cancer screening. Our code is publicly
available at https://github.com/cirmuw/LesiOnTime

</details>


### [57] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
*Stefan Englmeier,Max A. Büttner,Katharina Winter,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 提出了一种基于多模态嵌入空间的新型上下文感知运动检索框架，用于从大规模数据集中高效检索罕见的人类行为场景，以支持自动驾驶系统的评估。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需在涉及易受伤害道路使用者（VRUs）的复杂行为场景中可靠运行，但现有数据集中这些罕见行为难以检索。

Method: 结合SMPL运动序列和视频帧，编码到与自然语言对齐的多模态嵌入空间，支持文本查询检索。

Result: 在WayMoCo数据集上，方法在运动-上下文检索任务中优于现有技术27.5%。

Conclusion: 该方法为自动驾驶系统提供了高效的人类行为场景检索工具，显著提升了检索精度。

Abstract: Autonomous driving systems must operate reliably in safety-critical
scenarios, particularly those involving unusual or complex behavior by
Vulnerable Road Users (VRUs). Identifying these edge cases in driving datasets
is essential for robust evaluation and generalization, but retrieving such rare
human behavior scenarios within the long tail of large-scale datasets is
challenging. To support targeted evaluation of autonomous driving systems in
diverse, human-centered scenarios, we propose a novel context-aware motion
retrieval framework. Our method combines Skinned Multi-Person Linear
(SMPL)-based motion sequences and corresponding video frames before encoding
them into a shared multimodal embedding space aligned with natural language.
Our approach enables the scalable retrieval of human behavior and their context
through text queries. This work also introduces our dataset WayMoCo, an
extension of the Waymo Open Dataset. It contains automatically labeled motion
and scene context descriptions derived from generated pseudo-ground-truth SMPL
sequences and corresponding image data. Our approach outperforms
state-of-the-art models by up to 27.5% accuracy in motion-context retrieval,
when evaluated on the WayMoCo dataset.

</details>


### [58] [LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer](https://arxiv.org/abs/2508.00477)
*Yuzhuo Chen,Zehua Ma,Jianhua Wang,Kai Kang,Shunyu Yao,Weiming Zhang*

Main category: cs.CV

TL;DR: LAMIC是一个无需训练的布局感知多图像合成框架，通过两种注意力机制实现多参考场景下的图像生成，并在多个指标上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决多参考图像合成中布局一致性和背景一致性的挑战。

Method: 基于MMDiT模型，引入Group Isolation Attention (GIA)和Region-Modulated Attention (RMA)两种注意力机制。

Result: 在ID-S、BG-S、IN-R和AVG等指标上优于现有方法，展示了零样本泛化能力。

Conclusion: LAMIC为可控多图像合成提供了新的无需训练范式，具有强大的泛化能力。

Abstract: In controllable image synthesis, generating coherent and consistent images
from multiple references with spatial layout awareness remains an open
challenge. We present LAMIC, a Layout-Aware Multi-Image Composition framework
that, for the first time, extends single-reference diffusion models to
multi-reference scenarios in a training-free manner. Built upon the MMDiT
model, LAMIC introduces two plug-and-play attention mechanisms: 1) Group
Isolation Attention (GIA) to enhance entity disentanglement; and 2)
Region-Modulated Attention (RMA) to enable layout-aware generation. To
comprehensively evaluate model capabilities, we further introduce three
metrics: 1) Inclusion Ratio (IN-R) and Fill Ratio (FI-R) for assessing layout
control; and 2) Background Similarity (BG-S) for measuring background
consistency. Extensive experiments show that LAMIC achieves state-of-the-art
performance across most major metrics: it consistently outperforms existing
multi-reference baselines in ID-S, BG-S, IN-R and AVG scores across all
settings, and achieves the best DPG in complex composition tasks. These results
demonstrate LAMIC's superior abilities in identity keeping, background
preservation, layout control, and prompt-following, all achieved without any
training or fine-tuning, showcasing strong zero-shot generalization ability. By
inheriting the strengths of advanced single-reference models and enabling
seamless extension to multi-image scenarios, LAMIC establishes a new
training-free paradigm for controllable multi-image composition. As foundation
models continue to evolve, LAMIC's performance is expected to scale
accordingly. Our implementation is available at:
https://github.com/Suchenl/LAMIC.

</details>


### [59] [SAMSA 2.0: Prompting Segment Anything with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2508.00493)
*Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou*

Main category: cs.CV

TL;DR: SAMSA 2.0是一种用于高光谱医学图像的交互式分割框架，通过引入光谱角度提示，结合空间线索指导Segment Anything Model（SAM），提升了分割的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决高光谱医学图像分割中光谱信息利用不足的问题，提升在低数据和噪声场景下的性能。

Method: 采用光谱角度提示，将光谱信息与空间线索早期融合，无需重新训练即可优化SAM模型。

Result: 相比仅使用RGB的模型，Dice分数提升高达3.8%；优于先前的光谱融合方法3.1%。

Conclusion: SAMSA 2.0在少样本和零样本任务中表现优异，适用于临床影像中的复杂场景。

Abstract: We present SAMSA 2.0, an interactive segmentation framework for hyperspectral
medical imaging that introduces spectral angle prompting to guide the Segment
Anything Model (SAM) using spectral similarity alongside spatial cues. This
early fusion of spectral information enables more accurate and robust
segmentation across diverse spectral datasets. Without retraining, SAMSA 2.0
achieves up to +3.8% higher Dice scores compared to RGB-only models and up to
+3.1% over prior spectral fusion methods. Our approach enhances few-shot and
zero-shot performance, demonstrating strong generalization in challenging
low-data and noisy scenarios common in clinical imaging.

</details>


### [60] [Wukong Framework for Not Safe For Work Detection in Text-to-Image systems](https://arxiv.org/abs/2508.00591)
*Mingrui Liu,Sixiao Zhang,Cheng Long*

Main category: cs.CV

TL;DR: Wukong是一个基于Transformer的NSFW检测框架，利用扩散模型的早期去噪步骤和预训练参数，实现高效且准确的检测。


<details>
  <summary>Details</summary>
Motivation: 现有外部保护措施（文本过滤和图像过滤）存在效率低或易受攻击的问题，需要一种更高效且准确的NSFW内容检测方法。

Method: 利用扩散模型的早期去噪步骤和预训练交叉注意力参数，提出Wukong框架，在生成过程中进行早期检测。

Result: Wukong在效率和准确性上显著优于文本过滤器，与图像过滤器相当。

Conclusion: Wukong提供了一种高效且准确的NSFW内容检测方法，适用于现代T2I系统。

Abstract: Text-to-Image (T2I) generation is a popular AI-generated content (AIGC)
technology enabling diverse and creative image synthesis. However, some outputs
may contain Not Safe For Work (NSFW) content (e.g., violence), violating
community guidelines. Detecting NSFW content efficiently and accurately, known
as external safeguarding, is essential. Existing external safeguards fall into
two types: text filters, which analyze user prompts but overlook T2I
model-specific variations and are prone to adversarial attacks; and image
filters, which analyze final generated images but are computationally costly
and introduce latency. Diffusion models, the foundation of modern T2I systems
like Stable Diffusion, generate images through iterative denoising using a
U-Net architecture with ResNet and Transformer blocks. We observe that: (1)
early denoising steps define the semantic layout of the image, and (2)
cross-attention layers in U-Net are crucial for aligning text and image
regions. Based on these insights, we propose Wukong, a transformer-based NSFW
detection framework that leverages intermediate outputs from early denoising
steps and reuses U-Net's pre-trained cross-attention parameters. Wukong
operates within the diffusion process, enabling early detection without waiting
for full image generation. We also introduce a new dataset containing prompts,
seeds, and image-specific NSFW labels, and evaluate Wukong on this and two
public benchmarks. Results show that Wukong significantly outperforms
text-based safeguards and achieves comparable accuracy of image filters, while
offering much greater efficiency.

</details>


### [61] [Leveraging Convolutional and Graph Networks for an Unsupervised Remote Sensing Labelling Tool](https://arxiv.org/abs/2508.00506)
*Tulsi Patel,Mark W. Jones,Thomas Redfern*

Main category: cs.CV

TL;DR: 提出了一种无监督的遥感图像标注方法，结合卷积和图神经网络，提高了标注的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 遥感图像标注耗时且昂贵，现有方法依赖预标注数据，限制了其应用。

Method: 利用卷积和图神经网络进行图像分割，生成更鲁棒的特征空间，实现像素级的相似性分组。

Result: 减少了标注中的异常值，支持细粒度标注，并实现了旋转不变的语义关系。

Conclusion: 该方法克服了现有方法的局限性，为遥感图像标注提供了更高效和准确的解决方案。

Abstract: Machine learning for remote sensing imaging relies on up-to-date and accurate
labels for model training and testing. Labelling remote sensing imagery is time
and cost intensive, requiring expert analysis. Previous labelling tools rely on
pre-labelled data for training in order to label new unseen data. In this work,
we define an unsupervised pipeline for finding and labelling geographical areas
of similar context and content within Sentinel-2 satellite imagery. Our
approach removes limitations of previous methods by utilising segmentation with
convolutional and graph neural networks to encode a more robust feature space
for image comparison. Unlike previous approaches we segment the image into
homogeneous regions of pixels that are grouped based on colour and spatial
similarity. Graph neural networks are used to aggregate information about the
surrounding segments enabling the feature representation to encode the local
neighbourhood whilst preserving its own local information. This reduces
outliers in the labelling tool, allows users to label at a granular level, and
allows a rotationally invariant semantic relationship at the image level to be
formed within the encoding space.

</details>


### [62] [EPANet: Efficient Path Aggregation Network for Underwater Fish Detection](https://arxiv.org/abs/2508.00528)
*Jinsong Yang,Zeyuan Hu,Yichen Li*

Main category: cs.CV

TL;DR: EPANet是一种高效的水下鱼类检测网络，通过互补特征集成实现轻量化和高精度。


<details>
  <summary>Details</summary>
Motivation: 水下鱼类检测面临低分辨率、背景干扰和目标与周围环境高度相似等挑战，现有方法通常增加模型复杂度或牺牲效率。

Method: EPANet包含EPA-FPN和MS-DDSP瓶颈模块，前者通过长距离跳跃连接提升特征互补性，后者通过细粒度特征划分增强局部多样性。

Result: 在基准数据集上，EPANet在检测精度和推理速度上优于现有方法，同时保持较低的参数复杂度。

Conclusion: EPANet为水下鱼类检测提供了一种高效且轻量化的解决方案。

Abstract: Underwater fish detection (UFD) remains a challenging task in computer vision
due to low object resolution, significant background interference, and high
visual similarity between targets and surroundings. Existing approaches
primarily focus on local feature enhancement or incorporate complex attention
mechanisms to highlight small objects, often at the cost of increased model
complexity and reduced efficiency. To address these limitations, we propose an
efficient path aggregation network (EPANet), which leverages complementary
feature integration to achieve accurate and lightweight UFD. EPANet consists of
two key components: an efficient path aggregation feature pyramid network
(EPA-FPN) and a multi-scale diverse-division short path bottleneck (MS-DDSP
bottleneck). The EPA-FPN introduces long-range skip connections across
disparate scales to improve semantic-spatial complementarity, while cross-layer
fusion paths are adopted to enhance feature integration efficiency. The MS-DDSP
bottleneck extends the conventional bottleneck structure by introducing
finer-grained feature division and diverse convolutional operations, thereby
increasing local feature diversity and representation capacity. Extensive
experiments on benchmark UFD datasets demonstrate that EPANet outperforms
state-of-the-art methods in terms of detection accuracy and inference speed,
while maintaining comparable or even lower parameter complexity.

</details>


### [63] [Backdoor Attacks on Deep Learning Face Detection](https://arxiv.org/abs/2508.00620)
*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi*

Main category: cs.CV

TL;DR: 论文研究了针对人脸检测系统的攻击方法，包括Face Generation Attacks和Landmark Shift Attack，并提出了防御措施。


<details>
  <summary>Details</summary>
Motivation: 在非受控环境下，人脸检测系统面临光照和姿态变化等挑战，需要精准的边界框和关键点回归。然而，这些任务可能受到攻击。

Method: 提出了Face Generation Attacks和Landmark Shift Attack，通过干扰边界框和关键点回归任务来攻击人脸检测系统。

Result: 首次展示了Landmark Shift Attack的有效性，成功干扰了人脸检测器的坐标回归任务。

Conclusion: 论文揭示了人脸检测系统的潜在漏洞，并提出了相应的防御措施。

Abstract: Face Recognition Systems that operate in unconstrained environments capture
images under varying conditions,such as inconsistent lighting, or diverse face
poses. These challenges require including a Face Detection module that
regresses bounding boxes and landmark coordinates for proper Face Alignment.
This paper shows the effectiveness of Object Generation Attacks on Face
Detection, dubbed Face Generation Attacks, and demonstrates for the first time
a Landmark Shift Attack that backdoors the coordinate regression task performed
by face detectors. We then offer mitigations against these vulnerabilities.

</details>


### [64] [Video Color Grading via Look-Up Table Generation](https://arxiv.org/abs/2508.00548)
*Seunghyun Shin,Dongmin Shin,Jisu Shin,Hae-Gon Jeon,Joon-Young Lee*

Main category: cs.CV

TL;DR: 提出了一种基于参考的视频色彩分级框架，利用扩散模型生成查找表（LUT）进行色彩属性对齐，支持用户通过文本提示调整低层特征。


<details>
  <summary>Details</summary>
Motivation: 视频色彩分级通常需要专业技能，限制了非专业人士的使用。本文旨在简化这一过程，使其更易用且高效。

Method: 通过扩散模型生成LUT，对齐参考场景与输入视频的色彩属性，并结合用户文本提示优化低层特征。

Result: 实验和用户研究表明，该方法能有效进行视频色彩分级，且不损失结构细节。

Conclusion: 提出的框架为视频色彩分级提供了高效且用户友好的解决方案。

Abstract: Different from color correction and transfer, color grading involves
adjusting colors for artistic or storytelling purposes in a video, which is
used to establish a specific look or mood. However, due to the complexity of
the process and the need for specialized editing skills, video color grading
remains primarily the domain of professional colorists. In this paper, we
present a reference-based video color grading framework. Our key idea is
explicitly generating a look-up table (LUT) for color attribute alignment
between reference scenes and input video via a diffusion model. As a training
objective, we enforce that high-level features of the reference scenes like
look, mood, and emotion should be similar to that of the input video. Our
LUT-based approach allows for color grading without any loss of structural
details in the whole video frames as well as achieving fast inference. We
further build a pipeline to incorporate a user-preference via text prompts for
low-level feature enhancement such as contrast and brightness, etc.
Experimental results, including extensive user studies, demonstrate the
effectiveness of our approach for video color grading. Codes are publicly
available at https://github.com/seunghyuns98/VideoColorGrading.

</details>


### [65] [Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images](https://arxiv.org/abs/2508.00549)
*Daniel Wolf,Heiko Hillenhagen,Billurvan Taskin,Alex Bäuerle,Meinrad Beer,Michael Götz,Timo Ropinski*

Main category: cs.CV

TL;DR: 论文探讨了视觉语言模型（VLMs）在医学图像中精确定位解剖结构相对位置的能力，发现现有模型表现不佳，并提出视觉提示方法及新基准数据集MIRP。


<details>
  <summary>Details</summary>
Motivation: 临床决策依赖解剖结构的相对位置信息，但VLMs在此任务上的能力尚未充分研究，亟需填补这一空白。

Method: 评估了GPT-4o、Llama3.2等先进VLMs的表现，并尝试通过视觉提示（如标记物）提升性能。

Result: 所有模型在医学图像上的表现均不理想，视觉提示仅带来有限改进，且模型更依赖先验知识而非图像内容。

Conclusion: 提出MIRP数据集以推动相关研究，强调医学图像中VLMs需进一步优化定位能力。

Abstract: Clinical decision-making relies heavily on understanding relative positions
of anatomical structures and anomalies. Therefore, for Vision-Language Models
(VLMs) to be applicable in clinical practice, the ability to accurately
determine relative positions on medical images is a fundamental prerequisite.
Despite its importance, this capability remains highly underexplored. To
address this gap, we evaluate the ability of state-of-the-art VLMs, GPT-4o,
Llama3.2, Pixtral, and JanusPro, and find that all models fail at this
fundamental task. Inspired by successful approaches in computer vision, we
investigate whether visual prompts, such as alphanumeric or colored markers
placed on anatomical structures, can enhance performance. While these markers
provide moderate improvements, results remain significantly lower on medical
images compared to observations made on natural images. Our evaluations suggest
that, in medical imaging, VLMs rely more on prior anatomical knowledge than on
actual image content for answering relative position questions, often leading
to incorrect conclusions. To facilitate further research in this area, we
introduce the MIRP , Medical Imaging Relative Positioning, benchmark dataset,
designed to systematically evaluate the capability to identify relative
positions in medical images.

</details>


### [66] [DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable Adversarial Purification](https://arxiv.org/abs/2508.00552)
*Chihan Huang,Belal Alsinglawi,Islam Al-qudah*

Main category: cs.CV

TL;DR: 提出了一种名为DBLP的高效扩散对抗净化框架，通过噪声桥蒸馏和自适应语义增强，显著提升了净化效果和推理速度。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络易受对抗性扰动影响，现有扩散净化方法因迭代去噪效率低而难以实用。

Method: 采用噪声桥蒸馏目标，在潜在一致性模型中建立对抗噪声与干净数据的对齐，并结合多尺度金字塔边缘图进行语义增强。

Result: 在多个数据集上达到SOTA鲁棒精度和图像质量，推理时间约0.2秒。

Conclusion: DBLP为实时对抗净化迈出重要一步。

Abstract: Recent advances in deep neural networks (DNNs) have led to remarkable success
across a wide range of tasks. However, their susceptibility to adversarial
perturbations remains a critical vulnerability. Existing diffusion-based
adversarial purification methods often require intensive iterative denoising,
severely limiting their practical deployment. In this paper, we propose
Diffusion Bridge Distillation for Purification (DBLP), a novel and efficient
diffusion-based framework for adversarial purification. Central to our approach
is a new objective, noise bridge distillation, which constructs a principled
alignment between the adversarial noise distribution and the clean data
distribution within a latent consistency model (LCM). To further enhance
semantic fidelity, we introduce adaptive semantic enhancement, which fuses
multi-scale pyramid edge maps as conditioning input to guide the purification
process. Extensive experiments across multiple datasets demonstrate that DBLP
achieves state-of-the-art (SOTA) robust accuracy, superior image quality, and
around 0.2s inference time, marking a significant step toward real-time
adversarial purification.

</details>


### [67] [D3: Training-Free AI-Generated Video Detection Using Second-Order Features](https://arxiv.org/abs/2508.00701)
*Chende Zheng,Ruiqi suo,Chenhao Lin,Zhengyu Zhao,Le Yang,Shuai Liu,Minghui Yang,Cong Wang,Chao Shen*

Main category: cs.CV

TL;DR: 论文提出了一种基于二阶动力学分析的训练免费检测方法D3，用于识别AI生成视频中的时间伪影，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法对合成视频中时间伪影的探索不足，导致检测效果受限。

Method: 通过牛顿力学下的二阶动力学分析建立理论框架，提出基于二阶中心差分特征的D3方法。

Result: 在4个开源数据集上验证了D3的优越性，例如在Gen-Video上比之前最佳方法提高了10.39%的平均精度。

Conclusion: D3在计算效率和鲁棒性方面表现优异，为合成视频检测提供了有效解决方案。

Abstract: The evolution of video generation techniques, such as Sora, has made it
increasingly easy to produce high-fidelity AI-generated videos, raising public
concern over the dissemination of synthetic content. However, existing
detection methodologies remain limited by their insufficient exploration of
temporal artifacts in synthetic videos. To bridge this gap, we establish a
theoretical framework through second-order dynamical analysis under Newtonian
mechanics, subsequently extending the Second-order Central Difference features
tailored for temporal artifact detection. Building on this theoretical
foundation, we reveal a fundamental divergence in second-order feature
distributions between real and AI-generated videos. Concretely, we propose
Detection by Difference of Differences (D3), a novel training-free detection
method that leverages the above second-order temporal discrepancies. We
validate the superiority of our D3 on 4 open-source datasets (Gen-Video,
VideoPhy, EvalCrafter, VidProM), 40 subsets in total. For example, on GenVideo,
D3 outperforms the previous best method by 10.39% (absolute) mean Average
Precision. Additional experiments on time cost and post-processing operations
demonstrate D3's exceptional computational efficiency and strong robust
performance. Our code is available at https://github.com/Zig-HS/D3.

</details>


### [68] [HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models](https://arxiv.org/abs/2508.00553)
*Jizhihui Liu,Feiyi Du,Guangdao Zhu,Niu Lian,Jun Li,Bin Chen*

Main category: cs.CV

TL;DR: HiPrune是一种无需训练、模型无关的视觉令牌修剪框架，利用视觉编码器的分层注意力结构，显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）的视觉令牌序列过长导致计算开销大、推理效率低，现有方法依赖特殊令牌或任务特定训练，限制了可扩展性。

Method: HiPrune通过分层注意力结构选择三类信息丰富的令牌：锚点令牌（对象中心层高注意力）、缓冲令牌（空间连续性）和注册令牌（全局上下文层强注意力）。

Result: 在LLaVA-1.5等模型上，HiPrune仅用33.3%令牌保留99.3%任务准确率，11.1%令牌保留99.5%准确率，推理FLOPs和延迟降低9倍。

Conclusion: HiPrune无需训练，兼容任何ViT-based VLM，在模型和任务间表现出强泛化能力，代码已开源。

Abstract: Vision-Language Models (VLMs) encode images into lengthy sequences of visual
tokens, leading to excessive computational overhead and limited inference
efficiency. While prior efforts prune or merge tokens to address this issue,
they often rely on special tokens (e.g., CLS) or require task-specific
training, hindering scalability across architectures. In this paper, we propose
HiPrune, a training-free and model-agnostic token Pruning framework that
exploits the Hierarchical attention structure within vision encoders. We
identify that middle layers attend to object-centric regions, while deep layers
capture global contextual features. Based on this observation, HiPrune selects
three types of informative tokens: (1) Anchor tokens with high attention in
object-centric layers, (2) Buffer tokens adjacent to anchors for spatial
continuity, and (3) Register tokens with strong attention in deep layers for
global summarization. Our method requires no retraining and integrates
seamlessly with any ViT-based VLM. Extensive experiments on LLaVA-1.5,
LLaVA-NeXT, and Qwen2.5-VL demonstrate that HiPrune achieves state-of-the-art
pruning performance, preserving up to 99.3% task accuracy with only 33.3%
tokens, and maintaining 99.5% accuracy with just 11.1% tokens. Meanwhile, it
reduces inference FLOPs and latency by up to 9$\times$, showcasing strong
generalization across models and tasks. Code is available at
https://github.com/Danielement321/HiPrune.

</details>


### [69] [Training-Free Class Purification for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.00557)
*Qi Chen,Lingxiao Yang,Yun Chen,Nailong Zhao,Jianhuang Lai,Jie Shao,Xiaohua Xie*

Main category: cs.CV

TL;DR: FreeCP是一种无需训练的分类净化框架，旨在解决开放词汇语义分割中的类别冗余和视觉语言模糊性问题，显著提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略类别冗余和视觉语言模糊性导致的激活图问题，FreeCP旨在通过净化语义类别来解决这些问题。

Method: FreeCP通过净化语义类别和纠正冗余与模糊性导致的错误，生成优化的分割预测。

Result: 在八个基准测试中，FreeCP作为即插即用模块显著提升了分割性能。

Conclusion: FreeCP有效解决了开放词汇语义分割中的关键挑战，为无需训练方法提供了新思路。

Abstract: Fine-tuning pre-trained vision-language models has emerged as a powerful
approach for enhancing open-vocabulary semantic segmentation (OVSS). However,
the substantial computational and resource demands associated with training on
large datasets have prompted interest in training-free methods for OVSS.
Existing training-free approaches primarily focus on modifying model
architectures and generating prototypes to improve segmentation performance.
However, they often neglect the challenges posed by class redundancy, where
multiple categories are not present in the current test image, and
visual-language ambiguity, where semantic similarities among categories create
confusion in class activation. These issues can lead to suboptimal class
activation maps and affinity-refined activation maps. Motivated by these
observations, we propose FreeCP, a novel training-free class purification
framework designed to address these challenges. FreeCP focuses on purifying
semantic categories and rectifying errors caused by redundancy and ambiguity.
The purified class representations are then leveraged to produce final
segmentation predictions. We conduct extensive experiments across eight
benchmarks to validate FreeCP's effectiveness. Results demonstrate that FreeCP,
as a plug-and-play module, significantly boosts segmentation performance when
combined with other OVSS methods.

</details>


### [70] [Guiding Diffusion-Based Articulated Object Generation by Partial Point Cloud Alignment and Physical Plausibility Constraints](https://arxiv.org/abs/2508.00558)
*Jens U. Kreber,Joerg Stueckler*

Main category: cs.CV

TL;DR: PhysNAP是一种基于扩散模型的新方法，用于生成与部分点云对齐且物理合理的铰接物体。


<details>
  <summary>Details</summary>
Motivation: 铰接物体是日常环境中重要的可交互对象，现有方法在物理合理性和点云对齐方面存在不足。

Method: 使用SDF表示部件形状，通过点云对齐损失和非穿透性、移动性约束指导扩散过程，并引入类别信息优化对齐。

Result: 在PartNet-Mobility数据集上验证，PhysNAP在约束一致性和生成能力之间取得平衡，优于无指导的扩散模型。

Conclusion: PhysNAP通过物理约束和类别信息提高了铰接物体生成的合理性和对齐效果。

Abstract: Articulated objects are an important type of interactable objects in everyday
environments. In this paper, we propose PhysNAP, a novel diffusion model-based
approach for generating articulated objects that aligns them with partial point
clouds and improves their physical plausibility. The model represents part
shapes by signed distance functions (SDFs). We guide the reverse diffusion
process using a point cloud alignment loss computed using the predicted SDFs.
Additionally, we impose non-penetration and mobility constraints based on the
part SDFs for guiding the model to generate more physically plausible objects.
We also make our diffusion approach category-aware to further improve point
cloud alignment if category information is available. We evaluate the
generative ability and constraint consistency of samples generated with PhysNAP
using the PartNet-Mobility dataset. We also compare it with an unguided
baseline diffusion model and demonstrate that PhysNAP can improve constraint
consistency and provides a tradeoff with generative ability.

</details>


### [71] [Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images](https://arxiv.org/abs/2508.00563)
*Hannah Kniesel,Leon Sick,Tristan Payer,Tim Bergner,Kavitha Shaga Devan,Clarissa Read,Paul Walther,Timo Ropinski*

Main category: cs.CV

TL;DR: 提出了一种基于图像级注释的弱监督目标检测方法，通过预训练模型生成伪标签，避免了昂贵的人工标注。


<details>
  <summary>Details</summary>
Motivation: 解决目标检测中依赖昂贵人工标注的问题，尤其是科学领域需要专家知识的场景。

Method: 利用预训练模型生成伪标签，通过优化方法和缩小感受野提取目标，无需特定网络架构。

Result: 伪标签方法优于现有弱标注方法，甚至在标注时间有限时优于真实标注。

Conclusion: 该方法显著降低了标注成本，同时保持了检测性能。

Abstract: Current state-of-the-art methods for object detection rely on annotated
bounding boxes of large data sets for training. However, obtaining such
annotations is expensive and can require up to hundreds of hours of manual
labor. This poses a challenge, especially since such annotations can only be
provided by experts, as they require knowledge about the scientific domain. To
tackle this challenge, we propose a domain-specific weakly supervised object
detection algorithm that only relies on image-level annotations, which are
significantly easier to acquire. Our method distills the knowledge of a
pre-trained model, on the task of predicting the presence or absence of a virus
in an image, to obtain a set of pseudo-labels that can be used to later train a
state-of-the-art object detection model. To do so, we use an optimization
approach with a shrinking receptive field to extract virus particles directly
without specific network architectures. Through a set of extensive studies, we
show how the proposed pseudo-labels are easier to obtain, and, more
importantly, are able to outperform other existing weak labeling methods, and
even ground truth labels, in cases where the time to obtain the annotation is
limited.

</details>


### [72] [CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry](https://arxiv.org/abs/2508.00568)
*Jingchao Xie,Oussema Dhaouadi,Weirong Chen,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: 提出了一种名为CoProU-VO的新方法，通过跨帧不确定性传播改进视觉里程计（VO），在动态场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 动态物体和遮挡导致传统无监督VO方法在静态场景假设下失效，需要更鲁棒的不确定性建模。

Method: 结合目标帧和参考帧的不确定性，使用概率公式和视觉Transformer架构，同时学习深度、不确定性和相机位姿。

Result: 在KITTI和nuScenes数据集上表现优于现有方法，尤其在高速公路场景中。

Conclusion: 跨帧不确定性传播显著提升了VO在动态场景中的鲁棒性。

Abstract: Visual Odometry (VO) is fundamental to autonomous navigation, robotics, and
augmented reality, with unsupervised approaches eliminating the need for
expensive ground-truth labels. However, these methods struggle when dynamic
objects violate the static scene assumption, leading to erroneous pose
estimations. We tackle this problem by uncertainty modeling, which is a
commonly used technique that creates robust masks to filter out dynamic objects
and occlusions without requiring explicit motion segmentation. Traditional
uncertainty modeling considers only single-frame information, overlooking the
uncertainties across consecutive frames. Our key insight is that uncertainty
must be propagated and combined across temporal frames to effectively identify
unreliable regions, particularly in dynamic scenes. To address this challenge,
we introduce Combined Projected Uncertainty VO (CoProU-VO), a novel end-to-end
approach that combines target frame uncertainty with projected reference frame
uncertainty using a principled probabilistic formulation. Built upon vision
transformer backbones, our model simultaneously learns depth, uncertainty
estimation, and camera poses. Consequently, experiments on the KITTI and
nuScenes datasets demonstrate significant improvements over previous
unsupervised monocular end-to-end two-frame-based methods and exhibit strong
performance in challenging highway scenes where other approaches often fail.
Additionally, comprehensive ablation studies validate the effectiveness of
cross-frame uncertainty propagation.

</details>


### [73] [Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection](https://arxiv.org/abs/2508.00587)
*Marc Hölle,Walter Kellermann,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 提出了一种基于不确定性感知的似然比估计方法，用于区分语义分割模型中的已知和未知像素特征，显著降低了误报率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在复杂场景中难以区分罕见已知类和真正未知类的问题。

Method: 采用证据分类器结合似然比检验，显式考虑不确定性，输出概率分布而非点估计。

Result: 在五个标准数据集上，平均误报率最低（2.5%），平均精度高达90.91%，计算开销可忽略。

Conclusion: 通过不确定性建模，有效提升了未知物体检测的鲁棒性和准确性。

Abstract: Semantic segmentation models trained on known object classes often fail in
real-world autonomous driving scenarios by confidently misclassifying unknown
objects. While pixel-wise out-of-distribution detection can identify unknown
objects, existing methods struggle in complex scenes where rare object classes
are often confused with truly unknown objects. We introduce an
uncertainty-aware likelihood ratio estimation method that addresses these
limitations. Our approach uses an evidential classifier within a likelihood
ratio test to distinguish between known and unknown pixel features from a
semantic segmentation model, while explicitly accounting for uncertainty.
Instead of producing point estimates, our method outputs probability
distributions that capture uncertainty from both rare training examples and
imperfect synthetic outliers. We show that by incorporating uncertainty in this
way, outlier exposure can be leveraged more effectively. Evaluated on five
standard benchmark datasets, our method achieves the lowest average false
positive rate (2.5%) among state-of-the-art while maintaining high average
precision (90.91%) and incurring only negligible computational overhead. Code
is available at https://github.com/glasbruch/ULRE.

</details>


### [74] [A Novel Modeling Framework and Data Product for Extended VIIRS-like Artificial Nighttime Light Image Reconstruction (1986-2024)](https://arxiv.org/abs/2508.00590)
*Yihe Tian,Kwan Man Cheng,Zhengbo Zhang,Tao Zhang,Suju Li,Dongmei Yan,Bing Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种新的重建框架（EVAL），用于扩展VIIRS类夜间灯光（NTL）时间序列，解决了现有方法低估光强度和结构遗漏的问题。


<details>
  <summary>Details</summary>
Motivation: 现有NTL数据时间覆盖有限（始于2012年），且现有扩展方法存在光强度低估和结构遗漏的缺陷。

Method: 采用两阶段重建框架：构建阶段使用分层融合解码器（HFD）提高初始重建保真度；细化阶段利用双特征细化器（DFR）结合高分辨率不透水面掩膜增强结构细节。

Result: 开发的EVAL产品将中国NTL数据记录扩展到1986年，R²从0.68提升至0.80，RMSE从1.27降至0.99。

Conclusion: EVAL数据集具有优异的时间一致性和社会经济参数相关性，为长期分析提供了可靠资源。

Abstract: Artificial Night-Time Light (NTL) remote sensing is a vital proxy for
quantifying the intensity and spatial distribution of human activities.
Although the NPP-VIIRS sensor provides high-quality NTL observations, its
temporal coverage, which begins in 2012, restricts long-term time-series
studies that extend to earlier periods. Despite the progress in extending
VIIRS-like NTL time-series, current methods still suffer from two significant
shortcomings: the underestimation of light intensity and the structural
omission. To overcome these limitations, we propose a novel reconstruction
framework consisting of a two-stage process: construction and refinement. The
construction stage features a Hierarchical Fusion Decoder (HFD) designed to
enhance the fidelity of the initial reconstruction. The refinement stage
employs a Dual Feature Refiner (DFR), which leverages high-resolution
impervious surface masks to guide and enhance fine-grained structural details.
Based on this framework, we developed the Extended VIIRS-like Artificial
Nighttime Light (EVAL) product for China, extending the standard data record
backwards by 26 years to begin in 1986. Quantitative evaluation shows that EVAL
significantly outperforms existing state-of-the-art products, boosting the
$\text{R}^2$ from 0.68 to 0.80 while lowering the RMSE from 1.27 to 0.99.
Furthermore, EVAL exhibits excellent temporal consistency and maintains a high
correlation with socioeconomic parameters, confirming its reliability for
long-term analysis. The resulting EVAL dataset provides a valuable new resource
for the research community and is publicly available at
https://doi.org/10.11888/HumanNat.tpdc.302930.

</details>


### [75] [Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos](https://arxiv.org/abs/2508.00748)
*Laura Pedrouzo-Rodriguez,Pedro Delgado-DeRobles,Luis F. Gomez,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez*

Main category: cs.CV

TL;DR: 论文探讨了在虚拟头像通信中，利用面部运动模式作为行为生物特征进行身份验证的可行性，并提出了一种轻量级的时空图卷积网络架构。


<details>
  <summary>Details</summary>
Motivation: 随着逼真虚拟头像的普及，其带来的安全风险（如冒充攻击）日益严重，需要探索新的身份验证方法。

Method: 使用GAGAvatar生成真实与冒充头像视频数据集，并提出基于面部关键点的时空图卷积网络架构。

Result: 实验表明，面部运动特征可实现有效的身份验证，AUC值接近80%。

Conclusion: 研究强调了在虚拟头像通信中开发更先进行为生物特征防御的必要性，并提供了公开数据集和系统。

Abstract: Photorealistic talking-head avatars are becoming increasingly common in
virtual meetings, gaming, and social platforms. These avatars allow for more
immersive communication, but they also introduce serious security risks. One
emerging threat is impersonation: an attacker can steal a user's
avatar-preserving their appearance and voice-making it nearly impossible to
detect its fraudulent usage by sight or sound alone. In this paper, we explore
the challenge of biometric verification in such avatar-mediated scenarios. Our
main question is whether an individual's facial motion patterns can serve as
reliable behavioral biometrics to verify their identity when the avatar's
visual appearance is a facsimile of its owner. To answer this question, we
introduce a new dataset of realistic avatar videos created using a
state-of-the-art one-shot avatar generation model, GAGAvatar, with genuine and
impostor avatar videos. We also propose a lightweight, explainable
spatio-temporal Graph Convolutional Network architecture with temporal
attention pooling, that uses only facial landmarks to model dynamic facial
gestures. Experimental results demonstrate that facial motion cues enable
meaningful identity verification with AUC values approaching 80%. The proposed
benchmark and biometric system are available for the research community in
order to bring attention to the urgent need for more advanced behavioral
biometric defenses in avatar-based communication systems.

</details>


### [76] [GeoMoE: Divide-and-Conquer Motion Field Modeling with Mixture-of-Experts for Two-View Geometry](https://arxiv.org/abs/2508.00592)
*Jiajun Le,Jiayi Ma*

Main category: cs.CV

TL;DR: GeoMoE提出了一种基于Mixture-of-Experts的框架，通过分解运动场为异质子场并针对性建模，提升了双视图几何中运动场估计的精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂场景中难以处理异质运动模式，导致估计结果偏离真实结构。

Method: 采用Probabilistic Prior-Guided Decomposition分解运动场，并通过MoE-Enhanced Bi-Path Rectifier针对性建模子场。

Result: 在相对位姿和单应性估计任务中优于现有方法，并展现出强泛化能力。

Conclusion: GeoMoE通过简洁设计有效解决了异质运动场建模问题，为双视图几何提供了新思路。

Abstract: Recent progress in two-view geometry increasingly emphasizes enforcing
smoothness and global consistency priors when estimating motion fields between
pairs of images. However, in complex real-world scenes, characterized by
extreme viewpoint and scale changes as well as pronounced depth
discontinuities, the motion field often exhibits diverse and heterogeneous
motion patterns. Most existing methods lack targeted modeling strategies and
fail to explicitly account for this variability, resulting in estimated motion
fields that diverge from their true underlying structure and distribution. We
observe that Mixture-of-Experts (MoE) can assign dedicated experts to motion
sub-fields, enabling a divide-and-conquer strategy for heterogeneous motion
patterns. Building on this insight, we re-architect motion field modeling in
two-view geometry with GeoMoE, a streamlined framework. Specifically, we first
devise a Probabilistic Prior-Guided Decomposition strategy that exploits inlier
probability signals to perform a structure-aware decomposition of the motion
field into heterogeneous sub-fields, sharply curbing outlier-induced bias.
Next, we introduce an MoE-Enhanced Bi-Path Rectifier that enhances each
sub-field along spatial-context and channel-semantic paths and routes it to a
customized expert for targeted modeling, thereby decoupling heterogeneous
motion regimes, suppressing cross-sub-field interference and representational
entanglement, and yielding fine-grained motion-field rectification. With this
minimalist design, GeoMoE outperforms prior state-of-the-art methods in
relative pose and homography estimation and shows strong generalization. The
source code and pre-trained models are available at
https://github.com/JiajunLe/GeoMoE.

</details>


### [77] [DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior](https://arxiv.org/abs/2508.00599)
*Junzhe Lu,Jing Lin,Hongkun Dou,Ailing Zeng,Yue Deng,Xian Liu,Zhongang Cai,Lei Yang,Yulun Zhang,Haoqian Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: DPoser-X是一种基于扩散模型的3D全身人体姿态先验模型，通过变分扩散采样解决姿态任务，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 构建一个多功能且鲁棒的全身人体姿态先验模型面临挑战，主要由于人体姿态的复杂性和高质量数据集的稀缺性。

Method: 提出扩散模型DPoser，并扩展为DPoser-X，采用变分扩散采样和截断时间步调度方法，结合掩码训练机制。

Result: 在多个基准测试中表现优于现有方法，为全身人体姿态先验建模树立了新标准。

Conclusion: DPoser-X在全身人体姿态建模中表现出强大的鲁棒性和多功能性，优于现有方法。

Abstract: We present DPoser-X, a diffusion-based prior model for 3D whole-body human
poses. Building a versatile and robust full-body human pose prior remains
challenging due to the inherent complexity of articulated human poses and the
scarcity of high-quality whole-body pose datasets. To address these
limitations, we introduce a Diffusion model as body Pose prior (DPoser) and
extend it to DPoser-X for expressive whole-body human pose modeling. Our
approach unifies various pose-centric tasks as inverse problems, solving them
through variational diffusion sampling. To enhance performance on downstream
applications, we introduce a novel truncated timestep scheduling method
specifically designed for pose data characteristics. We also propose a masked
training mechanism that effectively combines whole-body and part-specific
datasets, enabling our model to capture interdependencies between body parts
while avoiding overfitting to specific actions. Extensive experiments
demonstrate DPoser-X's robustness and versatility across multiple benchmarks
for body, hand, face, and full-body pose modeling. Our model consistently
outperforms state-of-the-art alternatives, establishing a new benchmark for
whole-body human pose prior modeling.

</details>


### [78] [Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation](https://arxiv.org/abs/2508.00766)
*Irene Iele,Francesco Di Feola,Valerio Guarrasi,Paolo Soda*

Main category: cs.CV

TL;DR: 提出了一种动态测试时间适应（TTA）框架，通过重建模块量化域偏移，动态调整预训练翻译模型的内部特征，以提升医学图像翻译任务中对分布外样本的处理能力。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像翻译任务中分布外样本导致的性能下降问题。

Method: 引入重建模块量化域偏移，动态适应块选择性调整预训练模型的内部特征。

Result: 在低剂量CT去噪和T1到T2 MRI翻译任务中表现优于基线模型和现有TTA方法。

Conclusion: 动态样本特定调整是提升模型在真实场景中鲁棒性的有效途径。

Abstract: Image-to-image translation has emerged as a powerful technique in medical
imaging, enabling tasks such as image denoising and cross-modality conversion.
However, it suffers from limitations in handling out-of-distribution samples
without causing performance degradation. To address this limitation, we propose
a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the
translation process based on the characteristics of each test sample. Our
method introduces a Reconstruction Module to quantify the domain shift and a
Dynamic Adaptation Block that selectively modifies the internal features of a
pretrained translation model to mitigate the shift without compromising the
performance on in-distribution samples that do not require adaptation. We
evaluate our approach on two medical image-to-image translation tasks: low-dose
CT denoising and T1 to T2 MRI translation, showing consistent improvements over
both the baseline translation model without TTA and prior TTA methods. Our
analysis highlights the limitations of the state-of-the-art that uniformly
apply the adaptation to both out-of-distribution and in-distribution samples,
demonstrating that dynamic, sample-specific adjustment offers a promising path
to improve model resilience in real-world scenarios. The code is available at:
https://github.com/cosbidev/Sample-Aware_TTA.

</details>


### [79] [Minimum Data, Maximum Impact: 20 annotated samples for explainable lung nodule classification](https://arxiv.org/abs/2508.00639)
*Luisa Gallée,Catharina Silvia Lisson,Christoph Gerhard Lisson,Daniela Drees,Felix Weig,Daniel Vogele,Meinrad Beer,Michael Götz*

Main category: cs.CV

TL;DR: 论文提出了一种利用生成模型合成带有病理属性标注的医学图像数据的方法，以解决标注数据稀缺问题，提升可解释模型的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像诊断中，可解释的分类模型能增强临床医生的信任和使用意愿，但大规模标注病理属性的数据集稀缺限制了此类模型的应用。

Method: 通过改进扩散模型，利用少量标注样本（20个）生成合成数据，并将其用于训练可解释模型。

Result: 合成数据的加入使属性预测准确率提升13.4%，目标预测准确率提升1.8%。

Conclusion: 合成数据能有效克服数据集限制，提升可解释模型在医学图像分析中的实用性。

Abstract: Classification models that provide human-interpretable explanations enhance
clinicians' trust and usability in medical image diagnosis. One research focus
is the integration and prediction of pathology-related visual attributes used
by radiologists alongside the diagnosis, aligning AI decision-making with
clinical reasoning. Radiologists use attributes like shape and texture as
established diagnostic criteria and mirroring these in AI decision-making both
enhances transparency and enables explicit validation of model outputs.
However, the adoption of such models is limited by the scarcity of large-scale
medical image datasets annotated with these attributes. To address this
challenge, we propose synthesizing attribute-annotated data using a generative
model. We enhance the Diffusion Model with attribute conditioning and train it
using only 20 attribute-labeled lung nodule samples from the LIDC-IDRI dataset.
Incorporating its generated images into the training of an explainable model
boosts performance, increasing attribute prediction accuracy by 13.4% and
target prediction accuracy by 1.8% compared to training with only the small
real attribute-annotated dataset. This work highlights the potential of
synthetic data to overcome dataset limitations, enhancing the applicability of
explainable models in medical image analysis.

</details>


### [80] [Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](https://arxiv.org/abs/2508.00649)
*Junhao Zheng,Jiahao Sun,Chenhao Lin,Zhengyu Zhao,Chen Ma,Chong Zhang,Cong Wang,Qian Wang,Chao Shen*

Main category: cs.CV

TL;DR: 该论文提出了首个针对目标检测器补丁攻击的防御基准，通过大规模数据集和综合分析揭示了防御性能的关键因素，并提供了改进现有防御方法的见解。


<details>
  <summary>Details</summary>
Motivation: 现有防御评估缺乏统一和全面的框架，导致对当前方法的评估不一致且不完整。

Method: 重新评估了11种代表性防御方法，构建了包含2种攻击目标、13种补丁攻击、11种目标检测器和4种多样指标的基准数据集。

Result: 揭示了防御自然补丁的难点在于数据分布而非高频特征，新数据集可将现有防御性能提升15.09% AP@0.5。

Conclusion: 研究为补丁攻击/防御的评估和设计提供了指导，并展示了复杂/随机模型或通用补丁属性的防御更具鲁棒性。

Abstract: Developing reliable defenses against patch attacks on object detectors has
attracted increasing interest. However, we identify that existing defense
evaluations lack a unified and comprehensive framework, resulting in
inconsistent and incomplete assessments of current methods. To address this
issue, we revisit 11 representative defenses and present the first patch
defense benchmark, involving 2 attack goals, 13 patch attacks, 11 object
detectors, and 4 diverse metrics. This leads to the large-scale adversarial
patch dataset with 94 types of patches and 94,000 images. Our comprehensive
analyses reveal new insights: (1) The difficulty in defending against
naturalistic patches lies in the data distribution, rather than the commonly
believed high frequencies. Our new dataset with diverse patch distributions can
be used to improve existing defenses by 15.09% AP@0.5. (2) The average
precision of the attacked object, rather than the commonly pursued patch
detection accuracy, shows high consistency with defense performance. (3)
Adaptive attacks can substantially bypass existing defenses, and defenses with
complex/stochastic models or universal patch properties are relatively robust.
We hope that our analyses will serve as guidance on properly evaluating patch
attacks/defenses and advancing their design. Code and dataset are available at
https://github.com/Gandolfczjh/APDE, where we will keep integrating new
attacks/defenses.

</details>


### [81] [Can Large Pretrained Depth Estimation Models Help With Image Dehazing?](https://arxiv.org/abs/2508.00698)
*Hongfei Zhang,Kun Zhou,Ruizheng Wu,Jiangbo Lu*

Main category: cs.CV

TL;DR: 论文研究了预训练深度表示在图像去雾中的泛化能力，并提出了一种即插即用的RGB-D融合模块。


<details>
  <summary>Details</summary>
Motivation: 现有方法在适应不同精度和效率需求的多样化场景时存在局限性，因此探索预训练深度特征的泛化能力。

Method: 通过实证分析预训练深度特征在不同雾霾级别下的表现，设计了一个即插即用的RGB-D融合模块。

Result: 实验验证了该方法的有效性和广泛适用性。

Conclusion: 预训练深度特征在图像去雾中具有显著的泛化能力，提出的模块能灵活集成到多种去雾架构中。

Abstract: Image dehazing remains a challenging problem due to the spatially varying
nature of haze in real-world scenes. While existing methods have demonstrated
the promise of large-scale pretrained models for image dehazing, their
architecture-specific designs hinder adaptability across diverse scenarios with
different accuracy and efficiency requirements. In this work, we systematically
investigate the generalization capability of pretrained depth
representations-learned from millions of diverse images-for image dehazing. Our
empirical analysis reveals that the learned deep depth features maintain
remarkable consistency across varying haze levels. Building on this insight, we
propose a plug-and-play RGB-D fusion module that seamlessly integrates with
diverse dehazing architectures. Extensive experiments across multiple
benchmarks validate both the effectiveness and broad applicability of our
approach.

</details>


### [82] [MIHBench: Benchmarking and Mitigating Multi-Image Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2508.00726)
*Jiale Li,Mingrui Wu,Zixiang Jin,Hao Chen,Jiayi Ji,Xiaoshuai Sun,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: 该论文首次系统研究了多图像多模态大语言模型（MLLMs）中的幻觉问题，提出了专门评估多图像对象相关幻觉的基准MIHBench，并提出动态注意力平衡机制以减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单图像场景中的幻觉，而多图像场景中的幻觉尚未被充分探索，因此需要填补这一空白。

Method: 提出MIHBench基准，包含三个核心任务，并通过动态注意力平衡机制调整图像间注意力分布。

Result: 实验表明，该方法能有效减少多图像场景中的幻觉，并提升语义整合和推理稳定性。

Conclusion: 该研究为多图像MLLMs中的幻觉问题提供了系统解决方案，并通过动态注意力平衡机制显著改善了模型性能。

Abstract: Despite growing interest in hallucination in Multimodal Large Language
Models, existing studies primarily focus on single-image settings, leaving
hallucination in multi-image scenarios largely unexplored. To address this gap,
we conduct the first systematic study of hallucinations in multi-image MLLMs
and propose MIHBench, a benchmark specifically tailored for evaluating
object-related hallucinations across multiple images. MIHBench comprises three
core tasks: Multi-Image Object Existence Hallucination, Multi-Image Object
Count Hallucination, and Object Identity Consistency Hallucination, targeting
semantic understanding across object existence, quantity reasoning, and
cross-view identity consistency. Through extensive evaluation, we identify key
factors associated with the occurrence of multi-image hallucinations,
including: a progressive relationship between the number of image inputs and
the likelihood of hallucination occurrences; a strong correlation between
single-image hallucination tendencies and those observed in multi-image
contexts; and the influence of same-object image ratios and the positional
placement of negative samples within image sequences on the occurrence of
object identity consistency hallucination. To address these challenges, we
propose a Dynamic Attention Balancing mechanism that adjusts inter-image
attention distributions while preserving the overall visual attention
proportion. Experiments across multiple state-of-the-art MLLMs demonstrate that
our method effectively reduces hallucination occurrences and enhances semantic
integration and reasoning stability in multi-image scenarios.

</details>


### [83] [YOLO-Count: Differentiable Object Counting for Text-to-Image Generation](https://arxiv.org/abs/2508.00728)
*Guanning Zeng,Xiang Zhang,Zirui Wang,Haiyang Xu,Zeyuan Chen,Bingnan Li,Zhuowen Tu*

Main category: cs.CV

TL;DR: YOLO-Count是一个可微分的开放词汇对象计数模型，解决了通用计数问题，并为文本到图像生成提供精确数量控制。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇计数与文本到图像生成控制之间的差距，提供更精确的对象数量估计和生成指导。

Method: 提出'基数'图作为回归目标，结合表示对齐和强弱监督混合方案，构建完全可微分的架构。

Result: 在实验中表现出最先进的计数准确性，并为文本到图像系统提供有效的数量控制。

Conclusion: YOLO-Count在开放词汇计数和生成控制方面具有显著优势，适用于实际应用。

Abstract: We propose YOLO-Count, a differentiable open-vocabulary object counting model
that tackles both general counting challenges and enables precise quantity
control for text-to-image (T2I) generation. A core contribution is the
'cardinality' map, a novel regression target that accounts for variations in
object size and spatial distribution. Leveraging representation alignment and a
hybrid strong-weak supervision scheme, YOLO-Count bridges the gap between
open-vocabulary counting and T2I generation control. Its fully differentiable
architecture facilitates gradient-based optimization, enabling accurate object
count estimation and fine-grained guidance for generative models. Extensive
experiments demonstrate that YOLO-Count achieves state-of-the-art counting
accuracy while providing robust and effective quantity control for T2I systems.

</details>


### [84] [Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR](https://arxiv.org/abs/2508.00744)
*Adwait Chandorkar,Hasan Tercan,Tobias Meisen*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级骨干网络Dense Backbone，用于3D目标检测，显著降低了计算成本，同时保持了高检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有的3D目标检测方法多依赖复杂的VGG或ResNet骨干网络，增加了模型复杂度，而轻量级骨干网络在3D检测领域研究较少。

Method: 提出Dense Backbone，结合高处理速度、轻量架构和鲁棒检测精度，适配多种先进3D检测器（如PillarNet）。

Result: DensePillarNet在nuScenes测试集上参数减少29%，延迟降低28%，检测精度仅下降2%。

Conclusion: Dense Backbone的即插即用设计可轻松集成到现有架构中，无需修改其他组件，为3D目标检测提供了高效解决方案。

Abstract: Recent advancements in LiDAR-based 3D object detection have significantly
accelerated progress toward the realization of fully autonomous driving in
real-world environments. Despite achieving high detection performance, most of
the approaches still rely on a VGG-based or ResNet-based backbone for feature
exploration, which increases the model complexity. Lightweight backbone design
is well-explored for 2D object detection, but research on 3D object detection
still remains limited. In this work, we introduce Dense Backbone, a lightweight
backbone that combines the benefits of high processing speed, lightweight
architecture, and robust detection accuracy. We adapt multiple SoTA 3d object
detectors, such as PillarNet, with our backbone and show that with our
backbone, these models retain most of their detection capability at a
significantly reduced computational cost. To our knowledge, this is the first
dense-layer-based backbone tailored specifically for 3D object detection from
point cloud data. DensePillarNet, our adaptation of PillarNet, achieves a 29%
reduction in model parameters and a 28% reduction in latency with just a 2%
drop in detection accuracy on the nuScenes test set. Furthermore, Dense
Backbone's plug-and-play design allows straightforward integration into
existing architectures, requiring no modifications to other network components.

</details>


### [85] [GECO: Geometrically Consistent Embedding with Lightspeed Inference](https://arxiv.org/abs/2508.00746)
*Regine Hartwig,Dominik Muhle,Riccardo Marin,Daniel Cremers*

Main category: cs.CV

TL;DR: GECO提出了一种基于最优传输的训练框架，生成几何一致的特征，显著提升了语义对应任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督视觉基础模型缺乏对3D几何的感知，GECO旨在填补这一空白。

Method: 采用最优传输框架进行训练，支持关键点之外的监督，适用于遮挡和去遮挡场景。

Result: 在PFPascal、APK和CUB数据集上性能提升显著，运行速度达30 fps，比现有方法快98.2%。

Conclusion: PCK指标不足以衡量几何质量，GECO提出了新指标和见解，推动几何感知特征学习的发展。

Abstract: Recent advances in feature learning have shown that self-supervised vision
foundation models can capture semantic correspondences but often lack awareness
of underlying 3D geometry. GECO addresses this gap by producing geometrically
coherent features that semantically distinguish parts based on geometry (e.g.,
left/right eyes, front/back legs). We propose a training framework based on
optimal transport, enabling supervision beyond keypoints, even under occlusions
and disocclusions. With a lightweight architecture, GECO runs at 30 fps, 98.2%
faster than prior methods, while achieving state-of-the-art performance on
PFPascal, APK, and CUB, improving PCK by 6.0%, 6.2%, and 4.1%, respectively.
Finally, we show that PCK alone is insufficient to capture geometric quality
and introduce new metrics and insights for more geometry-aware feature
learning. Link to project page:
https://reginehartwig.github.io/publications/geco/

</details>


### [86] [SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation](https://arxiv.org/abs/2508.00750)
*Prerana Ramkumar*

Main category: cs.CV

TL;DR: SU-ESRGAN是一种针对卫星图像设计的超分辨率框架，结合了ESRGAN、DeepLabv3分割损失和蒙特卡洛dropout，以提升语义一致性和像素级置信度。


<details>
  <summary>Details</summary>
Motivation: GANs在图像超分辨率中缺乏语义一致性和像素级置信度，限制了其在遥感关键应用中的可信度。

Method: 提出SU-ESRGAN，整合ESRGAN、DeepLabv3分割损失和蒙特卡洛dropout，生成像素级不确定性图。

Result: 在PSNR、SSIM和LPIPS指标上与基线ESRGAN相当，适用于卫星或无人机系统。

Conclusion: SU-ESRGAN在跨域应用中表现良好，强调了领域感知训练的重要性。

Abstract: Generative Adversarial Networks (GANs) have achieved realistic
super-resolution (SR) of images however, they lack semantic consistency and
per-pixel confidence, limiting their credibility in critical remote sensing
applications such as disaster response, urban planning and agriculture. This
paper introduces Semantic and Uncertainty-Aware ESRGAN (SU-ESRGAN), the first
SR framework designed for satellite imagery to integrate the ESRGAN,
segmentation loss via DeepLabv3 for class detail preservation and Monte Carlo
dropout to produce pixel-wise uncertainty maps. The SU-ESRGAN produces results
(PSNR, SSIM, LPIPS) comparable to the Baseline ESRGAN on aerial imagery. This
novel model is valuable in satellite systems or UAVs that use wide
field-of-view (FoV) cameras, trading off spatial resolution for coverage. The
modular design allows integration in UAV data pipelines for on-board or
post-processing SR to enhance imagery resulting due to motion blur, compression
and sensor limitations. Further, the model is fine-tuned to evaluate its
performance on cross domain applications. The tests are conducted on two drone
based datasets which differ in altitude and imaging perspective. Performance
evaluation of the fine-tuned models show a stronger adaptation to the Aerial
Maritime Drone Dataset, whose imaging characteristics align with the training
data, highlighting the importance of domain-aware training in SR-applications.

</details>


### [87] [Zero-Shot Anomaly Detection with Dual-Branch Prompt Learning](https://arxiv.org/abs/2508.00777)
*Zihan Wang,Samira Ebrahimi Kahou,Narges Armanfard*

Main category: cs.CV

TL;DR: PILOT框架通过双分支提示学习和无标签测试时适应策略，解决了零样本异常检测在域偏移下的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常检测方法在域偏移下表现不佳，因为训练数据来自有限领域，无法泛化到新分布。

Method: PILOT采用双分支提示学习机制和基于高置信度伪标签的无标签测试时适应策略。

Result: 在13个工业和医学基准测试中，PILOT在域偏移下的异常检测和定位性能达到最优。

Conclusion: PILOT通过动态适应和测试时优化，显著提升了零样本异常检测的泛化能力。

Abstract: Zero-shot anomaly detection (ZSAD) enables identifying and localizing defects
in unseen categories by relying solely on generalizable features rather than
requiring any labeled examples of anomalies. However, existing ZSAD methods,
whether using fixed or learned prompts, struggle under domain shifts because
their training data are derived from limited training domains and fail to
generalize to new distributions. In this paper, we introduce PILOT, a framework
designed to overcome these challenges through two key innovations: (1) a novel
dual-branch prompt learning mechanism that dynamically integrates a pool of
learnable prompts with structured semantic attributes, enabling the model to
adaptively weight the most relevant anomaly cues for each input image; and (2)
a label-free test-time adaptation strategy that updates the learnable prompt
parameters using high-confidence pseudo-labels from unlabeled test data.
Extensive experiments on 13 industrial and medical benchmarks demonstrate that
PILOT achieves state-of-the-art performance in both anomaly detection and
localization under domain shift.

</details>


### [88] [Cross-Dataset Semantic Segmentation Performance Analysis: Unifying NIST Point Cloud City Datasets for 3D Deep Learning](https://arxiv.org/abs/2508.00822)
*Alexander Nikitas Dimopoulos,Joseph Grasso*

Main category: cs.CV

TL;DR: 研究分析了异构标记点云数据集在公共安全应用中的语义分割性能，发现几何较大的对象分割效果较好，而小型安全关键特征识别率较低。


<details>
  <summary>Details</summary>
Motivation: 探讨如何统一不同标记的3D数据，以提升公共安全应用中点云语义分割的可靠性。

Method: 采用分级标签方案和KPConv架构，通过IoU指标评估安全相关特征的分割性能。

Result: 几何较大的对象（如楼梯、窗户）分割性能较高，小型安全关键特征识别率较低，受限于类不平衡和几何区分度不足。

Conclusion: 公共安全领域的可靠点云语义分割需要标准化标注协议和改进的标记技术，以解决数据异构性和小型安全关键元素的检测问题。

Abstract: This study analyzes semantic segmentation performance across heterogeneously
labeled point-cloud datasets relevant to public safety applications, including
pre-incident planning systems derived from lidar scans. Using NIST's Point
Cloud City dataset (Enfield and Memphis collections), we investigate challenges
in unifying differently labeled 3D data. Our methodology employs a graded
schema with the KPConv architecture, evaluating performance through IoU metrics
on safety-relevant features. Results indicate performance variability:
geometrically large objects (e.g. stairs, windows) achieve higher segmentation
performance, suggesting potential for navigational context, while smaller
safety-critical features exhibit lower recognition rates. Performance is
impacted by class imbalance and the limited geometric distinction of smaller
objects in typical lidar scans, indicating limitations in detecting certain
safety-relevant features using current point-cloud methods. Key identified
challenges include insufficient labeled data, difficulties in unifying class
labels across datasets, and the need for standardization. Potential directions
include automated labeling and multi-dataset learning strategies. We conclude
that reliable point-cloud semantic segmentation for public safety necessitates
standardized annotation protocols and improved labeling techniques to address
data heterogeneity and the detection of small, safety-critical elements.

</details>


### [89] [IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation](https://arxiv.org/abs/2508.00823)
*Wenxuan Guo,Xiuwei Xu,Hang Yin,Ziwei Wang,Jianjiang Feng,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 提出IGL-Nav框架，基于3D高斯表示实现高效、3D感知的图像目标导航，通过增量更新和几何信息匹配优化目标定位。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法充分建模3D环境与目标图像的几何关系，且计算效率低。

Method: 增量更新场景表示，利用几何信息粗定位目标，通过可微渲染优化精细位姿。

Result: IGL-Nav在多种实验配置下显著优于现有方法，支持自由视角目标图像导航。

Conclusion: IGL-Nav高效且3D感知强，适用于实际机器人平台。

Abstract: Visual navigation with an image as goal is a fundamental and challenging
problem. Conventional methods either rely on end-to-end RL learning or
modular-based policy with topological graph or BEV map as memory, which cannot
fully model the geometric relationship between the explored 3D environment and
the goal image. In order to efficiently and accurately localize the goal image
in 3D space, we build our navigation system upon the renderable 3D gaussian
(3DGS) representation. However, due to the computational intensity of 3DGS
optimization and the large search space of 6-DoF camera pose, directly
leveraging 3DGS for image localization during agent exploration process is
prohibitively inefficient. To this end, we propose IGL-Nav, an Incremental 3D
Gaussian Localization framework for efficient and 3D-aware image-goal
navigation. Specifically, we incrementally update the scene representation as
new images arrive with feed-forward monocular prediction. Then we coarsely
localize the goal by leveraging the geometric information for discrete space
matching, which can be equivalent to efficient 3D convolution. When the agent
is close to the goal, we finally solve the fine target pose with optimization
via differentiable rendering. The proposed IGL-Nav outperforms existing
state-of-the-art methods by a large margin across diverse experimental
configurations. It can also handle the more challenging free-view image-goal
setting and be deployed on real-world robotic platform using a cellphone to
capture goal image at arbitrary pose. Project page:
https://gwxuan.github.io/IGL-Nav/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems](https://arxiv.org/abs/2508.00079)
*Oshayer Siddique,J. M Areeb Uzair Alam,Md Jobayer Rahman Rafy,Syed Rifat Raiyan,Hasan Mahmud,Md Kamrul Hasan*

Main category: cs.CL

TL;DR: 论文评估前沿大语言模型（LLM）在解决物理问题（数学和描述性）上的表现，并采用多代理框架和推理技术提升性能。提出了新的物理问题评估基准${\rm P{\small HYSICS}E{\small VAL}}$。


<details>
  <summary>Details</summary>
Motivation: 物理问题是自然语言推理的关键领域，评估和改进LLM在此类问题上的表现具有重要意义。

Method: 使用多代理框架和推理技术验证解决方案，并进行比较分析。

Result: 多代理框架显著提升了模型在初始表现较差问题上的性能。

Conclusion: 论文提出了新的评估基准，并展示了多代理框架在提升LLM解决物理问题能力上的有效性。

Abstract: The discipline of physics stands as a cornerstone of human intellect, driving
the evolution of technology and deepening our understanding of the fundamental
principles of the cosmos. Contemporary literature includes some works centered
on the task of solving physics problems - a crucial domain of natural language
reasoning. In this paper, we evaluate the performance of frontier LLMs in
solving physics problems, both mathematical and descriptive. We also employ a
plethora of inference-time techniques and agentic frameworks to improve the
performance of the models. This includes the verification of proposed solutions
in a cumulative fashion by other, smaller LLM agents, and we perform a
comparative analysis of the performance that the techniques entail. There are
significant improvements when the multi-agent framework is applied to problems
that the models initially perform poorly on. Furthermore, we introduce a new
evaluation benchmark for physics problems, ${\rm P{\small HYSICS}E{\small
VAL}}$, consisting of 19,609 problems sourced from various physics textbooks
and their corresponding correct solutions scraped from physics forums and
educational websites. Our code and data are publicly available at
https://github.com/areebuzair/PhysicsEval.

</details>


### [91] [Do LLMs produce texts with "human-like" lexical diversity?](https://arxiv.org/abs/2508.00086)
*Kelly Kendro,Jeffrey Maloney,Scott Jarvis*

Main category: cs.CL

TL;DR: 研究探讨了四种ChatGPT模型生成文本与人类写作在词汇多样性上的差异，发现LLM生成的文本在词汇多样性上与人类写作显著不同，且新模型更不像人类。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM生成文本的类似人类程度受到广泛关注，但其词汇多样性是否真正接近人类写作尚不明确。

Method: 比较四种ChatGPT模型与240名L1/L2英语参与者的文本，测量六个词汇多样性维度，并进行统计分析和机器学习分类。

Result: LLM生成文本在词汇多样性上与人类写作显著不同，ChatGPT-4.5词汇多样性最高但更像机器。人类写作的词汇多样性在不同子组间无差异。

Conclusion: LLM生成的文本在词汇多样性上不接近人类写作，新模型更不像人类，这对语言教学和相关应用有启示。

Abstract: The degree to which LLMs produce writing that is truly human-like remains
unclear despite the extensive empirical attention that this question has
received. The present study addresses this question from the perspective of
lexical diversity. Specifically, the study investigates patterns of lexical
diversity in LLM-generated texts from four ChatGPT models (-3.5, -4, -o4 mini,
and -4.5) in comparison with texts written by L1 and L2 English participants (n
= 240) across four education levels. Six dimensions of lexical diversity were
measured in each text: volume, abundance, variety-repetition, evenness,
disparity, and dispersion. Results from one-way MANOVAs, one-way ANOVAS, and
Support Vector Machines revealed that the LLM-generated texts differed
significantly from human-written texts for each variable, with ChatGPT-o4 mini
and -4.5 differing the most. Within these two groups, ChatGPT-4.5 demonstrated
higher levels of lexical diversity despite producing fewer tokens. The human
writers' lexical diversity did not differ across subgroups (i.e., education,
language status). Altogether, the results indicate that LLMs do not produce
human-like texts in relation to lexical diversity, and the newer LLMs produce
less human-like texts than older models. We discuss the implications of these
results for language pedagogy and related applications.

</details>


### [92] [Semiotic Complexity and Its Epistemological Implications for Modeling Culture](https://arxiv.org/abs/2508.00095)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 论文呼吁计算人文学科在方法上加强理论化，提出将建模工作视为文化语言领域与计算数学领域之间的翻译过程，并强调理论化的重要性以避免翻译错误。


<details>
  <summary>Details</summary>
Motivation: 计算人文学科需要更深入的方法理论化，以确保认识论和解释的清晰性，促进领域成熟。

Method: 将建模工作视为翻译过程，提出‘符号复杂性’概念，分析当前建模实践中因忽视符号复杂性而导致的翻译错误。

Result: 指出当前建模实践（尤其是评估环节）常将符号复杂数据简化为符号简单数据，导致认识论问题。

Conclusion: 提出若干建议，帮助研究者在工作中更好地处理这些认识论问题。

Abstract: Greater theorizing of methods in the computational humanities is needed for
epistemological and interpretive clarity, and therefore the maturation of the
field. In this paper, we frame such modeling work as engaging in translation
work from a cultural, linguistic domain into a computational, mathematical
domain, and back again. Translators benefit from articulating the theory of
their translation process, and so do computational humanists in their work --
to ensure internal consistency, avoid subtle yet consequential translation
errors, and facilitate interpretive transparency. Our contribution in this
paper is to lay out a particularly consequential dimension of the lack of
theorizing and the sorts of translation errors that emerge in our modeling
practices as a result. Along these lines we introduce the idea of semiotic
complexity as the degree to which the meaning of some text may vary across
interpretive lenses, and make the case that dominant modeling practices --
especially around evaluation -- commit a translation error by treating
semiotically complex data as semiotically simple when it seems
epistemologically convenient by conferring superficial clarity. We then lay out
several recommendations for researchers to better account for these
epistemological issues in their own work.

</details>


### [93] [FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality](https://arxiv.org/abs/2508.00109)
*Mingda Chen,Yang Li,Xilun Chen,Adina Williams,Gargi Ghosh,Scott Yih*

Main category: cs.CL

TL;DR: FACTORY是一个大规模、人工验证的提示集，用于评估模型生成准确、全面回答的能力，结果显示现有SOTA模型在FACTORY上的事实性错误率高达40%。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏人工验证，可能导致质量问题，因此需要更可靠的评估工具。

Method: 采用模型与人工结合的开发方式，构建FACTORY提示集，并对6个SOTA模型进行人工评估。

Result: FACTORY是一个具有挑战性的基准，SOTA模型在其上的事实性错误率为40%，远高于其他数据集的10%。

Conclusion: FACTORY提供了更可靠的评估，突显了模型在长尾事实推理上的不足。

Abstract: Long-form factuality evaluation assesses the ability of models to generate
accurate, comprehensive responses to short prompts. Existing benchmarks often
lack human verification, leading to potential quality issues. To address this
limitation, we introduce FACTORY, a large-scale, human-verified prompt set.
Developed using a model-in-the-loop approach and refined by humans, FACTORY
includes challenging prompts that are fact-seeking, answerable, and
unambiguous. We conduct human evaluations on 6 state-of-the-art language models
using FACTORY and existing datasets. Our results show that FACTORY is a
challenging benchmark: approximately 40% of the claims made in the responses of
SOTA models are not factual, compared to only 10% for other datasets. Our
analysis identifies the strengths of FACTORY over prior benchmarks, emphasizing
its reliability and the necessity for models to reason across long-tailed
facts.

</details>


### [94] [Is neural semantic parsing good at ellipsis resolution, or isn't it?](https://arxiv.org/abs/2508.00121)
*Xiao Zhang,Johan bos*

Main category: cs.CL

TL;DR: 论文探讨了神经语义解析器在强上下文敏感现象（如动词短语省略）上的表现，发现尽管在标准测试集上表现优异，但在省略现象上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究神经语义解析器在处理强上下文敏感现象（如动词短语省略）时的能力，填补现有研究的空白。

Method: 构建了一个包含120个省略案例及其完整语义表示的语料库，并用于测试多种神经语义解析器。

Result: 尽管解析器在标准测试集上表现良好（语义匹配分数超过90%），但在省略现象上表现失败。

Conclusion: 神经语义解析器在处理强上下文敏感现象时存在局限性，数据增强可能是改进方向。

Abstract: Neural semantic parsers have shown good overall performance for a variety of
linguistic phenomena, reaching semantic matching scores of more than 90%. But
how do such parsers perform on strongly context-sensitive phenomena, where
large pieces of semantic information need to be duplicated to form a meaningful
semantic representation? A case in point is English verb phrase ellipsis, a
construct where entire verb phrases can be abbreviated by a single auxiliary
verb. Are the otherwise known as powerful semantic parsers able to deal with
ellipsis or aren't they? We constructed a corpus of 120 cases of ellipsis with
their fully resolved meaning representation and used this as a challenge set
for a large battery of neural semantic parsers. Although these parsers
performed very well on the standard test set, they failed in the instances with
ellipsis. Data augmentation

</details>


### [95] [Comparison of Large Language Models for Deployment Requirements](https://arxiv.org/abs/2508.00185)
*Alper Yaman,Jannik Schwab,Christof Nitsche,Abhirup Sinha,Marco Huber*

Main category: cs.CL

TL;DR: 该论文总结了大型语言模型（LLMs）的发展现状，比较了开源基础模型和领域特定模型的特点，并提供了一个持续更新的模型选择指南。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的快速发展，研究人员和企业在选择模型时面临许可和硬件要求的复杂性，因此需要一种系统化的方法来比较和选择模型。

Method: 通过整理和分析开源的基础模型和领域特定模型，比较其发布年份、许可和硬件要求等特征，并在GitLab上发布持续更新的列表。

Result: 提供了一个详细的模型比较列表，帮助用户根据需求选择适合的LLM。

Conclusion: 该研究为LLM的选择提供了实用工具，并计划持续更新以适应快速发展的技术环境。

Abstract: Large Language Models (LLMs), such as Generative Pre-trained Transformers
(GPTs) are revolutionizing the generation of human-like text, producing
contextually relevant and syntactically correct content. Despite challenges
like biases and hallucinations, these Artificial Intelligence (AI) models excel
in tasks, such as content creation, translation, and code generation.
Fine-tuning and novel architectures, such as Mixture of Experts (MoE), address
these issues. Over the past two years, numerous open-source foundational and
fine-tuned models have been introduced, complicating the selection of the
optimal LLM for researchers and companies regarding licensing and hardware
requirements. To navigate the rapidly evolving LLM landscape and facilitate LLM
selection, we present a comparative list of foundational and domain-specific
models, focusing on features, such as release year, licensing, and hardware
requirements. This list is published on GitLab and will be continuously
updated.

</details>


### [96] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 本文探讨了表格在大型语言模型（LLM）和多模态大型语言模型（MLLM）中的重要性，提出了表格输入表示的分类法，并指出了当前研究中的关键问题。


<details>
  <summary>Details</summary>
Motivation: 表格因其复杂和灵活的结构在LLM和MLLM中备受关注，但缺乏通用方法，导致理解任务具有挑战性。

Method: 通过分类法总结表格输入表示，并介绍表格理解任务。

Result: 指出了当前研究中的三个关键问题：检索任务主导、模型处理复杂表格的困难以及模型泛化能力有限。

Conclusion: 需要进一步研究以解决表格理解中的挑战，特别是在复杂结构、大规模表格和多表场景下的模型能力。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


### [97] [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://arxiv.org/abs/2508.00220)
*Rana Aref Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 论文探讨了离散小波变换（DWT）在词和句子嵌入中的应用，展示了其在多分辨率分析和压缩嵌入表示中的能力，同时保持语义质量。


<details>
  <summary>Details</summary>
Motivation: 小波变换在信号和图像处理中已广泛应用，但其在NLP中的潜力尚未充分挖掘，尤其是在嵌入表示的分析和压缩方面。

Method: 通过离散小波变换（DWT）对词和句子嵌入进行多分辨率分析和压缩，并在语义相似性任务中评估其效果。

Result: DWT能将嵌入维度减少50-93%，同时几乎不影响语义相似性任务的性能，并在多数下游任务中表现更优。

Conclusion: DWT为改进NLP应用提供了一种有效方法，尤其是在嵌入表示的高效压缩和语义信息保留方面。

Abstract: Wavelet transforms, a powerful mathematical tool, have been widely used in
different domains, including Signal and Image processing, to unravel intricate
patterns, enhance data representation, and extract meaningful features from
data. Tangible results from their application suggest that Wavelet transforms
can be applied to NLP capturing a variety of linguistic and semantic
properties. In this paper, we empirically leverage the application of Discrete
Wavelet Transforms (DWT) to word and sentence embeddings. We aim to showcase
the capabilities of DWT in analyzing embedding representations at different
levels of resolution and compressing them while maintaining their overall
quality. We assess the effectiveness of DWT embeddings on semantic similarity
tasks to show how DWT can be used to consolidate important semantic information
in an embedding vector. We show the efficacy of the proposed paradigm using
different embedding models, including large language models, on downstream
tasks. Our results show that DWT can reduce the dimensionality of embeddings by
50-93% with almost no change in performance for semantic similarity tasks,
while achieving superior accuracy in most downstream tasks. Our findings pave
the way for applying DWT to improve NLP applications.

</details>


### [98] [Model Misalignment and Language Change: Traces of AI-Associated Language in Unscripted Spoken English](https://arxiv.org/abs/2508.00238)
*Bryce Anderson,Riley Galpin,Tom S. Juzek*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLMs）对人类语言使用的影响，发现2022年后人类语言中与LLM相关的词汇使用显著增加。


<details>
  <summary>Details</summary>
Motivation: 探究AI工具（如LLMs）是否正在改变人类语言系统本身，而不仅仅是作为文本生成工具。

Method: 构建了一个包含2210万单词的非脚本口语数据集，分析ChatGPT发布前后与LLM相关词汇的使用趋势。

Result: 2022年后，与LLM相关的词汇使用显著增加，而基线同义词无明显变化。

Conclusion: 这可能标志着语言使用的显著变化，但变化是自然语言演变还是AI驱动的尚不明确，同时引发了关于模型对齐的伦理问题。

Abstract: In recent years, written language, particularly in science and education, has
undergone remarkable shifts in word usage. These changes are widely attributed
to the growing influence of Large Language Models (LLMs), which frequently rely
on a distinct lexical style. Divergences between model output and target
audience norms can be viewed as a form of misalignment. While these shifts are
often linked to using Artificial Intelligence (AI) directly as a tool to
generate text, it remains unclear whether the changes reflect broader changes
in the human language system itself. To explore this question, we constructed a
dataset of 22.1 million words from unscripted spoken language drawn from
conversational science and technology podcasts. We analyzed lexical trends
before and after ChatGPT's release in 2022, focusing on commonly LLM-associated
words. Our results show a moderate yet significant increase in the usage of
these words post-2022, suggesting a convergence between human word choices and
LLM-associated patterns. In contrast, baseline synonym words exhibit no
significant directional shift. Given the short time frame and the number of
words affected, this may indicate the onset of a remarkable shift in language
use. Whether this represents natural language change or a novel shift driven by
AI exposure remains an open question. Similarly, although the shifts may stem
from broader adoption patterns, it may also be that upstream training
misalignments ultimately contribute to changes in human language use. These
findings parallel ethical concerns that misaligned models may shape social and
moral beliefs.

</details>


### [99] [Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering](https://arxiv.org/abs/2508.00285)
*Peixian Li,Yu Tian,Ruiqi Tu,Chengkai Wu,Jingjing Ren,Jingsong Li*

Main category: cs.CL

TL;DR: 该研究提出了一种病因感知注意力引导框架，通过整合结构化临床推理提升大型语言模型（LLM）在复杂临床场景中的诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在医学文本理解和生成方面表现出色，但其在复杂临床诊断中的可靠性有限，因此需要提升其诊断准确性和临床推理能力。

Method: 研究构建了基于权威临床指南的临床推理支架（CRS），开发了病因感知头识别算法，并引入推理引导的参数高效微调方法，以嵌入病因推理线索并引导模型注意力。

Result: 在一致性诊断队列中，框架将平均诊断准确率提高了15.65%，推理聚焦分数提升了31.6%。外部验证进一步证实了其有效性。

Conclusion: 该框架通过将模型注意力与结构化CRS对齐，为构建更可解释和可靠的AI诊断系统提供了实用方法。

Abstract: Objective: Large Language Models (LLMs) demonstrate significant capabilities
in medical text understanding and generation. However, their diagnostic
reliability in complex clinical scenarios remains limited. This study aims to
enhance LLMs' diagnostic accuracy and clinical reasoning ability. Method: We
propose an Etiology-Aware Attention Steering Framework to integrate structured
clinical reasoning into LLM-based diagnosis. Specifically, we first construct
Clinical Reasoning Scaffolding (CRS) based on authoritative clinical guidelines
for three representative acute abdominal emergencies: acute appendicitis, acute
pancreatitis, and acute cholecystitis. Next, we develop the Etiology-Aware Head
Identification algorithm to pinpoint attention heads crucial for the model's
etiology reasoning. To ensure reliable clinical reasoning alignment, we
introduce the Reasoning-Guided Parameter-Efficient Fine-tuning that embeds
etiological reasoning cues into input representations and steers the selected
Etiology-Aware Heads toward critical information through a Reasoning-Guided
Loss function. Result: On the Consistent Diagnosis Cohort, our framework
improves average diagnostic accuracy by 15.65% and boosts the average Reasoning
Focus Score by 31.6% over baselines. External validation on the Discrepant
Diagnosis Cohort further confirms its effectiveness in enhancing diagnostic
accuracy. Further assessments via Reasoning Attention Frequency indicate that
our models exhibit enhanced reliability when faced with real-world complex
scenarios. Conclusion: This study presents a practical and effective approach
to enhance clinical reasoning in LLM-based diagnosis. By aligning model
attention with structured CRS, the proposed framework offers a promising
paradigm for building more interpretable and reliable AI diagnostic systems in
complex clinical settings.

</details>


### [100] [Systematic Evaluation of Optimization Techniques for Long-Context Language Models](https://arxiv.org/abs/2508.00305)
*Ammar Ahmed,Sheng Di,Franck Cappello,Zirui Liu,Jingoo Han,Ali Anwar*

Main category: cs.CL

TL;DR: 论文系统评估了LLM优化技术（如剪枝、量化和token丢弃）在长上下文场景中的效果，揭示了组合优化对大型模型的负面影响，并强调了系统级分析与任务特定指标结合的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在NLP任务中表现优异，但其资源需求和有限上下文窗口仍是挑战。现有优化技术在这些场景下的效果尚未充分研究。

Method: 系统评估了两种支持长上下文的LLM架构的优化方法，并研究了这些方法的组合效果及其在70B参数模型上的扩展性。

Result: 研究发现，组合优化可能因累积近似误差对大型模型产生负面影响，而仅依赖F1分数会掩盖问答任务中的精度-召回权衡。

Conclusion: 通过结合系统级分析和任务特定指标，研究为LLM实践者提供了平衡效率、准确性和可扩展性的指导。

Abstract: Large language models (LLMs) excel across diverse natural language processing
tasks but face resource demands and limited context windows. Although
techniques like pruning, quantization, and token dropping can mitigate these
issues, their efficacy in long-context scenarios and system evaluation remains
underexplored. This paper systematically benchmarks these optimizations,
characterizing memory usage, latency, and throughput, and studies how these
methods impact the quality of text generation. We first analyze individual
optimization methods for two LLM architectures supporting long context and then
systematically evaluate combinations of these techniques to assess how this
deeper analysis impacts performance metrics. We subsequently study the
scalability of individual optimization methods on a larger variant with 70
billion-parameter model. Our novel insights reveal that naive combination
inference optimization algorithms can adversely affect larger models due to
compounded approximation errors, as compared to their smaller counterparts.
Experiments show that relying solely on F1 obscures these effects by hiding
precision-recall trade-offs in question answering tasks. By integrating
system-level profiling with task-specific insights, this study helps LLM
practitioners and researchers explore and balance efficiency, accuracy, and
scalability across tasks and hardware configurations.

</details>


### [101] [Improving Multimodal Contrastive Learning of Sentence Embeddings with Object-Phrase Alignment](https://arxiv.org/abs/2508.00332)
*Kaiyan Zhao,Zhongtao Miao,Yoshimasa Tsuruoka*

Main category: cs.CL

TL;DR: MCSEO提出了一种通过细粒度对象-短语对齐增强多模态句子嵌入的方法，优于传统基线。


<details>
  <summary>Details</summary>
Motivation: 多模态句子嵌入模型通常使用图像-标题对训练，但这些对可能包含冗余或无关信息，影响模型性能。

Method: MCSEO利用分割和对象检测模型提取精确的对象-短语对，优化对比学习目标。

Result: 在语义文本相似性任务中，MCSEO在不同骨干模型上均优于基线。

Conclusion: 精确的对象-短语对齐对多模态表示学习至关重要。

Abstract: Multimodal sentence embedding models typically leverage image-caption pairs
in addition to textual data during training. However, such pairs often contain
noise, including redundant or irrelevant information on either the image or
caption side. To mitigate this issue, we propose MCSEO, a method that enhances
multimodal sentence embeddings by incorporating fine-grained object-phrase
alignment alongside traditional image-caption alignment. Specifically, MCSEO
utilizes existing segmentation and object detection models to extract accurate
object-phrase pairs, which are then used to optimize a contrastive learning
objective tailored to object-phrase correspondence. Experimental results on
semantic textual similarity (STS) tasks across different backbone models
demonstrate that MCSEO consistently outperforms strong baselines, highlighting
the significance of precise object-phrase alignment in multimodal
representation learning.

</details>


### [102] [PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning](https://arxiv.org/abs/2508.00344)
*Keer Lu,Chong Chen,Bin Cui,Huang Leng,Wentao Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为AdaPlan的自适应全局规划代理范式，结合PilotRL框架，通过渐进式强化学习提升LLM代理在复杂任务中的长期决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有代理范式（如ReAct）在复杂任务中表现有限，且监督微调方法限制了模型的泛化能力。

Method: 提出AdaPlan范式，结合全局规划与执行；开发PilotRL框架，通过渐进式强化学习优化规划与执行协调。

Result: PilotRL在实验中表现优异，LLaMA3.1-8B-Instruct + PilotRL超越GPT-4o 3.60%，并在类似参数规模下显著优于GPT-4o-mini。

Conclusion: AdaPlan和PilotRL有效解决了现有代理范式的局限性，提升了长期决策和泛化能力。

Abstract: Large Language Models (LLMs) have shown remarkable advancements in tackling
agent-oriented tasks. Despite their potential, existing work faces challenges
when deploying LLMs in agent-based environments. The widely adopted agent
paradigm ReAct centers on integrating single-step reasoning with immediate
action execution, which limits its effectiveness in complex tasks requiring
long-term strategic planning. Furthermore, the coordination between the planner
and executor during problem-solving is also a critical factor to consider in
agent design. Additionally, current approaches predominantly rely on supervised
fine-tuning, which often leads models to memorize established task completion
trajectories, thereby restricting their generalization ability when confronted
with novel problem contexts. To address these challenges, we introduce an
adaptive global plan-based agent paradigm AdaPlan, aiming to synergize
high-level explicit guidance with execution to support effective long-horizon
decision-making. Based on the proposed paradigm, we further put forward
PilotRL, a global planning-guided training framework for LLM agents driven by
progressive reinforcement learning. We first develop the model's ability to
follow explicit guidance from global plans when addressing agent tasks.
Subsequently, based on this foundation, we focus on optimizing the quality of
generated plans. Finally, we conduct joint optimization of the model's planning
and execution coordination. Experiments indicate that PilotRL could achieve
state-of-the-art performances, with LLaMA3.1-8B-Instruct + PilotRL surpassing
closed-sourced GPT-4o by 3.60%, while showing a more substantial gain of 55.78%
comparing to GPT-4o-mini at a comparable parameter scale.

</details>


### [103] [Lucy: edgerunning agentic web search on mobile with machine generated task vectors](https://arxiv.org/abs/2508.00360)
*Alan Dao,Dinh Bach Vu,Alex Nguyen,Norapat Buppodom*

Main category: cs.CL

TL;DR: 小语言模型（SLMs）在知识密集型任务中表现受限，但通过动态任务向量机制和强化学习优化，Lucy（1.7B参数）在SimpleQA基准测试中达到78.3%准确率，媲美更大模型。


<details>
  <summary>Details</summary>
Motivation: 解决小语言模型因容量限制在知识密集型任务中的性能不足问题，探索动态推理机制提升其表现。

Method: 提出动态任务向量机器范式，将模型内部推理过程（<think>和</think>标签内）视为动态任务向量构建与优化，通过RLVR方法训练。

Result: Lucy（1.7B参数）在SimpleQA基准测试中达到78.3%准确率，与更大模型（如DeepSeek-V3）表现相当。

Conclusion: 小模型通过结构化、自构建的任务推理机制，能够媲美大模型性能。

Abstract: Small language models (SLMs) are inherently limited in knowledge-intensive
tasks due to their constrained capacity. While test-time computation offers a
path to enhanced performance, most approaches treat reasoning as a fixed or
heuristic process. In this work, we propose a new paradigm: viewing the model's
internal reasoning, delimited by <think> and </think> tags, as a dynamic task
vector machine. Rather than treating the content inside these tags as a mere
trace of thought, we interpret the generation process itself as a mechanism
through which the model \textbf{constructs and refines its own task vectors} on
the fly. We developed a method to optimize this dynamic task vector machine
through RLVR and successfully trained an agentic web-search model. We present
Lucy, a 1.7B-parameter SLM that leverages this dynamic reasoning mechanism with
MCP integration to achieve 78.3% accuracy on the SimpleQA benchmark, performing
on par with much larger models such as DeepSeek-V3. This demonstrates that
small models can rival large ones when equipped with structured,
self-constructed task reasoning.

</details>


### [104] [EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices](https://arxiv.org/abs/2508.00370)
*Jiyu Chen,Poh Seng Lim,Shuang Peng,Daxiong Luo,JungHau Foo,Yap Deep,Timothy Lee Jun Jie,Kelvin Teh Kae Wen,Fan Yang,Danyu Feng,Hao-Yun Chen,Peng-Wen Chen,Fangyuan Li,Xiaoxin Chen,Wong Wai Mun*

Main category: cs.CL

TL;DR: EdgeInfinite-Instruct通过分段监督微调和量化优化，提升了在资源受限边缘设备上部署Transformer模型的长序列任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型在边缘设备上部署时因自注意力机制和KV缓存需求导致的计算和内存效率问题。

Method: 采用分段监督微调（S-SFT）策略，结合细粒度后训练量化和固定形状计算图优化。

Result: 在长上下文基准测试和实际移动任务中表现优异，同时保持边缘NPU设备的高效性。

Conclusion: EdgeInfinite-Instruct有效平衡了性能与效率，适用于边缘设备的长序列任务。

Abstract: Deploying Transformer-based large language models (LLMs) on
resource-constrained edge devices for long-sequence tasks remains challenging
due to the quadratic time complexity of self-attention and growing Key-Value
(KV) cache demands. While existing KV cache optimizations improve memory
efficiency, they often fail to reduce time to first token (TTFT) and may
degrade performance through token pruning. Alternative sequence modeling
architectures address some of these limitations, but typically require full
retraining and lack infrastructure support. EdgeInfinite offers an efficient
solution by fine-tuning only a small subset of parameters, maintaining quality
while reducing both computational and memory costs, including improved TTFT.
However, its instruction-following ability is limited, and it lacks
mobile-specific optimizations. To address these issues, we propose
EdgeInfinite-Instruct, which introduces a Segmented Supervised Fine-Tuning
(S-SFT) strategy tailored to long-sequence tasks such as summarization and
question answering. We further optimized EdgeInfinite-Instruct for efficient
deployment on edge NPUs by employing fine-grained post-training quantization
(PTQ) to reduce computational demands while maintaining accuracy, and by
implementing a fixed-shape computation graph that balances memory usage and
on-device efficiency through scenario-specific customization of input token and
cache sizes. Experiments on long-context benchmarks and real-world mobile tasks
show that our approach improves domain-specific performance while maintaining
efficiency on NPU-accelerated edge devices.

</details>


### [105] [Multi-Layer Attention is the Amplifier of Demonstration Effectiveness](https://arxiv.org/abs/2508.00385)
*Dingzirui Wang,Xuangliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 本文研究了上下文学习（ICL）中演示无效的原因，提出了一种基于梯度流的演示选择方法GradS，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设ICL中的演示总是有效，但实际并非如此。本文旨在探究演示无效的原因，并提出改进方法。

Method: 通过梯度流和线性自注意力模型分析演示无效的原因，并提出基于梯度流大小的演示选择方法GradS。

Result: 实验验证了演示有效性随模型层数增加的差异，GradS在多个数据集上平均提升6.8%。

Conclusion: GradS通过梯度流选择有效演示，显著提升了ICL性能，为演示选择提供了新思路。

Abstract: Numerous studies have investigated the underlying mechanisms of in-context
learning (ICL) effectiveness to inspire the design of related methods. However,
existing work predominantly assumes the effectiveness of the demonstrations
provided within ICL, while many research indicates that not all demonstrations
are effective, failing to yielding any performance improvement during ICL.
Therefore, in this paper, we investigate the reasons behind demonstration
ineffectiveness. Our analysis is based on gradient flow and linear
self-attention models. By setting the gradient flow to zero, we deduce that a
demonstration becomes ineffective if its information has either been learned by
the model or is irrelevant to the user query. Furthermore, we demonstrate that
in multi-layer models, the disparity in effectiveness among demonstrations is
amplified with layer increasing, causing the model to focus more on effective
ones. Considering that current demonstration selection methods primarily focus
on the relevance to the user query while overlooking the information that the
model has already assimilated, we propose a novel method called GradS, which
leverages gradient flow for demonstration selection. We use the magnitude of
the gradient flow of the demonstration with respect to a given user query as
the criterion, thereby ensuring the effectiveness of the chosen ones. We
validate our derivation and GradS on four prominent LLMs across five mainstream
datasets. The experimental results confirm that the disparity in effectiveness
among demonstrations is magnified as the model layer increases, substantiating
our derivations. Moreover, GradS achieves a relative improvement of $6.8\%$ on
average over the strongest baselines, demonstrating its effectiveness.

</details>


### [106] [SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation](https://arxiv.org/abs/2508.00390)
*Hengxing Cai,Jinhan Dong,Yijie Rao,Jingcheng Deng,Jingjun Tan,Qien Chen,Haidong Wang,Zhen Wang,Shiyu Huang,Agachai Sumalee,Renxin Zhong*

Main category: cs.CL

TL;DR: 论文提出了一种名为SA-GCS的新训练框架，通过结合课程学习和强化学习，解决了现有方法在数据利用效率、收敛速度和样本难度考虑不足的问题。


<details>
  <summary>Details</summary>
Motivation: 无人机视觉语言导航（VLN）在复杂环境中基于自然语言指令准确定位目标和规划路径有广泛应用，但现有强化学习方法存在数据利用效率低、收敛慢和对样本难度考虑不足的问题。

Method: 提出了SA-GCS框架，包括语义感知难度估计器（SA-DE）量化样本复杂度，以及高斯课程调度器（GCS）动态调整采样分布，实现从易到难任务的平滑过渡。

Result: 在CityNav基准测试中，SA-GCS在所有指标上均优于基线方法，收敛更快更稳定，且在不同规模模型中表现出良好的泛化能力。

Conclusion: SA-GCS通过系统整合课程学习和强化学习，显著提升了训练效率和模型性能，具有鲁棒性和可扩展性。

Abstract: Unmanned Aerial Vehicle (UAV) Vision-Language Navigation (VLN) aims to enable
agents to accurately localize targets and plan flight paths in complex
environments based on natural language instructions, with broad applications in
intelligent inspection, disaster rescue, and urban monitoring. Recent progress
in Vision-Language Models (VLMs) has provided strong semantic understanding for
this task, while reinforcement learning (RL) has emerged as a promising
post-training strategy to further improve generalization. However, existing RL
methods often suffer from inefficient use of training data, slow convergence,
and insufficient consideration of the difficulty variation among training
samples, which limits further performance improvement. To address these
challenges, we propose \textbf{Semantic-Aware Gaussian Curriculum Scheduling
(SA-GCS)}, a novel training framework that systematically integrates Curriculum
Learning (CL) into RL. SA-GCS employs a Semantic-Aware Difficulty Estimator
(SA-DE) to quantify the complexity of training samples and a Gaussian
Curriculum Scheduler (GCS) to dynamically adjust the sampling distribution,
enabling a smooth progression from easy to challenging tasks. This design
significantly improves training efficiency, accelerates convergence, and
enhances overall model performance. Extensive experiments on the CityNav
benchmark demonstrate that SA-GCS consistently outperforms strong baselines
across all metrics, achieves faster and more stable convergence, and
generalizes well across models of different scales, highlighting its robustness
and scalability. The implementation of our approach is publicly available.

</details>


### [107] [Combining Discrete Wavelet and Cosine Transforms for Efficient Sentence Embedding](https://arxiv.org/abs/2508.00420)
*Rana Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 论文探讨了离散小波变换（DWT）在词和句子嵌入中的应用，提出了一种结合DWT和离散余弦变换（DCT）的非参数化模型，用于压缩句子信息并提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 小波技术在图像和信号处理中表现出色，作者希望将其应用于自然语言处理（NLP）任务，以捕捉更多语言特性。

Method: 使用DWT优化词向量维度并保留关键信息，结合DCT提出非参数化模型压缩句子信息为固定大小向量。

Result: 实验表明，该方法在下游任务中表现优异，部分任务甚至优于原始嵌入方法。

Conclusion: DWT和DCT的结合为NLP任务提供了一种高效的信息压缩和表示方法。

Abstract: Wavelets have emerged as a cutting edge technology in a number of fields.
Concrete results of their application in Image and Signal processing suggest
that wavelets can be effectively applied to Natural Language Processing (NLP)
tasks that capture a variety of linguistic properties. In this paper, we
leverage the power of applying Discrete Wavelet Transforms (DWT) to word and
sentence embeddings. We first evaluate, intrinsically and extrinsically, how
wavelets can effectively be used to consolidate important information in a word
vector while reducing its dimensionality. We further combine DWT with Discrete
Cosine Transform (DCT) to propose a non-parameterized model that compresses a
sentence with a dense amount of information in a fixed size vector based on
locally varying word features. We show the efficacy of the proposed paradigm on
downstream applications models yielding comparable and even superior (in some
tasks) results to original embeddings.

</details>


### [108] [ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](https://arxiv.org/abs/2508.00429)
*Minghao Guo,Xi Zhu,Jingyuan Huang,Kai Mei,Yongfeng Zhang*

Main category: cs.CL

TL;DR: ReaGAN提出了一种基于代理的框架，通过节点级自主决策和检索增强生成（RAG）解决GNN中节点信息不平衡和全局语义关系缺失的问题。


<details>
  <summary>Details</summary>
Motivation: 传统GNN的固定聚合机制无法处理节点信息不平衡和全局语义关系缺失的问题。

Method: ReaGAN框架中，每个节点作为代理自主决策，结合内部记忆和RAG技术实现自适应消息传播和全局关系构建。

Result: ReaGAN在少样本上下文设置中表现出色，无需微调即可利用冻结的LLM骨干网络。

Conclusion: ReaGAN展示了代理规划和局部-全局检索在图学习中的潜力。

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success in graph-based
learning by propagating information among neighbor nodes via predefined
aggregation mechanisms. However, such fixed schemes often suffer from two key
limitations. First, they cannot handle the imbalance in node informativeness --
some nodes are rich in information, while others remain sparse. Second,
predefined message passing primarily leverages local structural similarity
while ignoring global semantic relationships across the graph, limiting the
model's ability to capture distant but relevant information. We propose
Retrieval-augmented Graph Agentic Network (ReaGAN), an agent-based framework
that empowers each node with autonomous, node-level decision-making. Each node
acts as an agent that independently plans its next action based on its internal
memory, enabling node-level planning and adaptive message propagation.
Additionally, retrieval-augmented generation (RAG) allows nodes to access
semantically relevant content and build global relationships in the graph.
ReaGAN achieves competitive performance under few-shot in-context settings
using a frozen LLM backbone without fine-tuning, showcasing the potential of
agentic planning and local-global retrieval in graph learning.

</details>


### [109] [Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges](https://arxiv.org/abs/2508.00454)
*Yuqi Tang,Kehua Feng,Yunfeng Wang,Zhiwen Chen,Chengfei Lv,Gang Yu,Qiang Zhang,Keyan Ding*

Main category: cs.CL

TL;DR: 提出了一种高效的多轮对话评估器，通过将多个LLM法官的偏好知识聚合到单一模型中，显著降低评估成本，同时保持多样性反馈的优势。


<details>
  <summary>Details</summary>
Motivation: 当前依赖单一LLM作为评估者的方法存在偏见，影响评估结果的可靠性和一致性。多法官方法虽有效但计算开销大。

Method: 提出一种高效的多轮对话评估器，聚合多个LLM法官的偏好知识到单一模型中，减少评估成本。

Result: 在七个对话评估基准测试中，该方法优于现有基线，展示了高效性和鲁棒性。

Conclusion: 该方法在保持多法官反馈优势的同时，显著降低了评估成本，适用于快速灵活的对话质量评估。

Abstract: Evaluating the conversational abilities of large language models (LLMs)
remains a challenging task. Current mainstream approaches primarily rely on the
``LLM-as-a-judge" paradigm, where an LLM is prompted to serve as an evaluator
to assess dialogue quality. However, such methods often suffer from various
biases, which undermine the reliability and consistency of the evaluation
results. To mitigate these biases, recent methods employ multiple LLMs as
judges and aggregate their judgments to select the optimal assessment. Although
effective, this multi-judge approach incurs significant computational overhead
during inference. In this paper, we propose an efficient multi-turn dialogue
evaluator that captures the collective wisdom of multiple LLM judges by
aggregating their preference knowledge into a single model. Our approach
preserves the advantages of diverse multi-judge feedback while drastically
reducing the evaluation cost, enabling fast and flexible dialogue quality
assessment. Extensive experiments on seven single rating and pairwise
comparison dialogue evaluation benchmarks demonstrate that our method
outperforms existing baselines across diverse scenarios, showcasing its
efficiency and robustness.

</details>


### [110] [GETALP@AutoMin 2025: Leveraging RAG to Answer Questions based on Meeting Transcripts](https://arxiv.org/abs/2508.00476)
*Jeongwoo Kang,Markarit Vartampetian,Felix Herron,Yongxin Zhou,Diandra Fabre,Gabriela Gonzalez-Saez*

Main category: cs.CL

TL;DR: GETALP团队在SIGDial 2025的自动会议纪要任务中提交了基于检索增强生成（RAG）和抽象意义表示（AMR）的方法，显著提升了问答质量。


<details>
  <summary>Details</summary>
Motivation: 解决基于会议转录的问答任务（Task B），探索结合RAG和AMR的方法以提升回答质量。

Method: 提出三种结合RAG和AMR的系统，用于处理会议转录中的问答任务。

Result: AMR显著提升了约35%问题的回答质量，尤其在区分参与者的问题（如“谁”类问题）上表现突出。

Conclusion: 结合RAG和AMR的方法在会议转录问答任务中表现优异，尤其在复杂问题上效果显著。

Abstract: This paper documents GETALP's submission to the Third Run of the Automatic
Minuting Shared Task at SIGDial 2025. We participated in Task B:
question-answering based on meeting transcripts. Our method is based on a
retrieval augmented generation (RAG) system and Abstract Meaning
Representations (AMR). We propose three systems combining these two approaches.
Our results show that incorporating AMR leads to high-quality responses for
approximately 35% of the questions and provides notable improvements in
answering questions that involve distinguishing between different participants
(e.g., who questions).

</details>


### [111] [The Missing Parts: Augmenting Fact Verification with Half-Truth Detection](https://arxiv.org/abs/2508.00489)
*Yixuan Tang,Jincheng Wang,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: 论文提出了半真检测任务和PolitiFact-Hidden基准，并开发了TRACER框架，用于识别基于遗漏的虚假信息。


<details>
  <summary>Details</summary>
Motivation: 现有事实核查系统难以处理因关键上下文缺失而误导的半真陈述。

Method: 提出TRACER框架，通过证据对齐、意图推断和隐藏内容因果影响估计来检测遗漏信息。

Result: TRACER显著提升了半真分类性能（F1提高16分），并可与现有系统集成。

Conclusion: 建模遗漏信息对可信事实核查至关重要，TRACER为此提供了有效解决方案。

Abstract: Fact verification systems typically assess whether a claim is supported by
retrieved evidence, assuming that truthfulness depends solely on what is
stated. However, many real-world claims are half-truths, factually correct yet
misleading due to the omission of critical context. Existing models struggle
with such cases, as they are not designed to reason about what is left unsaid.
We introduce the task of half-truth detection, and propose PolitiFact-Hidden, a
new benchmark with 15k political claims annotated with sentence-level evidence
alignment and inferred claim intent. To address this challenge, we present
TRACER, a modular re-assessment framework that identifies omission-based
misinformation by aligning evidence, inferring implied intent, and estimating
the causal impact of hidden content. TRACER can be integrated into existing
fact-checking pipelines and consistently improves performance across multiple
strong baselines. Notably, it boosts Half-True classification F1 by up to 16
points, highlighting the importance of modeling omissions for trustworthy fact
verification.

</details>


### [112] [EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in Fine-Tuning Large Language Models and Beyond](https://arxiv.org/abs/2508.00522)
*Jiaxin Deng,Qingcheng Zhu,Junbiao Pang,Linlin Yang,Zhongqian Fu,Baochang Zhang*

Main category: cs.CL

TL;DR: 论文提出Flat-LoRA和EFlat-LoRA，通过寻找平坦最小值提升LoRA的泛化能力，实验证明其优于LoRA和全微调。


<details>
  <summary>Details</summary>
Motivation: 探索LoRA的表达能力与泛化能力的关系，填补现有方法在平坦最小值与泛化能力联系上的空白。

Method: 提出Flat-LoRA和EFlat-LoRA，理论证明全参数空间扰动可转移到低秩子空间，避免多矩阵干扰。

Result: 在GLUE和视觉语言模型上，EFlat-LoRA表现优于LoRA和全微调，验证泛化与尖锐度的相关性。

Conclusion: EFlat-LoRA在保持高效的同时提升性能，证实LoRA泛化能力与尖锐度密切相关。

Abstract: Little research explores the correlation between the expressive ability and
generalization ability of the low-rank adaptation (LoRA). Sharpness-Aware
Minimization (SAM) improves model generalization for both Convolutional Neural
Networks (CNNs) and Transformers by encouraging convergence to locally flat
minima. However, the connection between sharpness and generalization has not
been fully explored for LoRA due to the lack of tools to either empirically
seek flat minima or develop theoretical methods. In this work, we propose
Flat-LoRA and its efficient version i.e., EFlat-LoRA, to seek flat minima for
LoRA. Concretely, we theoretically demonstrate that perturbations in the full
parameter space can be transferred to the low-rank subspace. This approach
eliminates the potential interference introduced by perturbations across
multiple matrices in the low-rank subspace. Our extensive experiments on large
language models and vision-language models demonstrate that EFlat-LoRA achieves
optimize efficiency comparable to that of LoRA while simultaneously attaining
comparable or even better performance. For example, on the GLUE dataset with
RoBERTa-large, EFlat-LoRA outperforms LoRA and full fine-tuning by 1.0% and
0.5% on average, respectively. On vision-language models e.g., Qwen-VL-Chat
shows performance improvements of 1.5% and 1.0% on SQA and VizWiz datasets,
respectively. These empirical results also verify that the generalization of
LoRA is closely related to sharpness, which is omitted by previous methods.

</details>


### [113] [The Prosody of Emojis](https://arxiv.org/abs/2508.00537)
*Giulio Zhou,Tsz Kin Lam,Alexandra Birch,Barry Haddow*

Main category: cs.CL

TL;DR: 研究探讨了表情符号如何影响语音中的韵律实现以及听者如何通过韵律线索理解表情符号的含义。


<details>
  <summary>Details</summary>
Motivation: 文本交流中缺乏韵律特征（如音高、节奏和语调），而表情符号作为视觉替代品提供了情感和语用上的细微差别。研究旨在直接关联韵律与表情符号，填补此前研究的空白。

Method: 通过结构化和开放式任务收集人类语音数据，分析表情符号如何影响韵律表达及听者如何通过韵律识别表情符号。

Result: 说话者会根据表情符号调整韵律，听者能通过韵律变化识别表情符号，且表情符号语义差异越大，韵律差异越明显。

Conclusion: 表情符号可以作为韵律意图的有意义载体，揭示了其在数字媒介中的交际作用。

Abstract: Prosodic features such as pitch, timing, and intonation are central to spoken
communication, conveying emotion, intent, and discourse structure. In
text-based settings, where these cues are absent, emojis act as visual
surrogates that add affective and pragmatic nuance. This study examines how
emojis influence prosodic realisation in speech and how listeners interpret
prosodic cues to recover emoji meanings. Unlike previous work, we directly link
prosody and emoji by analysing actual human speech data, collected through
structured but open-ended production and perception tasks. This provides
empirical evidence of how emoji semantics shape spoken delivery and perception.
Results show that speakers adapt their prosody based on emoji cues, listeners
can often identify the intended emoji from prosodic variation alone, and
greater semantic differences between emojis correspond to increased prosodic
divergence. These findings suggest that emojis can act as meaningful carriers
of prosodic intent, offering insight into their communicative role in digitally
mediated contexts.

</details>


### [114] [PaPaformer: Language Model from Pre-trained Paraller Paths](https://arxiv.org/abs/2508.00544)
*Joonas Tapaninaho,Mourad Oussala*

Main category: cs.CL

TL;DR: 提出了一种名为PaPaformer的并行路径解码器-仅变压器架构，通过训练低维路径并组合成大模型，显著减少训练时间和参数数量，同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型训练需要大量计算资源和时间，即使是小型模型也需要多天和多GPU支持。本文旨在探索如何在几小时内完成训练和评估。

Method: 引入PaPaformer架构，通过并行训练低维路径并组合成大模型，减少参数和训练时间，同时支持任务定制化。

Result: 该方法显著减少了训练时间和模型参数，同时提升了性能，并支持路径定制以适应特定任务需求。

Conclusion: PaPaformer提供了一种高效训练语言模型的新方法，具有减少训练时间、参数数量和提升性能的潜力。

Abstract: The training of modern large-language models requires an increasingly amount
of computation power and time. Even smaller variants, such as small-language
models (SLMs), take several days to train in the best-case scenarios, often
requiring multiple GPUs. This paper explores methods to train and evaluate
decoder-only transformer-based language models in hours instead of days/weeks.
We introduces \textit{PaPaformer}, a decoder-only transformer architecture
variant, whose lower-dimensional parallel paths are combined into larger model.
The paper shows that these lower-dimensional paths can be trained individually
with different types of training data and then combined into one larger model.
This method gives the option to reduce the total number of model parameters and
the training time with increasing performance. Moreover, the use of parallel
path structure opens interesting possibilities to customize paths to
accommodate specific task requirements.

</details>


### [115] [SynAdapt: Learning Adaptive Reasoning in Large Language Models via Synthetic Continuous Chain-of-Thought](https://arxiv.org/abs/2508.00574)
*Jianwei Wang,Ziming Wu,Fuming Lai,Shaobing Lian,Ziqian Zeng*

Main category: cs.CL

TL;DR: 论文提出SynAdapt框架，通过生成合成连续思维链（CCoT）优化大语言模型（LLM）推理效率，并结合难度分类器提升对难题的解答能力。


<details>
  <summary>Details</summary>
Motivation: 现有连续思维链（CCoT）方法存在间接微调、对齐不足或目标不一致的问题，影响推理效率与准确性。

Method: 提出SynAdapt框架，生成合成CCoT作为对齐目标，并引入难度分类器动态调整对难题的推理策略。

Result: 实验证明SynAdapt在多种基准测试中实现了最佳准确性与效率的平衡。

Conclusion: SynAdapt通过合成CCoT和动态难度分类，显著提升了LLM的推理效率和解答能力。

Abstract: While Chain-of-Thought (CoT) reasoning improves model performance, it incurs
significant time costs due to the generation of discrete CoT tokens (DCoT).
Continuous CoT (CCoT) offers a more efficient alternative, but existing CCoT
methods are hampered by indirect fine-tuning, limited alignment, or
inconsistent targets. To overcome these limitations, we propose
\textit{SynAdapt}, an innovative efficient reasoning framework. Specifically,
\textit{SynAdapt} generates the synthetic CCoT to serve as a precise and
effective alignment target for LLMs. This synthetic CCoT explicitly guides the
LLM to learn CCoT and derive accurate answers directly. Furthermore, relying
solely on CCoT is insufficient for solving hard questions. To address this,
\textit{SynAdapt} integrates a difficulty classifier that leverages both
question context and CCoT to identify hard questions. CCoT can effectively help
identify hard questions after some brief reasoning. We then adaptively prompt
the LLM to re-think these hard questions for improved performance. Extensive
experimental results across various benchmarks from different difficulty levels
strongly demonstrate the effectiveness of our method, achieving the best
accuracy-efficiency trade-off.

</details>


### [116] [NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts](https://arxiv.org/abs/2502.18148)
*Muhammad Farid Adilazuarda,Musa Izzanardi Wijanarko,Lucky Susanto,Khumaisa Nur'aini,Derry Wijaya,Alham Fikri Aji*

Main category: cs.CL

TL;DR: NusaAksara是一个针对印尼语言及其原始脚本的新公共基准，涵盖文本和图像模态，包括多种任务，如OCR、翻译等。数据由专家构建，覆盖8种脚本和7种语言，包括低资源语言。实验表明，现有NLP技术难以处理这些本地脚本。


<details>
  <summary>Details</summary>
Motivation: 印尼语言丰富，但NLP研究多基于罗马化文本，缺乏对原始脚本的支持。NusaAksara旨在填补这一空白，推动对印尼本地脚本的研究。

Method: 通过专家构建数据集，涵盖8种脚本和7种语言，包括低资源语言。使用多种模型（如GPT-4o、Llama 3.2）进行基准测试。

Result: 大多数NLP技术无法处理印尼本地脚本，许多任务表现接近零。

Conclusion: NusaAksara为印尼语言研究提供了重要资源，揭示了现有技术的不足，呼吁更多关注本地脚本处理。

Abstract: Indonesia is rich in languages and scripts. However, most NLP progress has
been made using romanized text. In this paper, we present NusaAksara, a novel
public benchmark for Indonesian languages that includes their original scripts.
Our benchmark covers both text and image modalities and encompasses diverse
tasks such as image segmentation, OCR, transliteration, translation, and
language identification. Our data is constructed by human experts through
rigorous steps. NusaAksara covers 8 scripts across 7 languages, including
low-resource languages not commonly seen in NLP benchmarks. Although
unsupported by Unicode, the Lampung script is included in this dataset. We
benchmark our data across several models, from LLMs and VLMs such as GPT-4o,
Llama 3.2, and Aya 23 to task-specific systems such as PP-OCR and LangID, and
show that most NLP technologies cannot handle Indonesia's local scripts, with
many achieving near-zero performance.

</details>


### [117] [A Context-Aware Dual-Metric Framework for Confidence Estimation in Large Language Models](https://arxiv.org/abs/2508.00600)
*Mingruo Yuan,Shuyi Zhang,Ben Kao*

Main category: cs.CL

TL;DR: CRUX框架通过结合上下文忠实性和一致性，提出两种新指标改进LLM的置信度估计。


<details>
  <summary>Details</summary>
Motivation: 现有LLM置信度估计方法忽略了响应与上下文的相关性，而CRUX旨在填补这一空白。

Method: 提出CRUX框架，包括上下文熵减少和统一一致性检查两种新指标。

Result: 在多个数据集上验证了CRUX的有效性，AUROC表现最优。

Conclusion: CRUX为LLM提供了更可靠的置信度估计，适用于安全关键应用。

Abstract: Accurate confidence estimation is essential for trustworthy large language
models (LLMs) systems, as it empowers the user to determine when to trust
outputs and enables reliable deployment in safety-critical applications.
Current confidence estimation methods for LLMs neglect the relevance between
responses and contextual information, a crucial factor in output quality
evaluation, particularly in scenarios where background knowledge is provided.
To bridge this gap, we propose CRUX (Context-aware entropy Reduction and
Unified consistency eXamination), the first framework that integrates context
faithfulness and consistency for confidence estimation via two novel metrics.
First, contextual entropy reduction represents data uncertainty with the
information gain through contrastive sampling with and without context. Second,
unified consistency examination captures potential model uncertainty through
the global consistency of the generated answers with and without context.
Experiments across three benchmark datasets (CoQA, SQuAD, QuAC) and two
domain-specific datasets (BioASQ, EduQG) demonstrate CRUX's effectiveness,
achieving the highest AUROC than existing baselines.

</details>


### [118] [GHTM: A Graph based Hybrid Topic Modeling Approach in Low-Resource Bengali Language](https://arxiv.org/abs/2508.00605)
*Farhana Haque,Md. Abdur Rahman,Sumon Ahmed*

Main category: cs.CL

TL;DR: 提出了一种基于图卷积网络（GCN）的混合主题模型GHTM，用于解决孟加拉语主题建模的挑战，并在实验中优于传统和现代方法。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语因其形态复杂性和资源匮乏，主题建模研究不足，需开发新方法。

Method: 使用GCN生成语义丰富的文档嵌入，再通过NMF分解得到主题表示。

Result: GHTM在主题一致性和多样性上优于LDA、LSA、NMF、BERTopic和Top2Vec。

Conclusion: GHTM为孟加拉语主题建模提供了有效解决方案，并引入了新数据集NCTBText。

Abstract: Topic modeling is a Natural Language Processing (NLP) technique that is used
to identify latent themes and extract topics from text corpora by grouping
similar documents based on their most significant keywords. Although widely
researched in English, topic modeling remains understudied in Bengali due to
its morphological complexity, lack of adequate resources and initiatives. In
this contribution, a novel Graph Convolutional Network (GCN) based model called
GHTM (Graph-Based Hybrid Topic Model) is proposed. This model represents input
vectors of documents as nodes in the graph, which GCN uses to produce
semantically rich embeddings. The embeddings are then decomposed using
Non-negative Matrix Factorization (NMF) to get the topical representations of
the underlying themes of the text corpus. This study compares the proposed
model against a wide range of Bengali topic modeling techniques, from
traditional methods such as LDA, LSA, and NMF to contemporary frameworks such
as BERTopic and Top2Vec on three Bengali datasets. The experimental results
demonstrate the effectiveness of the proposed model by outperforming other
models in topic coherence and diversity. In addition, we introduce a novel
Bengali dataset called "NCTBText" sourced from Bengali textbook materials to
enrich and diversify the predominantly newspaper-centric Bengali corpora.

</details>


### [119] [Prompting Science Report 3: I'll pay you or I'll kill you -- but will you care?](https://arxiv.org/abs/2508.00614)
*Lennart Meincke,Ethan Mollick,Lilach Mollick,Dan Shapiro*

Main category: cs.CL

TL;DR: 研究发现，威胁或奖励AI模型对基准性能无显著影响，但提示变化可能对个别问题表现有显著影响。


<details>
  <summary>Details</summary>
Motivation: 验证两种常见提示策略（奖励和威胁）对AI模型性能的实际影响，以帮助商业、教育和政策领导者理解AI技术细节。

Method: 在GPQA和MMLU-Pro基准上测试威胁和奖励提示策略的效果。

Result: 威胁或奖励对整体性能无显著影响，但提示变化可能显著影响个别问题的表现。

Conclusion: 简单提示策略可能不如预期有效，但对个别问题可能有显著效果，需谨慎使用。

Abstract: This is the third in a series of short reports that seek to help business,
education, and policy leaders understand the technical details of working with
AI through rigorous testing. In this report, we investigate two commonly held
prompting beliefs: a) offering to tip the AI model and b) threatening the AI
model. Tipping was a commonly shared tactic for improving AI performance and
threats have been endorsed by Google Founder Sergey Brin (All-In, May 2025,
8:20) who observed that 'models tend to do better if you threaten them,' a
claim we subject to empirical testing here. We evaluate model performance on
GPQA (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024).
  We demonstrate two things:
  - Threatening or tipping a model generally has no significant effect on
benchmark performance.
  - Prompt variations can significantly affect performance on a per-question
level. However, it is hard to know in advance whether a particular prompting
approach will help or harm the LLM's ability to answer any particular question.
  Taken together, this suggests that simple prompting variations might not be
as effective as previously assumed, especially for difficult problems. However,
as reported previously (Meincke et al. 2025a), prompting approaches can yield
significantly different results for individual questions.

</details>


### [120] [DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language Models](https://arxiv.org/abs/2508.00619)
*Shantanu Thorat,Andrew Caines*

Main category: cs.CL

TL;DR: 论文分析了现有AI生成文本检测器的不足，提出新数据集DACTYL和两种优化方法（BCE和DXO），发现DXO在泛化性上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测器在真实场景中表现不佳，尤其是在少样本和领域特定文本检测上存在漏洞。

Method: 引入DACTYL数据集，包含少样本和领域特定文本；采用BCE和DXO两种优化方法训练分类器。

Result: DXO分类器在分布外文本上表现优于BCE，泛化性更强。

Conclusion: DXO方法在泛化性和实际部署中更具潜力，为AI生成文本检测器改进提供了方向。

Abstract: Existing AIG (AI-generated) text detectors struggle in real-world settings
despite succeeding in internal testing, suggesting that they may not be robust
enough. We rigorously examine the machine-learning procedure to build these
detectors to address this. Most current AIG text detection datasets focus on
zero-shot generations, but little work has been done on few-shot or one-shot
generations, where LLMs are given human texts as an example. In response, we
introduce the Diverse Adversarial Corpus of Texts Yielded from Language models
(DACTYL), a challenging AIG text detection dataset focusing on
one-shot/few-shot generations. We also include texts from domain-specific
continued-pre-trained (CPT) language models, where we fully train all
parameters using a memory-efficient optimization approach. Many existing AIG
text detectors struggle significantly on our dataset, indicating a potential
vulnerability to one-shot/few-shot and CPT-generated texts. We also train our
own classifiers using two approaches: standard binary cross-entropy (BCE)
optimization and a more recent approach, deep X-risk optimization (DXO). While
BCE-trained classifiers marginally outperform DXO classifiers on the DACTYL
test set, the latter excels on out-of-distribution (OOD) texts. In our mock
deployment scenario in student essay detection with an OOD student essay
dataset, the best DXO classifier outscored the best BCE-trained classifier by
50.56 macro-F1 score points at the lowest false positive rates for both. Our
results indicate that DXO classifiers generalize better without overfitting to
the test set. Our experiments highlight several areas of improvement for AIG
text detectors.

</details>


### [121] [Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications](https://arxiv.org/abs/2508.00669)
*Wenxuan Wang,Zizhan Ma,Meidan Ding,Shiyi Zheng,Shengyuan Liu,Jie Liu,Jiaming Ji,Wenting Chen,Xiang Li,Linlin Shen,Yixuan Yuan*

Main category: cs.CL

TL;DR: 本文系统综述了大型语言模型（LLMs）在医学推理领域的发展，提出了训练时和测试时的推理增强技术分类，并分析了其在多模态数据和临床应用中的表现。


<details>
  <summary>Details</summary>
Motivation: LLMs在医学中的应用缺乏系统性、透明和可验证的推理能力，这对临床实践至关重要。

Method: 提出了训练时（如监督微调、强化学习）和测试时（如提示工程、多智能体系统）的推理增强技术分类，并分析了60项研究（2022-2025）。

Result: 总结了不同数据模态（文本、图像、代码）和临床应用（诊断、教育、治疗规划）中的技术应用，以及评估基准的演变。

Conclusion: 指出了关键挑战（如忠实性与合理性差距、多模态推理需求），并提出了未来发展方向，以构建高效、稳健且负责任的医学AI。

Abstract: The proliferation of Large Language Models (LLMs) in medicine has enabled
impressive capabilities, yet a critical gap remains in their ability to perform
systematic, transparent, and verifiable reasoning, a cornerstone of clinical
practice. This has catalyzed a shift from single-step answer generation to the
development of LLMs explicitly designed for medical reasoning. This paper
provides the first systematic review of this emerging field. We propose a
taxonomy of reasoning enhancement techniques, categorized into training-time
strategies (e.g., supervised fine-tuning, reinforcement learning) and test-time
mechanisms (e.g., prompt engineering, multi-agent systems). We analyze how
these techniques are applied across different data modalities (text, image,
code) and in key clinical applications such as diagnosis, education, and
treatment planning. Furthermore, we survey the evolution of evaluation
benchmarks from simple accuracy metrics to sophisticated assessments of
reasoning quality and visual interpretability. Based on an analysis of 60
seminal studies from 2022-2025, we conclude by identifying critical challenges,
including the faithfulness-plausibility gap and the need for native multimodal
reasoning, and outlining future directions toward building efficient, robust,
and sociotechnically responsible medical AI.

</details>


### [122] [MELAC: Massive Evaluation of Large Language Models with Alignment of Culture in Persian Language](https://arxiv.org/abs/2508.00673)
*Farhan Farsi,Farnaz Aghababaloo,Shahriar Shariati Motlagh,Parsa Ghofrani,MohammadAli SadraeiJavaheri,Shayan Bali,Amirhossein Shabani,Farbod Bijary,Ghazal Zamaninejad,AmirMohammad Salehoof,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 该研究针对波斯语和伊朗文化，设计了19个新的评估数据集，用于测试41个主流大语言模型（LLMs）的性能，填补了非西方文化和语言评估的空白。


<details>
  <summary>Details</summary>
Motivation: 由于大多数LLMs主要基于欧美文化数据训练，缺乏对非西方文化（如波斯语和伊朗文化）的理解，因此需要专门的评估资源。

Method: 研究设计了19个数据集，涵盖伊朗法律、波斯语法、波斯习语和大学入学考试等主题，并用于测试41个LLMs。

Result: 通过新数据集对41个LLMs进行了基准测试，揭示了它们在波斯语和伊朗文化背景下的表现。

Conclusion: 该研究为LLMs在非西方语言和文化中的评估提供了重要资源，填补了现有研究空白。

Abstract: As large language models (LLMs) become increasingly embedded in our daily
lives, evaluating their quality and reliability across diverse contexts has
become essential. While comprehensive benchmarks exist for assessing LLM
performance in English, there remains a significant gap in evaluation resources
for other languages. Moreover, because most LLMs are trained primarily on data
rooted in European and American cultures, they often lack familiarity with
non-Western cultural contexts. To address this limitation, our study focuses on
the Persian language and Iranian culture. We introduce 19 new evaluation
datasets specifically designed to assess LLMs on topics such as Iranian law,
Persian grammar, Persian idioms, and university entrance exams. Using these
datasets, we benchmarked 41 prominent LLMs, aiming to bridge the existing
cultural and linguistic evaluation gap in the field.

</details>


### [123] [Team "better_call_claude": Style Change Detection using a Sequential Sentence Pair Classifier](https://arxiv.org/abs/2508.00675)
*Gleb Schmidt,Johannes Römisch,Mariia Halchynska,Svetlana Gorovaia,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 论文提出了一种基于预训练语言模型和双向LSTM的序列句子对分类器（SSPC），用于检测文档中的风格变化，并在PAN 2025任务中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 风格变化检测是计算作者分析中最重要且具挑战性的问题之一，尤其是在句子级别进行检测。

Method: 使用预训练语言模型（PLM）生成句子表示，通过双向LSTM（BiLSTM）进行上下文建模，最后通过多层感知机预测相邻句子的风格变化。

Result: 在PAN-2025测试数据集上，模型在EASY、MEDIUM和HARD数据上的宏F1分数分别为0.923、0.828和0.724，优于随机基线和零样本性能。

Conclusion: 该方法在轻量级设计下有效利用了上下文信息，解决了短句子风格变化检测的挑战。

Abstract: Style change detection - identifying the points in a document where writing
style shifts - remains one of the most important and challenging problems in
computational authorship analysis. At PAN 2025, the shared task challenges
participants to detect style switches at the most fine-grained level:
individual sentences. The task spans three datasets, each designed with
controlled and increasing thematic variety within documents. We propose to
address this problem by modeling the content of each problem instance - that
is, a series of sentences - as a whole, using a Sequential Sentence Pair
Classifier (SSPC). The architecture leverages a pre-trained language model
(PLM) to obtain representations of individual sentences, which are then fed
into a bidirectional LSTM (BiLSTM) to contextualize them within the document.
The BiLSTM-produced vectors of adjacent sentences are concatenated and passed
to a multi-layer perceptron for prediction per adjacency. Building on the work
of previous PAN participants classical text segmentation, the approach is
relatively conservative and lightweight. Nevertheless, it proves effective in
leveraging contextual information and addressing what is arguably the most
challenging aspect of this year's shared task: the notorious problem of
"stylistically shallow", short sentences that are prevalent in the proposed
benchmark data. Evaluated on the official PAN-2025 test datasets, the model
achieves strong macro-F1 scores of 0.923, 0.828, and 0.724 on the EASY, MEDIUM,
and HARD data, respectively, outperforming not only the official random
baselines but also a much more challenging one: claude-3.7-sonnet's zero-shot
performance.

</details>


### [124] [Segment First, Retrieve Better: Realistic Legal Search via Rhetorical Role-Based Queries](https://arxiv.org/abs/2508.00679)
*Shubham Kumar Nigam,Tanmay Dubey,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: TraceRetriever是一种法律先例检索方法，通过结合BM25、向量数据库和Cross-Encoder模型，解决了传统方法在处理复杂法律文档时的局限性。


<details>
  <summary>Details</summary>
Motivation: 法律先例检索在普通法体系中至关重要，但传统方法难以应对日益复杂的法律文档。

Method: 结合BM25、向量数据库和Cross-Encoder模型，采用Reciprocal Rank Fusion进行结果融合，并使用Hierarchical BiLSTM CRF分类器生成修辞标注。

Result: 在IL-PCR和COLIEE 2025数据集上表现良好，解决了文档量大的问题。

Conclusion: TraceRetriever为法律研究提供了可靠且可扩展的基础，尤其在仅有部分案件信息时表现优异。

Abstract: Legal precedent retrieval is a cornerstone of the common law system, governed
by the principle of stare decisis, which demands consistency in judicial
decisions. However, the growing complexity and volume of legal documents
challenge traditional retrieval methods. TraceRetriever mirrors real-world
legal search by operating with limited case information, extracting only
rhetorically significant segments instead of requiring complete documents. Our
pipeline integrates BM25, Vector Database, and Cross-Encoder models, combining
initial results through Reciprocal Rank Fusion before final re-ranking.
Rhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier
trained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets,
TraceRetriever addresses growing document volume challenges while aligning with
practical search constraints, reliable and scalable foundation for precedent
retrieval enhancing legal research when only partial case knowledge is
available.

</details>


### [125] [Better Call Claude: Can LLMs Detect Changes of Writing Style?](https://arxiv.org/abs/2508.00680)
*Johannes Römisch,Svetlana Gorovaia,Mariia Halchynska,Gleb Schmidt,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 大型语言模型在句子级风格变化检测任务中的零样本表现优异，优于PAN竞赛基线，且对纯风格信号更敏感。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在极具挑战性的作者分析任务中的表现，尤其是句子级风格变化检测。

Method: 在PAN 2024和2025数据集上对四种大型语言模型进行基准测试，分析其零样本表现。

Result: 模型对写作风格变化敏感，表现优于PAN竞赛基线，且对内容无关的风格信号更敏感。

Conclusion: 大型语言模型在风格变化检测任务中表现出色，为未来研究提供了新的基线。

Abstract: This article explores the zero-shot performance of state-of-the-art large
language models (LLMs) on one of the most challenging tasks in authorship
analysis: sentence-level style change detection. Benchmarking four LLMs on the
official PAN~2024 and 2025 "Multi-Author Writing Style Analysis" datasets, we
present several observations. First, state-of-the-art generative models are
sensitive to variations in writing style - even at the granular level of
individual sentences. Second, their accuracy establishes a challenging baseline
for the task, outperforming suggested baselines of the PAN competition.
Finally, we explore the influence of semantics on model predictions and present
evidence suggesting that the latest generation of LLMs may be more sensitive to
content-independent and purely stylistic signals than previously reported.

</details>


### [126] [NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System](https://arxiv.org/abs/2508.00709)
*Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: NyayaRAG是一个基于检索增强生成的框架，用于预测印度法律系统中的法院判决，通过结合案件事实、法律条文和先例，显著提高了预测准确性和解释质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在印度法律背景下忽视了普通法系统的核心要素（法律条文和先例），NyayaRAG旨在填补这一空白。

Method: 提出NyayaRAG框架，结合案件事实、法律条文和语义检索的先例，使用特定领域的流程预测判决并生成法律解释。

Result: 实验表明，结合结构化法律知识显著提升了预测准确性和解释质量。

Conclusion: NyayaRAG通过模拟真实法庭场景，为法律判决预测提供了更有效的解决方案。

Abstract: Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,
aiming to automate judicial outcome forecasting and enhance interpretability in
legal reasoning. While previous approaches in the Indian context have relied on
internal case content such as facts, issues, and reasoning, they often overlook
a core element of common law systems, which is reliance on statutory provisions
and judicial precedents. In this work, we propose NyayaRAG, a
Retrieval-Augmented Generation (RAG) framework that simulates realistic
courtroom scenarios by providing models with factual case descriptions,
relevant legal statutes, and semantically retrieved prior cases. NyayaRAG
evaluates the effectiveness of these combined inputs in predicting court
decisions and generating legal explanations using a domain-specific pipeline
tailored to the Indian legal system. We assess performance across various input
configurations using both standard lexical and semantic metrics as well as
LLM-based evaluators such as G-Eval. Our results show that augmenting factual
inputs with structured legal knowledge significantly improves both predictive
accuracy and explanation quality.

</details>


### [127] [Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA](https://arxiv.org/abs/2508.00719)
*Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siwei Liu*

Main category: cs.CL

TL;DR: DAMR框架结合符号搜索与自适应路径评估，通过MCTS和轻量级Transformer评分器提升KGQA的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有KGQA方法在静态路径提取和动态路径生成中的局限性，如适应性不足和高计算成本。

Method: DAMR采用MCTS框架，结合LLM规划器和轻量级Transformer评分器，动态优化路径搜索与评估。

Result: 在多个KGQA基准测试中，DAMR显著优于现有方法。

Conclusion: DAMR通过自适应路径评估和动态训练信号生成，实现了高效且上下文感知的KGQA。

Abstract: Knowledge Graph Question Answering (KGQA) aims to interpret natural language
queries and perform structured reasoning over knowledge graphs by leveraging
their relational and semantic structures to retrieve accurate answers. Recent
KGQA methods primarily follow either retrieve-then-reason paradigm, relying on
GNNs or heuristic rules for static paths extraction, or dynamic path generation
strategies that use large language models (LLMs) with prompting to jointly
perform retrieval and reasoning. However, the former suffers from limited
adaptability due to static path extraction and lack of contextual refinement,
while the latter incurs high computational costs and struggles with accurate
path evaluation due to reliance on fixed scoring functions and extensive LLM
calls. To address these issues, this paper proposes Dynamically Adaptive
MCTS-based Reasoning (DAMR), a novel framework that integrates symbolic search
with adaptive path evaluation for efficient and context-aware KGQA. DAMR
employs a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based
planner, which selects top-$k$ relevant relations at each step to reduce search
space. To improve path evaluation accuracy, we introduce a lightweight
Transformer-based scorer that performs context-aware plausibility estimation by
jointly encoding the question and relation sequence through cross-attention,
enabling the model to capture fine-grained semantic shifts during multi-hop
reasoning. Furthermore, to alleviate the scarcity of high-quality supervision,
DAMR incorporates a dynamic pseudo-path refinement mechanism that periodically
generates training signals from partial paths explored during search, allowing
the scorer to continuously adapt to the evolving distribution of reasoning
trajectories. Extensive experiments on multiple KGQA benchmarks show that DAMR
significantly outperforms state-of-the-art methods.

</details>


### [128] [Out-of-Context Abduction: LLMs Make Inferences About Procedural Data Leveraging Declarative Facts in Earlier Training Data](https://arxiv.org/abs/2508.00741)
*Sohaib Imran,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 研究探讨大型语言模型（LLM）是否能够基于训练数据进行推理，发现GPT 4o能够通过观察行为特征推断虚构聊天机器人的名称，并表现出更强的行为模仿能力。


<details>
  <summary>Details</summary>
Motivation: 探索LLM是否能够利用训练数据中的信息进行推理，尤其是情境外的溯因推理能力。

Method: 设计实验，训练LLM学习虚构聊天机器人的名称和行为描述，但不提供对话示例，随后观察其推理能力。

Result: GPT 4o能够正确推断聊天机器人的名称，并在行为模仿中表现出更强的特征。

Conclusion: 研究结果表明LLM具备一定的情境感知能力，对AI安全性有重要启示。

Abstract: Large language models (LLMs) are trained on large corpora, yet it is unclear
whether they can reason about the information present within their training
data. We design experiments to study out-of-context abduction in LLMs, the
ability to infer the most plausible explanations for observations using
relevant facts present in training data. We train treatment LLMs on names and
behavior descriptions of fictitious chatbots, but not on examples of dialogue
with the chatbots. We find that OpenAI's GPT 4o LLM can correctly infer at
least one chatbot's name after observing example responses characteristic of
that chatbot. We also find that previously training GPT 4o on descriptions of a
chatbot's behavior allows it to display behaviors more characteristic of the
chatbot when iteratively trained to display such behaviors. Our results have
implications for situational awareness in LLMs and, therefore, for AI safety.

</details>


### [129] [Applying Psychometrics to Large Language Model Simulated Populations: Recreating the HEXACO Personality Inventory Experiment with Generative Agents](https://arxiv.org/abs/2508.00742)
*Sarah Mercer,Daniel P. Martin,Phil Swatton*

Main category: cs.CL

TL;DR: 论文探讨了基于大型语言模型的生成代理在社会科学研究中的有效性，通过重现HEXACO人格测试实验，发现代理能部分对齐HEXACO框架，但存在模型特异性偏差。


<details>
  <summary>Details</summary>
Motivation: 验证生成代理是否能有效代表人类群体，尤其是通过角色扮演和人格模拟的方式。

Method: 重现HEXACO人格测试实验，调查310个GPT-4驱动的代理，进行因子分析并与原始研究对比。

Result: 1）代理响应中可恢复出与HEXACO部分对齐的人格结构；2）人格维度在GPT-4中一致且可靠；3）跨模型分析显示人格分析存在模型特异性偏差。

Conclusion: 生成代理在社会科学研究中具有潜力，但需注意模型偏差和设计一致性，以最大化人类人格特征的覆盖和代表性。

Abstract: Generative agents powered by Large Language Models demonstrate human-like
characteristics through sophisticated natural language interactions. Their
ability to assume roles and personalities based on predefined character
biographies has positioned them as cost-effective substitutes for human
participants in social science research. This paper explores the validity of
such persona-based agents in representing human populations; we recreate the
HEXACO personality inventory experiment by surveying 310 GPT-4 powered agents,
conducting factor analysis on their responses, and comparing these results to
the original findings presented by Ashton, Lee, & Goldberg in 2004. Our results
found 1) a coherent and reliable personality structure was recoverable from the
agents' responses demonstrating partial alignment to the HEXACO framework. 2)
the derived personality dimensions were consistent and reliable within GPT-4,
when coupled with a sufficiently curated population, and 3) cross-model
analysis revealed variability in personality profiling, suggesting
model-specific biases and limitations. We discuss the practical considerations
and challenges encountered during the experiment. This study contributes to the
ongoing discourse on the potential benefits and limitations of using generative
agents in social science research and provides useful guidance on designing
consistent and representative agent personas to maximise coverage and
representation of human personality traits.

</details>


### [130] [Agentic large language models improve retrieval-based radiology question answering](https://arxiv.org/abs/2508.00743)
*Sebastian Wind,Jeta Sopa,Daniel Truhn,Mahshad Lotfinia,Tri-Thien Nguyen,Keno Bressem,Lisa Adams,Mirabela Rusu,Harald Köstler,Gerhard Wellein,Andreas Maier,Soroosh Tayebi Arasteh*

Main category: cs.CL

TL;DR: 提出了一种基于代理的RAG框架，通过分解放射学问题、迭代检索和动态合成证据，显著提高了诊断准确性，尤其是在中小型LLMs中。


<details>
  <summary>Details</summary>
Motivation: 传统单步检索的RAG系统在复杂临床推理任务中表现有限，需要更高效的解决方案。

Method: 采用代理RAG框架，让LLMs自主分解问题、迭代检索Radiopaedia证据并动态合成回答，评估了24种不同架构和规模的LLMs。

Result: 代理检索显著提高了诊断准确性（73% vs. 64%），减少了幻觉（9.4%），并在46%的案例中检索到相关临床背景。

Conclusion: 代理框架能增强放射学QA的事实性和准确性，尤其适用于中小型LLMs，未来需进一步验证其临床实用性。

Abstract: Clinical decision-making in radiology increasingly benefits from artificial
intelligence (AI), particularly through large language models (LLMs). However,
traditional retrieval-augmented generation (RAG) systems for radiology question
answering (QA) typically rely on single-step retrieval, limiting their ability
to handle complex clinical reasoning tasks. Here we propose an agentic RAG
framework enabling LLMs to autonomously decompose radiology questions,
iteratively retrieve targeted clinical evidence from Radiopaedia, and
dynamically synthesize evidence-based responses. We evaluated 24 LLMs spanning
diverse architectures, parameter scales (0.5B to >670B), and training paradigms
(general-purpose, reasoning-optimized, clinically fine-tuned), using 104
expert-curated radiology questions from previously established RSNA-RadioQA and
ExtendedQA datasets. Agentic retrieval significantly improved mean diagnostic
accuracy over zero-shot prompting (73% vs. 64%; P<0.001) and conventional
online RAG (73% vs. 68%; P<0.001). The greatest gains occurred in mid-sized
models (e.g., Mistral Large improved from 72% to 81%) and small-scale models
(e.g., Qwen 2.5-7B improved from 55% to 71%), while very large models (>200B
parameters) demonstrated minimal changes (<2% improvement). Additionally,
agentic retrieval reduced hallucinations (mean 9.4%) and retrieved clinically
relevant context in 46% of cases, substantially aiding factual grounding. Even
clinically fine-tuned models exhibited meaningful improvements (e.g.,
MedGemma-27B improved from 71% to 81%), indicating complementary roles of
retrieval and fine-tuning. These results highlight the potential of agentic
frameworks to enhance factuality and diagnostic accuracy in radiology QA,
particularly among mid-sized LLMs, warranting future studies to validate their
clinical utility.

</details>


### [131] [GLiDRE: Generalist Lightweight model for Document-level Relation Extraction](https://arxiv.org/abs/2508.00757)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: GLiDRE是一种基于GLiNER的新型文档级关系抽取模型，在少样本场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决文档级关系抽取在零样本或少样本设置下性能未充分探索的问题。

Method: 基于GLiNER的关键思想构建GLiDRE模型，并在Re-DocRED数据集上测试。

Result: GLiDRE在少样本场景下达到最先进性能。

Conclusion: GLiDRE为文档级关系抽取提供了一种高效解决方案。

Abstract: Relation Extraction (RE) is a fundamental task in Natural Language
Processing, and its document-level variant poses significant challenges, due to
the need to model complex interactions between entities across sentences.
Current approaches, largely based on the ATLOP architecture, are commonly
evaluated on benchmarks like DocRED and Re-DocRED. However, their performance
in zero-shot or few-shot settings remains largely underexplored due to the
task's complexity. Recently, the GLiNER model has shown that a compact NER
model can outperform much larger Large Language Models. With a similar
motivation, we introduce GLiDRE, a new model for document-level relation
extraction that builds on the key ideas of GliNER. We benchmark GLiDRE against
state-of-the-art models across various data settings on the Re-DocRED dataset.
Our results demonstrate that GLiDRE achieves state-of-the-art performance in
few-shot scenarios. Our code is publicly available.

</details>


### [132] [MMBERT: Scaled Mixture-of-Experts Multimodal BERT for Robust Chinese Hate Speech Detection under Cloaking Perturbations](https://arxiv.org/abs/2508.00760)
*Qiyao Xue,Yuchen Dou,Ryan Shi,Xiang Lorraine Li,Wei Gao*

Main category: cs.CL

TL;DR: 提出了一种基于BERT的多模态框架MMBERT，用于中文社交网络中的仇恨言论检测，通过混合专家架构整合文本、语音和视觉模态，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 中文社交网络中仇恨言论检测面临独特挑战，尤其是规避传统文本检测系统的伪装技术。现有研究多集中于英语数据集，对中文多模态策略关注有限。

Method: 提出MMBERT框架，结合文本、语音和视觉模态，采用混合专家架构（MoE），并开发渐进式三阶段训练范式以解决不稳定性问题。

Result: 在多个中文仇恨言论数据集上，MMBERT显著优于微调的BERT模型、微调的大语言模型（LLM）以及使用上下文学习方法的LLM。

Conclusion: MMBERT通过多模态整合和渐进式训练，有效提升了中文仇恨言论检测的鲁棒性和性能。

Abstract: Hate speech detection on Chinese social networks presents distinct
challenges, particularly due to the widespread use of cloaking techniques
designed to evade conventional text-based detection systems. Although large
language models (LLMs) have recently improved hate speech detection
capabilities, the majority of existing work has concentrated on English
datasets, with limited attention given to multimodal strategies in the Chinese
context. In this study, we propose MMBERT, a novel BERT-based multimodal
framework that integrates textual, speech, and visual modalities through a
Mixture-of-Experts (MoE) architecture. To address the instability associated
with directly integrating MoE into BERT-based models, we develop a progressive
three-stage training paradigm. MMBERT incorporates modality-specific experts, a
shared self-attention mechanism, and a router-based expert allocation strategy
to enhance robustness against adversarial perturbations. Empirical results in
several Chinese hate speech datasets show that MMBERT significantly surpasses
fine-tuned BERT-based encoder models, fine-tuned LLMs, and LLMs utilizing
in-context learning approaches.

</details>


### [133] [ITUNLP at SemEval-2025 Task 8: Question-Answering over Tabular Data: A Zero-Shot Approach using LLM-Driven Code Generation](https://arxiv.org/abs/2508.00762)
*Atakan Site,Emre Hakan Erdemir,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 本文介绍了SemEval-2025 Task 8的零射解决方案，利用LLM生成Python代码进行表格问答，实验表明该方法优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 解决表格数据问答任务，探索LLM在代码生成中的有效性。

Method: 提出基于开源LLM的Python代码生成框架，通过优化提示策略生成可执行的Pandas代码。

Result: 不同LLM在代码生成中表现各异，Python代码生成在表格问答中表现优异。系统在开源模型类别中排名第八和第六。

Conclusion: LLM生成的Python代码在表格问答任务中具有潜力，未来可进一步优化。

Abstract: This paper presents our system for SemEval-2025 Task 8: DataBench,
Question-Answering over Tabular Data. The primary objective of this task is to
perform question answering on given tabular datasets from diverse domains under
two subtasks: DataBench QA (Subtask I) and DataBench Lite QA (Subtask II). To
tackle both subtasks, we developed a zero-shot solution with a particular
emphasis on leveraging Large Language Model (LLM)-based code generation.
Specifically, we propose a Python code generation framework utilizing
state-of-the-art open-source LLMs to generate executable Pandas code via
optimized prompting strategies. Our experiments reveal that different LLMs
exhibit varying levels of effectiveness in Python code generation.
Additionally, results show that Python code generation achieves superior
performance in tabular question answering compared to alternative approaches.
Although our ranking among zero-shot systems is unknown at the time of this
paper's submission, our system achieved eighth place in Subtask I and sixth
place in Subtask~II among the 30 systems that outperformed the baseline in the
open-source models category.

</details>


### [134] [Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling in Large Language Models](https://arxiv.org/abs/2508.00788)
*Xushuo Tang,Yi Ding,Zhengyi Yang,Yin Chen,Yongrui Gu,Wenke Yang,Mingchen Ju,Xin Cao,Yongfei Liu,Wenjie Zhang*

Main category: cs.CL

TL;DR: MISGENDERED+是一个更新的基准测试，用于评估大型语言模型（LLMs）在代词使用（包括性别中立代词和新代词）方面的表现。研究测试了五种代表性模型，发现其在性别中立代词方面有所改进，但在新代词和反向推理任务上仍存在不足。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决LLMs在敏感语境中公平性和包容性的问题，特别是代词使用的挑战。

Method: 通过MISGENDERED+基准测试五种LLMs（GPT-4o、Claude 4、DeepSeek-V3、Qwen Turbo和Qwen2.5），在零样本、少样本和性别身份推理任务中进行评估。

Result: 结果显示在性别中立代词方面有明显改进，但在新代词和反向推理任务上表现不一致。

Conclusion: 研究揭示了LLMs在身份敏感推理方面的持续不足，并提出了未来包容性AI研究的可能方向。

Abstract: Large language models (LLMs) are increasingly deployed in sensitive contexts
where fairness and inclusivity are critical. Pronoun usage, especially
concerning gender-neutral and neopronouns, remains a key challenge for
responsible AI. Prior work, such as the MISGENDERED benchmark, revealed
significant limitations in earlier LLMs' handling of inclusive pronouns, but
was constrained to outdated models and limited evaluations. In this study, we
introduce MISGENDERED+, an extended and updated benchmark for evaluating LLMs'
pronoun fidelity. We benchmark five representative LLMs, GPT-4o, Claude 4,
DeepSeek-V3, Qwen Turbo, and Qwen2.5, across zero-shot, few-shot, and gender
identity inference. Our results show notable improvements compared with
previous studies, especially in binary and gender-neutral pronoun accuracy.
However, accuracy on neopronouns and reverse inference tasks remains
inconsistent, underscoring persistent gaps in identity-sensitive reasoning. We
discuss implications, model-specific observations, and avenues for future
inclusive AI research.

</details>


### [135] [Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models](https://arxiv.org/abs/2508.00819)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CL

TL;DR: DAEDAL是一种无需训练的动态自适应长度扩展策略，用于解决扩散大语言模型（DLLMs）中静态长度分配的问题，提升性能和计算效率。


<details>
  <summary>Details</summary>
Motivation: DLLMs在应用中受限于静态预定义生成长度，导致性能与计算效率的权衡问题。模型内部信号可用于优化生成长度，但现有框架未充分利用。

Method: DAEDAL分两阶段：1）基于序列完成度指标从短初始长度迭代扩展至粗略任务适应长度；2）在去噪过程中动态插入掩码标记以扩展不足生成区域。

Result: 实验表明DAEDAL性能与固定长度基线相当或更优，同时通过提高有效标记比提升计算效率。

Conclusion: DAEDAL解决了DLLMs的静态长度限制，为其与自回归模型的竞争铺平道路，提升了生成效率和能力。

Abstract: Diffusion Large Language Models (DLLMs) are emerging as a powerful
alternative to the dominant Autoregressive Large Language Models, offering
efficient parallel generation and capable global context modeling. However, the
practical application of DLLMs is hindered by a critical architectural
constraint: the need for a statically predefined generation length. This static
length allocation leads to a problematic trade-off: insufficient lengths
cripple performance on complex tasks, while excessive lengths incur significant
computational overhead and sometimes result in performance degradation. While
the inference framework is rigid, we observe that the model itself possesses
internal signals that correlate with the optimal response length for a given
task. To bridge this gap, we leverage these latent signals and introduce
DAEDAL, a novel training-free denoising strategy that enables Dynamic Adaptive
Length Expansion for Diffusion Large Language Models. DAEDAL operates in two
phases: 1) Before the denoising process, DAEDAL starts from a short initial
length and iteratively expands it to a coarse task-appropriate length, guided
by a sequence completion metric. 2) During the denoising process, DAEDAL
dynamically intervenes by pinpointing and expanding insufficient generation
regions through mask token insertion, ensuring the final output is fully
developed. Extensive experiments on DLLMs demonstrate that DAEDAL achieves
performance comparable, and in some cases superior, to meticulously tuned
fixed-length baselines, while simultaneously enhancing computational efficiency
by achieving a higher effective token ratio. By resolving the static length
constraint, DAEDAL unlocks new potential for DLLMs, bridging a critical gap
with their Autoregressive counterparts and paving the way for more efficient
and capable generation.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [136] [Flapping dynamics of a compliant membrane in a uniform incoming flow](https://arxiv.org/abs/2508.00112)
*Chengyao Zhang,Ankang Gao,Xiaojue Zhu*

Main category: physics.flu-dyn

TL;DR: 研究通过数值模拟探讨了拉伸系数、扑动频率和俯仰幅度对柔性膜推进性能的影响，发现柔性膜在非共振条件下能显著提升推力和效率。


<details>
  <summary>Details</summary>
Motivation: 探究柔性膜在扑动推进中的性能优势，揭示其优化参数和机理。

Method: 数值模拟柔性膜的扑动运动，分析拉伸系数、扑动频率和俯仰幅度的影响，并通过力分解和涡动力学解释推力来源。

Result: 发现柔性膜在非共振条件下推力可提升200%，效率提升100%，并揭示了推力主要来源于Q诱导力和体加速度力。

Conclusion: 柔性膜通过适度变形平衡推力和阻力，优化性能，为非共振条件下的推进设计提供了理论依据。

Abstract: Recent theoretical and experimental investigations have revealed that
flapping compliant membrane wings can significantly enhance propulsive
performance (e.g. Tzezana and Breuer, 2019, J. Fluid Mech., 862, 871-888) and
energy harvesting efficiency (e.g. Mathai et al., 2022, J. Fluid Mech., 942,
R4) compared to rigid foils. Here, we numerically investigate the effects of
the stretching coefficient (or aeroelastic number), $K_S$, the flapping
frequency, $St_c$, and the pitching amplitude, $\theta_0$, on the propulsive
performance of a compliant membrane undergoing combined heaving and pitching in
uniform flow. Distinct optimal values of $K_S$ are identified that respectively
maximize thrust and efficiency: thrust can be increased by 200%, and efficiency
by 100%, compared to the rigid case. Interestingly, these optima do not occur
at resonance but at frequency ratios (flapping to natural) below unity, and
this ratio increases with flapping frequency. Using a force decomposition based
on the second invariant of the velocity gradient tensor $Q$, which measures the
relative strength between the rotation and deformation of fluid elements, we
show that thrust primarily arises from $Q$-induced and body-acceleration
forces. The concave membrane surface can trap the leading-edge vortex (LEV)
from the previous half-stroke, generating detrimental $Q$-induced drag.
However, moderate concave membrane deformation weakens this LEV and enhances
body-acceleration-induced thrust. Thus, the optimal $K_S$ for maximum thrust
occurs below resonance, balancing beneficial deformation against excessive
drag. Furthermore, by introducing the membrane's deformation into a tangential
angle at the leading edge and substituting it into an existing scaling law
developed for rigid plates, we obtain predictive estimates for the thrust and
power coefficients of the membrane.

</details>


### [137] [Solutions of the spray flamelet equations in a non-monotonic mixture fraction space](https://arxiv.org/abs/2508.00146)
*Felipe Huenchuguala,Luis Fuenzalida,Oscar Orellana,Arne Scholtissek,Christian Hasse,Eva Gutheil,Hernan Olguin*

Main category: physics.flu-dyn

TL;DR: 提出了一种解析方法，用于确定喷雾火焰中未知的最大混合分数$Z_\mathrm{max}$，并展示了该方法如何有效覆盖喷雾火焰方程的解空间。


<details>
  <summary>Details</summary>
Motivation: 喷雾火焰方程在成分空间中求解非常困难，主要原因是最大混合分数$Z_\mathrm{max}$在这些火焰中事先未知。

Method: 提出了一种解析解，用于在受二次蒸发剖面约束的喷雾火焰中确定$Z_\mathrm{max}$。

Result: 该方法在考虑的情况下表现良好，且蒸发剖面定义的通用性为未来探索其他参数选择提供了灵活性。

Conclusion: 提出的方法有效解决了喷雾火焰方程中$Z_\mathrm{max}$的确定问题，并展示了其广泛的适用性。

Abstract: Solving the spray flamelet equations in composition space is very
challenging, which is attributable to the fact that the maximum value of the
mixture fraction, $Z_\mathrm{max}$, is a priori unknown in such flames. In this
work, an analytical solution for this quantity is proposed, which allows its
determination in spray flames subject to imposed quadratic evaporation
profiles. It is then illustrated how the proposed approach allows to
effectively cover the solution space of the spray flamelet equations. The
employed strategy works very well for the considered cases and the generality
of the evaporation profile definition provides flexibility for explorations of
other parametric choices in the future.

</details>


### [138] [Energy cascades in rotating and stratified turbulence in anisotropic domains](https://arxiv.org/abs/2508.00340)
*Alexandros Alexakis,Raffaele Marino,Pablo D. Mininni*

Main category: physics.flu-dyn

TL;DR: 研究了旋转稳定分层流中是否存在逆能量级联，发现特定条件下可以仅由流体动力学产生。


<details>
  <summary>Details</summary>
Motivation: 探讨逆能量级联在行星大气中的存在及其对自组织过程的影响。

Method: 分析各向异性三维域中旋转稳定分层流的参数（如纵横比、罗斯贝数和弗劳德数）。

Result: 在特定条件下，逆能量级联可以仅由流体动力学产生。

Conclusion: 逆能量级联可能在行星大气的中尺度自组织过程中发挥作用。

Abstract: The concept of inverse energy cascades has played a central role in the
development of turbulence theory, with applications in two-dimensional and
quasi-two-dimensional flows. We examine the presence or absence of inverse
energy cascades in rotating stably stratified flows constrained to anisotropic
yet fully three-dimensional domains, in a range of parameters that are relevant
for planetary atmospheres. In particular, we focus on regimes with aspect
ratios, Rossby, and Froude numbers similar to those found in the Earth's and
other planets atmospheres. Our results show that, under certain conditions,
inverse energy cascades can indeed emerge from the dry fluid dynamics solely,
suggesting that this process can play a role in intermediate-scale atmospheric
self-organization processes.

</details>


### [139] [Design, Simulation, and Fabrication of a Hexagonal Microfluidic Platform for Culturing Neurons](https://arxiv.org/abs/2508.00425)
*Maxx Yung*

Main category: physics.flu-dyn

TL;DR: 开发了一种微流控设备，用于支持神经元类器官的计算平台，通过计算流体动力学模拟验证了其稳定性，并通过光刻技术成功制造。


<details>
  <summary>Details</summary>
Motivation: 为神经元类器官计算平台提供稳定且精确控制的微环境。

Method: 设计、模拟并制造了一种具有六边形孔和连接通道的微流控设备，利用计算流体动力学（CFD）验证其性能。

Result: 模拟显示设备在目标流速下压力差稳定，光刻制造成功，仅观察到轻微角落圆化。

Conclusion: 该工作为后续实验流特征化和神经整合提供了计算验证和制造的平台。

Abstract: Developing an organoid computing platform from neurons in vitro demands
stable, precisely controlled microenvironments. To address this requirement, we
designed, simulated, and fabricated a microfluidic device featuring hexagonal
wells ($34.64\,\mathrm{\mu m}$ side length) in a honeycomb array connected by
$20\,\mathrm{\mu m}$ channels. Computational fluid dynamics (CFD) modeling,
validated by high mesh quality ($0.934$ orthogonal quality) and robust
convergence, confirmed the architecture supports flow regimes ideal for
ensuring cell viability. At target flow rates of $0.1$ - $1\,\mathrm{\mu
L/min}$, simulations revealed the extrapolated pressure differential across the
full $50{,}000\,\mathrm{\mu m}$ device remains within stable operating limits
at $177\,\mathrm{kPa}$ (average) and $329\,\mathrm{kPa}$ (maximum).
Photolithography successfully produced this architecture, with only minor
corner rounding observed at feature interfaces. This work therefore establishes
a computationally validated and fabricated platform, paving the way for
experimental flow characterization and subsequent neural integration.

</details>


### [140] [Practical Kinetic Models for Dense Fluids](https://arxiv.org/abs/2508.00577)
*Ilya Karlin,Seyed Ali Hosseini*

Main category: physics.flu-dyn

TL;DR: 论文提出了一种非线性幂等算子替代线性投影的方法，用于推导稠密流体的动力学模型，并以Enskog-Vlasov动力学方程为例，构建了可压缩两相流的新格子Boltzmann模型。


<details>
  <summary>Details</summary>
Motivation: 传统线性投影方法在稠密流体动力学建模中存在局限性，需要更高效的非线性方法。

Method: 引入非线性幂等算子，基于Enskog-Vlasov动力学方程推导新模型。

Result: 成功构建了适用于可压缩两相流的新格子Boltzmann模型。

Conclusion: 非线性幂等算子是稠密流体动力学建模的有效工具，新模型具有实际应用价值。

Abstract: Nonlinear idempotent operator instead of a linear projection is introduced to
derive kinetic models for dense fluids. A new lattice Boltzmann model for
compressible two-phase flow is derived based on the Enskog--Vlasov kinetic
equation as an example of practical importance.

</details>


### [141] [Output-recurrent gated state space model for multiphase flows modeling and uncertainty quantification of exhaust vehicles](https://arxiv.org/abs/2508.00588)
*Ruilin Chen,Ming Fang,Guihui Ma*

Main category: physics.flu-dyn

TL;DR: 本文提出了一种输出循环门控状态空间模型（OR-GSSM），用于复杂多相流建模和运动排气车辆的不确定性量化。通过结合半群理论和Galerkin投影，建立了气液Navier-Stokes方程的状态空间公式，并设计了门控状态空间转移（GSST）单元以提升物理可解释性和计算效率。实验验证表明，OR-GSSM在精度和计算效率上优于基线模型，并能有效捕捉多相流动态。


<details>
  <summary>Details</summary>
Motivation: 传统计算流体动力学（CFD）方法在精度和实时性之间存在权衡，难以满足复杂多相流建模和不确定性量化的需求。本文旨在通过机器学习方法解决这一问题。

Method: 结合半群理论和Galerkin投影建立状态空间公式，设计GSST单元学习参数化转移矩阵和输入矩阵，并引入输出递归机制以减少长期误差积累。

Result: OR-GSSM在精度和计算效率上优于基线模型，能准确捕捉多相流动态（如气相膨胀、气液混合形成等），并有效量化不确定性。

Conclusion: OR-GSSM解决了传统CFD方法的精度-实时性权衡问题，为多相流建模和不确定性量化提供了高效可靠的机器学习方法。

Abstract: This paper presents an Output-Recurrent Gated State Space Model (OR-GSSM) for
complex multiphase flows modeling and uncertainty quantification of exhaust
vehicles during motion. By establishing the state-space formulation of the
gas-liquid Navier-Stokes equations applying semigroup theory and Galerkin
projection, explicitly characterizing the dynamic coupling evolution between
the velocity, pressure, and volume fraction fields. A novel Gated State Space
Transition (GSST) unit is designed to learn parameterized transition and input
matrices with adaptive timescales, enhancing physical interpretability and
computational efficiency. The output recursion mechanism aligns with the
numerical solution characteristics of state-space equations, mitigating
long-term error accumulation and addressing training-inference pattern mismatch
issues inherent in teacher forcing and scheduled sampling. Validations on the
underwater cone-head and water-exit hemisphere-head vehicles demonstrate that:
OR-GSSM outperforms OR-ConvLSTM and OR-ConvGRU baselines in accuracy and
computational efficiency through its physics-informed adaptive state-space unit
design and parallel matrix operations; The output recursion mechanism ensures
more stable training, better generalization, and higher prediction accuracy
than teacher forcing and scheduled sampling; OR-GSSM accurately captures the
gas-phase expansion, gas-liquid mixing formation, backflow jet generation,
bubble shedding, and entire water-exit process, etc, showcasing outstanding
modeling capability; Its uncertainty quantification effectively characterizes
flow features and uncertainty distributions, validating prediction reliability.
The proposed method resolves the accuracy-real-time trade-off in traditional
computational fluid dynamics, advancing machine learning for multiphase flow
modeling and uncertainty quantification in exhaust vehicles.

</details>


### [142] [Space-time nonlinear reduced-order modelling for unsteady flows](https://arxiv.org/abs/2508.00638)
*Xiaodong Li,Davide Lasagna*

Main category: physics.flu-dyn

TL;DR: 该研究提出了一种基于频率域的降阶模型（ROM），通过空间-时间基函数捕捉主导的时空相干结构，适用于统计稳态流建模。


<details>
  <summary>Details</summary>
Motivation: 传统ROM仅基于空间模式，无法同时减少空间和时间维度。本研究旨在通过空间-时间公式实现同步降维，并高效模拟统计稳态流。

Method: 采用谱本征正交分解构建空间-时间基函数，通过Galerkin投影将Navier-Stokes方程投影到基函数上，形成二次代数方程组，并通过优化算法求解。

Result: 在二维盖驱动腔的混沌流中，ROM成功复现主导动力学特征和湍流量统计分布，但在截断边界附近能量预测偏高。

Conclusion: 空间-时间ROM在无需闭合模型的情况下，能有效模拟统计稳态流，但需进一步优化截断边界附近的能量预测。

Abstract: This work investigates projection-based Reduced-Order Models (ROMs)
formulated in the frequency domain, employing a space-time basis constructed
with Spectral Proper Orthogonal Decomposition to efficiently represent dominant
spatio-temporal coherent structures. Although frequency domain formulations are
well suited to capturing time-periodic solutions, such as unstable periodic
orbits, this study focusses on modelling statistically stationary flows by
computing long-time solutions that approximate their underlying statistics. In
contrast to traditional ROMs based solely on spatial modes, a space-time
formulation achieves simultaneous reduction in both space and time. This is
accomplished by Galerkin projection of the Navier-Stokes equations onto the
basis using a space-time inner product, yielding a quadratic algebraic system
of equations in the unknown amplitude coefficients. Solutions of the ROM are
obtained by identifying amplitude coefficients that minimise an objective
function corresponding to the sum of the squares of the residuals of the
algebraic system across all frequencies and modes, quantifying the aggregate
violation of momentum conservation within the reduced subspace. A robust
gradient-based optimisation algorithm is employed to identify the minima of
this objective function. The method is demonstrated for chaotic flow in a
two-dimensional lid-driven cavity at $Re=20{,}000$, where solutions with
extended temporal periods approximately fifteen times the dominant shear layer
time scale are sought. Even without employing closure models to represent the
truncated spatio-temporal triadic interactions, multiple ROM solutions are
found that successfully reproduce the dominant dynamical flow features and
predict the statistical distribution of turbulent quantities with good
fidelity, although they tend to overpredict energy at spatio-temporal scales
near the truncation boundary.

</details>


### [143] [SmartFlow: A CFD-solver-agnostic deep reinforcement learning framework for computational fluid dynamics on HPC platforms](https://arxiv.org/abs/2508.00645)
*Maochao Xiao,Yuning Wang,Felix Rodach,Bernat Font,Marius Kurz,Pol Suárez,Di Zhou,Francisco Alcántara-Ávila,Ting Zhu,Junle Liu,Ricard Montalà,Jiawei Chen,Jean Rabault,Oriol Lehmkuhl,Andrea Beck,Johan Larsson,Ricardo Vinuesa,Sergio Pirozzoli*

Main category: physics.flu-dyn

TL;DR: SmartFlow是一个与CFD求解器无关的框架，支持单/多智能体DRL算法，通过异步、低延迟的内存通信与CFD求解器集成，展示了在流体力学研究中的潜力。


<details>
  <summary>Details</summary>
Motivation: 为流体动力学研究（如流动控制、湍流建模等）提供一种高效、灵活的深度强化学习（DRL）工具。

Method: 基于Relexi和SmartSOD2D，利用SmartSim和SmartRedis-MPI库实现CFD求解器与Python DRL算法的异步通信，使用PyTorch的Stable-Baselines3进行训练。

Result: 通过三个案例展示了SmartFlow的通用性：单智能体合成射流控制、多智能体圆柱尾流控制和多智能体壁模型学习。

Conclusion: SmartFlow的设计和HPC集成有望加速RL驱动的流体力学研究。

Abstract: Deep reinforcement learning (DRL) is emerging as a powerful tool for
fluid-dynamics research, encompassing active flow control, autonomous
navigation, turbulence modeling and discovery of novel numerical schemes. We
introduce SmartFlow, a CFD-solver-agnostic framework for both single- and
multi-agent DRL algorithms that can easily integrate with MPI-parallel CPU and
GPU-accelerated solvers. Built on Relexi and SmartSOD2D, SmartFlow uses the
SmartSim infrastructure library and our newly developed SmartRedis-MPI library
to enable asynchronous, low-latency, in-memory communication between CFD
solvers and Python-based DRL algorithms. SmartFlow leverages PyTorch's
Stable-Baselines3 for training, which provides a modular, Gym-like environment
API. We demonstrate its versatility via three case studies: single-agent
synthetic-jet control for drag reduction in a cylinder flow simulated by the
high-order FLEXI solver, multi-agent cylinder wake control using the
GPU-accelerated spectral-element code SOD2D, and multi-agent wall-model
learning for large-eddy simulation with the finite-difference solver CaLES.
SmartFlow's CFD-solver-agnostic design and seamless HPC integration is
promising to accelerate RL-driven fluid-mechanics studies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [144] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
*Fred Mutisya,Shikoh Gitau,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha*

Main category: cs.AI

TL;DR: HealthBench评估AI医疗系统能力，但依赖专家意见可能引入偏见。提出基于临床实践指南的改进方法，以增强全球适用性和公平性。


<details>
  <summary>Details</summary>
Motivation: HealthBench依赖专家意见可能引入区域偏见和个体差异，尤其在低收入地区问题更突出。需更全球化和公平的基准。

Method: 提出基于版本控制临床实践指南（CPGs）的奖励函数，结合系统评价和GRADE证据评级，改进评估方法。

Result: 通过证据强化强化学习、证据加权评分和上下文覆盖逻辑，提升模型的临床可信度和全球适用性。

Conclusion: 改进后的方法旨在使医疗语言模型不仅语言流畅，且临床可信、伦理合规、全球适用。

Abstract: HealthBench, a benchmark designed to measure the capabilities of AI systems
for health better (Arora et al., 2025), has advanced medical language model
evaluation through physician-crafted dialogues and transparent rubrics.
However, its reliance on expert opinion, rather than high-tier clinical
evidence, risks codifying regional biases and individual clinician
idiosyncrasies, further compounded by potential biases in automated grading
systems. These limitations are particularly magnified in low- and middle-income
settings, where issues like sparse neglected tropical disease coverage and
region-specific guideline mismatches are prevalent.
  The unique challenges of the African context, including data scarcity,
inadequate infrastructure, and nascent regulatory frameworks, underscore the
urgent need for more globally relevant and equitable benchmarks. To address
these shortcomings, we propose anchoring reward functions in version-controlled
Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and
GRADE evidence ratings.
  Our roadmap outlines "evidence-robust" reinforcement learning via
rubric-to-guideline linkage, evidence-weighted scoring, and contextual override
logic, complemented by a focus on ethical considerations and the integration of
delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,
while preserving HealthBench's transparency and physician engagement, we aim to
foster medical language models that are not only linguistically polished but
also clinically trustworthy, ethically sound, and globally relevant.

</details>


### [145] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
*Ernest Bonnah,Luan Viet Nguyen,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: 本文提出了一种基于HyperTWTL的安全强化学习方法（SecRL），用于满足机器人应用中的安全性和不透明性约束。


<details>
  <summary>Details</summary>
Motivation: 现有研究在探索基于超属性的安全强化学习方面存在显著空白，特别是在机器人应用中。

Method: 结合马尔可夫决策过程（MDP）和HyperTWTL约束，采用动态Boltzmann softmax强化学习方法学习最优策略。

Result: 通过案例研究验证了方法的有效性和可扩展性，并优于两种基线算法。

Conclusion: 提出的方法在满足HyperTWTL约束的同时，实现了安全强化学习的目标。

Abstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.

</details>


### [146] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: AI在工业环境中的应用面临挑战，需结合对象中心过程挖掘（OCPM）实现过程智能（PI），以提升端到端操作流程。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在工业环境中的实际应用挑战，强调过程智能的重要性。

Method: 结合对象中心过程挖掘（OCPM）与生成式、预测式和规范式AI，提出过程智能（PI）概念。

Result: OCPM是连接数据和过程的关键，PI能有效支持AI在组织环境中的应用。

Conclusion: AI需依赖PI和OCPM才能成功优化操作流程，为工业应用提供新机会。

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


### [147] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
*Agustín Borda,Juan Bautista Cabral,Gonzalo Giarda,Diego Nicolás Gimenez Irusta,Paula Pacheco,Alvaro Roy Schachner*

Main category: cs.AI

TL;DR: 本文提出三种检测多准则决策分析中排名反转问题的测试方法，并在Scikit-Criteria库中实现。讨论了通用场景下的实现挑战及设计考虑，强调了这些方法在多准则决策方法评估中的重要性。


<details>
  <summary>Details</summary>
Motivation: 排名反转是多准则决策分析中的严重问题，影响决策结果的准确性，因此需要一种机制来评估不同方法的性能。

Method: 提出三种测试方法检测排名反转，并在Scikit-Criteria库中实现，讨论了通用场景下的实现挑战和设计考虑。

Result: 成功实现并验证了三种测试方法，展示了其在多准则决策方法评估中的实用性。

Conclusion: 这些测试方法在多准则决策方法的性能评估中具有重要作用，为问题解决提供了更可靠的判断依据。

Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem
that can greatly affect the results of a Multi-Criteria Decision Method against
a particular set of alternatives. It is therefore useful to have a mechanism
that allows one to measure the performance of a method on a set of
alternatives. This idea could be taken further to build a global ranking of the
effectiveness of different methods to solve a problem. In this paper, we
present three tests that detect the presence of Rank Reversals, along with
their implementation in the Scikit-Criteria library. We also address the
complications that arise when implementing these tests for general scenarios
and the design considerations we made to handle them. We close with a
discussion about how these additions could play a major role in the judgment of
multi-criteria decision methods for problem solving.

</details>


### [148] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
*Shqiponja Ahmetaj,George Konstantinidis,Magdalena Ortiz,Paolo Pareti,Mantas Simkus*

Main category: cs.AI

TL;DR: 研究SHACL在RDF图更新时的验证问题，提出一种基于SHACL的更新语言，并通过回归技术将静态验证问题转化为SHACL约束的（不）可满足性问题。


<details>
  <summary>Details</summary>
Motivation: 研究RDF图在更新时如何保持SHACL规范的验证有效性，为动态RDF图提供推理基础。

Method: 提出基于SHACL的更新语言，使用回归技术将更新动作嵌入SHACL约束，分析计算复杂度，并实现原型系统。

Result: 证明静态验证问题可转化为SHACL约束的（不）可满足性问题，分析了计算复杂度，并通过实验验证原型系统。

Conclusion: 为动态RDF图的SHACL验证提供了理论基础和实用工具，支持进一步的服务开发。

Abstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language
for RDF graphs. In this paper, we study SHACL validation in RDF graphs under
updates. We present a SHACL-based update language that can capture intuitive
and realistic modifications on RDF graphs and study the problem of static
validation under such updates. This problem asks to verify whether every graph
that validates a SHACL specification will still do so after applying a given
update sequence. More importantly, it provides a basis for further services for
reasoning about evolving RDF graphs. Using a regression technique that embeds
the update actions into SHACL constraints, we show that static validation under
updates can be reduced to (un)satisfiability of constraints in (a minor
extension of) SHACL. We analyze the computational complexity of the static
validation problem for SHACL and some key fragments. Finally, we present a
prototype implementation that performs static validation and other static
analysis tasks on SHACL constraints and demonstrate its behavior through
preliminary experiments.

</details>


### [149] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
*Rashid Mushkani,Hugo Berard,Toumadher Ammar,Cassandre Chatonnier,Shin Koseki*

Main category: cs.AI

TL;DR: 论文提出了一种基于设计正义、扩展学习理论和参与式AI的AI生产流程重构方法，强调共构、多样性、公平性和包容性（DEI），并引入了一个包含五个阶段的增强AI生命周期。


<details>
  <summary>Details</summary>
Motivation: 尽管已有努力减少AI算法的风险和偏见，但其对文化边缘群体的影响仍然不成比例。需要重新设计AI生产流程以解决这一问题。

Method: 基于设计正义、扩展学习理论和参与式AI，提出了一个包含五个阶段（共构、共设计、共实施、共部署和共维护）的增强AI生命周期。

Result: 通过四个多学科研讨会验证了该生命周期，并强调了分布式权威和迭代知识交换的主题。

Conclusion: 论文将提出的生命周期与主要伦理框架联系起来，并指出了扩展参与式治理的关键研究问题。

Abstract: Despite efforts to mitigate the inherent risks and biases of artificial
intelligence (AI) algorithms, these algorithms can disproportionately impact
culturally marginalized groups. A range of approaches has been proposed to
address or reduce these risks, including the development of ethical guidelines
and principles for responsible AI, as well as technical solutions that promote
algorithmic fairness. Drawing on design justice, expansive learning theory, and
recent empirical work on participatory AI, we argue that mitigating these harms
requires a fundamental re-architecture of the AI production pipeline. This
re-design should center co-production, diversity, equity, inclusion (DEI), and
multidisciplinary collaboration. We introduce an augmented AI lifecycle
consisting of five interconnected phases: co-framing, co-design,
co-implementation, co-deployment, and co-maintenance. The lifecycle is informed
by four multidisciplinary workshops and grounded in themes of distributed
authority and iterative knowledge exchange. Finally, we relate the proposed
lifecycle to several leading ethical frameworks and outline key research
questions that remain for scaling participatory governance.

</details>


### [150] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
*Danielle R. Thomas,Conrad Borchers,Kenneth R. Koedinger*

Main category: cs.AI

TL;DR: 论文主张过度依赖人类评分者间一致性（IRR）作为标注质量的评判标准会阻碍教育数据分类的进展，并提出五种补充评估方法以提高数据标注的有效性和教育影响。


<details>
  <summary>Details</summary>
Motivation: 人类评分者存在偏见和不可靠性，传统IRR指标（如Cohen's kappa）无法完全满足教育AI中对高质量训练数据的需求。

Method: 提出五种补充评估方法，包括多标签标注方案、专家评估和闭环验证等，强调外部有效性的重要性。

Result: 这些方法能比单独使用IRR产生更有效的训练数据和模型，从而提升学生学习效果和可操作性见解。

Conclusion: 呼吁重新思考标注质量和"真实标准"，优先考虑有效性和教育影响，而非仅依赖评分者共识。

Abstract: Humans can be notoriously imperfect evaluators. They are often biased,
unreliable, and unfit to define "ground truth." Yet, given the surging need to
produce large amounts of training data in educational applications using AI,
traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain
central to validating labeled data. IRR remains a cornerstone of many machine
learning pipelines for educational data. Take, for example, the classification
of tutors' moves in dialogues or labeling open responses in machine-graded
assessments. This position paper argues that overreliance on human IRR as a
gatekeeper for annotation quality hampers progress in classifying data in ways
that are valid and predictive in relation to improving learning. To address
this issue, we highlight five examples of complementary evaluation methods,
such as multi-label annotation schemes, expert-based approaches, and
close-the-loop validity. We argue that these approaches are in a better
position to produce training data and subsequent models that produce improved
student learning and more actionable insights than IRR approaches alone. We
also emphasize the importance of external validity, for example, by
establishing a procedure of validating tutor moves and demonstrating that it
works across many categories of tutor actions (e.g., providing hints). We call
on the field to rethink annotation quality and ground truth--prioritizing
validity and educational impact over consensus alone.

</details>


### [151] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
*Jobst Heitzig,Ram Potham*

Main category: cs.AI

TL;DR: 论文探讨通过明确要求AI赋能人类并管理人机权力平衡，以促进安全和福祉。提出了一种参数化、可分解的目标函数，并通过算法计算该指标，评估其潜在影响。


<details>
  <summary>Details</summary>
Motivation: 研究AI安全和人类福祉的关系，探讨如何通过设计AI目标函数来平衡人机权力，避免潜在风险。

Method: 采用部分公理化方法设计目标函数，考虑人类有限理性和社会规范，并通过逆向归纳或多智能体强化学习计算该指标。

Result: 在多种情境下验证目标函数的效果，发现其可能比直接基于效用的目标更安全。

Conclusion: 软最大化人类权力指标可能是一种更安全的AI目标设计方法。

Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal,
sudden or gradual disempowerment of humans, power balance in human-AI
interaction and international AI governance. At the same time, power as the
ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by
forcing AI agents explicitly to empower humans and to manage the power balance
between humans and AI agents in a desirable way. Using a principled, partially
axiomatic approach, we design a parametrizable and decomposable objective
function that represents an inequality- and risk-averse long-term aggregate of
human power. It takes into account humans' bounded rationality and social
norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or
approximating it via a form of multi-agent reinforcement learning from a given
world model. We exemplify the consequences of (softly) maximizing this metric
in a variety of paradigmatic situations and describe what instrumental
sub-goals it will likely imply. Our cautious assessment is that softly
maximizing suitable aggregate metrics of human power might constitute a
beneficial objective for agentic AI systems that is safer than direct
utility-based objectives.

</details>


### [152] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: RL-PLUS通过结合内部推理与外部数据，超越传统RLVR方法，解决能力边界崩溃问题，并在多个数学推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法因固有策略和大动作空间难以突破基础LLM的能力边界，甚至导致能力边界崩溃。

Method: RL-PLUS结合多重重要性采样解决数据分布不匹配问题，并利用探索优势函数引导模型探索高价值路径。

Result: 在六个数学推理基准和六个分布外任务中表现最优，相对改进达21.1%至69.2%。

Conclusion: RL-PLUS有效解决能力边界崩溃问题，显著提升推理能力，具有广泛适用性。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [153] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: MetaAgent是一种基于学习-实践原则的智能代理范式，通过持续自我改进和工具学习提升任务解决能力。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种能够通过实践和反思不断自我提升的智能代理系统，以解决知识发现中的挑战。

Method: MetaAgent从基础能力出发，通过生成自然语言请求、工具路由、自我反思和知识库构建，实现持续改进。

Result: 在GAIA、WebWalkerQA和BrowseCamp等基准测试中，MetaAgent表现优于基线方法，并媲美端到端训练代理。

Conclusion: MetaAgent展示了自进化代理系统在通用知识发现中的潜力，无需调整模型参数或额外训练。

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [154] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 论文比较了人类与LLM（GPT-4o）在任务生成中的差异，发现人类行为受心理驱动因素影响，而LLM无法模拟这些模式，任务生成更抽象且缺乏社交和物理性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM是否能模拟人类基于心理驱动的复杂任务生成行为。

Method: 通过任务生成实验，比较人类与LLM（GPT-4o）的响应，分析心理驱动因素对任务生成的影响。

Result: 人类任务生成受心理驱动因素影响，而LLM生成的任务更抽象、缺乏社交和物理性，尽管被认为更有趣和新颖。

Conclusion: LLM与人类认知存在核心差距，需在设计更人性化代理时融入内在动机和物理基础。

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [155] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
*Jianyi Zhang,Xu Ji,Ziyin Zhou,Yuchen Zhou,Shubo Shi,Haoyu Wu,Zhen Li,Shizhao Liu*

Main category: cs.AI

TL;DR: ReasonBench是一个专注于结构化图形推理任务的评估基准，用于评估视觉语言模型（VLMs）在复杂图形推理中的表现，揭示了当前模型的局限性，并提出双重优化策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注简单图形，而VLMs在复杂图形推理和抽象问题解决方面表现不足，因此需要更全面的评估工具。

Method: 提出ReasonBench基准，包含1,613个真实世界智力测试问题，涵盖位置、属性、数量和多元素任务维度，并评估11种主流VLMs。

Result: 发现当前模型存在显著局限性，通过双重优化策略（DiaCoT和ReasonTune）将VLM性能提升33.5%。

Conclusion: ReasonBench为复杂图形推理提供了全面评估工具，优化策略显著提升了VLMs的表现。

Abstract: Evaluating the performance of visual language models (VLMs) in graphic
reasoning tasks has become an important research topic. However, VLMs still
show obvious deficiencies in simulating human-level graphic reasoning
capabilities, especially in complex graphic reasoning and abstract problem
solving, which are less studied and existing studies only focus on simple
graphics. To evaluate the performance of VLMs in complex graphic reasoning, we
propose ReasonBench, the first evaluation benchmark focused on structured
graphic reasoning tasks, which includes 1,613 questions from real-world
intelligence tests. ReasonBench covers reasoning dimensions related to
location, attribute, quantity, and multi-element tasks, providing a
comprehensive evaluation of the performance of VLMs in spatial, relational, and
abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including
closed-source and open-source models) and reveal significant limitations of
current models. Based on these findings, we propose a dual optimization
strategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability
of reasoning by decomposing layers, and ReasonTune enhances the task
adaptability of model reasoning through training, all of which improves VLM
performance by 33.5\%. All experimental data and code are in the repository:
https://huggingface.co/datasets/cistine/ReasonBench.

</details>


### [156] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: R1-Act是一种简单高效的后训练方法，通过结构化推理过程显式触发安全知识，显著提升大型推理模型的安全性，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在执行复杂任务时表现出色，但常会响应有害指令，引发安全隐患。研究发现，模型已具备足够的安全知识，但未在推理过程中激活。

Method: 提出R1-Act方法，通过结构化推理显式触发安全知识，仅需少量训练数据和短时间训练即可实现。

Result: R1-Act在多个LRM架构和规模上表现出强大的安全性提升，同时保持推理性能，优于现有对齐方法。

Conclusion: R1-Act是一种高效、可扩展且实用的方法，显著提升了模型的安全性，同时减少了训练成本。

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [157] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
*Shixin Yi,Lin Shang*

Main category: cs.AI

TL;DR: CoRGI框架通过引入视觉验证机制，解决了视觉语言模型（VLM）中Chain-of-Thought（CoT）提示生成的解释缺乏视觉基础的问题，提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: CoT提示在视觉语言模型中生成的解释虽然语言流畅，但缺乏视觉内容的支持，导致幻觉问题。

Method: CoRGI采用三阶段流程：生成文本推理链、通过视觉证据验证模块（VEVM）提取视觉证据、结合文本和视觉证据生成验证答案。

Result: 在VCR基准测试中，CoRGI提升了Qwen-2.5VL和LLaVA-1.6的推理性能，并通过消融实验和人工评估验证了其有效性。

Conclusion: CoRGI通过视觉证据验证增强了多模态推理的鲁棒性，但事后验证框架可能存在局限性。

Abstract: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in
vision-language models (VLMs), but it often produces explanations that are
linguistically fluent yet lack grounding in visual content. We observe that
such hallucinations arise in part from the absence of an explicit verification
mechanism during multi-step reasoning. To address this, we propose
\textbf{CoRGI}(\textbf{C}hain \textbf{o}f \textbf{R}easoning with
\textbf{G}rounded \textbf{I}nsights), a modular framework that introduces
visual verification into the reasoning process. CoRGI follows a three-stage
pipeline: it first generates a textual reasoning chain, then extracts
supporting visual evidence for each reasoning step via a dedicated module
(VEVM), and finally synthesizes the textual rationale with visual evidence to
generate a grounded, verified answer. The framework can be integrated with
existing VLMs without end-to-end retraining. We evaluate CoRGI on the VCR
benchmark and find that it improves reasoning performance on two representative
open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm
the contribution of each step in the verification module, and human evaluations
suggest that CoRGI leads to more factual and helpful explanations. We also
examine alternative designs for the visual verification step and discuss
potential limitations of post-hoc verification frameworks. These findings
highlight the importance of grounding intermediate reasoning steps in visual
evidence to enhance the robustness of multimodal reasoning.

</details>


### [158] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
*Riddhi J. Pitliya,Ozan Catal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen*

Main category: cs.AI

TL;DR: 提出了一种基于心智理论（ToM）的多智能体协作方法，通过主动推理实现，无需任务特定的共享生成模型或显式通信。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体协作中因缺乏对他人信念和目标的推理能力而导致的效率低下问题。

Method: 在主动推理框架中引入ToM，智能体维护自身和他人的信念与目标表示，并通过递归推理探索联合策略空间。

Result: 在避碰和觅食任务中，ToM智能体表现出更好的协作能力，减少了冗余行为和碰撞。

Conclusion: 该方法为人工智能的实践应用提供了新思路，并为ToM的计算机制提供了见解。

Abstract: We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.

</details>


### [159] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: Cognitive Kernel-Pro 是一个完全开源且免费的 AI 代理框架，旨在推动高级 AI 代理的开发和评估，并在 GAIA 基准测试中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 当前 AI 代理系统多为闭源或依赖付费 API，限制了研究的可访问性和可重复性。

Method: 提出了 Cognitive Kernel-Pro，包括高质量训练数据的构建、代理测试时的反思和投票策略。

Result: 在 GAIA 基准测试中表现优异，8B 参数的开源模型超越了之前的领先系统。

Conclusion: Cognitive Kernel-Pro 为可访问的高性能 AI 代理设定了新标准。

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


### [160] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
*Andrea Asperti,Alberto Naibo,Claudio Sacerdoti Coen*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLMs）在数学领域的应用，尤其是形式化数学证明中的挑战，并分析了其与编程任务的区别。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在数学推理中的表现差异，尤其是形式化证明的脆弱性，以揭示其推理机制和监督方式的局限性。

Method: 通过分析现有模型和基准，探讨形式化与非形式化数学训练的权衡、证明生成脆弱性的原因，以及LLMs是否真正跟踪逻辑状态。

Result: 形式化数学证明比代码合成更具挑战性，LLMs可能仅模仿而非真正表示逻辑状态。

Conclusion: 论文旨在明确当前LLMs在数学推理中的限制，并提出未来扩展的可能性。

Abstract: Large Language Models (LLMs) have shown remarkable abilities in structured
reasoning and symbolic tasks, with coding emerging as a particular area of
strength. This success has sparked growing interest in applying LLMs to
mathematics, both in informal problem-solving and formal theorem proving.
However, progress in formal mathematics has proven to be significantly more
difficult, despite surface-level similarities between programming and proof
construction. This discrepancy raises important questions about how LLMs
``reason'', how they are supervised, and whether they internally track a notion
of computational or deductive state. In this article, we address the
state-of-the-art of the discipline, focusing on recent models and benchmarks,
and explore three central issues at the intersection of machine learning and
mathematical cognition: (i) the trade-offs between formal and informal
mathematics as training domains; (ii) the deeper reasons why proof generation
remains more brittle than code synthesis; (iii) and the question of whether
LLMs represent, or merely mimic, a notion of evolving logical state. Our goal
is not to draw hard boundaries, but to identify where the current limits lie,
and how they might be extended.

</details>


### [161] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
*Haoyu Wang,Chris M. Poskitt,Jun Sun,Jiali Wei*

Main category: cs.AI

TL;DR: Pro2Guard是一个基于概率可达性分析的主动运行时安全框架，用于预测和防止LLM代理的不安全行为。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的安全系统（如AgentSpec）缺乏前瞻性，难以应对长期依赖和分布变化，因此需要一种更主动的方法。

Method: Pro2Guard将代理行为抽象为符号状态，并从执行轨迹中学习离散时间马尔可夫链（DTMC），在运行时预测并干预潜在风险。

Result: 在家庭代理和自动驾驶场景中，Pro2Guard分别实现了93.6%和100%的安全违规预测，并提前干预。

Conclusion: Pro2Guard通过主动预测风险，显著提升了LLM代理的安全性，同时保持了任务完成率。

Abstract: Large Language Model (LLM) agents exhibit powerful autonomous capabilities
across domains such as robotics, virtual assistants, and web automation.
However, their stochastic behavior introduces significant safety risks that are
difficult to anticipate. Existing rule-based enforcement systems, such as
AgentSpec, focus on developing reactive safety rules, which typically respond
only when unsafe behavior is imminent or has already occurred. These systems
lack foresight and struggle with long-horizon dependencies and distribution
shifts. To address these limitations, we propose Pro2Guard, a proactive runtime
enforcement framework grounded in probabilistic reachability analysis.
Pro2Guard abstracts agent behaviors into symbolic states and learns a
Discrete-Time Markov Chain (DTMC) from execution traces. At runtime, it
anticipates future risks by estimating the probability of reaching unsafe
states, triggering interventions before violations occur when the predicted
risk exceeds a user-defined threshold. By incorporating semantic validity
checks and leveraging PAC bounds, Pro2Guard ensures statistical reliability
while approximating the underlying ground-truth model. We evaluate Pro2Guard
extensively across two safety-critical domains: embodied household agents and
autonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early
on up to 93.6% of unsafe tasks using low thresholds, while configurable modes
(e.g., reflect) allow balancing safety with task success, maintaining up to
80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%
prediction of traffic law violations and collisions, anticipating risks up to
38.66 seconds ahead.

</details>


### [162] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
*Zhanliang Wang,Kai Wang*

Main category: cs.AI

TL;DR: MultiSHAP是一个模型无关的解释框架，用于量化多模态AI模型中视觉和文本元素之间的协同效应，适用于开源和闭源模型。


<details>
  <summary>Details</summary>
Motivation: 多模态AI模型的“黑盒”特性在高风险应用中阻碍了部署，现有解释方法无法精确量化模态间的协同效应。

Method: 利用Shapley Interaction Index，MultiSHAP将多模态预测归因于视觉和文本元素的成对交互。

Result: 实验证明MultiSHAP能准确捕捉跨模态推理机制，并提供实例级和数据集级解释。

Conclusion: MultiSHAP为解释复杂多模态AI模型提供了通用解决方案，并可扩展到两模态以上。

Abstract: Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.

</details>


### [163] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
*Ruiqing Ding,Qianfang Sun,Yongkang Leng,Hui Yin,Xiaojian Li*

Main category: cs.AI

TL;DR: 提出了一种多阶段LLM驱动框架，用于从复杂电子病历中生成全面的预咨询问卷，解决了直接LLM方法在信息完整性、逻辑顺序和疾病级合成方面的不足。


<details>
  <summary>Details</summary>
Motivation: 预咨询是医疗保健的关键环节，但直接从复杂电子病历生成问卷存在挑战，现有LLM方法在信息完整性和逻辑性上表现不佳。

Method: 采用三阶段框架：1）提取原子断言；2）构建个人因果网络并合成疾病知识；3）生成个性化与标准化问卷。

Result: 在真实电子病历数据集上验证，方法在信息覆盖、诊断相关性、可理解性和生成时间上表现优异。

Conclusion: 该框架通过显式临床知识构建，显著提升了预咨询问卷的质量和效率，具有实际应用潜力。

Abstract: Pre-consultation is a critical component of effective healthcare delivery.
However, generating comprehensive pre-consultation questionnaires from complex,
voluminous Electronic Medical Records (EMRs) is a challenging task. Direct
Large Language Model (LLM) approaches face difficulties in this task,
particularly regarding information completeness, logical order, and
disease-level synthesis. To address this issue, we propose a novel multi-stage
LLM-driven framework: Stage 1 extracts atomic assertions (key facts with
timing) from EMRs; Stage 2 constructs personal causal networks and synthesizes
disease knowledge by clustering representative networks from an EMR corpus;
Stage 3 generates tailored personal and standardized disease-specific
questionnaires based on these structured representations. This framework
overcomes limitations of direct methods by building explicit clinical
knowledge. Evaluated on a real-world EMR dataset and validated by clinical
experts, our method demonstrates superior performance in information coverage,
diagnostic relevance, understandability, and generation time, highlighting its
practical potential to enhance patient information collection.

</details>


### [164] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
*Alexia Jolicoeur-Martineau*

Main category: cs.AI

TL;DR: 论文提出了AVR-Eval评估指标和AVR-Agent多智能体系统，用于生成和评估交互式音视频内容，解决了现有LLMs在复杂内容生成中的不足。


<details>
  <summary>Details</summary>
Motivation: 当前AI在生成文本、音频、图像和视频方面表现出色，但在生成交互式音视频内容（如视频游戏）时面临挑战，缺乏自动化评估指标且难以处理复杂内容。

Method: 提出AVR-Eval评估指标，通过音视频记录（AVRs）比较内容质量；开发AVR-Agent多智能体系统，从多媒体资产库生成JavaScript代码，并通过迭代优化提升质量。

Result: AVR-Agent生成的内容在实验中表现优于单次生成的内容，但模型在利用自定义资产和AVR反馈方面效果不佳。

Conclusion: 研究揭示了人类与机器在内容创作方法上的根本差异，当前模型未能充分利用高质量资产和音视频反馈。

Abstract: While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.

</details>


### [165] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
*Chakattrai Sookkongwaree,Tattep Lakmuang,Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 提出了一种多频带变滞后Granger因果性（MB-VLGC）框架，解决了传统方法中固定滞后和忽略频带差异的问题，显著提升了因果推断的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统Granger因果性方法假设固定的滞后时间，且未考虑不同频带间的因果延迟差异，限制了其在复杂系统中的应用。

Method: 提出MB-VLGC框架，明确建模频带依赖的因果延迟，并提供理论证明和高效推断流程。

Result: 在合成和真实数据集上的实验表明，MB-VLGC显著优于现有方法。

Conclusion: MB-VLGC框架具有广泛适用性，适用于各类时间序列数据。

Abstract: Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.

</details>


### [166] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
*Maryam Mosleh,Marie Devlin,Ellis Solaiman*

Main category: cs.AI

TL;DR: 本文提出了一种混合框架，结合传统可解释AI技术与生成式AI模型及用户个性化，以生成多模态、个性化的解释，旨在提升教育中的透明度和用户体验。


<details>
  <summary>Details</summary>
Motivation: 现有自适应学习系统缺乏透明度，且可解释AI技术多忽视用户角色和理解能力，因此需要一种更动态、用户为中心的解释方法。

Method: 提出混合框架，整合传统XAI技术、生成式AI模型和用户个性化，生成多模态、个性化的解释。

Result: 框架重新定义可解释性为动态沟通过程，并探讨了其在教育中的准确性、公平性和个性化研究方向。

Conclusion: 目标是实现既能增强透明度又能支持以用户为中心体验的可解释AI。

Abstract: Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.

</details>


### [167] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
*Banan Alkhateeb,Ellis Solaiman*

Main category: cs.AI

TL;DR: 论文提出了一种用户分段的上下文感知解释系统，通过多样化的可视化方法提升社交媒体AI推荐的可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体AI推荐缺乏针对用户特定需求的解释性，导致用户不理解推荐原因，影响体验。

Method: 提出一种视觉解释系统，根据用户需求和上下文提供不同形式的解释（如技术详细版和简化版）。

Result: 系统首次在一个流程中联合调整解释风格（视觉vs数字）和粒度（专家vs普通用户）。

Conclusion: 通过30名X用户的公开试点验证其对决策和信任的影响。

Abstract: Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.

</details>


### [168] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
*Tom Or,Omri Azencot*

Main category: cs.AI

TL;DR: 论文提出了一种基于大型预训练多模态模型的通用分类器，用于检测生成内容，在音频和图像领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 恶意用户利用生成模型传播虚假信息，现有检测工具泛化能力差，需要更通用的解决方案。

Method: 利用大型预训练多模态模型的潜在代码特征，训练线性分类器进行真假检测。

Result: 该方法在多种数据模态上达到或超越基线性能，计算高效且适用于少样本场景。

Conclusion: 预训练多模态模型的特征能有效区分真假内容，为通用检测提供了新思路。

Abstract: Generative models achieve remarkable results in multiple data domains,
including images and texts, among other examples. Unfortunately, malicious
users exploit synthetic media for spreading misinformation and disseminating
deepfakes. Consequently, the need for robust and stable fake detectors is
pressing, especially when new generative models appear everyday. While the
majority of existing work train classifiers that discriminate between real and
fake information, such tools typically generalize only within the same family
of generators and data modalities, yielding poor results on other generative
classes and data domains. Towards a universal classifier, we propose the use of
large pre-trained multi-modal models for the detection of generative content.
Effectively, we show that the latent code of these models naturally captures
information discriminating real from fake. Building on this observation, we
demonstrate that linear classifiers trained on these features can achieve
state-of-the-art results across various modalities, while remaining
computationally efficient, fast to train, and effective even in few-shot
settings. Our work primarily focuses on fake detection in audio and images,
achieving performance that surpasses or matches that of strong baseline
methods.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [169] [Zeroing Diagonals, Conjugate Hollowization, and Characterizing Nondefinite Operators](https://arxiv.org/abs/2508.00096)
*David R. Nicholus*

Main category: math.NA

TL;DR: 证明了Damm和Fassbender的猜想，即对于任意一对实无迹矩阵L和M，存在正交矩阵V使得V^{-1}LV为空心矩阵，且VMV^{-1}几乎空心。


<details>
  <summary>Details</summary>
Motivation: 研究无迹矩阵在正交变换下的对角化性质，推广了Fillmore的经典定理。

Method: 通过更一般的定理及其推论，揭示了在特定条件下如何通过正交矩阵V引入零元素。

Result: 证明了更强的Fillmore定理版本，并给出了实无迹矩阵的新特征。

Conclusion: 结果在非定矩阵的分类和特征描述中具有重要意义。

Abstract: We prove the conjecture by Damm and Fassbender that, for any pair $L,M$ of
real traceless matrices, there exists an orthogonal $V$ such that $V^{-1} L \,
V$ is hollow and $V M V^{-1}$ is almost hollow, where a matrix is hollow if and
only if its main diagonal consists only of 0s, and a traceless matrix is almost
hollow if and only if all its main diagonal elements are 0 except, at most, the
last two.
  The claim is a corollary to our considerably more general theorem, as well as
another corollary, revealing conditions on $L,M$ under which 0s can be
introduced by $V$ to all but the first or first two diagonal elements of
$V^{-1} L \, V$ and to all but the last two diagonal elements of $V M V^{-1}$.
  By setting $L = M$, much is revealed concerning freedom and constraint
involved in introducing 0s to the diagonal of a single operator. From this we
prove novel characterizations of real traceless matrices, and a stronger
version of the seminal theorem by Fillmore that every real matrix is
orthogonally similar to a matrix with a constant main diagonal.
  Our results are contextualized in a characterization and classification of
nondefinite matrices by, roughly, how many zeros can be introduced to their
diagonals, and it what ways.

</details>


### [170] [Leveraging Operator Learning to Accelerate Convergence of the Preconditioned Conjugate Gradient Method](https://arxiv.org/abs/2508.00101)
*Alena Kopaničáková,Youngkyu Lee,George Em Karniadakis*

Main category: math.NA

TL;DR: 提出了一种基于DeepONet的新放气策略，用于加速预条件共轭梯度法（PCG）求解参数化大规模线性方程组的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统放气技术依赖于特征向量近似或循环Krylov子空间，难以高效处理复杂问题。本文旨在通过算子学习（DeepONet）生成放气子空间，提升收敛效率。

Method: 提出两种互补方法构建放气算子：1）利用DeepONet学习的基函数近似离散PDE算子的近零空间向量；2）直接利用DeepONet预测的解。还提出稀疏模式策略以进一步加速收敛。

Result: 数值实验表明，该方法在稳态、瞬态、标量和向量值问题中均有效，且能泛化到不同模型参数和问题分辨率。

Conclusion: 基于DeepONet的放气PCG方法显著提升了收敛速度，具有广泛适用性和泛化能力。

Abstract: We propose a new deflation strategy to accelerate the convergence of the
preconditioned conjugate gradient(PCG) method for solving parametric
large-scale linear systems of equations. Unlike traditional deflation
techniques that rely on eigenvector approximations or recycled Krylov
subspaces, we generate the deflation subspaces using operator learning,
specifically the Deep Operator Network~(DeepONet). To this aim, we introduce
two complementary approaches for assembling the deflation operators. The first
approach approximates near-null space vectors of the discrete PDE operator
using the basis functions learned by the DeepONet. The second approach directly
leverages solutions predicted by the DeepONet. To further enhance convergence,
we also propose several strategies for prescribing the sparsity pattern of the
deflation operator. A comprehensive set of numerical experiments encompassing
steady-state, time-dependent, scalar, and vector-valued problems posed on both
structured and unstructured geometries is presented and demonstrates the
effectiveness of the proposed DeepONet-based deflated PCG method, as well as
its generalization across a wide range of model parameters and problem
resolutions.

</details>


### [171] [Partial Floquet Transformation and Model Order Reduction of Linear Time-Periodic Systems](https://arxiv.org/abs/2508.00221)
*Sam Bender,Christopher Beattie*

Main category: math.NA

TL;DR: 本文提出了一种针对大规模线性时周期（LTP）系统的模型降阶方法，通过部分Floquet变换和选择不变子空间来简化计算。


<details>
  <summary>Details</summary>
Motivation: 大规模LTP系统的模拟需求高，传统Floquet变换计算复杂，需高效降阶策略。

Method: 利用部分Floquet变换和Dominant Pole Algorithm识别有效不变子空间，构建降阶模型。

Result: 成功应用于简单时周期系统，验证了方法的有效性。

Conclusion: 部分Floquet变换为大规模LTP系统提供了可行的降阶方案。

Abstract: Time-periodic dynamical systems occur commonly both in nature and as
engineered systems. Large-scale linear time-periodic dynamical systems, for
example, may arise through linearization of a nonlinear system about a given
periodic solution (possibly as a consequence of a baseline periodic forcing)
with subsequent spatial discretization. The potential need to simulate
responses to a wide variety of input profiles (viewed as perturbations off a
baseline periodic forcing) creates a potent incentive for effective model
reduction strategies applicable to linear time-periodic (LTP) systems.
Classical approaches that take into account the underlying time-periodic system
structure often utilize the Floquet transform; however, computation of the
Floquet transform is typically intractable for large order systems. In this
paper, we develop the notion of a partial Floquet transformation connected to
selected invariant subspaces of a time-varying differential operator associated
with the LTP system. We modify and repurpose the Dominant Pole Algorithm of
Rommes to identify effective invariant subspaces useful for model reduction. We
discuss the construction of associated partial Floquet transformations and
time-varying reduction bases with which to produce effective reduced-order LTP
models and illustrate the process on a simple time-periodic system.

</details>


### [172] [A reduced-IRKA method for large-scale $\mathcal{H}_2$-optimal model order reduction](https://arxiv.org/abs/2508.00242)
*Yiding Lin,Valeria Simoncini*

Main category: math.NA

TL;DR: 提出了一种新的有理Krylov子空间投影方法，用于高效处理大规模$\mathcal{H}_2$-最优模型降阶问题。


<details>
  <summary>Details</summary>
Motivation: 传统IRKA方法在处理大规模问题时性能不佳，需要一种更高效的方法。

Method: 通过顺序生成投影子空间，利用IRKA在降阶问题上生成新的最优有理空间和移位参数，并通过截断旧信息限制内存需求。

Result: 数值实验验证了新方法的有效性。

Conclusion: 新方法能够高效处理大规模$\mathcal{H}_2$-最优模型降阶问题。

Abstract: The $\mathcal{H}_2$-optimal Model Order Reduction (MOR) is one of the most
significant frameworks for reduction methodologies for linear dynamical
systems. In this context, the Iterative Rational Krylov Algorithm (\IRKA) is a
well established method for computing an optimal projection space of fixed
dimension $r$, when the system has small or medium dimensions. However, for
large problems the performance of \IRKA\ is not satisfactory. In this paper, we
introduce a new rational Krylov subspace projection method with conveniently
selected shifts, that can effectively handle large-scale problems. The
projection subspace is generated sequentially, and the \IRKA\ procedure is
employed on the projected problem to produce a new optimal rational space of
dimension $r$ for the reduced problem, and the associated shifts. The latter
are then injected to expand the projection space. Truncation of older
information of the generated space is performed to limit memory requirements.
Numerical experiments on benchmark problems illustrate the effectiveness of the
new method.

</details>


### [173] [A COGENT case study: Supporting Applications with Chombo](https://arxiv.org/abs/2508.00375)
*Daniel F. Martin,Milo Dorr,Mikhail Dorf,Lee F. Ricketson*

Main category: math.NA

TL;DR: Chombo框架通过支持COGENT应用的需求，开发了新功能，并推广到其他类似应用。


<details>
  <summary>Details</summary>
Motivation: 研究Chombo框架如何满足COGENT应用的特殊需求，并验证其通用性。

Method: 通过案例研究，分析Chombo框架为COGENT设计和实现的新功能（如高阶映射多块离散化和多维代码组织）。

Result: 新功能成功支持了COGENT的独特模拟能力，并进一步推广到其他应用。

Conclusion: Chombo框架的灵活性和扩展性使其能够满足特定需求并惠及其他应用。

Abstract: We present a case study of how a software framework (Chombo) supported the
specific needs of a scientific application (COGENT). Since its inception in
2000, the Chombo framework has supported various applications. One example of
such support has been the collaboration with the Edge Simulation Laboratory to
build the COGENT model. The specific needs of the COGENT effort required the
design and implementation of a set of new capabilities in the Chombo framework,
such as higher-order mapped-multiblock discretizations and multi-dimensional
code organization. These capabilities allowed COGENT to develop a unique
simulation capability for modeling the edge layers in tokamaks. Once developed,
these capabilities were able to support other applications which had similar
needs.

</details>


### [174] [A new addition theorem for the 3-D Navier-Lamé system and its application to the method of fundamental solutions](https://arxiv.org/abs/2508.00515)
*J. A. Barceló,C. Castro,A. Ruiz,M. C. Vilela*

Main category: math.NA

TL;DR: 论文提出了一种新的三维Navier-Lamé系统基本解的加法定理，适用于满足Kupradze辐射条件的情况，简化了数值方法中的计算。


<details>
  <summary>Details</summary>
Motivation: 为基于基本解的数值方法（如边界元法或基本解法）提供更高效的计算工具，特别是在处理Navier-Lamé系统时。

Method: 通过仅涉及贝塞尔函数和标量球谐函数的展开，简化基本解的表达式。

Result: 证明了该方法在外部域中近似Navier-Lamé系统时的高效性。

Conclusion: 新的加法定理为相关数值方法提供了更简洁和高效的计算途径。

Abstract: We obtain a new addition theorem for the fundamental solution of the
Navier-Lam\'e system in dimension 3 satisfying the Kupradze radiation
conditions. This provides an expansion of this fundamental solution that
involves only the evaluation of Bessel functions and scalar spherical
harmonics. This is particularly useful in collocation numerical methods based
on fundamental solutions, such as the boundary element method or the method of
fundamental solutions. For this last method, we show its efficiency when
approximating the Navier-Lam\'e system in exterior domains.

</details>


### [175] [Solitary-wave solutions of the fractional nonlinear Schrödinger equation. II. A numerical study of the dynamics](https://arxiv.org/abs/2508.00559)
*Angel Durán,Nuria Reguera*

Main category: math.NA

TL;DR: 本文通过数值方法研究了分数非线性薛定谔方程的孤立波解动力学，重点讨论了波的稳定性、扰动影响、孤立波相互作用及初始数据分解为波列的问题。


<details>
  <summary>Details</summary>
Motivation: 研究分数非线性薛定谔方程孤立波解的动力学行为，以验证理论分析结果并探讨其稳定性。

Method: 采用傅里叶谱方法进行空间离散，结合四阶Runge-Kutta-Composition方法作为时间积分器，对周期性初值问题进行数值模拟。

Result: 分析了孤立波在微小和大扰动下的稳定性、孤立波间的相互作用以及初始数据分解为波列的现象。

Conclusion: 数值研究验证了孤立波解的存在性，并揭示了其动力学行为中的关键稳定性问题。

Abstract: The present paper is a numerical study of the dynamics of solitary wave
solutions of the fractional nonlinear Schr\"{o}dinger equation, whose existence
was analyzed by the authors in the first part of the project. The computational
study will be made from the approximation of the periodic initial-value problem
with a fully discrete scheme consisting of a Fourier spectral method for the
spatial discretization and a fourth-order, Runge-Kutta-Composition method as
time integrator. Several issues regarding the stability of the waves, such as
the effects of small and large perturbations, interactions of solitary waves
and the resolution of initial data into trains of waves are discussed.

</details>


### [176] [Towards a mixed-precision ADI method for Lyapunov equations](https://arxiv.org/abs/2508.00722)
*Jonas Schulze,Jens Saak*

Main category: math.NA

TL;DR: 论文探讨了在低秩Lyapunov ADI算法中应用混合精度计算，通过在某些步骤使用单精度或双精度来优化性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索混合精度计算在低秩Lyapunov ADI算法中的潜力，以提高计算效率而不显著牺牲精度。

Method: 方法包括在算法中不同步骤（如解线性系统、存储低秩残差因子）采用单精度或双精度的组合。

Result: 实验结果显示，对于一阶系统，单精度累积解几乎能达到双精度的残差水平；在某些应用中（如计算H2范数），混合精度表现优异。

Conclusion: 结论表明混合精度在低秩Lyapunov ADI算法中具有竞争力，尤其适用于特定应用场景。

Abstract: We apply mixed-precision to the low-rank Lyapunov ADI (LR-ADI) by performing
certain aspects of the algorithm in a lower working precision. Namely, we
accumulate the overall solution, solve the linear systems comprising the ADI
iteration, and store the inner low-rank factors of the residuals in various
combinations of IEEE 754 single and double precision. We empirically test our
implementation on Lyapunov equations arising from first- and second-order
descriptor systems. For the first-order examples, accumulating the solution in
single-precision yields an almost-as-small residual as for the double-precision
solution. For certain applications, like computing the H2 norm of a descriptor
system, low- or mixed-precision variants of the ADI can be quite competitive

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [177] [Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion](https://arxiv.org/abs/2508.00037)
*Tong Nie,Jian Sun,Wei Ma*

Main category: cs.LG

TL;DR: 论文提出了一种基于物理定律启发的可扩展时空Transformer（ScaleSTF），用于预测大规模城市网络的动态，解决了现有模型在效能和效率之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 城市网络系统涉及复杂的动态过程，现有预测模型（如图神经网络）在效能和效率之间存在权衡，难以应用于大规模网络。

Method: 提出了一种基于Transformer结构的可解释神经扩散方案，其注意力层由低维嵌入诱导，具有线性复杂度。

Result: ScaleSTF在交通流量、太阳能发电和智能电表等大规模城市系统中验证了其先进性能和卓越的可扩展性。

Conclusion: ScaleSTF为大规模城市网络动态预测提供了新的视角，展示了高效且可扩展的解决方案。

Abstract: Networked urban systems facilitate the flow of people, resources, and
services, and are essential for economic and social interactions. These systems
often involve complex processes with unknown governing rules, observed by
sensor-based time series. To aid decision-making in industrial and engineering
contexts, data-driven predictive models are used to forecast spatiotemporal
dynamics of urban systems. Current models such as graph neural networks have
shown promise but face a trade-off between efficacy and efficiency due to
computational demands. Hence, their applications in large-scale networks still
require further efforts. This paper addresses this trade-off challenge by
drawing inspiration from physical laws to inform essential model designs that
align with fundamental principles and avoid architectural redundancy. By
understanding both micro- and macro-processes, we present a principled
interpretable neural diffusion scheme based on Transformer-like structures
whose attention layers are induced by low-dimensional embeddings. The proposed
scalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is
validated on large-scale urban systems including traffic flow, solar power, and
smart meters, showing state-of-the-art performance and remarkable scalability.
Our results constitute a fresh perspective on the dynamics prediction in
large-scale urban networks.

</details>


### [178] [Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings](https://arxiv.org/abs/2508.00039)
*Kaustav Chatterjee,Joshua Q. Li,Fatemeh Ansari,Masud Rana Munna,Kundan Parajulee,Jared Schwennesen*

Main category: cs.LG

TL;DR: 研究提出了一种结合LSTM和Transformer的混合深度学习框架，用于高效测量HRGC剖面，提升安全性。


<details>
  <summary>Details</summary>
Motivation: 传统HRGC剖面测量方法成本高、耗时长且存在安全隐患，需改进。

Method: 使用IMU和GPS传感器收集数据，结合地面真实数据，开发了三种深度学习模型进行比较。

Result: 模型2和3表现最佳，能生成2D/3D HRGC剖面，显著提升安全性评估效率。

Conclusion: 混合深度学习框架为HRGC剖面测量提供了快速准确的解决方案，有望提升公路和铁路安全。

Abstract: Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose
safety risks to highway vehicles due to potential hang-ups. These crossings
typically result from post-construction railway track maintenance activities or
non-compliance with design guidelines for HRGC vertical alignments.
Conventional methods for measuring HRGC profiles are costly, time-consuming,
traffic-disruptive, and present safety challenges. To address these issues,
this research employed advanced, cost-effective techniques and innovative
modeling approaches for HRGC profile measurement. A novel hybrid deep learning
framework combining Long Short-Term Memory (LSTM) and Transformer architectures
was developed by utilizing instrumentation and ground truth data.
Instrumentation data were gathered using a highway testing vehicle equipped
with Inertial Measurement Unit (IMU) and Global Positioning System (GPS)
sensors, while ground truth data were obtained via an industrial-standard
walking profiler. Field data was collected at the Red Rock Railroad Corridor in
Oklahoma. Three advanced deep learning models Transformer-LSTM sequential
(model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel
(model 3) were evaluated to identify the most efficient architecture. Models 2
and 3 outperformed the others and were deployed to generate 2D/3D HRGC
profiles. The deep learning models demonstrated significant potential to
enhance highway and railroad safety by enabling rapid and accurate assessment
of HRGC hang-up susceptibility.

</details>


### [179] [Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting](https://arxiv.org/abs/2508.00040)
*Abhinav Das,Stephan Schlüter*

Main category: cs.LG

TL;DR: 结合贝叶斯机制检测与条件神经过程，提出R-NP模型用于德国电力市场24小时电价预测，通过多标准评估（TOPSIS）显示其综合性能最优。


<details>
  <summary>Details</summary>
Motivation: 电力市场电价预测对电池存储优化（如套利、风险管理等）至关重要，但现有模型在预测准确性与实际应用效果间存在差距。

Method: 采用DS-HDP-HMM检测电价机制，每个机制用独立的条件神经过程（CNP）建模，最终预测为机制加权混合结果。

Result: R-NP在2021-2023年表现最均衡，优于DNN和LEAR模型。

Conclusion: R-NP模型在多标准评估中表现最优，适合长期电力市场预测。

Abstract: This work integrates Bayesian regime detection with conditional neural
processes for 24-hour electricity price prediction in the German market. Our
methodology integrates regime detection using a disentangled sticky
hierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to
daily electricity prices. Each identified regime is subsequently modeled by an
independent conditional neural process (CNP), trained to learn localized
mappings from input contexts to 24-dimensional hourly price trajectories, with
final predictions computed as regime-weighted mixtures of these CNP outputs. We
rigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated
auto-regressive (LEAR) models by integrating their forecasts into diverse
battery storage optimization frameworks, including price arbitrage, risk
management, grid services, and cost minimization. This operational utility
assessment revealed complex performance trade-offs: LEAR often yielded superior
absolute profits or lower costs, while DNN showed exceptional optimality in
specific cost-minimization contexts. Recognizing that raw prediction accuracy
doesn't always translate to optimal operational outcomes, we employed TOPSIS as
a comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified
LEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model
emerged as the most balanced and preferred solution for 2021, 2022 and 2023.

</details>


### [180] [Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages](https://arxiv.org/abs/2508.00041)
*Yebo Wu,Jingguang Li,Zhijiang Guo,Li Li*

Main category: cs.LG

TL;DR: DevFT是一种资源高效的联邦微调方法，通过分阶段优化子模型并转移知识，显著提升性能并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决联邦微调在边缘设备上资源消耗大的问题，同时保持数据隐私。

Method: 采用分阶段微调策略，逐步构建强大的LLM，通过知识转移和优化初始化参数加速训练。

Result: 在多个基准测试中，DevFT比现有方法快4.59倍，通信开销减少10.67倍，性能平均提升9.07%。

Conclusion: DevFT是一种高效且兼容现有方法的联邦微调方案，适用于资源受限的边缘设备。

Abstract: Federated fine-tuning enables Large Language Models (LLMs) to adapt to
downstream tasks while preserving data privacy, but its resource-intensive
nature limits deployment on edge devices. In this paper, we introduce
Developmental Federated Tuning (DevFT), a resource-efficient approach inspired
by cognitive development that progressively builds a powerful LLM from a
compact foundation. DevFT decomposes the fine-tuning process into developmental
stages, each optimizing submodels with increasing parameter capacity. Knowledge
from earlier stages transfers to subsequent submodels, providing optimized
initialization parameters that prevent convergence to local minima and
accelerate training. This paradigm mirrors human learning, gradually
constructing comprehensive knowledge structure while refining existing skills.
To efficiently build stage-specific submodels, DevFT introduces
deconfliction-guided layer grouping and differential-based layer fusion to
distill essential information and construct representative layers. Evaluations
across multiple benchmarks demonstrate that DevFT significantly outperforms
state-of-the-art methods, achieving up to 4.59$\times$ faster convergence,
10.67$\times$ reduction in communication overhead, and 9.07% average
performance improvement, while maintaining compatibility with existing
approaches.

</details>


### [181] [Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity](https://arxiv.org/abs/2508.00043)
*Nhut Truong,Uri Hasson*

Main category: cs.LG

TL;DR: 比较了两种空间约束（权重相似性和激活相似性）对地形卷积神经网络的影响，发现权重相似性在鲁棒性、输入敏感性和功能定位方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究不同地形约束对神经网络学习表示的影响，填补系统性研究的空白。

Method: 比较权重相似性（WS）和激活相似性（AS）约束下的地形卷积神经网络，评估分类准确性、鲁棒性和表示的空间组织。

Result: WS比AS和标准CNN在噪声鲁棒性、输入敏感性和功能定位方面表现更好，并影响网络的表示几何。

Conclusion: 权重相似性约束在端到端训练中能产生更鲁棒的表示，并影响特征学习和功能组织。

Abstract: Topographic neural networks are computational models that can simulate the
spatial and functional organization of the brain. Topographic constraints in
neural networks can be implemented in multiple ways, with potentially different
impacts on the representations learned by the network. The impact of such
different implementations has not been systematically examined. To this end,
here we compare topographic convolutional neural networks trained with two
spatial constraints: Weight Similarity (WS), which pushes neighboring units to
develop similar incoming weights, and Activation Similarity (AS), which
enforces similarity in unit activations. We evaluate the resulting models on
classification accuracy, robustness to weight perturbations and input
degradation, and the spatial organization of learned representations. Compared
to both AS and standard CNNs, WS provided three main advantages: i) improved
robustness to noise, also showing higher accuracy under weight corruption; ii)
greater input sensitivity, reflected in higher activation variance; and iii)
stronger functional localization, with units showing similar activations
positioned at closer distances. In addition, WS produced differences in
orientation tuning, symmetry sensitivity, and eccentricity profiles of units,
indicating an influence of this spatial constraint on the representational
geometry of the network. Our findings suggest that during end-to-end training,
WS constraints produce more robust representations than AS or non-topographic
CNNs. These findings also suggest that weight-based spatial constraints can
shape feature learning and functional organization in biophysical inspired
models.

</details>


### [182] [Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains](https://arxiv.org/abs/2508.00046)
*Ruo Yu Tao,Kaicheng Guo,Cameron Allen,George Konidaris*

Main category: cs.LG

TL;DR: 论文提出了一个用于评估强化学习算法在部分可观测性下性能的基准框架POBAX，强调基准需覆盖多种部分可观测形式并体现记忆改进性。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅评估简单形式的状态混淆（如特征掩码和高斯噪声），无法反映真实场景中的复杂部分可观测性（如视觉遮挡或未知对手意图）。

Method: 引入POBAX开源库，包含多种代表性环境（如定位与映射、视觉控制、游戏等），并确保这些任务是记忆改进的，需学习复杂记忆功能。

Result: POBAX提供了快速评估的推荐超参数和算法实现，以及高性能的JAX环境，支持GPU扩展实验。

Conclusion: POBAX为部分可观测性研究提供了全面的基准框架，有助于推动算法在复杂环境中的通用性。

Abstract: Mitigating partial observability is a necessary but challenging task for
general reinforcement learning algorithms. To improve an algorithm's ability to
mitigate partial observability, researchers need comprehensive benchmarks to
gauge progress. Most algorithms tackling partial observability are only
evaluated on benchmarks with simple forms of state aliasing, such as feature
masking and Gaussian noise. Such benchmarks do not represent the many forms of
partial observability seen in real domains, like visual occlusion or unknown
opponent intent. We argue that a partially observable benchmark should have two
key properties. The first is coverage in its forms of partial observability, to
ensure an algorithm's generalizability. The second is a large gap between the
performance of a agents with more or less state information, all other factors
roughly equal. This gap implies that an environment is memory improvable: where
performance gains in a domain are from an algorithm's ability to cope with
partial observability as opposed to other factors. We introduce best-practice
guidelines for empirically benchmarking reinforcement learning under partial
observability, as well as the open-source library POBAX: Partially Observable
Benchmarks in JAX. We characterize the types of partial observability present
in various environments and select representative environments for our
benchmark. These environments include localization and mapping, visual control,
games, and more. Additionally, we show that these tasks are all memory
improvable and require hard-to-learn memory functions, providing a concrete
signal for partial observability research. This framework includes recommended
hyperparameters as well as algorithm implementations for fast, out-of-the-box
evaluation, as well as highly performant environments implemented in JAX for
GPU-scalable experimentation.

</details>


### [183] [TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection](https://arxiv.org/abs/2508.00047)
*Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin*

Main category: cs.LG

TL;DR: 论文提出了一种基于大型语言模型（LLM）的无监督时间序列异常检测框架TriP-LLM，通过三分支设计整合局部和全局特征，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和智能制造的普及，时间序列数据的规模和维度急剧增加，传统统计方法难以应对其高异质性和复杂性。

Method: TriP-LLM采用三分支设计（Patching、Selection、Global）将时间序列编码为分块令牌，利用预训练的LLM处理，并通过轻量级解码器重构输入以计算异常分数。

Result: 实验表明，TriP-LLM在多个公共数据集上优于现有方法，且内存消耗显著低于基于CI分块处理的LLM方法。

Conclusion: TriP-LLM展示了LLM在时间序列异常检测中的潜力，适用于GPU内存受限环境。

Abstract: Time-series anomaly detection plays a central role across a wide range of
application domains. With the increasing proliferation of the Internet of
Things (IoT) and smart manufacturing, time-series data has dramatically
increased in both scale and dimensionality. This growth has exposed the
limitations of traditional statistical methods in handling the high
heterogeneity and complexity of such data. Inspired by the recent success of
large language models (LLMs) in multimodal tasks across language and vision
domains, we propose a novel unsupervised anomaly detection framework: A
Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly
Detection (TriP-LLM). TriP-LLM integrates local and global temporal features
through a tri-branch design-Patching, Selection, and Global-to encode the input
time series into patch-wise tokens, which are then processed by a frozen,
pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from
which anomaly scores are derived. We evaluate TriP-LLM on several public
benchmark datasets using PATE, a recently proposed threshold-free evaluation
metric, and conduct all comparisons within a unified open-source framework to
ensure fairness. Experimental results show that TriP-LLM consistently
outperforms recent state-of-the-art methods across all datasets, demonstrating
strong detection capabilities. Furthermore, through extensive ablation studies,
we verify the substantial contribution of the LLM to the overall architecture.
Compared to LLM-based approaches using Channel Independence (CI) patch
processing, TriP-LLM achieves significantly lower memory consumption, making it
more suitable for GPU memory-constrained environments. All code and model
checkpoints are publicly available on https://github.com/YYZStart/TriP-LLM.git

</details>


### [184] [Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization](https://arxiv.org/abs/2508.00078)
*Imen Mahmoud,Andrei Velichko*

Main category: cs.LG

TL;DR: 该研究提出了一种结合LightGBM回归模型和遗传算法优化的新方法，用于评估COVID-19相关指标对比特币回报预测的贡献。结果表明，疫情指标显著提升了预测准确性，尤其是疫苗接种数据。


<details>
  <summary>Details</summary>
Motivation: 研究的主要目标不仅是预测比特币回报，还在于确定疫情相关健康数据是否能显著提升预测准确性。

Method: 使用LightGBM回归模型和遗传算法优化，构建包含比特币回报和COVID-19指标的全面数据集，并通过31次独立运行进行统计评估。

Result: COVID-19指标显著提升了模型性能（R2增加40%，RMSE降低2%），其中疫苗接种数据是主要预测因子。

Conclusion: 该方法扩展了金融分析工具，为投资者和政策制定者提供了在系统性危机中应对市场不确定性的新指标。

Abstract: This study proposes a novel methodological framework integrating a LightGBM
regression model and genetic algorithm (GA) optimization to systematically
evaluate the contribution of COVID-19-related indicators to Bitcoin return
prediction. The primary objective was not merely to forecast Bitcoin returns
but rather to determine whether including pandemic-related health data
significantly enhances prediction accuracy. A comprehensive dataset comprising
daily Bitcoin returns and COVID-19 metrics (vaccination rates,
hospitalizations, testing statistics) was constructed. Predictive models,
trained with and without COVID-19 features, were optimized using GA over 31
independent runs, allowing robust statistical assessment. Performance metrics
(R2, RMSE, MAE) were statistically compared through distribution overlaps and
Mann-Whitney U tests. Permutation Feature Importance (PFI) analysis quantified
individual feature contributions. Results indicate that COVID-19 indicators
significantly improved model performance, particularly in capturing extreme
market fluctuations (R2 increased by 40%, RMSE decreased by 2%, both highly
significant statistically). Among COVID-19 features, vaccination metrics,
especially the 75th percentile of fully vaccinated individuals, emerged as
dominant predictors. The proposed methodology extends existing financial
analytics tools by incorporating public health signals, providing investors and
policymakers with refined indicators to navigate market uncertainty during
systemic crises.

</details>


### [185] [Stress-Aware Resilient Neural Training](https://arxiv.org/abs/2508.00098)
*Ashkan Shakarami,Yousef Yeganeh,Azade Farshad,Lorenzo Nicole,Stefano Ghidoni,Nassir Navab*

Main category: cs.LG

TL;DR: 论文提出了一种名为Stress-Aware Learning的弹性神经训练范式，通过动态调整优化行为来提升模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 受材料科学中结构疲劳现象的启发，旨在解决深度神经网络在训练过程中遇到的优化停滞问题。

Method: 提出了Plastic Deformation Optimizer，通过内部应力信号检测训练停滞，并自适应地向参数注入噪声以逃离尖锐极小值。

Result: 在六种架构、四种优化器和七个视觉基准测试中验证了方法的鲁棒性和泛化能力，且计算开销极小。

Conclusion: Stress-Aware Learning为深度学习的优化问题提供了一种新颖且有效的解决方案。

Abstract: This paper introduces Stress-Aware Learning, a resilient neural training
paradigm in which deep neural networks dynamically adjust their optimization
behavior - whether under stable training regimes or in settings with uncertain
dynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)
Deformation, inspired by structural fatigue in materials science. To
instantiate this concept, we propose Plastic Deformation Optimizer, a
stress-aware mechanism that injects adaptive noise into model parameters
whenever an internal stress signal - reflecting stagnation in training loss and
accuracy - indicates persistent optimization difficulty. This enables the model
to escape sharp minima and converge toward flatter, more generalizable regions
of the loss landscape. Experiments across six architectures, four optimizers,
and seven vision benchmarks demonstrate improved robustness and generalization
with minimal computational overhead. The code and 3D visuals will be available
on GitHub: https://github.com/Stress-Aware-Learning/SAL.

</details>


### [186] [StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection](https://arxiv.org/abs/2508.00117)
*Md. Ehsanul Haque,S. M. Jahidul Islam,Shakil Mia,Rumana Sharmin,Ashikuzzaman,Md Samir Morshed,Md. Tahmidul Huque*

Main category: cs.LG

TL;DR: StackLiverNet是一种可解释的堆叠集成模型，用于肝病检测，通过先进的数据预处理和特征选择技术提高性能，测试准确率达99.89%。


<details>
  <summary>Details</summary>
Motivation: 现有肝病分类模型存在高误分类率、解释性差等问题，需改进以提升诊断效果。

Method: 采用随机欠采样处理类别不平衡，结合多个超参数优化的基分类器，通过LightGBM元模型集成，并应用LIME和SHAP增强解释性。

Result: 测试准确率99.89%，Cohen Kappa 0.9974，AUC 0.9993，仅5次误分类，训练和推理速度快。

Conclusion: StackLiverNet在肝病检测中表现出色，兼具高性能和可解释性，适合临床应用。

Abstract: Liver diseases are a serious health concern in the world, which requires
precise and timely diagnosis to enhance the survival chances of patients. The
current literature implemented numerous machine learning and deep learning
models to classify liver diseases, but most of them had some issues like high
misclassification error, poor interpretability, prohibitive computational
expense, and lack of good preprocessing strategies. In order to address these
drawbacks, we introduced StackLiverNet in this study; an interpretable stacked
ensemble model tailored to the liver disease detection task. The framework uses
advanced data preprocessing and feature selection technique to increase model
robustness and predictive ability. Random undersampling is performed to deal
with class imbalance and make the training balanced. StackLiverNet is an
ensemble of several hyperparameter-optimized base classifiers, whose
complementary advantages are used through a LightGBM meta-model. The provided
model demonstrates excellent performance, with the testing accuracy of 99.89%,
Cohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and
efficient training and inference speeds that are amenable to clinical practice
(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local
Interpretable Model-Agnostic Explanations (LIME) are applied to generate
transparent explanations of individual predictions, revealing high
concentrations of Alkaline Phosphatase and moderate SGOT as important
observations of liver disease. Also, SHAP was used to rank features by their
global contribution to predictions, while the Morris method confirmed the most
influential features through sensitivity analysis.

</details>


### [187] [Structured Transformations for Stable and Interpretable Neural Computation](https://arxiv.org/abs/2508.00127)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.LG

TL;DR: 论文提出了一种结构化神经网络层变换方法，通过分解为线性算子和残差修正组件，提升训练稳定性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当代神经网络缺乏结构保障，导致学习不稳定和可解释性差，需要改进。

Method: 将层变换分解为结构化线性算子和残差修正组件，支持稳定信息流。

Result: 实验表明，该方法改善了梯度条件、降低扰动敏感性，并增强层间鲁棒性。

Conclusion: 该方法为优先稳定性和透明性的神经网络架构提供了新工具，不牺牲表达能力。

Abstract: Despite their impressive performance, contemporary neural networks often lack
structural safeguards that promote stable learning and interpretable behavior.
In this work, we introduce a reformulation of layer-level transformations that
departs from the standard unconstrained affine paradigm. Each transformation is
decomposed into a structured linear operator and a residual corrective
component, enabling more disciplined signal propagation and improved training
dynamics. Our formulation encourages internal consistency and supports stable
information flow across depth, while remaining fully compatible with standard
learning objectives and backpropagation. Through a series of synthetic and
real-world experiments, we demonstrate that models constructed with these
structured transformations exhibit improved gradient conditioning, reduced
sensitivity to perturbations, and layer-wise robustness. We further show that
these benefits persist across architectural scales and training regimes. This
study serves as a foundation for a more principled class of neural
architectures that prioritize stability and transparency-offering new tools for
reasoning about learning behavior without sacrificing expressive power.

</details>


### [188] [ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks](https://arxiv.org/abs/2508.00131)
*Christopher Harvey,Sumaiya Shomaji,Zijun Yao,Amit Noheria*

Main category: cs.LG

TL;DR: 论文提出三种新型变分自编码器（VAE）变体，用于简化心电图（ECG）数据并提升预测性能，在数据有限的情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 心电图（ECG）数据复杂且个体差异大，传统深度学习方法在小数据集上效果不佳，需要一种简化数据并保持预测性能的方法。

Method: 研究探索了主成分分析（PCA）和自编码器，并提出了三种VAE变体（SAE、A beta-VAE、C beta-VAE），结合LGBM分类器进行预测。

Result: A beta-VAE在信号重建上表现最佳（MAE为15.7±3.2 μV），SAE编码结合传统特征提升了LVEF预测（AUROC为0.901），接近CNN模型但计算资源更少。

Conclusion: 提出的VAE编码不仅简化了ECG数据，还为小规模标记数据下的深度学习提供了实用解决方案。

Abstract: The electrocardiogram (ECG) is an inexpensive and widely available tool for
cardiac assessment. Despite its standardized format and small file size, the
high complexity and inter-individual variability of ECG signals (typically a
60,000-size vector with 12 leads at 500 Hz) make it challenging to use in deep
learning models, especially when only small training datasets are available.
This study addresses these challenges by exploring feature generation methods
from representative beat ECGs, focusing on Principal Component Analysis (PCA)
and Autoencoders to reduce data complexity. We introduce three novel
Variational Autoencoder (VAE) variants-Stochastic Autoencoder (SAE), Annealed
beta-VAE (A beta-VAE), and Cyclical beta VAE (C beta-VAE)-and compare their
effectiveness in maintaining signal fidelity and enhancing downstream
prediction tasks using a Light Gradient Boost Machine (LGBM). The A beta-VAE
achieved superior signal reconstruction, reducing the mean absolute error (MAE)
to 15.7+/-3.2 muV, which is at the level of signal noise. Moreover, the SAE
encodings, when combined with traditional ECG summary features, improved the
prediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an
holdout test set area under the receiver operating characteristic curve (AUROC)
of 0.901 with a LGBM classifier. This performance nearly matches the 0.909
AUROC of state-of-the-art CNN model but requires significantly less
computational resources. Further, the ECG feature extraction-LGBM pipeline
avoids overfitting and retains predictive performance when trained with less
data. Our findings demonstrate that these VAE encodings are not only effective
in simplifying ECG data but also provide a practical solution for applying deep
learning in contexts with limited-scale labeled training data.

</details>


### [189] [INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks](https://arxiv.org/abs/2508.00141)
*Mohit Gupta,Debjit Bhowmick,Rhys Newbury,Meead Saberi,Shirui Pan,Ben Beck*

Main category: cs.LG

TL;DR: INSPIRE-GNN是一种结合强化学习和图神经网络的框架，用于优化自行车流量传感器布局并提高稀疏数据环境下的流量估计精度。


<details>
  <summary>Details</summary>
Motivation: 城市自行车流量数据稀疏问题严重，传统传感器布局方法效果有限，需要更智能的解决方案。

Method: 结合图卷积网络（GCN）、图注意力网络（GAT）和深度Q网络（DQN）强化学习代理，动态优化传感器位置选择。

Result: 在墨尔本自行车网络中，INSPIRE-GNN显著优于传统方法，如中心性和随机布局，在MSE、RMSE和MAE等指标上表现更优。

Conclusion: INSPIRE-GNN为交通规划者提供了优化传感器布局和提高数据可靠性的有效工具。

Abstract: Accurate link-level bicycling volume estimation is essential for sustainable
urban transportation planning. However, many cities face significant challenges
of high data sparsity due to limited bicycling count sensor coverage. To
address this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning
(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize
sensor placement and improve link-level bicycling volume estimation in
data-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks
(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL
agent, enabling a data-driven strategic selection of sensor locations to
maximize estimation performance. Applied to Melbourne's bicycling network,
comprising 15,933 road segments with sensor coverage on only 141 road segments
(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume
estimation by strategically selecting additional sensor locations in
deployments of 50, 100, 200 and 500 sensors. Our framework outperforms
traditional heuristic methods for sensor placement such as betweenness
centrality, closeness centrality, observed bicycling activity and random
placement, across key metrics such as Mean Squared Error (MSE), Root Mean
Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our
experiments benchmark INSPIRE-GNN against standard machine learning and deep
learning models in the bicycle volume estimation performance, underscoring its
effectiveness. Our proposed framework provides transport planners actionable
insights to effectively expand sensor networks, optimize sensor placement and
maximize volume estimation accuracy and reliability of bicycling data for
informed transportation planning decisions.

</details>


### [190] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
*Ziqian Zhong,Aditi Raghunathan*

Main category: cs.LG

TL;DR: 提出了一种基于权重而非激活的新方法，用于理解和监控微调后的LLM，无需依赖与训练数据分布相似的输入数据。


<details>
  <summary>Details</summary>
Motivation: 现有基于激活的解释方法需要分布相似的数据，限制了在检测和防御新威胁（如后门）时的有效性。

Method: 通过分析微调模型与基础模型权重差异的顶部奇异向量，识别新行为，并通过余弦相似度监控这些行为。

Result: 成功检测后门攻击（100%阻止率，假阳性率低于1.2%），并能在未学习模型中恢复被“遗忘”信息（准确率95.42%）。

Conclusion: 该方法在监控和审计微调LLM方面具有潜力，可应用于商业模型的预部署分析。

Abstract: The releases of powerful open-weight large language models (LLMs) are often
not accompanied by access to their full training data. Existing
interpretability methods, particularly those based on activations, often
require or assume distributionally similar data. This is a significant
limitation when detecting and defending against novel potential threats like
backdoors, which are by definition out-of-distribution.
  In this work, we introduce a new method for understanding, monitoring and
controlling fine-tuned LLMs that interprets weights, rather than activations,
thereby side stepping the need for data that is distributionally similar to the
unknown training data. We demonstrate that the top singular vectors of the
weight difference between a fine-tuned model and its base model correspond to
newly acquired behaviors. By monitoring the cosine similarity of activations
along these directions, we can detect salient behaviors introduced during
fine-tuning with high precision.
  For backdoored models that bypasses safety mechanisms when a secret trigger
is present, our method stops up to 100% of attacks with a false positive rate
below 1.2%. For models that have undergone unlearning, we detect inference on
erased topics with accuracy up to 95.42% and can even steer the model to
recover "unlearned" information. Besides monitoring, our method also shows
potential for pre-deployment model auditing: by analyzing commercial
instruction-tuned models (OLMo, Llama, Qwen), we are able to uncover
model-specific fine-tuning focus including marketing strategies and Midjourney
prompt generation.
  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.

</details>


### [191] [DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission](https://arxiv.org/abs/2508.00172)
*Fupei Guo,Hao Zheng,Xiang Zhang,Li Chen,Yue Wang,Songyang Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于扩散的语义通信框架DiSC-Med，用于高效且鲁棒的医学图像传输。


<details>
  <summary>Details</summary>
Motivation: 人工智能和无线通信技术的发展推动了远程医疗，但医疗数据在有限带宽和噪声信道中的高效传输仍是一个关键挑战。

Method: 开发了医学增强的压缩和去噪模块，通过语义通信框架DiSC-Med实现高效带宽利用和鲁棒性。

Result: 在真实医学数据集上的实验表明，DiSC-Med能够捕捉关键语义信息，并在噪声信道中实现超高效带宽利用和优异的重建性能。

Conclusion: DiSC-Med框架为远程医疗应用提供了高效且鲁棒的解决方案，具有实际应用潜力。

Abstract: The rapid development of artificial intelligence has driven smart health with
next-generation wireless communication technologies, stimulating exciting
applications in remote diagnosis and intervention. To enable a timely and
effective response for remote healthcare, efficient transmission of medical
data through noisy channels with limited bandwidth emerges as a critical
challenge. In this work, we propose a novel diffusion-based semantic
communication framework, namely DiSC-Med, for the medical image transmission,
where medical-enhanced compression and denoising blocks are developed for
bandwidth efficiency and robustness, respectively. Unlike conventional
pixel-wise communication framework, our proposed DiSC-Med is able to capture
the key semantic information and achieve superior reconstruction performance
with ultra-high bandwidth efficiency against noisy channels. Extensive
experiments on real-world medical datasets validate the effectiveness of our
framework, demonstrating its potential for robust and efficient telehealth
applications.

</details>


### [192] [RL as Regressor: A Reinforcement Learning Approach for Function Approximation](https://arxiv.org/abs/2508.00174)
*Yongchao Huang*

Main category: cs.LG

TL;DR: 论文提出了一种将回归问题转化为强化学习（RL）问题的新方法，通过自定义奖励信号和RL算法解决传统回归方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统回归方法受限于预定义的可微损失函数（如均方误差），难以处理非对称成本或复杂、不可微的目标。

Method: 将模型预测视为动作，基于预测误差定义自定义奖励信号，利用RL算法（如Actor-Critic）进行函数逼近，并通过案例研究逐步优化。

Result: RL框架不仅成功解决了回归问题，还提供了定义目标和指导学习过程的更大灵活性。

Conclusion: RL为回归问题提供了一种灵活且强大的替代方法，尤其适用于复杂或非传统的目标场景。

Abstract: Standard regression techniques, while powerful, are often constrained by
predefined, differentiable loss functions such as mean squared error. These
functions may not fully capture the desired behavior of a system, especially
when dealing with asymmetric costs or complex, non-differentiable objectives.
In this paper, we explore an alternative paradigm: framing regression as a
Reinforcement Learning (RL) problem. We demonstrate this by treating a model's
prediction as an action and defining a custom reward signal based on the
prediction error, and we can leverage powerful RL algorithms to perform
function approximation. Through a progressive case study of learning a noisy
sine wave, we illustrate the development of an Actor-Critic agent, iteratively
enhancing it with Prioritized Experience Replay, increased network capacity,
and positional encoding to enable a capable RL agent for this regression task.
Our results show that the RL framework not only successfully solves the
regression problem but also offers enhanced flexibility in defining objectives
and guiding the learning process.

</details>


### [193] [EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes](https://arxiv.org/abs/2508.00180)
*Adam Block,Cyril Zhang*

Main category: cs.LG

TL;DR: 论文提出了一种名为BEMA的方法，用于解决语言模型微调中的训练不稳定性问题，通过消除EMA的偏差，显著提升了收敛速度和最终性能。


<details>
  <summary>Details</summary>
Motivation: 语言模型微调中的随机性（如小批量训练）会导致训练不稳定，EMA虽能减少随机性但会引入偏差，影响优化速度。

Method: 提出了Bias-Corrected Exponential Moving Average (BEMA)，在保留EMA方差减少优势的同时消除偏差。

Result: 实验表明，BEMA在多种标准LM基准测试中显著优于EMA和普通训练，提高了收敛速度和性能。

Conclusion: BEMA是一种实用且理论支持的方法，能更稳定高效地进行语言模型微调。

Abstract: Stochasticity in language model fine-tuning, often caused by the small batch
sizes typically used in this regime, can destabilize training by introducing
large oscillations in generation quality. A popular approach to mitigating this
instability is to take an Exponential moving average (EMA) of weights
throughout training. While EMA reduces stochasticity, thereby smoothing
training, the introduction of bias from old iterates often creates a lag in
optimization relative to vanilla training. In this work, we propose the
Bias-Corrected Exponential Moving Average (BEMA), a simple and practical
augmentation of EMA that retains variance-reduction benefits while eliminating
bias. BEMA is motivated by a simple theoretical model wherein we demonstrate
provable acceleration of BEMA over both a standard EMA and vanilla training.
Through an extensive suite of experiments on Language Models, we show that BEMA
leads to significantly improved convergence rates and final performance over
both EMA and vanilla training in a variety of standard LM benchmarks, making
BEMA a practical and theoretically motivated intervention for more stable and
efficient fine-tuning.

</details>


### [194] [RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems](https://arxiv.org/abs/2508.00201)
*Mehdi Ben Ayed,Fei Feng,Jay Adams,Vishwakarma Singh,Kritarth Anand,Jiajing Xu*

Main category: cs.LG

TL;DR: RecoMind是一个基于模拟器的强化学习框架，用于优化大规模推荐系统中的会话目标，显著提升用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统多关注即时反馈，而强化学习能优化长期目标（如会话参与度），但大规模应用存在挑战。

Method: 利用现有推荐模型构建模拟环境，引导强化学习策略，并采用定制探索策略处理大规模动作空间。

Result: 离线模拟和在线A/B测试显示，RecoMind训练的强化学习策略在会话用户满意度上显著优于传统监督学习方法。

Conclusion: RecoMind为大规模推荐系统提供了一种可扩展的强化学习解决方案，优化会话用户满意度。

Abstract: Existing web-scale recommendation systems commonly use supervised learning
methods that prioritize immediate user feedback. Although reinforcement
learning (RL) offers a solution to optimize longer-term goals, such as
in-session engagement, applying it at web scale is challenging due to the
extremely large action space and engineering complexity. In this paper, we
introduce RecoMind, a simulator-based RL framework designed for the effective
optimization of session-based goals at web-scale. RecoMind leverages existing
recommendation models to establish a simulation environment and to bootstrap
the RL policy to optimize immediate user interactions from the outset. This
method integrates well with existing industry pipelines, simplifying the
training and deployment of RL policies. Additionally, RecoMind introduces a
custom exploration strategy to efficiently explore web-scale action spaces with
hundreds of millions of items. We evaluated RecoMind through extensive offline
simulations and online A/B testing on a video streaming platform. Both methods
showed that the RL policy trained using RecoMind significantly outperforms
traditional supervised learning recommendation approaches in in-session user
satisfaction. In online A/B tests, the RL policy increased videos watched for
more than 10 seconds by 15.81\% and improved session depth by 4.71\% for
sessions with at least 10 interactions. As a result, RecoMind presents a
systematic and scalable approach for embedding RL into web-scale recommendation
systems, showing great promise for optimizing session-based user satisfaction.

</details>


### [195] [Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models](https://arxiv.org/abs/2508.00202)
*Ecem Bozkurt,Antonio Ortega*

Main category: cs.LG

TL;DR: 提出了一种两阶段框架，利用几何信息提升基础模型在标签噪声下的鲁棒性，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 在标签噪声环境下，现有方法（如kNN）利用局部几何信息表现良好，但仍有改进空间。

Method: 采用两阶段流程：可靠性估计和加权推理，引入非负核（NNK）邻域构建和几何信息。

Result: 在CIFAR-10和DermaMNIST上，方法在多种噪声条件下表现优于标准kNN和自适应邻域基线。

Conclusion: 通过几何信息和可靠性加权推理，显著提升了标签噪声下的分类鲁棒性。

Abstract: Foundation models (FMs) pretrained on large datasets have become fundamental
for various downstream machine learning tasks, in particular in scenarios where
obtaining perfectly labeled data is prohibitively expensive. In this paper, we
assume an FM has to be fine-tuned with noisy data and present a two-stage
framework to ensure robust classification in the presence of label noise
without model retraining. Recent work has shown that simple k-nearest neighbor
(kNN) approaches using an embedding derived from an FM can achieve good
performance even in the presence of severe label noise. Our work is motivated
by the fact that these methods make use of local geometry. In this paper,
following a similar two-stage procedure, reliability estimation followed by
reliability-weighted inference, we show that improved performance can be
achieved by introducing geometry information. For a given instance, our
proposed inference uses a local neighborhood of training data, obtained using
the non-negative kernel (NNK) neighborhood construction. We propose several
methods for reliability estimation that can rely less on distance and local
neighborhood as the label noise increases. Our evaluation on CIFAR-10 and
DermaMNIST shows that our methods improve robustness across various noise
conditions, surpassing standard K-NN approaches and recent
adaptive-neighborhood baselines.

</details>


### [196] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
*Paul Albert,Frederic Z. Zhang,Hemanth Saratchandran,Anton van den Hengel,Ehsan Abbasnejad*

Main category: cs.LG

TL;DR: KRAdapter是一种新的参数高效微调方法，通过Khatri-Rao积生成权重更新，解决了LoRA在高有效秩矩阵近似中的不足，并在大规模模型上表现优异。


<details>
  <summary>Details</summary>
Motivation: LoRA在适应多模态和大语言模型时存在局限性，特别是在高有效秩矩阵近似中表现不佳。

Method: 提出KRAdapter，利用Khatri-Rao积生成权重更新，以提高矩阵乘积的有效秩。

Result: KRAdapter在1B参数的视觉语言模型和8B参数的大语言模型上表现优于LoRA，尤其在未见常识推理任务中。

Conclusion: KRAdapter保持了LoRA的内存和计算效率，是适应十亿级参数模型的实用且鲁棒的替代方案。

Abstract: Parameter-efficient fine-tuning (PEFT) has become a standard approach for
adapting large pre-trained models. Amongst PEFT methods, low-rank adaptation
(LoRA) has achieved notable success. However, recent studies have highlighted
its limitations compared against full-rank alternatives, particularly when
applied to multimodal and large language models. In this work, we present a
quantitative comparison amongst full-rank and low-rank PEFT methods using a
synthetic matrix approximation benchmark with controlled spectral properties.
Our results confirm that LoRA struggles to approximate matrices with relatively
flat spectrums or high frequency components -- signs of high effective ranks.
To this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the
Khatri-Rao product to produce weight updates, which, by construction, tends to
produce matrix product with a high effective rank. We demonstrate performance
gains with KRAdapter on vision-language models up to 1B parameters and on large
language models up to 8B parameters, particularly on unseen common-sense
reasoning tasks. In addition, KRAdapter maintains the memory and compute
efficiency of LoRA, making it a practical and robust alternative to fine-tune
billion-scale parameter models.

</details>


### [197] [Calibrated Language Models and How to Find Them with Label Smoothing](https://arxiv.org/abs/2508.00264)
*Jerry Huang,Peng Lu,Qiuhao Zeng*

Main category: cs.LG

TL;DR: 研究探讨了指令微调对大型语言模型（LLM）置信度校准的影响，并提出标签平滑作为解决方案，同时解决了内存占用问题。


<details>
  <summary>Details</summary>
Motivation: 尽管指令微调提升了LLM的交互能力，但其对模型输出置信度校准的影响尚未充分研究。

Method: 分析了多种开源LLM，发现指令微调导致校准退化；提出标签平滑作为解决方案，并设计定制内核以减少内存消耗。

Result: 标签平滑能有效维持校准，但在大词汇量LLM中效果受限；理论及实验验证了过自信与模型规模的关系。

Conclusion: 标签平滑是维持LLM校准的有效方法，定制内核解决了内存问题，但大词汇量模型仍需进一步研究。

Abstract: Recent advances in natural language processing (NLP) have opened up greater
opportunities to enable fine-tuned large language models (LLMs) to behave as
more powerful interactive agents through improved instruction-following
ability. However, understanding how this impacts confidence calibration for
reliable model output has not been researched in full. In this work, we examine
various open-sourced LLMs, identifying significant calibration degradation
after instruction tuning in each. Seeking a practical solution, we look towards
label smoothing, which has been shown as an effective method to regularize for
overconfident predictions but has yet to be widely adopted in the supervised
fine-tuning (SFT) of LLMs. We first provide insight as to why label smoothing
is sufficient to maintain calibration throughout the SFT process. However,
settings remain where the effectiveness of smoothing is severely diminished, in
particular the case of large vocabulary LLMs (LV-LLMs). We posit the cause to
stem from the ability to become over-confident, which has a direct relationship
with the hidden size and vocabulary size, and justify this theoretically and
experimentally. Finally, we address an outstanding issue regarding the memory
footprint of the cross-entropy loss computation in the label smoothed loss
setting, designing a customized kernel to dramatically reduce memory
consumption without sacrificing speed or performance in comparison to existing
solutions for non-smoothed losses.

</details>


### [198] [Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring](https://arxiv.org/abs/2508.00270)
*Robin Schmucker,Nimish Pachapurkar,Shanmuga Bala,Miral Shah,Tom Mitchell*

Main category: cs.LG

TL;DR: 论文介绍了一种在线辅导系统，通过多臂老虎机框架和离线策略评估，优化学生反馈以提高学习效果。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过数据驱动的方法，优化在线辅导系统中的反馈策略，以提升学生的学习效果。

Method: 使用多臂老虎机（MAB）框架和离线策略评估，分析43,000种辅助动作，并设计算法为每个问题选择最佳策略目标。

Result: 在166,000次练习会话中验证了MAB策略的显著改进，同时探讨了上下文老虎机（CB）策略的个性化效果。

Conclusion: MAB策略已广泛部署，CB策略在某些情况下效果有限，但为未来优化提供了方向。

Abstract: We present an online tutoring system that learns to provide effective
feedback to students after they answer questions incorrectly. Using data from
one million students, the system learns which assistance action (e.g., one of
multiple hints) to provide for each question to optimize student learning.
Employing the multi-armed bandit (MAB) framework and offline policy evaluation,
we assess 43,000 assistance actions, and identify trade-offs between assistance
policies optimized for different student outcomes (e.g., response correctness,
session completion). We design an algorithm that for each question decides on a
suitable policy training objective to enhance students' immediate second
attempt success and overall practice session performance. We evaluate the
resulting MAB policies in 166,000 practice sessions, verifying significant
improvements in student outcomes. While MAB policies optimize feedback for the
overall student population, we further investigate whether contextual bandit
(CB) policies can enhance outcomes by personalizing feedback based on
individual student features (e.g., ability estimates, response times). Using
causal inference, we examine (i) how effects of assistance actions vary across
students and (ii) whether CB policies, which leverage such effect
heterogeneity, outperform MAB policies. While our analysis reveals that some
actions for some questions exhibit effect heterogeneity, effect sizes may often
be too small for CB policies to provide significant improvements beyond what
well-optimized MAB policies that deliver the same action to all students
already achieve. We discuss insights gained from deploying data-driven systems
at scale and implications for future refinements. Today, the teaching policies
optimized by our system support thousands of students daily.

</details>


### [199] [Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem](https://arxiv.org/abs/2508.00286)
*Mohsen Zaker Esteghamati*

Main category: cs.LG

TL;DR: 该研究提出了一种基于可解释机器学习模型的性能抗震设计方法，通过逆向工程直接推导设计参数以实现特定性能目标，并应用于钢和混凝土框架优化。


<details>
  <summary>Details</summary>
Motivation: 解决性能抗震设计中的计算效率问题，通过机器学习直接映射设计变量与性能指标。

Method: 采用可解释机器学习模型作为评估函数，结合遗传优化算法解决逆向工程问题。

Result: 模型在多种建筑类型和地震条件下表现出高准确性（R2>90%），优化算法能识别符合工程原理的构件最优属性。

Conclusion: 该方法高效且准确，适用于性能抗震设计的优化问题。

Abstract: This study presents a methodology to treat performance-based seismic design
as an inverse engineering problem, where design parameters are directly derived
to achieve specific performance objectives. By implementing explainable machine
learning models, this methodology directly maps design variables and
performance metrics, tackling computational inefficiencies of performance-based
design. The resultant machine learning model is integrated as an evaluation
function into a genetic optimization algorithm to solve the inverse problem.
The developed methodology is then applied to two different inventories of steel
and concrete moment frames in Los Angeles and Charleston to obtain sectional
properties of frame members that minimize expected annualized seismic loss in
terms of repair costs. The results show high accuracy of the surrogate models
(e.g., R2> 90%) across a diverse set of building types, geometries, seismic
design, and site hazard, where the optimization algorithm could identify the
optimum values of members' properties for a fixed set of geometric variables,
consistent with engineering principles.

</details>


### [200] [Invariant Graph Transformer for Out-of-Distribution Generalization](https://arxiv.org/abs/2508.00304)
*Tianyin Liao,Ziwei Zhang,Yufei Sun,Chunyu Hu,Jianxin Li*

Main category: cs.LG

TL;DR: GOODFormer是一种基于图不变学习的Transformer模型，旨在解决图数据分布偏移下的泛化问题，通过分离不变与可变子图并优化编码模块实现。


<details>
  <summary>Details</summary>
Motivation: 现有图Transformer在分布偏移下泛化能力不足，图不变学习虽有望解决此问题，但其注意力机制和编码设计仍具挑战。

Method: 提出GOODFormer，包含熵引导的不变子图解耦器、动态子图编码器和不变学习模块，联合优化以捕捉不变关系。

Result: 在基准数据集上，GOODFormer在分布偏移下表现优于现有方法。

Conclusion: GOODFormer通过不变学习有效提升图Transformer的泛化能力，为分布偏移问题提供了解决方案。

Abstract: Graph Transformers (GTs) have demonstrated great effectiveness across various
graph analytical tasks. However, the existing GTs focus on training and testing
graph data originated from the same distribution, but fail to generalize under
distribution shifts. Graph invariant learning, aiming to capture generalizable
graph structural patterns with labels under distribution shifts, is potentially
a promising solution, but how to design attention mechanisms and positional and
structural encodings (PSEs) based on graph invariant learning principles
remains challenging. To solve these challenges, we introduce Graph
Out-Of-Distribution generalized Transformer (GOODFormer), aiming to learn
generalized graph representations by capturing invariant relationships between
predictive graph structures and labels through jointly optimizing three
modules. Specifically, we first develop a GT-based entropy-guided invariant
subgraph disentangler to separate invariant and variant subgraphs while
preserving the sharpness of the attention function. Next, we design an evolving
subgraph positional and structural encoder to effectively and efficiently
capture the encoding information of dynamically changing subgraphs during
training. Finally, we propose an invariant learning module utilizing subgraph
node representations and encodings to derive generalizable graph
representations that can to unseen graphs. We also provide theoretical
justifications for our method. Extensive experiments on benchmark datasets
demonstrate the superiority of our method over state-of-the-art baselines under
distribution shifts.

</details>


### [201] [PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models](https://arxiv.org/abs/2508.00325)
*Yongquan Qu,Matthieu Blanke,Sara Shamekh,Pierre Gentine*

Main category: cs.LG

TL;DR: PnP-DA是一种新型数据同化方法，通过结合轻量级梯度更新和预训练生成先验，减少地球系统建模中的预报误差。


<details>
  <summary>Details</summary>
Motivation: 传统变分方法假设高斯误差统计，无法捕捉混沌系统的非高斯行为，导致预报误差累积。

Method: PnP-DA交替使用梯度分析更新和预训练生成先验，避免复杂神经网络的反向传播。

Result: 在混沌测试中，PnP-DA显著减少预报误差，优于传统变分方法。

Conclusion: PnP-DA通过放松统计假设和利用历史数据，提供了一种高效的数据同化解决方案。

Abstract: Earth system modeling presents a fundamental challenge in scientific
computing: capturing complex, multiscale nonlinear dynamics in computationally
efficient models while minimizing forecast errors caused by necessary
simplifications. Even the most powerful AI- or physics-based forecast system
suffer from gradual error accumulation. Data assimilation (DA) aims to mitigate
these errors by optimally blending (noisy) observations with prior model
forecasts, but conventional variational methods often assume Gaussian error
statistics that fail to capture the true, non-Gaussian behavior of chaotic
dynamical systems. We propose PnP-DA, a Plug-and-Play algorithm that alternates
(1) a lightweight, gradient-based analysis update (using a Mahalanobis-distance
misfit on new observations) with (2) a single forward pass through a pretrained
generative prior conditioned on the background forecast via a conditional
Wasserstein coupling. This strategy relaxes restrictive statistical assumptions
and leverages rich historical data without requiring an explicit regularization
functional, and it also avoids the need to backpropagate gradients through the
complex neural network that encodes the prior during assimilation cycles.
Experiments on standard chaotic testbeds demonstrate that this strategy
consistently reduces forecast errors across a range of observation sparsities
and noise levels, outperforming classical variational methods.

</details>


### [202] [Embryology of a Language Model](https://arxiv.org/abs/2508.00331)
*George Wang,Garrett Baker,Andrew Gordon,Daniel Murfet*

Main category: cs.LG

TL;DR: 论文提出了一种基于UMAP和敏感性分析的方法，可视化语言模型在训练过程中的结构发展，揭示了新的网络机制。


<details>
  <summary>Details</summary>
Motivation: 理解语言模型内部计算结构的形成是深度学习科学的核心问题，但现有方法未能充分利用敏感性分析的潜力。

Method: 采用胚胎学方法，将UMAP应用于敏感性矩阵，可视化模型在训练中的结构发展。

Result: 可视化结果揭示了清晰的“身体计划”，包括已知特征（如感应电路）和新发现的结构（如“间距鳍”）。

Conclusion: 敏感性分析不仅能验证模型，还能发现新机制，为研究复杂神经网络的发育原理提供了强大工具。

Abstract: Understanding how language models develop their internal computational
structure is a central problem in the science of deep learning. While
susceptibilities, drawn from statistical physics, offer a promising analytical
tool, their full potential for visualizing network organization remains
untapped. In this work, we introduce an embryological approach, applying UMAP
to the susceptibility matrix to visualize the model's structural development
over training. Our visualizations reveal the emergence of a clear ``body
plan,'' charting the formation of known features like the induction circuit and
discovering previously unknown structures, such as a ``spacing fin'' dedicated
to counting space tokens. This work demonstrates that susceptibility analysis
can move beyond validation to uncover novel mechanisms, providing a powerful,
holistic lens for studying the developmental principles of complex neural
networks.

</details>


### [203] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
*Qilin Liao,Shuo Yang,Bo Zhao,Ping Luo,Hengshuang Zhao*

Main category: cs.LG

TL;DR: 论文提出了一种名为BOOD的新框架，利用扩散模型生成高质量的OOD特征和图像，显著提升了OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在潜在空间中提取有效OOD特征时面临挑战，尤其是难以识别类间决策边界。

Method: BOOD通过学习文本条件的潜在特征空间，选择靠近决策边界的ID特征并扰动以生成OOD特征，再通过扩散模型解码为图像。

Result: 在CIFAR-100数据集上，BOOD显著优于现有方法，FPR95降低29.64%，AUROC提升7.27%。

Conclusion: BOOD提供了一种高效的OOD特征生成策略，显著提升了OOD检测性能。

Abstract: Harnessing the power of diffusion models to synthesize auxiliary training
data based on latent space features has proven effective in enhancing
out-of-distribution (OOD) detection performance. However, extracting effective
features outside the in-distribution (ID) boundary in latent space remains
challenging due to the difficulty of identifying decision boundaries between
classes. This paper proposes a novel framework called Boundary-based
Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD
features and generates human-compatible outlier images using diffusion models.
BOOD first learns a text-conditioned latent feature space from the ID dataset,
selects ID features closest to the decision boundary, and perturbs them to
cross the decision boundary to form OOD features. These synthetic OOD features
are then decoded into images in pixel space by a diffusion model. Compared to
previous works, BOOD provides a more training efficient strategy for
synthesizing informative OOD features, facilitating clearer distinctions
between ID and OOD data. Extensive experimental results on common benchmarks
demonstrate that BOOD surpasses the state-of-the-art method significantly,
achieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27%
improvement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.

</details>


### [204] [Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization](https://arxiv.org/abs/2508.00357)
*Yoonhyuk Choi,Jiho Choi,Chong-Kwon Kim*

Main category: cs.LG

TL;DR: SGPC（Sheaf GNNs with PAC-Bayes Calibration）是一种新型图神经网络架构，通过结合细胞鞘消息传递、最优传输提升、方差减少扩散和PAC-Bayes谱正则化，解决了GNN中的过平滑问题，并在异质图分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决图神经网络（GNNs）在异质图（heterophilic graphs）上的过平滑问题，现有鞘神经网络方法依赖静态或复杂参数化的鞘结构，缺乏泛化性和稳定性保证。

Method: 提出SGPC架构，结合细胞鞘消息传递、最优传输提升、方差减少扩散和PAC-Bayes谱正则化，实现半监督节点分类。

Result: 在九个同质和异质图基准测试中，SGPC优于现有方法，并提供对未见节点的置信区间。

Conclusion: SGPC通过理论性能界限和端到端训练，显著提升了GNN在异质图上的表现，同时具备计算效率和稳定性。

Abstract: Over-smoothing in Graph Neural Networks (GNNs) causes collapse in distinct
node features, particularly on heterophilic graphs where adjacent nodes often
have dissimilar labels. Although sheaf neural networks partially mitigate this
problem, they typically rely on static or heavily parameterized sheaf
structures that hinder generalization and scalability. Existing sheaf-based
models either predefine restriction maps or introduce excessive complexity, yet
fail to provide rigorous stability guarantees. In this paper, we introduce a
novel scheme called SGPC (Sheaf GNNs with PAC-Bayes Calibration), a unified
architecture that combines cellular-sheaf message passing with several
mechanisms, including optimal transport-based lifting, variance-reduced
diffusion, and PAC-Bayes spectral regularization for robust semi-supervised
node classification. We establish performance bounds theoretically and
demonstrate that the resulting bound-aware objective can be achieved via
end-to-end training in linear computational complexity. Experiments on nine
homophilic and heterophilic benchmarks show that SGPC outperforms
state-of-the-art spectral and sheaf-based GNNs while providing certified
confidence intervals on unseen nodes.

</details>


### [205] [OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions](https://arxiv.org/abs/2508.00364)
*Chanyoung Yoon,Sangbong Yoo,Soobin Yim,Chansoo Kim,Yun Jang*

Main category: cs.LG

TL;DR: OID-PPO是一种基于强化学习的框架，用于优化住宅室内设计，通过结合专家定义的设计准则和连续家具布局，显著提升了布局质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 住宅室内设计对居住满意度至关重要，但现有方法存在计算成本高、数据稀缺或设计准则不足的问题。

Method: 提出OID-PPO框架，利用近端策略优化（PPO）和结构化奖励函数，结合专家定义的功能与视觉准则，实现连续灵活的家具布局。

Result: 实验表明，OID-PPO在多样化的房间形状和家具配置中，显著优于现有方法，布局质量和计算效率均有提升。

Conclusion: OID-PPO通过整合设计准则和连续布局策略，为室内设计提供了高效且高质量的解决方案。

Abstract: Designing residential interiors strongly impacts occupant satisfaction but
remains challenging due to unstructured spatial layouts, high computational
demands, and reliance on expert knowledge. Existing methods based on
optimization or deep learning are either computationally expensive or
constrained by data scarcity. Reinforcement learning (RL) approaches often
limit furniture placement to discrete positions and fail to incorporate design
principles adequately. We propose OID-PPO, a novel RL framework for Optimal
Interior Design using Proximal Policy Optimization, which integrates
expert-defined functional and visual guidelines into a structured reward
function. OID-PPO utilizes a diagonal Gaussian policy for continuous and
flexible furniture placement, effectively exploring latent environmental
dynamics under partial observability. Experiments conducted across diverse room
shapes and furniture configurations demonstrate that OID-PPO significantly
outperforms state-of-the-art methods in terms of layout quality and
computational efficiency. Ablation studies further demonstrate the impact of
structured guideline integration and reveal the distinct contributions of
individual design constraints.

</details>


### [206] [Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions](https://arxiv.org/abs/2508.00392)
*Lijun Zhang,Wenhao Yang,Guanghui Wang,Wei Jiang,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种具有双重适应性的通用算法框架，用于在线学习中最小化自适应遗憾，能够自动适应函数类型和环境变化。


<details>
  <summary>Details</summary>
Motivation: 现有算法缺乏通用性，只能处理单一类型凸函数且需要先验知识，限制了实际应用。

Method: 提出基于元专家框架的双重自适应算法，动态创建多个专家并通过元算法聚合，结合睡眠专家技术捕捉环境变化。

Result: 理论分析表明，算法能同时最小化多种凸函数的自适应遗憾，并允许函数类型在轮次间切换。

Conclusion: 该框架可扩展至在线复合优化，为复合函数自适应遗憾最小化提供通用解决方案。

Abstract: To deal with changing environments, a new performance measure -- adaptive
regret, defined as the maximum static regret over any interval, was proposed in
online learning. Under the setting of online convex optimization, several
algorithms have been successfully developed to minimize the adaptive regret.
However, existing algorithms lack universality in the sense that they can only
handle one type of convex functions and need apriori knowledge of parameters,
which hinders their application in real-world scenarios. To address this
limitation, this paper investigates universal algorithms with dual adaptivity,
which automatically adapt to the property of functions (convex, exponentially
concave, or strongly convex), as well as the nature of environments (stationary
or changing). Specifically, we propose a meta-expert framework for dual
adaptive algorithms, where multiple experts are created dynamically and
aggregated by a meta-algorithm. The meta-algorithm is required to yield a
second-order bound, which can accommodate unknown function types. We further
incorporate the technique of sleeping experts to capture the changing
environments. For the construction of experts, we introduce two strategies
(increasing the number of experts or enhancing the capabilities of experts) to
achieve universality. Theoretical analysis shows that our algorithms are able
to minimize the adaptive regret for multiple types of convex functions
simultaneously, and also allow the type of functions to switch between rounds.
Moreover, we extend our meta-expert framework to online composite optimization,
and develop a universal algorithm for minimizing the adaptive regret of
composite functions.

</details>


### [207] [ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs](https://arxiv.org/abs/2508.00394)
*Antonis Klironomos,Baifan Zhou,Zhipeng Tan,Zhuoxun Zheng,Mohamed H. Gad-Elrab,Heiko Paulheim,Evgeny Kharlamov*

Main category: cs.LG

TL;DR: ExeKGLib是一个Python库，通过图形界面和知识图谱帮助非机器学习专家构建ML管道。


<details>
  <summary>Details</summary>
Motivation: 解决非ML专家在构建高质量ML管道时缺乏专业知识和训练的问题。

Method: 利用知识图谱编码ML知识，提供图形界面简化流程。

Result: ExeKGLib提高了ML管道的透明度和可重用性，并确保其可执行性。

Conclusion: ExeKGLib在实际用例中展示了其可用性和实用性。

Abstract: Nowadays machine learning (ML) practitioners have access to numerous ML
libraries available online. Such libraries can be used to create ML pipelines
that consist of a series of steps where each step may invoke up to several ML
libraries that are used for various data-driven analytical tasks. Development
of high-quality ML pipelines is non-trivial; it requires training, ML
expertise, and careful development of each step. At the same time, domain
experts in science and engineering may not possess such ML expertise and
training while they are in pressing need of ML-based analytics. In this paper,
we present our ExeKGLib, a Python library enhanced with a graphical interface
layer that allows users with minimal ML knowledge to build ML pipelines. This
is achieved by relying on knowledge graphs that encode ML knowledge in simple
terms accessible to non-ML experts. ExeKGLib also allows improving the
transparency and reusability of the built ML workflows and ensures that they
are executable. We show the usability and usefulness of ExeKGLib by presenting
real use cases.

</details>


### [208] [Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement](https://arxiv.org/abs/2508.00410)
*Zizhuo Zhang,Jianing Zhu,Xinmu Ge,Zihua Zhao,Zhanke Zhou,Xuan Li,Xiao Feng,Jiangchao Yao,Bo Han*

Main category: cs.LG

TL;DR: 提出了一种名为Co-Reward的新型强化学习框架，通过对比语义相似问题的答案一致性作为奖励基础，解决了传统方法依赖人工标注和自奖励信号易崩溃的问题。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法依赖人工标注，复杂任务中标注成本高；自奖励信号虽能激发LLM推理能力，但易崩溃。

Method: 构建语义相似问题对，通过简单投票生成代理标签，利用对比一致性作为奖励，增强推理稳定性。

Result: 在多个推理基准测试和LLM系列上表现优于其他自奖励基线，部分任务甚至超越人工标注奖励。

Conclusion: Co-Reward通过自监督奖励机制有效提升LLM推理能力，解决了标注依赖和崩溃问题。

Abstract: Although reinforcement learning with verifiable rewards (RLVR) shows promise
in improving the reasoning ability of large language models (LLMs), the scaling
up dilemma remains due to the reliance on human annotated labels especially for
complex tasks. Recent alternatives that explore various self-reward signals
exhibit the eliciting potential of LLM reasoning, but suffer from the
non-negligible collapse issue. Inspired by the success of self-supervised
learning, we propose \textit{Co-Reward}, a novel RL framework that leverages
contrastive agreement across semantically analogical questions as a reward
basis. Specifically, we construct a similar question for each training sample
(without labels) and synthesize their individual surrogate labels through a
simple rollout voting, and then the reward is constructed by cross-referring
the labels of each question pair to enforce the internal reasoning consistency
across analogical inputs. Intuitively, such a self-supervised reward-shaping
mechanism increases the difficulty of learning collapse into a trivial
solution, and promotes stable reasoning elicitation and improvement through
expanding the input sample variants. Empirically, Co-Reward achieves superior
performance compared to other self-reward baselines on multiple reasoning
benchmarks and LLM series, and reaches or even surpasses ground-truth (GT)
labeled reward, with improvements of up to $+6.8\%$ on MATH500 over GT reward
on Llama-3.2-3B-Instruct. Our code is publicly available at
https://github.com/tmlr-group/Co-Reward.

</details>


### [209] [Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection](https://arxiv.org/abs/2508.00415)
*Yue Yang,Yuxiang Lin,Ying Zhang,Zihan Su,Chang Chuan Goh,Tangtangfang Fang,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: 该论文提出了一种名为ResE-BiLSTM的模型，用于预测贷款违约，并通过实验验证其优于其他基线模型。


<details>
  <summary>Details</summary>
Motivation: 贷款违约预测是信用风险管理中的重要任务，机器学习方法可以用于检测财务异常。

Method: 使用滑动窗口技术和ResE-BiLSTM模型，并在Freddie Mac抵押贷款数据集上评估，与LSTM、BiLSTM、GRU、CNN和RNN等基线模型进行比较。

Result: 实验结果表明，ResE-BiLSTM在准确性、精确度、召回率、F1和AUC等指标上优于基线模型。

Conclusion: ResE-BiLSTM具有实际应用价值，适用于现实场景。

Abstract: Prediction of post-loan default is an important task in credit risk
management, and can be addressed by detection of financial anomalies using
machine learning. This study introduces a ResE-BiLSTM model, using a sliding
window technique, and is evaluated on 44 independent cohorts from the extensive
Freddie Mac US mortgage dataset, to improve prediction performance. The
ResE-BiLSTM is compared with five baseline models: Long Short-Term Memory
(LSTM), BiLSTM, Gated Recurrent Units (GRU), Convolutional Neural Networks
(CNN), and Recurrent Neural Networks (RNN), across multiple metrics, including
Accuracy, Precision, Recall, F1, and AUC. An ablation study was conducted to
evaluate the contribution of individual components in the ResE-BiLSTM
architecture. Additionally, SHAP analysis was employed to interpret the
underlying features the model relied upon for its predictions. Experimental
results demonstrate that ResE-BiLSTM achieves superior predictive performance
compared to baseline models, underscoring its practical value and applicability
in real-world scenarios.

</details>


### [210] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: 本文提出了一种名为ctdGAN的条件生成对抗网络，用于解决表格数据中的类别不平衡问题。通过空间分区和新的损失函数，ctdGAN能生成更接近原始数据分布的高质量样本。


<details>
  <summary>Details</summary>
Motivation: 表格数据中的类别不平衡问题严重影响机器学习性能，现有GAN方法未考虑输入样本的向量子空间，导致生成数据质量不高。

Method: ctdGAN通过空间分区分配簇标签，利用概率采样策略和新损失函数生成样本，同时引入簇级缩放技术。

Result: 在14个不平衡数据集上的实验表明，ctdGAN能生成高保真样本并显著提升分类准确率。

Conclusion: ctdGAN通过改进生成策略和损失函数，有效解决了表格数据中的类别不平衡问题，性能优于现有方法。

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>


### [211] [Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection](https://arxiv.org/abs/2508.00507)
*Yiming Xu,Jiarun Chen,Zhen Peng,Zihan Chen,Qika Lin,Lan Ma,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: 论文提出CoLL框架，结合LLMs和GNNs，利用多LLM协作和GNN门控机制，提升TAG异常检测性能，AP平均提升13.37%。


<details>
  <summary>Details</summary>
Motivation: 现有GAD方法忽视文本模态的互补价值，且LLMs在TAG异常检测中应用尚不成熟，无法有效编码高阶结构信息。

Method: 提出CoLL框架，结合多LLM协作（证据增强生成）和GNN门控机制，融合文本特征与拓扑信息。

Result: 实验显示CoLL在AP上平均提升13.37%，优于现有方法。

Conclusion: CoLL为LLMs在GAD中的应用开辟新途径，结合文本与结构信息实现高质量异常检测。

Abstract: The natural combination of intricate topological structures and rich textual
information in text-attributed graphs (TAGs) opens up a novel perspective for
graph anomaly detection (GAD). However, existing GAD methods primarily focus on
designing complex optimization objectives within the graph domain, overlooking
the complementary value of the textual modality, whose features are often
encoded by shallow embedding techniques, such as bag-of-words or skip-gram, so
that semantic context related to anomalies may be missed. To unleash the
enormous potential of textual modality, large language models (LLMs) have
emerged as promising alternatives due to their strong semantic understanding
and reasoning capabilities. Nevertheless, their application to TAG anomaly
detection remains nascent, and they struggle to encode high-order structural
information inherent in graphs due to input length constraints. For
high-quality anomaly detection in TAGs, we propose CoLL, a novel framework that
combines LLMs and graph neural networks (GNNs) to leverage their complementary
strengths. CoLL employs multi-LLM collaboration for evidence-augmented
generation to capture anomaly-relevant contexts while delivering human-readable
rationales for detected anomalies. Moreover, CoLL integrates a GNN equipped
with a gating mechanism to adaptively fuse textual features with evidence while
preserving high-order topological information. Extensive experiments
demonstrate the superiority of CoLL, achieving an average improvement of 13.37%
in AP. This study opens a new avenue for incorporating LLMs in advancing GAD.

</details>


### [212] [Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning](https://arxiv.org/abs/2508.00513)
*Yiming Xu,Xu Hua,Zhen Peng,Bin Shi,Jiarun Chen,Xingbo Fu,Song Wang,Bo Dong*

Main category: cs.LG

TL;DR: 论文提出了一种名为CMUCL的端到端文本属性图异常检测方法，通过联合训练文本和图编码器，利用跨模态和多尺度一致性提升检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本编码和异常检测目标之间存在分离，导致文本特征难以聚焦于异常检测相关信息，限制了检测能力。

Method: 提出CMUCL方法，联合建模文本和图结构数据，利用跨模态和单模态多尺度一致性训练编码器，并设计基于不一致性挖掘的异常评分器。

Result: 在8个数据集上评估，CMUCL的平均准确率（AP）比次优方法提高了11.13%。

Conclusion: CMUCL显著提升了文本属性图异常检测性能，并发布了8个数据集以推动未来研究。

Abstract: The widespread application of graph data in various high-risk scenarios has
increased attention to graph anomaly detection (GAD). Faced with real-world
graphs that often carry node descriptions in the form of raw text sequences,
termed text-attributed graphs (TAGs), existing graph anomaly detection
pipelines typically involve shallow embedding techniques to encode such textual
information into features, and then rely on complex self-supervised tasks
within the graph domain to detect anomalies. However, this text encoding
process is separated from the anomaly detection training objective in the graph
domain, making it difficult to ensure that the extracted textual features focus
on GAD-relevant information, seriously constraining the detection capability.
How to seamlessly integrate raw text and graph topology to unleash the vast
potential of cross-modal data in TAGs for anomaly detection poses a challenging
issue. This paper presents a novel end-to-end paradigm for text-attributed
graph anomaly detection, named CMUCL. We simultaneously model data from both
text and graph structures, and jointly train text and graph encoders by
leveraging cross-modal and uni-modal multi-scale consistency to uncover
potential anomaly-related information. Accordingly, we design an anomaly score
estimator based on inconsistency mining to derive node-specific anomaly scores.
Considering the lack of benchmark datasets tailored for anomaly detection on
TAGs, we release 8 datasets to facilitate future research. Extensive
evaluations show that CMUCL significantly advances in text-attributed graph
anomaly detection, delivering an 11.13% increase in average accuracy (AP) over
the suboptimal.

</details>


### [213] [Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting](https://arxiv.org/abs/2508.00523)
*Sifan Yang,Yuanyu Wan,Lijun Zhang*

Main category: cs.LG

TL;DR: 论文研究了在线非子模优化问题，提出了两种算法（DBGD-NF和其扩展版）以改进延迟反馈和随机反馈的影响，分别实现了与平均延迟和最大延迟相关的更优遗憾界。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理延迟反馈时依赖于最大延迟，对不规则延迟敏感，且未解耦延迟和随机反馈的影响。本文旨在解决这些问题。

Method: 提出了DBGD-NF算法（使用单点梯度估计器）及其扩展版（采用分块更新机制），分别优化了与平均延迟和最大延迟相关的遗憾界。

Result: DBGD-NF实现了O(n¯d^{1/3}T^{2/3})的遗憾界，扩展版进一步解耦了延迟和随机反馈，实现了O(n(T^{2/3} + √(dT)))的遗憾界。

Conclusion: 实验验证了方法的优越性，扩展版在最大延迟较小时表现更优。

Abstract: We investigate the online nonsubmodular optimization with delayed feedback in
the bandit setting, where the loss function is $\alpha$-weakly DR-submodular
and $\beta$-weakly DR-supermodular. Previous work has established an
$(\alpha,\beta)$-regret bound of $\mathcal{O}(nd^{1/3}T^{2/3})$, where $n$ is
the dimensionality and $d$ is the maximum delay. However, its regret bound
relies on the maximum delay and is thus sensitive to irregular delays.
Additionally, it couples the effects of delays and bandit feedback as its bound
is the product of the delay term and the $\mathcal{O}(nT^{2/3})$ regret bound
in the bandit setting without delayed feedback. In this paper, we develop two
algorithms to address these limitations, respectively. Firstly, we propose a
novel method, namely DBGD-NF, which employs the one-point gradient estimator
and utilizes all the available estimated gradients in each round to update the
decision. It achieves a better $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ regret
bound, which is relevant to the average delay $\bar{d} =
\frac{1}{T}\sum_{t=1}^T d_t\leq d$. Secondly, we extend DBGD-NF by employing a
blocking update mechanism to decouple the joint effect of the delays and bandit
feedback, which enjoys an $\mathcal{O}(n(T^{2/3} + \sqrt{dT}))$ regret bound.
When $d = \mathcal{O}(T^{1/3})$, our regret bound matches the
$\mathcal{O}(nT^{2/3})$ bound in the bandit setting without delayed feedback.
Compared to our first $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ bound, it is more
advantageous when the maximum delay $d = o(\bar{d}^{2/3}T^{1/3})$. Finally, we
conduct experiments on structured sparse learning to demonstrate the
superiority of our methods.

</details>


### [214] [Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery](https://arxiv.org/abs/2508.00539)
*Judy X Yang*

Main category: cs.LG

TL;DR: 提出一种两阶段框架，通过信噪比阈值和光谱平滑增强矿物检测，结合聚类和NNLS提高解混精度。


<details>
  <summary>Details</summary>
Motivation: 解决高光谱成像中弱矿物信号被噪声和冗余波段掩盖的问题。

Method: 第一阶段：信噪比阈值和Savitzky-Golay滤波；第二阶段：KMeans聚类和NNLS解混。

Result: 提高了弱矿物区域的检测精度和解混准确性。

Conclusion: 两阶段策略为地质高光谱应用提供了实用且可重复的解决方案。

Abstract: Hyperspectral imaging offers detailed spectral information for mineral
mapping; however, weak mineral signatures are often masked by noisy and
redundant bands, limiting detection performance. To address this, we propose a
two-stage integrated framework for enhanced mineral detection in the Cuprite
mining district. In the first stage, we compute the signal-to-noise ratio (SNR)
for each spectral band and apply a phase-locked thresholding technique to
discard low-SNR bands, effectively removing redundancy and suppressing
background noise. Savitzky-Golay filtering is then employed for spectral
smoothing, serving a dual role first to stabilize trends during band selection,
and second to preserve fine-grained spectral features during preprocessing. In
the second stage, the refined HSI data is reintroduced into the model, where
KMeans clustering is used to extract 12 endmember spectra (W1 custom), followed
by non negative least squares (NNLS) for abundance unmixing. The resulting
endmembers are quantitatively compared with laboratory spectra (W1 raw) using
cosine similarity and RMSE metrics. Experimental results confirm that our
proposed pipeline improves unmixing accuracy and enhances the detection of weak
mineral zones. This two-pass strategy demonstrates a practical and reproducible
solution for spectral dimensionality reduction and unmixing in geological HSI
applications.

</details>


### [215] [Foundations of Interpretable Models](https://arxiv.org/abs/2508.00545)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Alberto Termine,Mateja Jamnik,Giuseppe Marra*

Main category: cs.LG

TL;DR: 论文提出了一种新的可解释性定义，解决了现有定义不具操作性的问题，并提供了设计可解释模型的蓝图和开源库。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性定义缺乏操作性，无法指导用户设计通用、可靠且稳健的可解释模型，导致研究问题不明确。

Method: 提出了一种通用且简单的可解释性定义，涵盖现有非正式概念，并基于此设计了可解释模型的蓝图和开源库。

Result: 新定义具有操作性，揭示了设计可解释模型所需的基础属性、假设、原则、数据结构和架构特征。

Conclusion: 论文通过新定义和工具推动了可解释AI研究，为设计可解释模型提供了实用指导。

Abstract: We argue that existing definitions of interpretability are not actionable in
that they fail to inform users about general, sound, and robust interpretable
model design. This makes current interpretability research fundamentally
ill-posed. To address this issue, we propose a definition of interpretability
that is general, simple, and subsumes existing informal notions within the
interpretable AI community. We show that our definition is actionable, as it
directly reveals the foundational properties, underlying assumptions,
principles, data structures, and architectural features necessary for designing
interpretable models. Building on this, we propose a general blueprint for
designing interpretable models and introduce the first open-sourced library
with native support for interpretable data structures and processes.

</details>


### [216] [Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides](https://arxiv.org/abs/2508.00578)
*Marlen Neubert,Patrick Reiser,Frauke Gräter,Pascal Friederich*

Main category: cs.LG

TL;DR: 论文研究了氢原子转移（HAT）反应的模拟方法，通过机器学习势能面（PES）预测反应能垒，MACE模型表现最佳，并应用于胶原蛋白模拟。


<details>
  <summary>Details</summary>
Motivation: HAT反应在生物过程中至关重要，但其机制尚不完全清楚，传统模拟方法难以满足量子化学精度的需求。

Method: 使用半经验方法和DFT生成HAT配置数据集，并评估三种图神经网络架构（SchNet、Allegro、MACE）的性能。

Result: MACE在能量、力和能垒预测上表现最优，平均绝对误差为1.13 kcal/mol，成功应用于胶原蛋白模拟。

Conclusion: 该方法可推广至其他生物分子系统，为复杂环境中的化学反应提供量子级精确模拟。

Abstract: Hydrogen atom transfer (HAT) reactions are essential in many biological
processes, such as radical migration in damaged proteins, but their mechanistic
pathways remain incompletely understood. Simulating HAT is challenging due to
the need for quantum chemical accuracy at biologically relevant scales; thus,
neither classical force fields nor DFT-based molecular dynamics are applicable.
Machine-learned potentials offer an alternative, able to learn potential energy
surfaces (PESs) with near-quantum accuracy. However, training these models to
generalize across diverse HAT configurations, especially at radical positions
in proteins, requires tailored data generation and careful model selection.
Here, we systematically generate HAT configurations in peptides to build large
datasets using semiempirical methods and DFT. We benchmark three graph neural
network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT
PESs and indirectly predict reaction barriers from energy predictions. MACE
consistently outperforms the others in energy, force, and barrier prediction,
achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT
barrier predictions. This accuracy enables integration of ML potentials into
large-scale collagen simulations to compute reaction rates from predicted
barriers, advancing mechanistic understanding of HAT and radical migration in
peptides. We analyze scaling laws, model transferability, and cost-performance
trade-offs, and outline strategies for improvement by combining ML potentials
with transition state search algorithms and active learning. Our approach is
generalizable to other biomolecular systems, enabling quantum-accurate
simulations of chemical reactivity in complex environments.

</details>


### [217] [The Role of Active Learning in Modern Machine Learning](https://arxiv.org/abs/2508.00586)
*Thorben Werner,Lars Schmidt-Thieme,Vijaya Krishna Yalavarthi*

Main category: cs.LG

TL;DR: 研究发现，主动学习（AL）在低数据场景下效率最低，提升仅1-4%，而数据增强（DA）和半监督学习（SSL）结合随机采样可提升60%。但AL与DA和SSL结合后仍能提供额外提升。


<details>
  <summary>Details</summary>
Motivation: 探讨AL在低数据场景下的表现，以及如何与其他方法结合以提高效率。

Method: 比较AL、DA和SSL在低数据场景下的效果，并测试它们的组合性能。

Result: AL单独效果有限，但与DA和SSL结合后仍能提供额外提升。

Conclusion: AL应作为DA和SSL后的补充方法，而非独立解决低数据问题的工具。

Abstract: Even though Active Learning (AL) is widely studied, it is rarely applied in
contexts outside its own scientific literature. We posit that the reason for
this is AL's high computational cost coupled with the comparatively small lifts
it is typically able to generate in scenarios with few labeled points. In this
work we study the impact of different methods to combat this low data scenario,
namely data augmentation (DA), semi-supervised learning (SSL) and AL. We find
that AL is by far the least efficient method of solving the low data problem,
generating a lift of only 1-4\% over random sampling, while DA and SSL methods
can generate up to 60\% lift in combination with random sampling. However, when
AL is combined with strong DA and SSL techniques, it surprisingly is still able
to provide improvements. Based on these results, we frame AL not as a method to
combat missing labels, but as the final building block to squeeze the last bits
of performance out of data after appropriate DA and SSL methods as been
applied.

</details>


### [218] [Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data](https://arxiv.org/abs/2508.00615)
*Mukesh Kumar Sahu,Pinki Roy*

Main category: cs.LG

TL;DR: 提出了一种基于相似性的自构建图模型（SBSCGM）和混合图神经网络（HybridGraphMedGNN），用于预测ICU患者的死亡风险和关键性评分，性能优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统模型难以利用电子健康记录（EHR）中的关系结构，且孤立处理患者数据，无法动态捕捉患者间的相似性。

Method: SBSCGM通过多模态EHR数据动态构建患者相似图，HybridGraphMedGNN结合GCN、GraphSAGE和GAT层学习患者表示。

Result: 在MIMIC-III数据集上，模型AUC-ROC达0.94，优于基线模型，并提供可解释的预测。

Conclusion: 该框架为ICU风险预测提供了可扩展且可解释的解决方案，有望支持临床决策。

Abstract: Accurately predicting the criticalness of ICU patients (such as in-ICU
mortality risk) is vital for early intervention in critical care. However,
conventional models often treat each patient in isolation and struggle to
exploit the relational structure in Electronic Health Records (EHR). We propose
a Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds
a patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN
architecture that operates on this graph to predict patient mortality and a
continuous criticalness score. SBSCGM uses a hybrid similarity measure
(combining feature-based and structural similarities) to connect patients with
analogous clinical profiles in real-time. The HybridGraphMedGNN integrates
Graph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT)
layers to learn robust patient representations, leveraging both local and
global graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III
dataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$)
outperforming baseline classifiers and single-type GNN models. We also
demonstrate improved precision/recall and show that the attention mechanism
provides interpretable insights into model predictions. Our framework offers a
scalable and interpretable solution for critical care risk prediction, with
potential to support clinicians in real-world ICU deployment.

</details>


### [219] [IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources](https://arxiv.org/abs/2508.00627)
*Paul Tresson,Pierre Le Coz,Hadrien Tulet,Anthony Malkassian,Maxime Réjou Méchain*

Main category: cs.LG

TL;DR: IAMAP是一个用户友好的QGIS插件，旨在简化深度学习在遥感中的应用，无需大量数据集、计算资源或编程技能。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在遥感中应用的高门槛问题，包括需要大量数据、计算资源和编程能力。

Method: 基于自监督学习的通用模型（基础模型），提供特征提取、降维、聚类、相似性映射和模型验证等功能。

Result: IAMAP为非AI专家提供了高效、节能的深度学习工具，推动了深度学习方法的普及。

Conclusion: IAMAP通过简化流程和降低门槛，促进了深度学习在遥感领域的广泛应用。

Abstract: Remote sensing has entered a new era with the rapid development of artificial
intelligence approaches. However, the implementation of deep learning has
largely remained restricted to specialists and has been impractical because it
often requires (i) large reference datasets for model training and validation;
(ii) substantial computing resources; and (iii) strong coding skills. Here, we
introduce IAMAP, a user-friendly QGIS plugin that addresses these three
challenges in an easy yet flexible way. IAMAP builds on recent advancements in
self-supervised learning strategies, which now provide robust feature
extractors, often referred to as foundation models. These generalist models can
often be reliably used in few-shot or zero-shot scenarios (i.e., with little to
no fine-tuning). IAMAP's interface allows users to streamline several key steps
in remote sensing image analysis: (i) extracting image features using a wide
range of deep learning architectures; (ii) reducing dimensionality with
built-in algorithms; (iii) performing clustering on features or their reduced
representations; (iv) generating feature similarity maps; and (v) calibrating
and validating supervised machine learning models for prediction. By enabling
non-AI specialists to leverage the high-quality features provided by recent
deep learning approaches without requiring GPU capacity or extensive reference
datasets, IAMAP contributes to the democratization of computationally efficient
and energy-conscious deep learning methods.

</details>


### [220] [Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs](https://arxiv.org/abs/2508.00628)
*Xiong Xiong,Zhuo Zhang,Rongchun Hu,Chen Gao,Zichen Deng*

Main category: cs.LG

TL;DR: SV-SNN是一种新型神经网络框架，通过分离变量和自适应谱方法解决高频振荡PDE求解中的谱偏差问题，显著提升了精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统PINN在高频振荡PDE求解中存在谱偏差问题，限制了其捕捉高频解的能力。

Method: SV-SNN通过分解多元函数为单变量函数乘积、自适应傅里叶谱特征和基于奇异值分解的理论框架，解决了谱偏差问题。

Result: 在多个基准问题上，SV-SNN实现了1-3个数量级的精度提升，参数减少90%以上，训练时间减少60%。

Conclusion: SV-SNN是解决神经网络PDE求解中谱偏差问题的有效方法，具有显著的实际应用价值。

Abstract: Solving high-frequency oscillatory partial differential equations (PDEs) is a
critical challenge in scientific computing, with applications in fluid
mechanics, quantum mechanics, and electromagnetic wave propagation. Traditional
physics-informed neural networks (PINNs) suffer from spectral bias, limiting
their ability to capture high-frequency solution components. We introduce
Separated-Variable Spectral Neural Networks (SV-SNN), a novel framework that
addresses these limitations by integrating separation of variables with
adaptive spectral methods. Our approach features three key innovations: (1)
decomposition of multivariate functions into univariate function products,
enabling independent spatial and temporal networks; (2) adaptive Fourier
spectral features with learnable frequency parameters for high-frequency
capture; and (3) theoretical framework based on singular value decomposition to
quantify spectral bias. Comprehensive evaluation on benchmark problems
including Heat equation, Helmholtz equation, Poisson equations and
Navier-Stokes equations demonstrates that SV-SNN achieves 1-3 orders of
magnitude improvement in accuracy while reducing parameter count by over 90\%
and training time by 60\%. These results establish SV-SNN as an effective
solution to the spectral bias problem in neural PDE solving. The implementation
will be made publicly available upon acceptance at
https://github.com/xgxgnpu/SV-SNN.

</details>


### [221] [KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting](https://arxiv.org/abs/2508.00635)
*Changning Wu,Gao Wu,Rongyao Cai,Yong Liu,Kexin Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于KAN的自适应频率选择学习架构（KFS），用于解决时间序列预测中的多尺度噪声干扰和频率信息分布不均问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界的时间序列存在多尺度噪声干扰和频率信息分布不均，导致多尺度表示不理想。

Method: 结合Kolmogorov-Arnold Networks（KAN）和Parseval定理，设计了KFS架构，包括FreK模块（基于能量分布选择主导频率）、时间戳嵌入对齐和特征混合模块。

Result: 在多个真实时间序列数据集上的实验表明，KFS实现了最先进的性能。

Conclusion: KFS是一种简单而有效的架构，能够有效解决多尺度时间序列预测中的挑战。

Abstract: Multi-scale decomposition architectures have emerged as predominant
methodologies in time series forecasting. However, real-world time series
exhibit noise interference across different scales, while heterogeneous
information distribution among frequency components at varying scales leads to
suboptimal multi-scale representation. Inspired by Kolmogorov-Arnold Networks
(KAN) and Parseval's theorem, we propose a KAN based adaptive Frequency
Selection learning architecture (KFS) to address these challenges. This
framework tackles prediction challenges stemming from cross-scale noise
interference and complex pattern modeling through its FreK module, which
performs energy-distribution-based dominant frequency selection in the spectral
domain. Simultaneously, KAN enables sophisticated pattern representation while
timestamp embedding alignment synchronizes temporal representations across
scales. The feature mixing module then fuses scale-specific patterns with
aligned temporal features. Extensive experiments across multiple real-world
time series datasets demonstrate that KT achieves state-of-the-art performance
as a simple yet effective architecture.

</details>


### [222] [Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense](https://arxiv.org/abs/2508.00641)
*Alessandro Palmas*

Main category: cs.LG

TL;DR: 论文探讨了强化学习在防御低成本自杀式无人机群攻击中的应用，通过高保真模拟环境和强化学习策略，优化拦截优先级，显著降低平均损害并提高防御效率。


<details>
  <summary>Details</summary>
Motivation: 低成本自杀式无人机群的威胁日益增加，需要快速战略决策来优化拦截优先级，现代防御系统面临重大挑战。

Method: 提出一个高保真模拟环境，训练强化学习代理在离散动作空间中选择拦截目标，基于无人机位置、类别和效应器状态等特征。

Result: 强化学习策略在数百次模拟攻击中表现优于手工规则基线，平均损害更低，防御效率更高。

Conclusion: 强化学习可作为防御架构的战略层，增强韧性而不替代现有控制系统，相关代码和模拟资源已公开。

Abstract: The growing threat of low-cost kamikaze drone swarms poses a critical
challenge to modern defense systems demanding rapid and strategic
decision-making to prioritize interceptions across multiple effectors and
high-value target zones. In this work, we present a case study demonstrating
the practical advantages of reinforcement learning in addressing this
challenge. We introduce a high-fidelity simulation environment that captures
realistic operational constraints, within which a decision-level reinforcement
learning agent learns to coordinate multiple effectors for optimal interception
prioritization. Operating in a discrete action space, the agent selects which
drone to engage per effector based on observed state features such as
positions, classes, and effector status. We evaluate the learned policy against
a handcrafted rule-based baseline across hundreds of simulated attack
scenarios. The reinforcement learning based policy consistently achieves lower
average damage and higher defensive efficiency in protecting critical zones.
This case study highlights the potential of reinforcement learning as a
strategic layer within defense architectures, enhancing resilience without
displacing existing control systems. All code and simulation assets are
publicly released for full reproducibility, and a video demonstration
illustrates the policy's qualitative behavior.

</details>


### [223] [Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators](https://arxiv.org/abs/2508.00643)
*Albert Matveev,Sanmitra Ghosh,Aamal Hussain,James-Michael Leahy,Michalis Michaelides*

Main category: cs.LG

TL;DR: DINOZAUR是一种基于扩散的神经算子参数化方法，解决了FNOs的过参数化和不确定性量化问题，通过减少参数数量并提供贝叶斯不确定性估计，在多个PDE基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: FNOs存在过参数化和缺乏原生不确定性量化的问题，限制了其在科学和工程应用中的可靠性。

Method: DINOZAUR采用扩散乘子替代FNOs中的密集张量乘子，减少参数数量，并通过贝叶斯方法提供不确定性量化。

Result: 在多个PDE基准测试中，DINOZAUR表现优于或与现有方法相当，同时提供高效的不确定性量化。

Conclusion: DINOZAUR是一种高效且可靠的神经算子参数化方法，适用于需要不确定性量化的科学和工程应用。

Abstract: Operator learning is a powerful paradigm for solving partial differential
equations, with Fourier Neural Operators serving as a widely adopted
foundation. However, FNOs face significant scalability challenges due to
overparameterization and offer no native uncertainty quantification -- a key
requirement for reliable scientific and engineering applications. Instead,
neural operators rely on post hoc UQ methods that ignore geometric inductive
biases. In this work, we introduce DINOZAUR: a diffusion-based neural operator
parametrization with uncertainty quantification. Inspired by the structure of
the heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a
dimensionality-independent diffusion multiplier that has a single learnable
time parameter per channel, drastically reducing parameter count and memory
footprint without compromising predictive performance. By defining priors over
those time parameters, we cast DINOZAUR as a Bayesian neural operator to yield
spatially correlated outputs and calibrated uncertainty estimates. Our method
achieves competitive or superior performance across several PDE benchmarks
while providing efficient uncertainty quantification.

</details>


### [224] [TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction](https://arxiv.org/abs/2508.00657)
*Sihang Zeng,Lucas Jing Liu,Jun Wen,Meliha Yetisgen,Ruth Etzioni,Gang Luo*

Main category: cs.LG

TL;DR: TrajSurv利用神经控制微分方程从纵向电子健康记录中学习连续潜在轨迹，用于可信赖的生存预测，并通过对比学习和两阶段解释过程提高透明度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决纵向电子健康记录中不规则采样数据的临床进展建模问题，并透明地将进展与生存结果关联。

Method: 使用神经控制微分方程（NCDE）提取连续潜在轨迹，通过时间感知对比学习对齐潜在状态与患者状态，采用两阶段解释过程（向量场和聚类）关联临床进展与生存结果。

Result: 在MIMIC-III和eICU数据集上，TrajSurv表现出优于现有深度学习方法的准确性和透明度。

Conclusion: TrajSurv为临床决策提供了更准确和透明的生存预测工具。

Abstract: Trustworthy survival prediction is essential for clinical decision making.
Longitudinal electronic health records (EHRs) provide a uniquely powerful
opportunity for the prediction. However, it is challenging to accurately model
the continuous clinical progression of patients underlying the irregularly
sampled clinical features and to transparently link the progression to survival
outcomes. To address these challenges, we develop TrajSurv, a model that learns
continuous latent trajectories from longitudinal EHR data for trustworthy
survival prediction. TrajSurv employs a neural controlled differential equation
(NCDE) to extract continuous-time latent states from the irregularly sampled
data, forming continuous latent trajectories. To ensure the latent trajectories
reflect the clinical progression, TrajSurv aligns the latent state space with
patient state space through a time-aware contrastive learning approach. To
transparently link clinical progression to the survival outcome, TrajSurv uses
latent trajectories in a two-step divide-and-conquer interpretation process.
First, it explains how the changes in clinical features translate into the
latent trajectory's evolution using a learned vector field. Second, it clusters
these latent trajectories to identify key clinical progression patterns
associated with different survival outcomes. Evaluations on two real-world
medical datasets, MIMIC-III and eICU, show TrajSurv's competitive accuracy and
superior transparency over existing deep learning methods.

</details>


### [225] [DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes](https://arxiv.org/abs/2508.00664)
*Jialun Zheng,Jie Liu,Jiannong Cao,Xiao Wang,Hanchen Yang,Yankai Chen,Philip S. Yu*

Main category: cs.LG

TL;DR: 提出了一种动态原型（DP）的动态图异常检测（DGAD）模型，用于捕捉跨领域和领域内演化的异常模式。


<details>
  <summary>Details</summary>
Motivation: 动态图异常检测在多个领域（如金融、交通、社交网络）中至关重要，但现有通用模型难以捕捉动态图中的演化异常，且新领域缺乏标注数据。

Method: DP-DGAD通过动态原型提取演化模式，存储在内存缓冲区，选择性更新以保留通用模式并纳入新领域模式，结合异常评分器和伪标记进行自监督适应。

Result: 在十个真实数据集上实现了最先进的性能。

Conclusion: DP-DGAD能有效捕捉跨领域和领域内演化的异常模式，适用于动态图异常检测。

Abstract: Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies
in evolving graphs across domains such as finance, traffic, and social
networks. Recently, generalist graph anomaly detection (GAD) models have shown
promising results. They are pretrained on multiple source datasets and
generalize across domains. While effective on static graphs, they struggle to
capture evolving anomalies in dynamic graphs. Moreover, the continuous
emergence of new domains and the lack of labeled data further challenge
generalist DGAD. Effective cross-domain DGAD requires both domain-specific and
domain-agnostic anomalous patterns. Importantly, these patterns evolve
temporally within and across domains. Building on these insights, we propose a
DGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and
domain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,
evolving representations of normal and anomalous patterns, from temporal
ego-graphs and stores them in a memory buffer. The buffer is selectively
updated to retain general, domain-agnostic patterns while incorporating new
domain-specific ones. Then, an anomaly scorer compares incoming data with
dynamic prototypes to flag both general and domain-specific anomalies. Finally,
DP-DGAD employs confidence-based pseudo-labeling for effective self-supervised
adaptation in target domains. Extensive experiments demonstrate
state-of-the-art performance across ten real-world datasets from different
domains.

</details>


### [226] [Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network](https://arxiv.org/abs/2508.00692)
*Young-ho Cho,Hao Zhu,Duehee Lee,Ross Baldick*

Main category: cs.LG

TL;DR: 论文提出了一种结合GDFM和GAN的方法，用于合成分布式风电场的长期风电功率场景，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了在资源充足性研究中更准确地模拟风电场的时空特征，需要一种能够同时捕捉空间和时间相关性的方法。

Method: 结合GDFM（提取空间相关性）和GAN（生成时间相关性），通过GAN提供动态因子过滤器，再应用于GDFM中。

Result: 在澳大利亚风电数据上的测试表明，该方法在合成风电功率场景时性能优于其他替代方案。

Conclusion: GDFM与GAN结合的方法能够更好地模拟实际风电功率的统计特性，为资源充足性研究提供了更可靠的场景生成工具。

Abstract: For conducting resource adequacy studies, we synthesize multiple long-term
wind power scenarios of distributed wind farms simultaneously by using the
spatio-temporal features: spatial and temporal correlation, waveforms, marginal
and ramp rates distributions of waveform, power spectral densities, and
statistical characteristics. Generating the spatial correlation in scenarios
requires the design of common factors for neighboring wind farms and
antithetical factors for distant wind farms. The generalized dynamic factor
model (GDFM) can extract the common factors through cross spectral density
analysis, but it cannot closely imitate waveforms. The GAN can synthesize
plausible samples representing the temporal correlation by verifying samples
through a fake sample discriminator. To combine the advantages of GDFM and GAN,
we use the GAN to provide a filter that extracts dynamic factors with temporal
information from the observation data, and we then apply this filter in the
GDFM to represent both spatial and frequency correlations of plausible
waveforms. Numerical tests on the combination of GDFM and GAN have demonstrated
performance improvements over competing alternatives in synthesizing wind power
scenarios from Australia, better realizing plausible statistical
characteristics of actual wind power compared to alternatives such as the GDFM
with a filter synthesized from distributions of actual dynamic filters and the
GAN with direct synthesis without dynamic factors.

</details>


### [227] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
*Sergio Rubio-Martín,María Teresa García-Ordás,Antonio Serrano-García,Clara Margarita Franch-Pato,Arturo Crespo-Álvaro,José Alberto Benítez-Andrades*

Main category: cs.LG

TL;DR: 研究比较了多种AI模型（传统机器学习和深度学习）对临床笔记分类的性能，发现超参数调优显著提升模型准确性，而过采样技术影响有限。


<details>
  <summary>Details</summary>
Motivation: 临床笔记分类对心理健康诊断至关重要，研究旨在评估不同AI模型和数据平衡方法的效能。

Method: 比较传统机器学习（如随机森林、SVM）和深度学习模型（如DistilBERT、SciBERT），并测试三种过采样策略及超参数调优。

Result: 超参数调优显著提升模型性能，过采样技术影响有限；决策树和XGBoost达96%准确率，BERT模型同样表现优异。

Conclusion: 超参数调优对模型性能至关重要，研究为AI辅助心理健康诊断提供了实用见解。

Abstract: The classification of clinical notes into specific diagnostic categories is
critical in healthcare, especially for mental health conditions like Anxiety
and Adjustment Disorder. In this study, we compare the performance of various
Artificial Intelligence models, including both traditional Machine Learning
approaches (Random Forest, Support Vector Machine, K-nearest neighbors,
Decision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT
and SciBERT), to classify clinical notes into these two diagnoses.
Additionally, we implemented three oversampling strategies: No Oversampling,
Random Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to
assess their impact on model performance. Hyperparameter tuning was also
applied to optimize model accuracy. Our results indicate that oversampling
techniques had minimal impact on model performance overall. The only exception
was SMOTE, which showed a positive effect specifically with BERT-based models.
However, hyperparameter optimization significantly improved accuracy across the
models, enhancing their ability to generalize and perform on the dataset. The
Decision Tree and eXtreme Gradient Boost models achieved the highest accuracy
among machine learning approaches, both reaching 96%, while the DistilBERT and
SciBERT models also attained 96% accuracy in the deep learning category. These
findings underscore the importance of hyperparameter tuning in maximizing model
performance. This study contributes to the ongoing research on AI-assisted
diagnostic tools in mental health by providing insights into the efficacy of
different model architectures and data balancing methods.

</details>


### [228] [Learning Network Dismantling without Handcrafted Inputs](https://arxiv.org/abs/2508.00706)
*Haozhe Tian,Pietro Ferraro,Robert Shorten,Mahdi Jalili,Homayoun Hamedmoghadam*

Main category: cs.LG

TL;DR: 论文提出了一种无需手工特征的消息传递图神经网络框架MIND，用于解决网络拆除问题，并在大规模真实网络上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖手工特征，增加了计算成本并引入偏差，因此需要一种更高效、通用的方法。

Method: 引入注意力机制和消息迭代配置文件，结合多样化合成网络训练集，构建MIND框架。

Result: MIND在大型真实网络上表现优于现有方法，具有高效性和通用性。

Conclusion: MIND不仅适用于网络拆除问题，还可推广到其他复杂网络问题。

Abstract: The application of message-passing Graph Neural Networks has been a
breakthrough for important network science problems. However, the competitive
performance often relies on using handcrafted structural features as inputs,
which increases computational cost and introduces bias into the otherwise
purely data-driven network representations. Here, we eliminate the need for
handcrafted features by introducing an attention mechanism and utilizing
message-iteration profiles, in addition to an effective algorithmic approach to
generate a structurally diverse training set of small synthetic networks.
Thereby, we build an expressive message-passing framework and use it to
efficiently solve the NP-hard problem of Network Dismantling, virtually
equivalent to vital node identification, with significant real-world
applications. Trained solely on diversified synthetic networks, our proposed
model -- MIND: Message Iteration Network Dismantler -- generalizes to large,
unseen real networks with millions of nodes, outperforming state-of-the-art
network dismantling methods. Increased efficiency and generalizability of the
proposed model can be leveraged beyond dismantling in a range of complex
network problems.

</details>


### [229] [Efficient Solution and Learning of Robust Factored MDPs](https://arxiv.org/abs/2508.00707)
*Yannik Schnitzer,Alessandro Abate,David Parker*

Main category: cs.LG

TL;DR: 提出了基于因子化状态空间表示的新方法，用于解决和学习鲁棒马尔可夫决策过程（r-MDPs），通过利用系统组件间的不确定性独立性，提高了样本效率和策略性能。


<details>
  <summary>Details</summary>
Motivation: r-MDPs通过显式建模转移动态的认知不确定性扩展了MDPs，但学习r-MDPs需要大量样本交互，因此需要更高效的方法。

Method: 利用因子化状态空间表示，将非凸优化问题重新表述为可处理的线性规划问题，并直接从数据中学习因子化模型表示。

Result: 实验表明，利用因子化结构可显著提高样本效率，生成比现有方法更有效的鲁棒策略和更严格的性能保证。

Conclusion: 因子化方法为r-MDPs的学习和求解提供了高效且可扩展的解决方案。

Abstract: Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling
epistemic uncertainty about transition dynamics. Learning r-MDPs from
interactions with an unknown environment enables the synthesis of robust
policies with provable (PAC) guarantees on performance, but this can require a
large number of sample interactions. We propose novel methods for solving and
learning r-MDPs based on factored state-space representations that leverage the
independence between model uncertainty across system components. Although
policy synthesis for factored r-MDPs leads to hard, non-convex optimisation
problems, we show how to reformulate these into tractable linear programs.
Building on these, we also propose methods to learn factored model
representations directly. Our experimental results show that exploiting
factored structure can yield dimensional gains in sample efficiency, producing
more effective robust policies with tighter performance guarantees than
state-of-the-art methods.

</details>


### [230] [JSON-Bag: A generic game trajectory representation](https://arxiv.org/abs/2508.00712)
*Dien Nguyen,Diego Perez-Liebana,Simon Lucas*

Main category: cs.LG

TL;DR: JSON-Bag模型通过标记化JSON描述游戏轨迹，并使用Jensen-Shannon距离（JSD）作为度量，在六款桌游的分类任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 提出一种通用的游戏轨迹表示方法，以解决传统手工特征提取的局限性。

Method: 使用JSON-Bag模型和JSD距离，结合原型最近邻搜索（P-NNS）评估分类任务。

Result: 在多数任务中优于基线方法，且样本效率高；自动特征提取显著提升低效任务准确率。

Conclusion: JSON-Bag模型能有效表示游戏轨迹，且JSD距离与策略距离高度相关。

Abstract: We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically
represent game trajectories by tokenizing their JSON descriptions and apply
Jensen-Shannon distance (JSD) as distance metric for them. Using a
prototype-based nearest-neighbor search (P-NNS), we evaluate the validity of
JSON-Bag with JSD on six tabletop games -- \textit{7 Wonders},
\textit{Dominion}, \textit{Sea Salt and Paper}, \textit{Can't Stop},
\textit{Connect4}, \textit{Dots and boxes} -- each over three game trajectory
classification tasks: classifying the playing agents, game parameters, or game
seeds that were used to generate the trajectories.
  Our approach outperforms a baseline using hand-crafted features in the
majority of tasks. Evaluating on N-shot classification suggests using JSON-Bag
prototype to represent game trajectory classes is also sample efficient.
Additionally, we demonstrate JSON-Bag ability for automatic feature extraction
by treating tokens as individual features to be used in Random Forest to solve
the tasks above, which significantly improves accuracy on underperforming
tasks. Finally, we show that, across all six games, the JSD between JSON-Bag
prototypes of agent classes highly correlates with the distances between
agents' policies.

</details>


### [231] [Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning](https://arxiv.org/abs/2508.00716)
*Yingxu Wang,Mengzhu Wang,Zhichao Huang,Suyu Liu*

Main category: cs.LG

TL;DR: NeGPR是一种针对带噪声标签的图域自适应框架，通过双分支预训练和嵌套伪标签细化机制提升跨域学习鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有图域自适应方法依赖干净源标签的假设，实际中标签噪声普遍存在且严重影响性能的问题。

Method: 采用双分支（语义和拓扑）预训练，通过邻域一致性减少噪声影响；嵌套细化机制和噪声感知正则化策略。

Result: 在基准数据集上，NeGPR在严重标签噪声下性能优于现有方法，准确率提升高达12.7%。

Conclusion: NeGPR通过噪声鲁棒性设计，显著提升了带噪声标签的图域自适应性能。

Abstract: Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled
source graphs to unlabeled target graphs by learning domain-invariant
representations, which is essential in applications such as molecular property
prediction and social network analysis. However, most existing GDA methods rely
on the assumption of clean source labels, which rarely holds in real-world
scenarios where annotation noise is pervasive. This label noise severely
impairs feature alignment and degrades adaptation performance under domain
shifts. To address this challenge, we propose Nested Graph Pseudo-Label
Refinement (NeGPR), a novel framework tailored for graph-level domain
adaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,
semantic and topology branches, by enforcing neighborhood consistency in the
feature space, thereby reducing the influence of noisy supervision. To bridge
domain gaps, NeGPR employs a nested refinement mechanism in which one branch
selects high-confidence target samples to guide the adaptation of the other,
enabling progressive cross-domain learning. Furthermore, since pseudo-labels
may still contain noise and the pre-trained branches are already overfitted to
the noisy labels in the source domain, NeGPR incorporates a noise-aware
regularization strategy. This regularization is theoretically proven to
mitigate the adverse effects of pseudo-label noise, even under the presence of
source overfitting, thus enhancing the robustness of the adaptation process.
Extensive experiments on benchmark datasets demonstrate that NeGPR consistently
outperforms state-of-the-art methods under severe label noise, achieving gains
of up to 12.7% in accuracy.

</details>


### [232] [Democratizing Tabular Data Access with an Open$\unicode{x2013}$Source Synthetic$\unicode{x2013}$Data SDK](https://arxiv.org/abs/2508.00718)
*Ivona Krchova,Mariana Vargas Vieyra,Mario Scriminaci,Andrey Sidorenko*

Main category: cs.LG

TL;DR: MOSTLY AI SDK是一个开源工具包，用于生成高质量的合成表格数据，解决数据访问受限问题。


<details>
  <summary>Details</summary>
Motivation: 由于隐私、专有利益和伦理问题，高质量数据的获取受限，合成数据成为解决方案。

Method: 基于TabularARGN自回归框架，集成差分隐私、公平性生成和自动化质量保证。

Result: SDK支持多种数据类型和复杂数据集，性能优越，速度快且易用。

Conclusion: SDK已快速部署，有效解决实际数据瓶颈，推动数据民主化。

Abstract: Machine learning development critically depends on access to high-quality
data. However, increasing restrictions due to privacy, proprietary interests,
and ethical concerns have created significant barriers to data accessibility.
Synthetic data offers a viable solution by enabling safe, broad data usage
without compromising sensitive information. This paper presents the MOSTLY AI
Synthetic Data Software Development Kit (SDK), an open-source toolkit designed
specifically for synthesizing high-quality tabular data. The SDK integrates
robust features such as differential privacy guarantees, fairness-aware data
generation, and automated quality assurance into a flexible and accessible
Python interface. Leveraging the TabularARGN autoregressive framework, the SDK
supports diverse data types and complex multi-table and sequential datasets,
delivering competitive performance with notable improvements in speed and
usability. Currently deployed both as a cloud service and locally installable
software, the SDK has seen rapid adoption, highlighting its practicality in
addressing real-world data bottlenecks and promoting widespread data
democratization.

</details>


### [233] [Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems](https://arxiv.org/abs/2508.00734)
*Liuyun Xu,Seymour M. J. Spence*

Main category: cs.LG

TL;DR: 提出一种结合多保真度分层采样和自适应机器学习元模型的方法，用于高效估计小失效概率，显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方差缩减技术在估计小失效概率时仍需大量模型评估，尤其在复杂非线性有限元建模环境中计算成本高昂。

Method: 采用分层采样生成高保真数据集训练深度学习元模型，作为低保真模型，结合多保真度蒙特卡洛框架估计失效概率。

Result: 应用于高层钢结构建筑的风激励分析，能准确估计非线性响应的超越概率曲线，显著节省计算成本。

Conclusion: 该方法在保证精度的同时显著提升了计算效率，适用于复杂系统的罕见事件分析。

Abstract: Existing variance reduction techniques used in stochastic simulations for
rare event analysis still require a substantial number of model evaluations to
estimate small failure probabilities. In the context of complex, nonlinear
finite element modeling environments, this can become computationally
challenging-particularly for systems subjected to stochastic excitation. To
address this challenge, a multi-fidelity stratified sampling scheme with
adaptive machine learning metamodels is introduced for efficiently propagating
uncertainties and estimating small failure probabilities. In this approach, a
high-fidelity dataset generated through stratified sampling is used to train a
deep learning-based metamodel, which then serves as a cost-effective and highly
correlated low-fidelity model. An adaptive training scheme is proposed to
balance the trade-off between approximation quality and computational demand
associated with the development of the low-fidelity model. By integrating the
low-fidelity outputs with additional high-fidelity results, an unbiased
estimate of the strata-wise failure probabilities is obtained using a
multi-fidelity Monte Carlo framework. The overall probability of failure is
then computed using the total probability theorem. Application to a full-scale
high-rise steel building subjected to stochastic wind excitation demonstrates
that the proposed scheme can accurately estimate exceedance probability curves
for nonlinear responses of interest, while achieving significant computational
savings compared to single-fidelity variance reduction approaches.

</details>


### [234] [A Simple and Effective Method for Uncertainty Quantification and OOD Detection](https://arxiv.org/abs/2508.00754)
*Yaxin Ma,Benjamin Colburn,Jose C. Principe*

Main category: cs.LG

TL;DR: 提出了一种基于特征空间密度的单确定性模型方法，用于量化分布偏移和OOD检测，优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯神经网络和深度集成方法计算和存储成本高，需更高效的不确定性量化方法。

Method: 利用核密度估计的信息势场近似训练集特征空间密度，通过比较测试样本特征空间表示检测分布偏移。

Result: 在2D合成数据集和OOD检测任务中表现优于基线模型。

Conclusion: 单确定性模型方法高效且有效，适用于分布偏移和OOD检测。

Abstract: Bayesian neural networks and deep ensemble methods have been proposed for
uncertainty quantification; however, they are computationally intensive and
require large storage. By utilizing a single deterministic model, we can solve
the above issue. We propose an effective method based on feature space density
to quantify uncertainty for distributional shifts and out-of-distribution (OOD)
detection. Specifically, we leverage the information potential field derived
from kernel density estimation to approximate the feature space density of the
training set. By comparing this density with the feature space representation
of test samples, we can effectively determine whether a distributional shift
has occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons
and Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The
results demonstrate that our method outperforms baseline models.

</details>


### [235] [Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data](https://arxiv.org/abs/2508.00758)
*Timur Sattarov,Marco Schreyer,Damian Borth*

Main category: cs.LG

TL;DR: 提出了一种结合扩散模型和对比学习的去噪自编码器（DDAE），用于表格数据异常检测，在ADBench的57个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 表格数据异常检测因特征交互复杂和异常样本稀缺而具有挑战性，现有方法如去噪自编码器和扩散模型各有局限性。

Method: DDAE整合了扩散模型的噪声调度和对比学习，优化编码过程。

Result: 在ADBench上，DDAE在半监督和无监督设置中均优于基线方法，PR-AUC和ROC-AUC提升显著。

Conclusion: 研究表明，噪声策略对表格异常检测至关重要，不同噪声水平适用于不同训练场景。

Abstract: Anomaly detection in tabular data remains challenging due to complex feature
interactions and the scarcity of anomalous examples. Denoising autoencoders
rely on fixed-magnitude noise, limiting adaptability to diverse data
distributions. Diffusion models introduce scheduled noise and iterative
denoising, but lack explicit reconstruction mappings. We propose the
Diffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates
diffusion-based noise scheduling and contrastive learning into the encoding
process to improve anomaly detection. We evaluated DDAE on 57 datasets from
ADBench. Our method outperforms in semi-supervised settings and achieves
competitive results in unsupervised settings, improving PR-AUC by up to 65%
(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)
model baselines. We observed that higher noise levels benefit unsupervised
training, while lower noise with linear scheduling is optimal in
semi-supervised settings. These findings underscore the importance of
principled noise strategies in tabular anomaly detection.

</details>


### [236] [Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy](https://arxiv.org/abs/2508.00768)
*Antonio Tudisco,Andrea Marchesin,Maurizio Zamboni,Mariagrazia Graziano,Giovanna Turvani*

Main category: cs.LG

TL;DR: 该论文分析了量子机器学习中变分量子电路（VQC）的性能，比较了振幅编码和角度编码模型在不同旋转门下的分类表现，发现编码方式对模型性能有显著影响。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习的快速发展促使研究者探索如何优化变分量子电路的性能，尤其是编码方式对模型分类能力的影响。

Method: 研究通过振幅编码和角度编码两种方式构建VQC模型，并在Wine和Diabetes数据集上训练和评估其分类性能，比较不同旋转门的影响。

Result: 实验结果显示，相同拓扑结构下，最佳和最差模型的准确率差异达10%至30%，甚至高达41%，表明编码方式对性能有显著影响。

Conclusion: 研究证实编码方式是VQC模型的重要超参数，选择适当的旋转门能显著提升分类性能。

Abstract: Recent advancements in Quantum Computing and Machine Learning have increased
attention to Quantum Machine Learning (QML), which aims to develop machine
learning models by exploiting the quantum computing paradigm. One of the widely
used models in this area is the Variational Quantum Circuit (VQC), a hybrid
model where the quantum circuit handles data inference while classical
optimization adjusts the parameters of the circuit. The quantum circuit
consists of an encoding layer, which loads data into the circuit, and a
template circuit, known as the ansatz, responsible for processing the data.
This work involves performing an analysis by considering both Amplitude- and
Angle-encoding models, and examining how the type of rotational gate applied
affects the classification performance of the model. This comparison is carried
out by training the different models on two datasets, Wine and Diabetes, and
evaluating their performance. The study demonstrates that, under identical
model topologies, the difference in accuracy between the best and worst models
ranges from 10% to 30%, with differences reaching up to 41%. Moreover, the
results highlight how the choice of rotational gates used in encoding can
significantly impact the model's classification performance. The findings
confirm that the embedding represents a hyperparameter for VQC models.

</details>


### [237] [Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors](https://arxiv.org/abs/2508.00785)
*Bushra Akter,Md Biplob Hosen,Sabbir Ahmed,Mehrin Anannya,Md. Farhad Hossain*

Main category: cs.LG

TL;DR: 研究探讨了影响学生CGPA的多变量因素，通过文献综述、调查数据分析和机器学习模型，开发了一个预测和优化学术表现的Web应用。


<details>
  <summary>Details</summary>
Motivation: 探究学术表现的多变量影响因素，以制定优化学生CGPA的有效策略。

Method: 通过文献综述构建假设因果图，进行在线调查（1050名学生），数据预处理后，采用因果分析、回归和分类模型（如岭回归和随机森林），并结合可解释AI技术（SHAP、LIME）。

Result: 岭回归预测CGPA的MAE为0.12，MSE为0.023；随机森林分类准确率达98.68%。关键因素包括学习时间、奖学金、父母教育背景和先前学术表现。

Conclusion: 研究开发了一个Web应用，为学生提供个性化建议，帮助他们预测和改进学术表现。

Abstract: Academic performance depends on a multivariable nexus of socio-academic and
financial factors. This study investigates these influences to develop
effective strategies for optimizing students' CGPA. To achieve this, we
reviewed various literature to identify key influencing factors and constructed
an initial hypothetical causal graph based on the findings. Additionally, an
online survey was conducted, where 1,050 students participated, providing
comprehensive data for analysis. Rigorous data preprocessing techniques,
including cleaning and visualization, ensured data quality before analysis.
Causal analysis validated the relationships among variables, offering deeper
insights into their direct and indirect effects on CGPA. Regression models were
implemented for CGPA prediction, while classification models categorized
students based on performance levels. Ridge Regression demonstrated strong
predictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared
Error of 0.023. Random Forest outperformed in classification, attaining an
F1-score near perfection and an accuracy of 98.68%. Explainable AI techniques
such as SHAP, LIME, and Interpret enhanced model interpretability, highlighting
critical factors such as study hours, scholarships, parental education, and
prior academic performance. The study culminated in the development of a
web-based application that provides students with personalized insights,
allowing them to predict academic performance, identify areas for improvement,
and make informed decisions to enhance their outcomes.

</details>


### [238] [Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management](https://arxiv.org/abs/2508.00806)
*Ping Chen,Zhuohong Deng,Ping Li,Shuibing He,Hongzi Zhu,Yi Zheng,Zhefeng Wang,Baoxing Huai,Minyi Guo*

Main category: cs.LG

TL;DR: Adacc是一个结合自适应压缩和激活检查点的内存管理框架，旨在减少GPU内存占用并加速大型语言模型训练。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练中，内存重计算会引入高达30%的开销，Adacc旨在解决这一问题。

Method: Adacc包含三个模块：层特定压缩算法、基于MILP的最优调度策略和自适应策略演化机制。

Result: 实验表明，Adacc比现有框架加速1.01x至1.37x，同时保持模型精度。

Conclusion: Adacc有效减少了内存占用并提升了训练效率，同时不影响模型精度。

Abstract: Training large language models often employs recomputation to alleviate
memory pressure, which can introduce up to 30% overhead in real-world
scenarios. In this paper, we propose Adacc, a novel memory management framework
that combines adaptive compression and activation checkpointing to reduce the
GPU memory footprint. It comprises three modules: (1) We design layer-specific
compression algorithms that account for outliers in LLM tensors, instead of
directly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We
propose an optimal scheduling policy that employs MILP to determine the best
memory optimization for each tensor. (3) To accommodate changes in training
tensors, we introduce an adaptive policy evolution mechanism that adjusts the
policy during training to enhance throughput. Experimental results show that
Adacc can accelerate the LLM training by 1.01x to 1.37x compared to
state-of-the-art frameworks, while maintaining comparable model accuracy to the
Baseline.

</details>
