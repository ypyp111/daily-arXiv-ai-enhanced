<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 64]
- [cs.CL](#cs.CL) [Total: 52]
- [cs.LG](#cs.LG) [Total: 51]
- [cs.AI](#cs.AI) [Total: 22]
- [math.NA](#math.NA) [Total: 14]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 7]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision](https://arxiv.org/abs/2509.09720)
*Akansel Cosgun,Lachlan Chumbley,Benjamin J. Meyer*

Main category: cs.CV

TL;DR: ASOS是一个包含50种常见超市商品的3D纹理网格数据集，专为机器人和计算机视觉基准测试设计，强调真实性和可获取性


<details>
  <summary>Details</summary>
Motivation: 现有数据集多依赖合成模型或难以获取的专业物品，缺乏真实世界常见物品的高质量3D数据，限制了在机器人抓取、物体检测等应用中的实用性

Method: 使用运动恢复结构技术从高分辨率图像生成水密3D网格，所有物品均来自澳大利亚主要超市连锁店，涵盖10个不同类别，具有多样化的形状、尺寸和重量

Result: 创建了一个包含50种常见超市物品的高质量3D纹理网格数据集，所有物品都易于获取且成本低廉，为基准测试提供了真实世界的实用性

Conclusion: ASOS数据集填补了现有基准测试数据集的空白，通过提供真实、易获取的超市物品3D模型，为物体检测、姿态估计和机器人应用提供了更有价值的评测标准

Abstract: This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.

</details>


### [2] [A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval](https://arxiv.org/abs/2509.09721)
*Jiayi Miao,Dingxin Lu,Zhuqi Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态检索增强生成框架(MM-RAG)，用于自然灾害后房屋损坏评估，通过双分支编码器和跨模态交互模块实现图像和文本的语义对齐，在检索准确性和损坏严重程度分类指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 自然灾害后准确的房屋损坏评估对于保险理赔响应和资源规划至关重要，需要结合图像和文本信息进行综合分析。

Method: 基于经典RAG架构，设计双分支多模态编码器结构：图像分支使用ResNet和Transformer视觉编码器提取建筑物损坏特征，文本分支使用BERT检索器对帖子和保险政策进行文本向量化；集成跨模态交互模块通过多头注意力实现语义对齐；引入模态注意力门控机制动态控制生成过程中视觉证据和文本先验信息的作用；采用端到端训练，结合对比损失、检索损失和生成损失进行多任务优化。

Result: 在检索准确性和损坏严重程度分类指标上表现出优异性能，Top-1检索准确率提高了9.6%。

Conclusion: 该MM-RAG框架通过有效的跨模态语义对齐和多任务学习，显著提升了自然灾害后房屋损坏评估的准确性和效率，为保险理赔和资源规划提供了可靠的技术支持。

Abstract: After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.

</details>


### [3] [Improving MLLM Historical Record Extraction with Test-Time Image](https://arxiv.org/abs/2509.09722)
*Taylor Archibald,Tony Martinez*

Main category: cs.CV

TL;DR: 提出一种基于LLM的集成框架，通过多图像增强变体转录和Needleman-Wunsch对齐器融合，提高噪声历史文档转录准确率4个百分点


<details>
  <summary>Details</summary>
Motivation: 解决噪声历史文档中文本提取的稳定性问题，传统单次转录方法在噪声文档上准确率有限

Method: 使用Gemini 2.0 Flash对多个增强变体图像进行转录，通过自定义Needleman-Wunsch风格对齐器融合输出，生成共识转录和置信度分数

Result: 在622份宾夕法尼亚死亡记录数据集上，相比单次转录基线准确率提升4个百分点；填充和模糊增强最有效，网格扭曲扰动最适合区分高低置信度案例

Conclusion: 该方法简单、可扩展，可立即部署到其他文档集合和转录模型，为历史文档数字化提供有效解决方案

Abstract: We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.

</details>


### [4] [MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance](https://arxiv.org/abs/2509.09730)
*Kaikai Zhao,Zhaoxiang Liu,Peng Wang,Xin Wang,Zhicheng Ma,Yajun Xu,Wenjing Zhang,Yibing Nan,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: 提出了第一个大规模多模态智能交通监控基准数据集MITS，包含17万张真实交通监控图像和500万条指令-问答对，显著提升了主流大模型在交通监控任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 通用大模型在智能交通监控领域表现有限，主要原因是缺乏专门的多模态数据集，需要构建专门的基准数据集来推动该领域发展。

Method: 收集17万张真实交通监控图像并标注8大类24小类对象和事件，通过系统化数据生成流程产生高质量图像描述和500万条指令-问答对，覆盖5个关键交通监控任务。

Result: 在MITS数据集上微调后，LLaVA-1.5性能从0.494提升至0.905（+83.2%），LLaVA-1.6从0.678到0.921（+35.8%），Qwen2-VL从0.584到0.926（+58.6%），Qwen2.5-VL从0.732到0.930（+27.0%）。

Conclusion: MITS数据集有效解决了智能交通监控领域缺乏专门多模态数据的问题，显著提升了大模型在该领域的性能，为ITS和LMM研究提供了高价值资源。

Abstract: General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.

</details>


### [5] [Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs](https://arxiv.org/abs/2509.09732)
*Sary Elmansoury,Islam Mesabah,Gerrit Großmann,Peter Neigel,Raj Bhalwankar,Daniel Kondermann,Sebastian J. Vollmer*

Main category: cs.CV

TL;DR: 本文研究树状结构化推理是否能提升视觉语言模型在细粒度分类任务中的性能，发现虽然模型能很好理解树状知识，但树基推理始终不如标准零样本提示方法。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在零样本视觉分类方面表现出色，但在细粒度任务和大规模层次标签空间中的性能尚未充分研究，需要探索结构化推理是否能提升性能。

Method: 引入一个框架，使用决策树将分类分解为可解释的决策，在细粒度(GTSRB)和粗粒度(CIFAR-10)数据集上进行评估，并探索用LLM生成的类别和图像描述来增强树提示。

Result: 模型在理解树状知识方面达到98.2%的准确率，但树基推理始终表现不如标准零样本提示。添加图像描述后，树基方法和零样本方法的性能都有所提升。

Conclusion: 研究结果揭示了结构化推理在视觉分类中的局限性，为设计更可解释的视觉语言模型系统提供了见解。

Abstract: Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.

</details>


### [6] [World Modeling with Probabilistic Structure Integration](https://arxiv.org/abs/2509.09737)
*Klemen Kotar,Wanhee Lee,Rahul Venkatesh,Honglin Chen,Daniel Bear,Jared Watrous,Simon Kim,Khai Loong Aw,Lilian Naing Chen,Stefan Stojanov,Kevin Feigelis,Imran Thobani,Alex Durango,Khaled Jedoui,Atlas Kazemian,Dan Yamins*

Main category: cs.CV

TL;DR: PSI是一个从数据中学习可控制、可提示的世界模型的系统，通过三步循环构建概率图模型，提取底层结构，并整合为新的token类型来增强模型能力


<details>
  <summary>Details</summary>
Motivation: 构建能够从视频数据中学习丰富可控性和灵活提示性的世界模型，支持对各种变量间依赖关系的完整条件分布建模

Method: 三步循环：1)概率预测-构建随机访问自回归序列模型；2)结构提取-通过因果推断零样本提取低维属性；3)整合-将结构转换为新token类型并融入训练

Result: 在1.4万亿token互联网视频数据上训练PSI实例，实现了视频预测和理解推理，提取了最先进的光流、自监督深度和对象分割，支持完整的预测改进循环

Conclusion: PSI系统通过循环增强机制成功构建了强大的世界模型，既改善了底层数据建模，又创建了类似LLM的通用提示语言的新控制手段

Abstract: We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.

</details>


### [7] [Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning](https://arxiv.org/abs/2509.09742)
*Md Fazle Rasul,Alanood Alqobaisi,Bruhadeshwar Bezawada,Indrakshi Ray*

Main category: cs.CV

TL;DR: 本文首次分析了联邦学习中视频数据的梯度反演攻击风险，发现特征提取器能提供更好的保护，但攻击者仍可通过超分辨率技术重建高质量视频


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然通过交换模型更新而非原始数据来保护隐私，但梯度反演攻击能够从共享梯度中重建敏感数据。目前对图像、文本和表格数据的攻击已有研究，但视频数据的泄露风险尚未被探索

Method: 评估两种视频分类方法：使用预训练特征提取器的方法和处理原始视频帧的简单变换方法。测试在不同攻击场景下（攻击者拥有0个、1个或多个参考帧）的梯度反演攻击效果，并使用图像超分辨率技术提升重建视频质量

Result: 特征提取器对梯度反演攻击具有更强的抵抗力，但如果分类器复杂度不足，数据泄露仍然可能发生。超分辨率技术能够显著提升攻击者重建视频的质量

Conclusion: 视频数据在联邦学习中存在可行的泄露威胁，需要进一步研究其发生条件和相应的防御措施

Abstract: Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.

</details>


### [8] [A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images](https://arxiv.org/abs/2509.09750)
*Hossein Yazdanjouei,Arash Mansouri,Mohammad Shokouhifar*

Main category: cs.CV

TL;DR: 提出了一种用于密集零售环境目标检测的半监督协同训练框架，结合Faster R-CNN和YOLO进行伪标签交换，使用集成分类器增强鲁棒性，通过元启发式算法优化超参数，在SKU-110k数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决密集零售环境中标注数据有限、遮挡和重叠物体复杂条件下的目标检测挑战，降低人工标注成本并适应零售环境频繁变化的需求。

Method: 采用半监督协同训练框架，结合Faster R-CNN（ResNet骨干）进行精确定位和YOLO（Darknet骨干）获取全局上下文，通过伪标签交换提升检测精度；使用XGBoost、随机森林和SVM集成分类器增强分类鲁棒性；应用元启发式算法优化超参数。

Result: 在SKU-110k数据集上表现出强大的性能，证明了框架在真实零售应用中的可扩展性和实用性。

Conclusion: 该框架有效减少了人工标注依赖，降低了标注成本，能够很好地适应零售环境中产品和布局的频繁变化，适用于自动化库存跟踪、产品监控和结账系统等实际应用。

Abstract: This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.

</details>


### [9] [Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging](https://arxiv.org/abs/2509.09785)
*Moslem Yazdanpanah,Ali Bahri,Mehrdad Noori,Sahar Dastani,Gustavo Adolfo Vargas Hakim,David Osowiechi,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出了Token Purging (PG)方法，一种无需反向传播的测试时自适应技术，通过移除受域偏移影响的token来提升3D点云分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决3D点云分类中由于分布偏移导致的性能下降问题，现有测试时自适应方法需要迭代更新，效率较低。

Method: 提出两种变体：PG-SP利用源域统计信息，PG-SF是完全源无关版本，使用CLS-token驱动自适应，在注意力层前移除受域偏移影响的token。

Result: 在ModelNet40-C、ShapeNet-C和ScanObjectNN-C数据集上，PG-SP比最先进的无反向传播方法平均准确率高10.3%，PG-SF在源无关自适应方面创下新基准，速度提升12.4倍，内存效率提升5.5倍。

Conclusion: Token Purging是一种高效、内存友好的测试时自适应方法，适用于实际部署，无需反向传播即可实现鲁棒的性能提升。

Abstract: Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}

</details>


### [10] [Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors](https://arxiv.org/abs/2509.09792)
*Zimin Xia,Chenghao Xu,Alexandre Alahi*

Main category: cs.CV

TL;DR: 提出了一种精确且高度可解释的跨视角细粒度定位方法，通过匹配地面图像与参考航空图像的局部特征来估计3自由度位姿，避免了传统鸟瞰图转换的信息损失问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法将地面图像转换为鸟瞰图表示再与航空图像对齐，这种转换常因透视畸变或高度信息压缩导致信息丢失，降低对齐质量。

Method: 直接在原始图像间建立对应关系，仅将匹配的关键点使用单目深度先验提升到鸟瞰空间。支持公制和相对深度，采用尺度感知的Procrustes对齐来估计相机位姿，并在使用相对深度时可选地恢复尺度。

Result: 实验结果表明，仅需相机位姿的弱监督，该方法就能学习准确的局部特征对应关系，在跨区域泛化和未知方向等挑战性条件下实现优越的定位性能。

Conclusion: 该方法与各种相对深度模型兼容且无需逐模型微调，这种灵活性结合强大的定位性能，使其非常适合实际部署。

Abstract: We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.

</details>


### [11] [Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test](https://arxiv.org/abs/2509.09808)
*Judith Massmann,Alexander Lichtenstein,Francisco M. López*

Main category: cs.CV

TL;DR: 开发基于智能手机的儿童视力筛查应用KidsVisionCheck，使用红眼反射图像和深度学习模型，准确率达90%，无需专业设备


<details>
  <summary>Details</summary>
Motivation: 利用智能手机和AI技术重现传统Bruckner测试，实现可访问的儿童视力筛查和早期干预

Method: 基于眼科医生收集标注的儿童瞳孔图像，训练深度神经网络模型

Result: 在未见测试数据上达到90%的准确率，能够识别最佳数据收集条件并提供即时用户反馈

Conclusion: 这是实现全球可访问的儿科视力筛查和视力异常早期干预的第一步

Abstract: Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.

</details>


### [12] [DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception](https://arxiv.org/abs/2509.09828)
*Tim Broedermannn,Christos Sakaridis,Luigi Piccinelli,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: 提出DGFusion方法，通过深度引导的多模态融合改进自动驾驶语义感知，利用激光雷达数据学习深度感知特征，实现动态传感器融合


<details>
  <summary>Details</summary>
Motivation: 现有传感器融合方法在空间上均匀处理传感器数据，在挑战性条件下性能受限，需要根据深度信息动态调整传感器融合策略

Method: 提出深度引导的多模态融合网络DGFusion，将多模态分割作为多任务问题处理，使用激光雷达测量作为输入和深度学习真值，通过局部深度token和全局条件token动态适应传感器可靠性

Result: 在MUSES和DELIVER数据集上实现了最先进的全景和语义分割性能

Conclusion: 深度引导的传感器融合方法能够有效提升自动驾驶语义感知在挑战性条件下的鲁棒性

Abstract: Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion

</details>


### [13] [Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework](https://arxiv.org/abs/2509.09841)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 提出基于图像块的ResNet-18深度学习框架，用于自动检测酒渣鼻，通过局部图像块分析提高检测准确性、鲁棒性和患者隐私保护


<details>
  <summary>Details</summary>
Motivation: 酒渣鼻是一种慢性炎症性皮肤病，需要精确早期检测来提高治疗效果。传统全图像方法可能包含过多无关信息且涉及隐私问题

Method: 使用ResNet-18深度学习框架，从面部图像提取不同大小、形状和位置的各种图像块，研究局部视觉信息对模型性能的影响

Result: 实验表明基于图像块的策略在准确性和敏感性方面达到或优于全图像方法，能够引导模型关注临床相关区域，增强鲁棒性和可解释性

Conclusion: 提出的基于图像块的策略为改进自动化皮肤病诊断提供了实用见解，既能提高检测性能又能保护患者隐私

Abstract: Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.

</details>


### [14] [Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection](https://arxiv.org/abs/2509.09844)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 提出了一种基于临床先验知识和合成数据的隐私保护型玫瑰痤疮自动检测方法，通过构建红色通道掩膜聚焦诊断相关区域，在真实测试数据上取得了优于全脸基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 玫瑰痤疮是一种常见但诊断不足的炎症性皮肤病，自动检测面临症状弥散、标注数据稀缺以及面部图像隐私问题等挑战。

Method: 首先构建基于红色通道强度的固定掩膜来聚焦脸颊、鼻子和前额等诊断相关区域，排除身份识别特征；然后使用ResNet-18深度学习模型在掩膜后的合成图像上进行训练。

Result: 在真实世界测试数据上，该方法在准确率、召回率和F1分数方面均显著优于全脸基线模型，表现出优越性能。

Conclusion: 合成数据和临床先验知识可以共同实现准确且符合伦理的皮肤病AI系统，特别适用于远程医疗和大规模筛查等隐私敏感应用场景。

Abstract: Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.

</details>


### [15] [Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking](https://arxiv.org/abs/2509.09849)
*Chengyu Yang,Chengjun Liu*

Main category: cs.CV

TL;DR: 本文对ULW腹腔镜图像去烟框架进行了全面的消融研究，评估了可学习维纳滤波器和复合损失函数中各损失项对整体性能的具体贡献。


<details>
  <summary>Details</summary>
Motivation: 为了严格评估ULW腹腔镜图像去烟框架中各个组件的有效性和必要性，需要系统性地分析每个组件对整体性能的具体贡献。

Method: 采用消融研究方法，包括：(1)移除可学习维纳滤波器模块；(2)选择性使用复合损失函数中的各个损失项（MSE、SSIM损失和感知损失）。所有变体在公开的配对腹腔镜图像数据集上进行基准测试。

Result: 使用定量指标（SSIM、PSNR、MSE和CIEDE-2000）和定性视觉比较对所有变体进行了评估，以确定各组件的重要性。

Conclusion: 通过系统的消融研究，明确了ULW框架中各个组件（特别是可学习维纳滤波器和复合损失函数）对腹腔镜图像去烟性能的具体贡献和必要性。

Abstract: To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.

</details>


### [16] [WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector](https://arxiv.org/abs/2509.09859)
*Razvan Stefanescu,Ethan Oh,Ruben Vazquez,Chris Mesterharm,Constantin Serban,Ritu Chadha*

Main category: cs.CV

TL;DR: WAVE-DETR是一个结合可见光RGB和声学信号的多模态无人机检测器，使用Deformable DETR和Wav2Vec2架构，在挑战性环境条件下实现强性能表现。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够融合视觉和声学特征的统一目标检测模型，以在复杂环境条件下实现更稳健的无人机检测。

Method: 基于Deformable DETR和Wav2Vec2架构，开发了四种不同的融合配置（门控机制、线性层、MLP和交叉注意力），将声学嵌入与多分辨率特征映射融合。

Result: 最佳的门控融合方法将Deformable DETR检测器在ARDrone数据集上的mAP提升了11.1%到15.3%（小型无人机），所有尺寸无人机的整体增益在3.27%到5.84%之间。

Conclusion: 声学信息能够显著提升无人机检测性能，特别是在挑战性环境条件下，多模态融合方法为无人机检测提供了有效的解决方案。

Abstract: We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.

</details>


### [17] [Surrogate Supervision for Robust and Generalizable Deformable Image Registration](https://arxiv.org/abs/2509.09869)
*Yihao Liu,Junyu Chen,Lianrui Zuo,Shuwen Wei,Brian D. Boyd,Carmen Andreescu,Olusola Ajilore,Warren D. Taylor,Aaron Carass,Bennett A. Landman*

Main category: cs.CV

TL;DR: 提出了一种名为"代理监督"的新训练范式，通过将估计的空间变换应用于代理图像，将输入域与监督域解耦，从而在异质输入上训练配准网络，同时确保在相似性定义良好的域中进行监督计算。


<details>
  <summary>Details</summary>
Motivation: 深度学习形变图像配准虽然精度高，但对输入图像特性变化（如伪影、视野不匹配、模态差异）敏感，需要提高配准网络的鲁棒性和泛化能力。

Method: 引入代理监督框架，将输入域与监督域解耦，通过将估计的空间变换应用于代理图像，在异质输入上训练网络，同时在相似性定义良好的域中进行监督计算。

Result: 在三个代表性应用中（抗伪影脑MR配准、掩码无关肺CT配准、多模态MR配准）均表现出对输入变化的强韧性，包括不均匀场、不一致视野和模态差异，同时在良好处理的数据上保持高性能。

Conclusion: 代理监督为训练鲁棒且可泛化的深度学习配准模型提供了原则性框架，不增加复杂性，为医学图像配准在多样化生物医学成像场景中的更广泛应用提供了实用途径。

Abstract: Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.

</details>


### [18] [An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars](https://arxiv.org/abs/2509.09911)
*Barkin Buyukcakir,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: 提出结合卷积自编码器和Vision Transformer的框架，提高牙齿年龄估计的准确性和可解释性，发现第三磨牙的高类内形态变异是性能限制因素


<details>
  <summary>Details</summary>
Motivation: 深度学习在法医年龄估计等高风险应用中面临'黑盒'问题，需要提高模型性能和透明度

Method: 使用卷积自编码器(AE)与Vision Transformer(ViT)结合的框架，分析AE的潜在空间指标和图像重建来提供多方面的诊断见解

Result: 分类准确率显著提升：牙齿37从0.712提高到0.815，牙齿38从0.462提高到0.543，发现剩余性能差距主要是数据中心的，由牙齿38数据集的高类内形态变异导致

Conclusion: 该框架不仅提高准确性，还提供模型不确定性的证据，强调单一可解释性模式（如注意力图）的不足，为法医年龄估计专家决策提供更可靠的工具

Abstract: The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.

</details>


### [19] [SCoDA: Self-supervised Continual Domain Adaptation](https://arxiv.org/abs/2509.09935)
*Chirayu Agrawal,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: SCoDA是一种无需源域数据的自监督域适应方法，通过几何流形对齐和EMA更新解决传统SFDA方法丢失几何信息的问题


<details>
  <summary>Details</summary>
Motivation: 传统SFDA方法依赖全监督预训练和余弦相似度对齐，会丢弃源模型潜在流形的关键几何信息，需要新的方法来保留这些信息

Method: 使用自监督预训练的教师模型初始化，结合实例级特征匹配和空间相似性损失进行几何流形对齐，通过EMA更新教师参数防止灾难性遗忘

Result: 在基准数据集上的大量实验表明，SCoDA显著优于最先进的SFDA方法

Conclusion: SCoDA通过自监督预训练和几何流形对齐，成功解决了SFDA中的几何信息丢失问题，取得了优异性能

Abstract: Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.

</details>


### [20] [Segment Anything for Cell Tracking](https://arxiv.org/abs/2509.09943)
*Zhu Chen,Mert Edgü,Er Jin,Johannes Stegmaier*

Main category: cs.CV

TL;DR: 提出了一种基于Segment Anything 2的零样本细胞追踪框架，无需手动标注训练数据，在2D和3D显微视频中实现竞争性精度


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的细胞追踪方法依赖手动标注数据集，成本高且泛化性有限，无法适应多样化的显微数据

Method: 将Segment Anything 2大型基础模型集成到追踪流程中，作为完全无监督方法，不依赖特定训练数据集

Result: 在2D和大规模3D延时显微视频中达到竞争性精度，无需针对特定数据集进行微调

Conclusion: 该方法克服了传统方法的局限性，具有良好的泛化能力，为细胞追踪提供了有效的零样本解决方案

Abstract: Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.

</details>


### [21] [Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation](https://arxiv.org/abs/2509.09946)
*Vu-Minh Le,Thao-Anh Tran,Duc Huy Do,Xuan Canh Do,Huong Ninh,Hai Tran*

Main category: cs.CV

TL;DR: 提出了一种将现有2D多相机跟踪系统扩展到3D空间的方法，通过深度信息重建目标点云并恢复3D边界框，在AI City Challenge 2025中获得第三名


<details>
  <summary>Details</summary>
Motivation: 现有MTMC系统需要完全重建3D跟踪组件，成本高昂且不现实。本文旨在利用深度信息将现有2D跟踪系统扩展到3D空间，避免完全重构

Method: 使用深度信息在点云空间重建目标，通过聚类和偏航角细化恢复3D边界框，并引入增强的在线数据关联机制，利用目标局部ID一致性分配全局ID

Result: 在2025 AI City Challenge的3D MTMC数据集上评估，获得排行榜第三名

Conclusion: 该方法成功将2D多相机跟踪系统扩展到3D空间，无需完全重构现有系统，为大规模监控自动化提供了可行的3D感知解决方案

Abstract: Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.

</details>


### [22] [Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification](https://arxiv.org/abs/2509.09958)
*Jeffrey Liu,Rongbin Hu*

Main category: cs.CV

TL;DR: 零样本工作流通过将指代表达式理解重构为基于检测框的视觉语言验证任务，无需特定训练即可达到竞争性甚至更优的性能


<details>
  <summary>Details</summary>
Motivation: 传统REC方法需要任务特定的训练，本文探索无需REC特定训练的零样本方法，通过工作流设计而非任务特定预训练来实现强性能

Method: 将REC重新定义为检测框级别的视觉语言验证：使用通用检测器(YOLO-World)生成候选框，通用VLM对每个区域独立回答True/False查询，无需微调

Result: 在RefCOCO、RefCOCO+和RefCOCOg数据集上，不仅超越零样本GroundingDINO基线，还超过经过REC训练的GroundingDINO及其变体的报告结果

Conclusion: 工作流设计而非任务特定预训练是驱动零样本REC性能的关键因素，验证方法显著优于基于选择提示的方法

Abstract: Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.

</details>


### [23] [Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation](https://arxiv.org/abs/2509.09961)
*Tianqi Wei,Xin Yu,Zhi Chen,Scott Chapman,Zi Huang*

Main category: cs.CV

TL;DR: 提出RPCP数据增强方法解决小麦叶片病虫害分割中的极端像素不平衡问题，通过随机几何变换和投影滤波来增强稀有类别的学习效果


<details>
  <summary>Details</summary>
Motivation: 小麦叶片病虫害分割中，虫害区域像素占比极低，导致严重的像素级不平衡问题，使得模型容易过拟合常见类别而忽略稀有类别，影响整体分割性能

Method: RPCP（随机投影复制粘贴）增强技术：从标注图像中提取稀有虫害斑块，应用随机几何变换模拟变化，将变换后的斑块粘贴到合适区域并避免与现有病变重叠，最后使用随机投影滤波器优化局部特征使其与背景自然融合

Result: 实验表明该方法显著提升了虫害类别的分割性能，同时保持甚至略微提高了其他类别的准确率

Conclusion: 针对性的数据增强能有效缓解极端像素不平衡问题，为农业图像分割提供了一种简单而有效的解决方案

Abstract: Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.

</details>


### [24] [An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock](https://arxiv.org/abs/2509.09962)
*Anne Marthe Sophie Ngo Bibinbe,Chiron Bang,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: 提出了一种结合不确定身份和跟踪的HMM框架，用于解决长期多目标跟踪中的身份切换问题，在猪只跟踪数据集和标准MOT基准上均取得了性能提升


<details>
  <summary>Details</summary>
Motivation: 现有MOT方法在长时间跟踪中由于身份切换问题性能下降，而现实应用（如畜牧业）中可以从喂食器等来源获得零星的身份识别信息

Method: 使用隐马尔可夫模型（HMM）框架，结合不确定的身份信息和跟踪数据，为动物提供真实身份识别

Result: 在10分钟猪只跟踪数据集上，即使只有21次喂食站识别，HMM框架也提升了ByteTrack的F1分数；在MOT17和MOT20基准测试中验证了方法的有效性，且性能随身份信息提供频率增加而提升

Conclusion: 提出的HMM框架能够有效利用零星身份信息改善长期多目标跟踪性能，对身份识别的不确定性具有鲁棒性，适用于畜牧业等实际应用场景

Abstract: The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking

</details>


### [25] [Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey](https://arxiv.org/abs/2509.09971)
*Aupendu Kar,Vishnu Raj,Guan-Ming Su*

Main category: cs.CV

TL;DR: 本调查论文系统回顾了事件相机与传统帧相机融合在视频恢复和3D重建领域的最新进展，重点关注深度学习在时空增强方面的应用，并提供了公开数据集资源。


<details>
  <summary>Details</summary>
Motivation: 事件相机作为新兴的生物启发式传感器，具有低延迟、低功耗和高捕获率等优势，但需要与传统帧相机融合才能充分发挥其潜力。本文旨在系统梳理这一融合技术的最新发展。

Method: 采用系统性文献综述方法，从两个维度分析：时间增强（帧插值、运动去模糊等）和空间增强（超分辨率、低光照增强、HDR增强等），同时涵盖3D重建领域的进展。

Result: 总结了事件流与传统帧捕获融合在各种视频恢复任务中的显著优势，整理了深度学习在该领域的主要贡献，并汇编了完整的公开数据集清单。

Conclusion: 事件相机系统与深度学习的结合为高级视觉媒体恢复和增强提供了巨大潜力，本调查旨在激发该领域的进一步研究，推动事件相机技术的更广泛应用。

Abstract: Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.

</details>


### [26] [ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking](https://arxiv.org/abs/2509.09977)
*Siying Liu,Zikai Wang,Hanle Zheng,Yifan Hu,Xilin Wang,Qingkai Yang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TL;DR: ISTASTrack是首个基于Transformer的ANN-SNN混合跟踪器，通过ISTA适配器实现RGB和事件数据的有效融合，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有ANN网络难以充分利用事件流的稀疏和异步特性，ANN-SNN混合架构在RGB-事件感知中展现出潜力，但跨异构范式的特征融合仍然是一个挑战。

Method: 采用双分支模型：视觉Transformer提取RGB空间上下文，脉冲Transformer捕获事件流时空动态。设计基于ISTA算法的适配器进行双向特征交互，并加入时序下采样注意力模块对齐特征。

Result: 在FE240hz、VisEvent、COESOT和FELT等RGB-事件跟踪基准测试中实现了最先进的性能，同时保持高能效。

Conclusion: ISTASTrack证明了ANN-SNN混合设计在鲁棒视觉跟踪中的有效性和实用性，为跨模态特征融合提供了新思路。

Abstract: RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.

</details>


### [27] [FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction](https://arxiv.org/abs/2509.09988)
*Yusuke Takagi,Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 提出基于多深度状态空间模型的太阳耀斑预测方法，引入FLARE损失函数解决类别不平衡问题，在11年太阳活动周期数据上性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前太阳耀斑预测性能不足，现有方法难以有效处理耀斑类别间的严重不平衡问题，需要更准确可靠的预测方法来保护关键基础设施。

Method: 使用多深度状态空间模型构建预测框架，提出频率和局部边界感知可靠性损失函数（FLARE loss）来处理类别不平衡问题。

Result: 在覆盖完整11年太阳活动周期的多波长太阳图像数据集上，该方法在Gandin-Murphy-Gerrity评分和真实技能统计等标准指标上均优于基线方法。

Conclusion: 所提出的多深度状态空间模型结合FLARE损失函数能够有效提升太阳耀斑预测的性能和可靠性，特别是在处理类别不平衡问题上表现出色。

Abstract: Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.

</details>


### [28] [TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion](https://arxiv.org/abs/2509.10005)
*Xiaodong Guo,Tong Liu,Yike Li,Zi'ang Lin,Zhihong Deng*

Main category: cs.CV

TL;DR: TUNI是一个用于RGB-热成像语义分割的统一编码器模型，通过多模态特征提取和跨模态融合的统一架构，在保持高性能的同时实现了更少的参数和更低的计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有RGB-热成像分割模型中热特征提取有限、跨模态融合不理想以及编码器冗余导致的实时效率问题。

Method: 提出统一RGB-T编码器，使用大规模RGB和伪热数据预训练，集成特征提取和融合；采用精简的热分支架构；引入RGB-T局部模块，使用自适应余弦相似度选择性地强调跨模态的一致性和差异性局部特征。

Result: 在FMB、PST900和CART数据集上达到与最先进模型竞争的性能，参数更少、计算成本更低；在Jetson Orin NX上实现27 FPS的推理速度。

Conclusion: TUNI通过统一的编码器架构成功解决了RGB-热成像分割中的特征提取和融合问题，在保持高性能的同时显著提升了实时部署能力。

Abstract: RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.

</details>


### [29] [Few-Part-Shot Font Generation](https://arxiv.org/abs/2509.10006)
*Masaki Akiba,Shumpei Takezaki,Daichi Haraguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: 提出了一种基于部分设计元素的少部件字体生成模型，只需输入部分形状而非完整字符即可生成整个字体


<details>
  <summary>Details</summary>
Motivation: 传统少样本字体生成需要完整字符形状，而本方法旨在通过部分设计元素提高字体创建效率，并探索局部设计细节如何影响整体字符结构

Method: 设计了一个新颖的少部件字体生成模型，以部分形状作为输入来生成整个字体

Result: 该方法不仅提高了字体创建效率，还提供了关于局部设计细节如何影响字符整体结构的见解

Conclusion: 该模型为字体设计提供了一种更高效的方法，通过分析部分设计元素来理解字符结构的形成机制

Abstract: This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.

</details>


### [30] [Efficient and Accurate Downfacing Visual Inertial Odometry](https://arxiv.org/abs/2509.10021)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: 本文提出了一种针对微型和纳米无人机优化的高效视觉惯性里程计（VIO）流水线，在超低功耗RISC-V SoC上实现了实时VIO，相比基线流水线RMSE平均降低3.65倍。


<details>
  <summary>Details</summary>
Motivation: 传统高精度VIO流水线需要强大计算系统，而现有轻量级实现无法满足微型无人机对精度和功耗的双重要求，需要开发既高效又准确的VIO解决方案。

Method: 采用先进特征检测和跟踪方法（SuperPoint、PX4FLOW、ORB），进行优化和量化以适应RISC-V超低功耗并行SoC，并利用刚体运动模型减少估计误差。

Result: 在GAP9低功耗SoC上，使用ORB特征跟踪器时RMSE平均降低3.65倍；PX4FLOW在移动速度低于24像素/帧时达到与ORB相当的跟踪精度且运行时间更短。

Conclusion: 该设计成功弥合了高精度VIO流水线与轻量级实现之间的差距，为微型无人机提供了既满足实时性要求又保持高精度的VIO解决方案。

Abstract: Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.

</details>


### [31] [Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images](https://arxiv.org/abs/2509.10024)
*Danling Cao*

Main category: cs.CV

TL;DR: 提出基于卷积神经网络的层次化多级注意力网络(MLANet)，从单张野外图像重建3D人脸模型，预测几何、纹理、姿态和光照参数


<details>
  <summary>Details</summary>
Motivation: 从2D野外图像恢复3D人脸模型具有广泛应用，但缺乏标注数据和复杂环境是主要挑战

Method: 使用预训练层次化主干网络，引入多级注意力机制，采用半监督训练策略结合3DMM参数和可微分渲染器

Result: 在AFLW2000-3D和MICC Florence数据集上进行实验，定量和定性评估显示方法有效性

Conclusion: 该方法能够有效从单张野外图像重建详细的3D人脸模型

Abstract: Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.

</details>


### [32] [LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA](https://arxiv.org/abs/2509.10026)
*Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Jianshu Li*

Main category: cs.CV

TL;DR: LaV-CoT是一个语言感知的视觉思维链框架，通过多阶段推理管道和多方面奖励优化，显著提升多语言视觉问答性能，在多个基准测试中超越开源和专有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要依赖文本思维链，对多语言多模态推理支持有限，限制了在实际应用中的部署。需要开发能够同时处理多语言和视觉信息的推理框架。

Method: 设计了包含文本摘要与边界框、语言识别、空间对象级描述和逐步逻辑推理的多阶段推理管道。采用自动数据标注方法生成多语言CoT注释，并通过监督微调和语言感知组相对策略优化进行两阶段训练。

Result: 在MMMB、Multilingual MMBench和MTVQA等数据集上，比同规模开源基线准确率提升约9.5%，甚至超越规模大2倍的模型约2.6%，优于GPT-4o-0513和Gemini-2.5-flash等专有模型。

Conclusion: LaV-CoT通过语言感知的视觉思维链框架和多方面奖励优化，有效提升了多语言视觉问答的性能和可解释性，具有工业部署的实际价值。

Abstract: As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}

</details>


### [33] [Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation](https://arxiv.org/abs/2509.10058)
*Sung-Lin Tsai,Bo-Lun Huang,Yu Ting Shen,Cheng Yu Yeo,Chiang Tseng,Bo-Kai Ruan,Wen-Sheng Lien,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 提出无需训练的框架，利用大语言模型解析模糊颜色描述，在文本嵌入空间指导颜色混合，提升文本到图像生成中的颜色准确性


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在处理复杂颜色术语（如蒂芙尼蓝、柠檬绿）时存在颜色对齐问题，现有方法无法系统解决模糊颜色描述

Method: 使用大语言模型解析提示词中的模糊颜色术语，基于CIELAB色彩空间的空间关系细化文本嵌入，直接在嵌入空间指导颜色混合操作

Result: 实验结果表明该方法在不影响图像质量的情况下提高了颜色对齐准确性，弥合了文本语义与视觉生成之间的差距

Conclusion: 该训练免费框架能有效提升文本到图像生成中的颜色保真度，无需额外训练或参考图像

Abstract: Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.

</details>


### [34] [Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration](https://arxiv.org/abs/2509.10059)
*Yue Zhou,Litong Feng,Mengcheng Lan,Xue Yang,Qingyun Li,Yiping Ke,Xue Jiang,Wayne Zhang*

Main category: cs.CV

TL;DR: AVI-Math是首个评估无人机遥感图像中多模态数学推理能力的基准测试，包含3,773个高质量问题，涵盖几何、逻辑和代数等6个数学领域。测试显示当前视觉语言模型在数学推理方面存在显著局限。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在无人机遥感任务中的数学推理能力尚未得到充分测试，而精确的距离计算、面积计算和轨迹估计等任务需要强大的数学推理能力。

Method: 构建AVI-Math基准数据集，包含从不同高度和角度采集的3,773个车辆相关问题，涵盖6个数学学科和20个主题。对14个主流视觉语言模型进行全面评估，并探索思维链提示和微调技术。

Result: 尽管这些模型在以往的多模态基准测试中表现良好，但在AVI-Math的推理任务中表现不佳，暴露了当前视觉语言模型在数学推理能力方面的显著局限性。

Conclusion: 研究不仅揭示了视觉语言模型在数学推理方面的不足，还为推进无人机应用中可信视觉语言模型的发展提供了有价值的见解，思维链提示和微调技术显示出解决这些推理挑战的潜力。

Abstract: Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math

</details>


### [35] [BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals](https://arxiv.org/abs/2509.10080)
*Minsang Kong,Myeongjun Kim,Sang Gu Kang,Sang Hun Lee*

Main category: cs.CV

TL;DR: BEVTraj是一个新颖的轨迹预测框架，直接在鸟瞰图空间利用实时传感器数据进行轨迹预测，无需依赖预建高清地图，通过可变形注意力和稀疏目标候选提案模块实现端到端预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预建高清地图或实时地图构建模块，但预建地图局限于特定区域且无法适应瞬时变化，而地图构建模块可能遗漏关键场景细节或引入错误，影响预测性能。

Method: 提出BEVTraj框架，在BEV空间直接操作，使用可变形注意力从密集BEV特征中高效提取相关上下文，并引入稀疏目标候选提案(SGCP)模块实现完全端到端预测，无需后处理步骤。

Result: 大量实验表明，BEVTraj在性能上与最先进的基于高清地图的模型相当，同时通过消除对预建地图的依赖提供了更大的灵活性。

Conclusion: BEVTraj框架成功克服了现有地图依赖方法的局限性，在保持高性能的同时提供了更好的适应性和灵活性，为自动驾驶轨迹预测提供了新的解决方案。

Abstract: In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.

</details>


### [36] [Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing](https://arxiv.org/abs/2509.10093)
*Laura Bragagnolo,Matteo Terreran,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: 提出了一种利用多视角信息改进多人解析模型在遮挡场景下性能的新训练框架，通过弱监督和一致性损失实现，在遮挡情况下相对基线模型提升4.20%


<details>
  <summary>Details</summary>
Motivation: 现有方法在公开数据集上表现良好，但在处理身体重叠的遮挡场景时效果显著下降，基于多视角可以提供分离视角的直觉

Method: 提出基于弱监督人类实例和多视角一致性损失的新训练框架，利用半自动标注策略从多视角RGB+D数据和3D人体骨架生成标注

Result: 在遮挡场景下，该方法相比基线模型实现了4.20%的相对性能提升

Conclusion: 多视角信息可以有效改善多人解析模型在遮挡情况下的表现，提出的训练框架和标注策略为此类问题提供了有效解决方案

Abstract: Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.

</details>


### [37] [VARCO-VISION-2.0 Technical Report](https://arxiv.org/abs/2509.10105)
*Young-rok Cha,Jeongho Ju,SunYoung Park,Jong-Hyeon Lee,Younghyun Yu,Youngjune Kim*

Main category: cs.CV

TL;DR: VARCO-VISION-2.0是一个开源的韩英双语视觉语言模型，相比前代模型能力提升，支持多图像理解、文档图表处理，具备布局感知OCR功能，在OpenCompass VLM排行榜上取得第8名。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够同时处理韩语和英语的双语视觉语言模型，提升多模态理解能力，特别是对复杂文档、图表和表格的处理，并优化模型的安全性和实用性。

Method: 采用四阶段课程训练和内存高效技术，通过偏好优化来增强多模态对齐，同时保持核心语言能力并提高安全性。

Result: 模型在空间定位和多语言评估基准上表现优异，14B版本在同等规模模型中排名第8，同时还发布了1.7B轻量版本用于设备端部署。

Conclusion: VARCO-VISION-2.0推动了双语视觉语言模型的发展，提供了从14B完整版到1.7B轻量版的不同选择，具有广泛的实际应用价值。

Abstract: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

</details>


### [38] [A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss](https://arxiv.org/abs/2509.10114)
*MohammadAli Hamidi,Hadi Amirpour,Luigi Atzori,Christian Timmerer*

Main category: cs.CV

TL;DR: 提出了一种轻量级的人脸图像质量评估方法，通过集成MobileNetV3-Small和ShuffleNetV2两个紧凑卷积神经网络，并使用MSECorrLoss损失函数来提升与人类感知判断的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸图像质量评估方法要么是通用无参考图像质量评估技术无法捕捉人脸特定的退化，要么是计算密集型模型限制了实际应用。需要一种既准确又高效的方法。

Method: 集成两个紧凑CNN网络（MobileNetV3-Small和ShuffleNetV2），通过简单平均进行预测级融合，使用结合MSE和Pearson相关正则化的MSECorrLoss损失函数。

Result: 在VQualA FIQA基准测试中取得了SRCC 0.9829和PLCC 0.9894的高相关性分数，同时满足计算效率约束。

Conclusion: 该方法在准确性和计算成本之间取得了良好平衡，适合实际部署应用。

Abstract: Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.

</details>


### [39] [Realism Control One-step Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2509.10122)
*Zongliang Wu,Siming Zheng,Peng-Tao Jiang,Xin Yuan*

Main category: cs.CV

TL;DR: 提出RCOD框架，通过潜在域分组策略和退化感知采样，实现单步扩散模型中保真度与真实感的灵活控制


<details>
  <summary>Details</summary>
Motivation: 传统单步扩散方法在真实图像超分辨率任务中缺乏灵活的控制机制来平衡保真度和真实感这两个竞争目标

Method: 采用潜在域分组策略、退化感知采样策略和视觉提示注入模块，在噪声预测阶段实现显式控制

Result: 在定量指标和视觉质量上均优于最先进的单步扩散方法，同时保持计算效率

Conclusion: RCOD框架成功解决了单步扩散模型在保真度-真实感权衡方面的局限性，提供了灵活的推理阶段控制能力

Abstract: Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.

</details>


### [40] [Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment](https://arxiv.org/abs/2509.10134)
*Rini Smita Thakur,Rajeev Ranjan Dwivedi,Vinod K Kurmi*

Main category: cs.CV

TL;DR: Grad-CL是一种无需源数据的域自适应框架，通过梯度引导的伪标签优化和余弦相似度对比学习，在眼底图像分割任务中实现了优异的跨域性能。


<details>
  <summary>Details</summary>
Motivation: 解决眼底图像分割模型在不同成像协议或条件下性能显著下降的问题，特别是在无法访问原始源数据的情况下实现域自适应。

Method: 采用两阶段方法：第一阶段通过梯度机制提取类别特定特征，进行不确定性量化和原型估计来优化伪标签；第二阶段使用基于余弦相似度的对比损失来增强视杯和视盘特征间的类间可分性。

Result: 在具有挑战性的跨域眼底成像数据集上，Grad-CL超越了最先进的无监督和源无关域自适应方法，获得了优异的分割精度和边界描绘效果。

Conclusion: Grad-CL框架有效解决了眼底图像分割中的域偏移问题，无需源数据即可实现稳健的域自适应，为眼科疾病早期诊断提供了可靠的技术支持。

Abstract: Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.

</details>


### [41] [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://arxiv.org/abs/2509.10140)
*Yifan Chang,Jie Qin,Limeng Qiao,Xiaofeng Wang,Zheng Zhu,Lin Ma,Xingang Wang*

Main category: cs.CV

TL;DR: VQBridge方法通过compress-process-recover流水线解决了矢量量化训练中的不稳定问题，实现了100%的码本使用率，提升了重建性能和图像生成质量


<details>
  <summary>Details</summary>
Motivation: 矢量量化(VQ)在图像生成中关键但训练不稳定，存在straight-through estimation bias、一步延迟更新和码本梯度稀疏等问题，导致低码本使用率和次优重建性能

Method: 提出VQBridge方法，基于map function方法的投影器，通过compress-process-recover流水线优化码向量，结合learning annealing技术实现稳定的码本训练

Result: 在多种码本配置下实现100%码本使用率，包括262k大码本；达到最佳重建性能；与LlamaGen集成后在图像生成任务上超过VAR 0.5 rFID和DiT 0.2 rFID

Conclusion: VQBridge提供了一种简单有效的方法来解决VQ训练不稳定问题，高质量的标记化器对自回归图像生成至关重要

Abstract: Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.

</details>


### [42] [LayerLock: Non-collapsing Representation Learning with Progressive Freezing](https://arxiv.org/abs/2509.10156)
*Goker Erdogan,Nikhil Parthasarathy,Catalin Ionescu,Drew Hudson,Alexander Lerchner,Andrew Zisserman,Mehdi Sajjadi,Joao Carreira*

Main category: cs.CV

TL;DR: LayerLock是一种通过渐进层冻结从像素预测过渡到潜在预测的自监督视觉表示学习方法，能够加速MAE训练并避免表示崩溃


<details>
  <summary>Details</summary>
Motivation: 观察到在视频掩码自编码训练中，ViT层按深度顺序收敛（浅层先收敛，深层后收敛），这一现象可用于优化训练过程

Method: 通过明确的进度表逐步冻结模型层，实现从像素预测到潜在预测的渐进过渡，支持高达40亿参数的大模型

Result: 在4DS感知套件上的表现超越了非潜在掩码预测方法

Conclusion: LayerLock提供了一种简单有效的自监督学习策略，通过层冻结调度实现了训练加速和表示质量的提升

Abstract: We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.

</details>


### [43] [On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints](https://arxiv.org/abs/2509.10241)
*Elias De Smijter,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 本文系统比较了隐式和显式新视角合成方法在空间3D物体重建中的表现，发现外观嵌入主要提升光度保真度而非几何精度，凸面溅射比高斯溅射提供更紧凑的无杂乱表示。


<details>
  <summary>Details</summary>
Motivation: 评估外观嵌入在空间机器人应用中3D重建的作用，特别是几何精度这一关键需求，因为现有方法虽然能改善光照变化建模，但对几何准确性的提升效果不明确。

Method: 使用SPEED+数据集，比较K-Planes、高斯溅射和凸面溅射三种方法，分析外观嵌入对显式方法所需基元数量的影响以及几何保真度的改善程度。

Result: 外观嵌入主要减少显式方法所需的基元数量，而非显著提升几何精度；凸面溅射相比高斯溅射能产生更紧凑且无杂乱的表示，更适合安全关键应用。

Conclusion: 外观嵌入在几何中心任务中存在局限性，空间场景中需要在重建质量和表示效率之间进行权衡，凸面溅射在交互和碰撞避免等安全关键应用中具有优势。

Abstract: We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.

</details>


### [44] [GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection](https://arxiv.org/abs/2509.10250)
*Haozhen Yan,Yan Hong,Suning Lang,Jiahui Zhan,Yikun Ji,Yujie Gao,Jun Lan,Huijia Zhu,Weiqiang Wang,Jianfu Zhang*

Main category: cs.CV

TL;DR: GAMMA是一个新的AI生成图像检测框架，通过引入多样化操作策略和多任务监督，减少领域偏差并增强语义对齐，在GenImage基准上实现了5.8%的准确率提升，并对新发布模型如GPT-4o保持强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器在分布内生成图像上表现良好，但对未见生成模型的泛化能力有限，主要原因是过度依赖生成特定的伪影（如风格先验和压缩模式）。

Method: 提出GAMMA训练框架，引入基于修复的操作和语义保持扰动等多样化操作策略；采用多任务监督，包括双分割头和分类头；引入反向交叉注意力机制，让分割头指导并纠正分类分支中的偏差表示。

Result: 在GenImage基准上实现了最先进的泛化性能，准确率提升5.8%；对新发布的生成模型如GPT-4o保持强鲁棒性。

Conclusion: GAMMA通过减少领域偏差和增强语义对齐，有效解决了AI生成图像检测的泛化问题，为检测不断发展的生成模型提供了有效解决方案。

Abstract: With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.

</details>


### [45] [Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI](https://arxiv.org/abs/2509.10257)
*Ema Masterl,Tina Vipotnik Vesnaver,Žiga Špiclin*

Main category: cs.CV

TL;DR: 本研究比较了三种胎儿脑MRI超分辨率重建方法(NiftyMIC、SVRTK、NeSVoR)在140例扫描中的表现，包括健康对照和脑室扩大病理病例。NeSVoR显示出最高的重建成功率(>90%)，虽然不同方法间存在体积测量差异，但诊断分类性能不受影响。


<details>
  <summary>Details</summary>
Motivation: 胎儿脑MRI通常采用快速多视角2D切片采集以减少运动伪影，但这些堆栈分辨率低、可能受运动影响且无法充分捕捉3D解剖结构。超分辨率重建方法旨在解决这些限制，但不同方法的比较性能及其对下游分析的影响尚未充分探索。

Method: 应用三种最先进的SRR方法(NiftyMIC、SVRTK、NeSVoR)处理140例胎儿脑MRI扫描，包括健康对照和脑室扩大病理病例。使用BoUNTi算法对每个高分辨率重建进行分割，提取九个主要脑结构的体积。评估视觉质量、重建成功率、体积测量一致性和诊断分类性能。

Result: NeSVoR在健康组和病理组均表现出最高且最一致的重建成功率(>90%)。虽然不同SRR方法间的体积估计存在显著差异，但脑室扩大的分类性能不受SRR方法选择的影响。

Conclusion: 研究结果突显了NeSVoR的鲁棒性，以及尽管SRR引起的体积变异性，诊断性能仍具有韧性。这表明在选择SRR方法时需要考虑重建成功率和下游分析需求之间的平衡。

Abstract: Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.

</details>


### [46] [Mask Consistency Regularization in Object Removal](https://arxiv.org/abs/2509.10259)
*Hua Yuan,Jin Yuan,Yicheng Jiang,Yao Zhang,Xin Geng,Yong Rui*

Main category: cs.CV

TL;DR: 提出Mask Consistency Regularization (MCR)训练策略，通过掩码扩张和重塑扰动来解决图像修复中物体移除任务的两个关键问题：掩码幻觉和掩码形状偏差。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在物体移除任务中面临掩码幻觉（生成无关内容）和掩码形状偏差（输出模仿掩码形状而非周围内容）两大挑战，需要专门解决方案。

Method: 提出MCR训练策略，在训练过程中引入两种掩码扰动：扩张掩码帮助模型输出与周围内容对齐，重塑掩码鼓励模型打破掩码形状偏差，强制保持各分支输出一致性。

Result: 实验证明MCR显著减少了幻觉和掩码形状偏差，在物体移除任务中实现了更好的性能表现。

Conclusion: MCR通过掩码一致性正则化有效解决了物体移除中的关键问题，能够产生更鲁棒和上下文连贯的图像修复结果。

Abstract: Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.

</details>


### [47] [MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation](https://arxiv.org/abs/2509.10260)
*Jia Wang,Jie Hu,Xiaoqi Ma,Hanghang Ma,Yanbing Zeng,Xiaoming Wei*

Main category: cs.CV

TL;DR: MagicMirror是一个全面的文本到图像生成伪影评估框架，包含首个大规模人工标注数据集MagicData340K、基于VLM的评估模型MagicAssessor，以及自动化基准测试MagicBench，揭示了当前顶级T2I模型仍存在严重伪影问题


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成虽然取得了显著进展，但在物理伪影（如解剖和结构缺陷）方面仍存在严重问题，缺乏系统性和细粒度的评估框架

Method: 1)建立详细的生成图像伪影分类法 2)人工标注340K图像数据集MagicData340K 3)训练视觉语言模型MagicAssessor进行评估 4)设计新颖的数据采样策略和多级奖励系统用于GRPO 5)构建自动化基准测试MagicBench

Result: 评估发现即使像GPT-image-1这样的顶级模型也持续存在显著伪影，表明伪影减少是未来T2I发展的关键前沿

Conclusion: MagicMirror提供了一个全面的伪影评估框架，揭示了当前T2I模型的局限性，为未来改进提供了重要基准和方向

Abstract: Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.

</details>


### [48] [SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion](https://arxiv.org/abs/2509.10266)
*Wenfang Wu,Tingting Yuan,Yupeng Li,Daling Wang,Xiaoming Fu*

Main category: cs.CV

TL;DR: SignClip是一个新颖的手语翻译框架，通过融合手势和唇部运动特征，并采用分层对比学习来提高翻译准确性，在多个基准数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译方法主要关注手势信号，往往忽略了嘴部动作等非手动线索，而嘴部动作在手语中传达重要语言信息，对区分视觉相似的手势至关重要。

Method: 提出SignClip框架，融合空间手势和唇部运动特征，引入分层对比学习框架，具有多级对齐目标，确保手语-唇部和视觉-文本模态间的语义一致性。

Result: 在PHOENIX14T和How2Sign基准数据集上的实验显示，SignClip优于之前的最先进模型。在PHOENIX14T的无注释设置下，BLEU-4从24.32提升到24.71，ROUGE从46.57提升到48.38。

Conclusion: SignClip通过有效融合手动和非手动线索，结合分层对比学习，显著提升了手语翻译的准确性，证明了嘴部动作信息在手语翻译中的重要性。

Abstract: Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.

</details>


### [49] [Detecting Text Manipulation in Images using Vision Language Models](https://arxiv.org/abs/2509.10278)
*Vidit Vidit,Pavel Korshunov,Amir Mohammadi,Christophe Ecabert,Ketan Kotwal,Sébastien Marcel*

Main category: cs.CV

TL;DR: 该研究分析了开源和闭源大型视觉语言模型在文本篡改检测方面的性能，发现开源模型正在接近但仍在闭源模型之后，并展示了专门用于图像篡改检测的模型在文本篡改检测上存在泛化问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型视觉语言模型在图像篡改检测方面表现出色，但文本篡改检测研究相对缺失，需要填补这一知识空白。

Method: 通过在不同文本篡改数据集上测试闭源和开源VLMs，包括真实场景文本和模拟现实滥用的伪造ID卡片场景。

Result: 开源模型性能正在提升但仍落后于闭源模型如GPT-4o；专门用于图像篡改检测的VLMs在文本篡改检测上泛化能力不足。

Conclusion: 文本篡改检测是VLMs需要进一步发展的领域，开源模型有进步但仍需改进，专门化模型需要更好的跨模态泛化能力。

Abstract: Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.

</details>


### [50] [MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection](https://arxiv.org/abs/2509.10282)
*Gang Li,Tianjiao Chen,Mingle Zhou,Min Li,Delong Han,Jin Wan*

Main category: cs.CV

TL;DR: MCL-AD是一个新颖的多模态协作学习框架，通过整合点云、RGB图像和文本语义，实现了卓越的零样本3D异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要专注于点云数据，忽略了RGB图像和文本先验等互补模态提供的丰富语义线索。在数据稀缺、隐私保护或标注成本高的场景下，需要利用多模态信息来提升零样本3D异常检测能力。

Method: 提出了多模态提示学习机制（MPLM），包括对象无关的解耦文本提示和多模态对比损失，增强了模态内表示能力和模态间协作学习。还提出了协作调制机制（CMM），通过联合调制RGB图像引导和点云引导分支，充分利用点云和RGB图像的互补表示。

Result: 大量实验表明，MCL-AD框架在零样本3D异常检测中实现了最先进的性能。

Conclusion: 该研究证明了多模态协作学习在零样本3D异常检测中的有效性，通过整合点云、图像和文本信息，显著提升了检测性能。

Abstract: Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.

</details>


### [51] [Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks](https://arxiv.org/abs/2509.10298)
*Laith Nayal,Mahmoud Mousatat,Bader Rasheed*

Main category: cs.CV

TL;DR: 提出一种基于Lipschitz约束的随机深度(DropPath)方法，通过深度相关的丢弃概率来控制网络的有效Lipschitz常数，在保持清洁精度的同时提升对抗鲁棒性并减少计算量。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络和Vision Transformers在计算机视觉中表现优异但易受对抗扰动攻击，现有防御方法计算成本高或缺乏形式化保证。

Method: 采用Lipschitz引导的随机深度方法，丢弃概率随深度增加，以控制网络的有效Lipschitz常数，正则化深层网络。

Result: 在CIFAR-10数据集上使用ViT-Tiny的实验表明，该方法保持接近基线的清洁精度，在FGSM、PGD-20和AutoAttack攻击下提升鲁棒性，并显著减少FLOPs。

Conclusion: 深度相关的DropPath调度是一种有效的正则化方法，能够在保持模型性能的同时提升对抗鲁棒性和计算效率。

Abstract: Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.

</details>


### [52] [A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments](https://arxiv.org/abs/2509.10310)
*Evan Murphy,Marco Viola,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: 提出基于能量图的概率框架，用于复杂城市环境中街道家具的精确定位，通过随机生死优化算法整合地理空间信息，提高定位精度


<details>
  <summary>Details</summary>
Motivation: 解决城市环境中街道家具的精确定位问题，这对于地方政府和私人利益相关者有效监控和维护公共基础设施至关重要

Method: 基于能量图的概率框架，编码物体位置的空间可能性；使用随机生死优化算法推断最可能的资产配置；整合GIS图层、道路地图等外部地理空间信息

Result: 通过在都柏林市中心街灯基础设施数据集上的真实模拟评估，证明了该方法在可扩展和准确的城市资产测绘方面的潜力

Conclusion: 提出的概率框架能够有效提高城市环境中街道家具的定位精度，算法实现将在GitHub上开源

Abstract: In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.

</details>


### [53] [Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](https://arxiv.org/abs/2509.10312)
*Zhixin Zheng,Xinyu Wang,Chang Zou,Shaobo Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: ClusCa通过空间聚类减少扩散变换器中的token数量，实现4.96倍加速且保持图像质量


<details>
  <summary>Details</summary>
Motivation: 现有特征缓存方法只利用时间维度相似性，忽略了空间维度的相似性，导致计算效率仍有提升空间

Method: 在每时间步对token进行空间聚类，每个聚类只计算一个token并将其信息传播给其他token，减少90%以上token数量

Result: 在DiT、FLUX和HunyuanVideo上验证有效性，FLUX实现4.96倍加速，ImageReward达99.49%（比原模型提升0.51%）

Conclusion: ClusCa作为正交互补方法，无需训练即可直接应用于任何扩散变换器，显著提升计算效率

Abstract: Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.

</details>


### [54] [I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation](https://arxiv.org/abs/2509.10334)
*Jordan Sassoon,Michal Szczepanski,Martyna Poreba*

Main category: cs.CV

TL;DR: I-Segmenter是首个完全整数化的ViT分割框架，通过系统替换浮点运算、提出λ-ShiftGELU激活函数等技术，在保持精度的同时显著减小模型大小和加速推理。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在语义分割中表现优异，但其高内存占用和计算成本限制了在资源受限设备上的部署。量化是提高效率的有效策略，但ViT分割模型在低精度下表现脆弱。

Method: 基于Segmenter架构，系统替换浮点运算为整数运算；提出λ-ShiftGELU激活函数处理长尾分布；移除L2归一化层；用最近邻上采样替换双线性插值。

Result: 在保持与FP32基线合理差距（平均5.1%）的同时，模型大小减少3.8倍，推理速度提升1.2倍。单张校准图像的PTQ也能获得有竞争力的精度。

Conclusion: I-Segmenter为ViT分割模型的实际部署提供了实用解决方案，在效率和精度之间取得了良好平衡。

Abstract: Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.

</details>


### [55] [GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT](https://arxiv.org/abs/2509.10341)
*Botond Fazekas,Thomas Pinetz,Guilherme Aresta,Taha Emre,Hrvoje Bogunovic*

Main category: cs.CV

TL;DR: GARD是一种基于伽马扩散模型的新型OCT图像去噪方法，通过噪声减少保真项和加速推理框架，在保持解剖结构的同时有效去除散斑噪声


<details>
  <summary>Details</summary>
Motivation: OCT图像存在固有散斑噪声，传统去噪方法难以平衡噪声去除与解剖结构保留，需要更准确的噪声统计模型和更好的去噪效果

Method: 采用去噪扩散伽马模型替代传统高斯假设，引入噪声减少保真项利用预处理图像指导去噪，并适配DDIM框架加速推理

Result: 在配对噪声和低噪声OCT图像数据集上，GARD在PSNR、SSIM和MSE指标上显著优于传统方法和先进深度学习模型，定性结果显示边缘更清晰、解剖细节保留更好

Conclusion: GARD通过伽马扩散模型和噪声减少保真项，成功解决了OCT图像去噪中噪声统计准确性、结构保留和计算效率的问题，为视网膜疾病诊断提供了更高质量的成像工具

Abstract: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.

</details>


### [56] [GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography](https://arxiv.org/abs/2509.10344)
*Yuexi Du,Lihui Chen,Nicha C. Dvornek*

Main category: cs.CV

TL;DR: GLAM模型通过几何引导的多视图对齐预训练，在乳腺X线影像分析中实现了全局和局部特征的对齐学习，显著提升了诊断性能。


<details>
  <summary>Details</summary>
Motivation: 现有的乳腺X线影像视觉语言模型大多从自然图像迁移而来，忽略了乳腺X线影像特有的多视图关系和几何特征，导致诊断性能不佳。放射科医生会同时分析多个视图来处理同侧对应关系，而现有方法要么将视图视为独立图像，要么没有正确建模多视图对应学习。

Method: 提出GLAM模型，利用乳腺X线影像多视图成像过程的先验知识，通过联合全局和局部、视觉-视觉以及视觉-语言的对比学习，学习局部跨视图对齐和细粒度局部特征。在大型公开乳腺X线数据集EMBED上进行预训练。

Result: 在多个数据集和不同设置下，GLAM模型的表现均优于基线方法。

Conclusion: 通过几何引导的多视图对齐预训练，GLAM模型能够有效学习乳腺X线影像的领域特定特征，显著提升了诊断准确性和效率。

Abstract: Mammography screening is an essential tool for early detection of breast
cancer. The speed and accuracy of mammography interpretation have the potential
to be improved with deep learning methods. However, the development of a
foundation visual language model (VLM) is hindered by limited data and domain
differences between natural and medical images. Existing mammography VLMs,
adapted from natural images, often ignore domain-specific characteristics, such
as multi-view relationships in mammography. Unlike radiologists who analyze
both views together to process ipsilateral correspondence, current methods
treat them as independent images or do not properly model the multi-view
correspondence learning, losing critical geometric context and resulting in
suboptimal prediction. We propose GLAM: Global and Local Alignment for
Multi-view mammography for VLM pretraining using geometry guidance. By
leveraging the prior knowledge about the multi-view imaging process of
mammograms, our model learns local cross-view alignments and fine-grained local
features through joint global and local, visual-visual, and visual-language
contrastive learning. Pretrained on EMBED [14], one of the largest open
mammography datasets, our model outperforms baselines across multiple datasets
under different settings.

</details>


### [57] [Towards Understanding Visual Grounding in Visual Language Models](https://arxiv.org/abs/2509.10345)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.CV

TL;DR: 这篇综述论文系统回顾了现代通用视觉语言模型中的视觉基础能力，包括其核心组件、实际应用、评估方法，并探讨了视觉基础与多模态思维链、推理之间的关系，最后分析了当前挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 视觉基础能力使模型能够根据文本描述精确定位视觉输入中的特定区域，这对于实现细粒度的视觉语言理解、问答、图像描述以及环境控制等广泛应用至关重要。论文旨在全面梳理这一重要研究领域的发展现状。

Method: 采用文献综述方法，首先阐述视觉基础在VLM中的重要性，然后分析现代基础模型开发范式的核心组件，考察实际应用场景包括基准测试和评估指标，并探讨视觉基础与多模态思维链、推理的相互关系。

Result: 系统性地总结了视觉基础研究的关键进展，包括模型架构、训练方法、评估体系等方面的代表性工作，揭示了该领域的技术发展脉络和研究现状。

Conclusion: 视觉基础是构建强大视觉语言模型的核心能力，虽然已取得显著进展，但仍面临诸多挑战，需要进一步研究更高效的训练方法、更好的评估指标以及更深入的理论理解。

Abstract: Visual grounding refers to the ability of a model to identify a region within
some visual input that matches a textual description. Consequently, a model
equipped with visual grounding capabilities can target a wide range of
applications in various domains, including referring expression comprehension,
answering questions pertinent to fine-grained details in images or videos,
caption visual context by explicitly referring to entities, as well as low and
high-level control in simulated and real environments. In this survey paper, we
review representative works across the key areas of research on modern
general-purpose vision language models (VLMs). We first outline the importance
of grounding in VLMs, then delineate the core components of the contemporary
paradigm for developing grounded models, and examine their practical
applications, including benchmarks and evaluation metrics for grounded
multimodal generation. We also discuss the multifaceted interrelations among
visual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,
we analyse the challenges inherent to visual grounding and suggest promising
directions for future research.

</details>


### [58] [Immunizing Images from Text to Image Editing via Adversarial Cross-Attention](https://arxiv.org/abs/2509.10359)
*Matteo Trippodo,Federico Becattini,Lorenzo Seidenari*

Main category: cs.CV

TL;DR: 提出了一种针对文本图像编辑方法的视觉组件攻击——Attention Attack，通过使用源图像的自动生成标题作为编辑提示的代理，破坏文本提示与视觉表示之间的交叉注意力，从而破坏图像内容与其文本描述的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的基于文本的图像编辑方法容易受到对抗攻击，但现有攻击主要针对文本组件。本文旨在开发一种针对视觉组件的攻击方法，无需了解编辑方法或编辑提示即可破坏编辑效果。

Method: 提出Attention Attack攻击方法，利用源图像的自动生成标题作为编辑提示代理，破坏文本与视觉表示之间的交叉注意力机制。引入Caption Similarity和语义IoU两种新评估策略来衡量攻击效果。

Result: 在TEDBench++基准测试上的实验表明，该攻击方法显著降低了编辑性能，同时保持攻击的不可感知性。

Conclusion: Attention Attack是一种有效的针对文本图像编辑视觉组件的对抗攻击方法，能够在不了解编辑细节的情况下成功破坏编辑效果，为评估图像编辑系统的鲁棒性提供了新的评估指标。

Abstract: Recent advances in text-based image editing have enabled fine-grained
manipulation of visual content guided by natural language. However, such
methods are susceptible to adversarial attacks. In this work, we propose a
novel attack that targets the visual component of editing methods. We introduce
Attention Attack, which disrupts the cross-attention between a textual prompt
and the visual representation of the image by using an automatically generated
caption of the source image as a proxy for the edit prompt. This breaks the
alignment between the contents of the image and their textual description,
without requiring knowledge of the editing method or the editing prompt.
Reflecting on the reliability of existing metrics for immunization success, we
propose two novel evaluation strategies: Caption Similarity, which quantifies
semantic consistency between original and adversarial edits, and semantic
Intersection over Union (IoU), which measures spatial layout disruption via
segmentation masks. Experiments conducted on the TEDBench++ benchmark
demonstrate that our attack significantly degrades editing performance while
remaining imperceptible.

</details>


### [59] [Efficient Learned Image Compression Through Knowledge Distillation](https://arxiv.org/abs/2509.10366)
*Fabien Allemand,Attilio Fiandrotti,Sumanta Chaudhuri,Alaa Eddine Mazouz*

Main category: cs.CV

TL;DR: 该论文研究了通过知识蒸馏技术来降低神经网络图像压缩模型的资源需求，使小模型能够获得接近大模型的性能表现


<details>
  <summary>Details</summary>
Motivation: 虽然基于深度学习的图像压缩方法在性能上优于传统编解码器，但计算资源需求大，难以在资源受限平台上实时应用，阻碍了其主流部署

Method: 采用知识蒸馏训练范式，让小规模神经网络通过学习大型复杂模型的输出来提升性能，在不同架构大小、不同图像质量/比特率权衡下进行实验

Result: 研究表明知识蒸馏能有效应用于图像压缩任务，可以节省处理资源和能源消耗

Conclusion: 知识蒸馏为图像压缩提供了有效的资源优化方案，未来可探索不同教师模型、替代损失函数以及扩展到基于transformer的模型

Abstract: Learned image compression sits at the intersection of machine learning and
image processing. With advances in deep learning, neural network-based
compression methods have emerged. In this process, an encoder maps the image to
a low-dimensional latent space, which is then quantized, entropy-coded into a
binary bitstream, and transmitted to the receiver. At the receiver end, the
bitstream is entropy-decoded, and a decoder reconstructs an approximation of
the original image. Recent research suggests that these models consistently
outperform conventional codecs. However, they require significant processing
power, making them unsuitable for real-time use on resource-constrained
platforms, which hinders their deployment in mainstream applications. This
study aims to reduce the resource requirements of neural networks used for
image compression by leveraging knowledge distillation, a training paradigm
where smaller neural networks, partially trained on the outputs of larger, more
complex models, can achieve better performance than when trained independently.
Our work demonstrates that knowledge distillation can be effectively applied to
image compression tasks: i) across various architecture sizes, ii) to achieve
different image quality/bit rate tradeoffs, and iii) to save processing and
energy resources. This approach introduces new settings and hyperparameters,
and future research could explore the impact of different teacher models, as
well as alternative loss functions. Knowledge distillation could also be
extended to transformer-based models. The code is publicly available at:
https://github.com/FABallemand/PRIM .

</details>


### [60] [Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition](https://arxiv.org/abs/2509.10388)
*Zeqing Leo Yuan,Mani Ramanagopal,Aswin C. Sankaranarayanan,Srinivasa G. Narasimhan*

Main category: cs.CV

TL;DR: 提出一种无需训练的方法，利用可见光和热成像图像对进行本征图像分解，通过热成像检测吸收光能来建立强度顺序关系，实现自监督的着色和反射率恢复。


<details>
  <summary>Details</summary>
Motivation: 解决本征图像分解中缺乏真实世界场景地面实况数据的长期挑战，传统方法依赖合成数据或稀疏标注，难以扩展到户外场景。

Method: 使用可见光和热成像图像对，基于光能被吸收转化为热能的原理，建立可见光与热成像强度之间的顺序关系，通过顺序关系自监督优化神经网络来恢复着色和反射率。

Result: 在自然光和人工光照条件下进行了定量评估，并在多样化户外场景进行了定性实验，结果显示优于近期基于学习的方法。

Conclusion: 该方法为获取真实世界顺序监督提供了一条可扩展的路径，这是之前通过人工标注无法实现的，展示了在户外场景本征图像分解方面的优越性能。

Abstract: Decomposing an image into its intrinsic photometric factors--shading and
reflectance--is a long-standing challenge due to the lack of extensive
ground-truth data for real-world scenes. Recent methods rely on synthetic data
or sparse annotations for limited indoor and even fewer outdoor scenes. We
introduce a novel training-free approach for intrinsic image decomposition
using only a pair of visible and thermal images. We leverage the principle that
light not reflected from an opaque surface is absorbed and detected as heat by
a thermal camera. This allows us to relate the ordinalities between visible and
thermal image intensities to the ordinalities of shading and reflectance, which
can densely self-supervise an optimizing neural network to recover shading and
reflectance. We perform quantitative evaluations with known reflectance and
shading under natural and artificial lighting, and qualitative experiments
across diverse outdoor scenes. The results demonstrate superior performance
over recent learning-based models and point toward a scalable path to curating
real-world ordinal supervision, previously infeasible via manual labeling.

</details>


### [61] [Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards](https://arxiv.org/abs/2509.10407)
*Xiem HoangVan,Dang BuiDinh,Sang NguyenQuang,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 本文提出了一种新的压缩视频质量增强方法分类法、统一的基准测试框架，并系统分析了性能与计算复杂度之间的权衡关系，旨在为CVQE研究建立一致的评估基础。


<details>
  <summary>Details</summary>
Motivation: 现有压缩视频质量增强(CVQE)研究缺乏系统分类方法、跨编码类型的架构范式比较分析不足，以及基准测试实践不完善，需要解决这些局限性。

Method: 提出了三个关键贡献：1)基于架构范式、编码标准和压缩域特征利用的新分类法；2)集成现代压缩协议和标准测试序列的统一基准测试框架；3)对最先进方法的性能与计算复杂度权衡进行系统分析。

Result: 建立了一个全面的CVQE方法评估体系，提供了公平的多标准评估框架，并识别了重建性能与计算复杂度之间的关键权衡关系。

Conclusion: 该综述为CVQE研究建立了一致的评估基础，有助于知情模型选择，并指出了未来研究的有前景方向。

Abstract: Compressed video quality enhancement (CVQE) is crucial for improving user
experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.
While deep learning based CVQE has driven significant progress, existing
surveys still suffer from limitations: lack of systematic classification
linking methods to specific standards and artifacts, insufficient comparative
analysis of architectural paradigms across coding types, and underdeveloped
benchmarking practices. To address these gaps, this paper presents three key
contributions. First, it introduces a novel taxonomy classifying CVQE methods
across architectural paradigms, coding standards, and compressed-domain feature
utilization. Second, it proposes a unified benchmarking framework integrating
modern compression protocols and standard test sequences for fair
multi-criteria evaluation. Third, it provides a systematic analysis of the
critical trade-offs between reconstruction performance and computational
complexity observed in state-of-the-art methods and highlighting promising
directions for future research. This comprehensive review aims to establish a
foundation for consistent assessment and informed model selection in CVQE
research and deployment.

</details>


### [62] [Multimodal SAM-adapter for Semantic Segmentation](https://arxiv.org/abs/2509.10408)
*Iacopo Curti,Pierluigi Zama Ramirez,Alioscia Petrelli,Luigi Di Stefano*

Main category: cs.CV

TL;DR: MM SAM-adapter是一个新颖的多模态语义分割框架，通过适配器网络将融合的多模态特征注入到Segment Anything Model的RGB特征中，在保持RGB特征强泛化能力的同时选择性利用辅助模态信息，在多个挑战性基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前语义分割方法在恶劣光照、遮挡和恶劣天气等挑战性条件下仍然脆弱，需要整合辅助传感器数据（如LiDAR、红外）来提供互补信息以增强鲁棒性。

Method: 提出MM SAM-adapter框架，使用适配器网络将融合的多模态特征注入到SAM的RGB特征中，既能保留RGB特征的强泛化能力，又能选择性利用辅助模态提供的额外线索。

Result: 在DeLiVER、FMB和MUSES三个挑战性基准测试中实现了最先进的性能。在RGB-easy和RGB-hard子集上的结果一致表明，该框架在有利和不利条件下都优于竞争方法。

Conclusion: 多模态适配对于鲁棒场景理解非常有效，MM SAM-adapter实现了多模态信息的平衡和高效利用。

Abstract: Semantic segmentation, a key task in computer vision with broad applications
in autonomous driving, medical imaging, and robotics, has advanced
substantially with deep learning. Nevertheless, current approaches remain
vulnerable to challenging conditions such as poor lighting, occlusions, and
adverse weather. To address these limitations, multimodal methods that
integrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,
providing complementary information that enhances robustness. In this work, we
present MM SAM-adapter, a novel framework that extends the capabilities of the
Segment Anything Model (SAM) for multimodal semantic segmentation. The proposed
method employs an adapter network that injects fused multimodal features into
SAM's rich RGB features. This design enables the model to retain the strong
generalization ability of RGB features while selectively incorporating
auxiliary modalities only when they contribute additional cues. As a result, MM
SAM-adapter achieves a balanced and efficient use of multimodal information. We
evaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,
where MM SAM-adapter delivers state-of-the-art performance. To further analyze
modality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard
subsets. Results consistently demonstrate that our framework outperforms
competing methods in both favorable and adverse conditions, highlighting the
effectiveness of multimodal adaptation for robust scene understanding. The code
is available at the following link:
https://github.com/iacopo97/Multimodal-SAM-Adapter.

</details>


### [63] [InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis](https://arxiv.org/abs/2509.10441)
*Tao Han,Wanghan Xu,Junchao Gong,Xiaoyu Yue,Song Guo,Luping Zhou,Lei Bai*

Main category: cs.CV

TL;DR: InfGen是一种新的图像生成方法，通过用一步生成器替换VAE解码器，可以从固定大小的潜在表示生成任意分辨率的图像，显著降低计算复杂度，将4K图像生成时间从100多秒减少到10秒以内。


<details>
  <summary>Details</summary>
Motivation: 解决当前扩散模型在生成高分辨率图像时计算需求随分辨率二次增长的问题，4K图像生成延迟超过100秒，需要一种更高效的任意分辨率图像生成方法。

Method: 基于潜在扩散模型的第二代方法，将扩散模型生成的固定潜在表示作为内容表示，使用紧凑的一步生成器解码任意分辨率图像，用新生成器替换VAE解码器。

Result: InfGen能够将许多模型提升到任意高分辨率时代，同时将4K图像生成时间从100多秒减少到10秒以内，无需重新训练扩散模型。

Conclusion: InfGen提供了一种简化流程、降低计算复杂度的解决方案，可应用于使用相同潜在空间的任何模型，实现了高效且一致的跨设备视觉体验。

Abstract: Arbitrary resolution image generation provides a consistent visual experience
across devices, having extensive applications for producers and consumers.
Current diffusion models increase computational demand quadratically with
resolution, causing 4K image generation delays over 100 seconds. To solve this,
we explore the second generation upon the latent diffusion models, where the
fixed latent generated by diffusion models is regarded as the content
representation and we propose to decode arbitrary resolution images with a
compact generated latent using a one-step generator. Thus, we present the
\textbf{InfGen}, replacing the VAE decoder with the new generator, for
generating images at any resolution from a fixed-size latent without retraining
the diffusion models, which simplifies the process, reducing computational
complexity and can be applied to any model using the same latent space.
Experiments show InfGen is capable of improving many models into the arbitrary
high-resolution era while cutting 4K image generation time to under 10 seconds.

</details>


### [64] [SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets](https://arxiv.org/abs/2509.10453)
*Emily Kaczmarek,Justin Szeto,Brennan Nichyporuk,Tal Arbel*

Main category: cs.CV

TL;DR: 本研究将三种先进的时序自监督学习方法应用于3D脑部MRI分析，通过处理可变长度输入和学习鲁棒空间特征，在阿尔茨海默病预测任务中表现出色，在七个下游任务中有六个超越了监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病预测中的深度学习模型面临标注数据稀缺、跨数据集泛化能力差以及对不同扫描数量和扫描时间间隔缺乏灵活性的问题。

Method: 采用三种最先进的时序自监督学习（SSL）方法进行3D脑部MRI分析，添加了处理可变长度输入和学习鲁棒空间特征的新扩展，使用四个公开数据集（3,161名患者）进行预训练。

Result: 基于时序顺序预测和对比学习的SSL模型在七个下游任务中的六个任务上超越了监督学习，展现出跨任务和不同输入图像数量及时间间隔的适应性和泛化能力。

Conclusion: 时序自监督学习方法在阿尔茨海默病预测中表现出强大的性能，具有临床应用的鲁棒性和通用性，为解决数据稀缺和泛化问题提供了有效方案。

Abstract: Alzheimer's disease is a progressive, neurodegenerative disorder that causes
memory loss and cognitive decline. While there has been extensive research in
applying deep learning models to Alzheimer's prediction tasks, these models
remain limited by lack of available labeled data, poor generalization across
datasets, and inflexibility to varying numbers of input scans and time
intervals between scans. In this study, we adapt three state-of-the-art
temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,
and add novel extensions designed to handle variable-length inputs and learn
robust spatial features. We aggregate four publicly available datasets
comprising 3,161 patients for pre-training, and show the performance of our
model across multiple Alzheimer's prediction tasks including diagnosis
classification, conversion detection, and future conversion prediction.
Importantly, our SSL model implemented with temporal order prediction and
contrastive learning outperforms supervised learning on six out of seven
downstream tasks. It demonstrates adaptability and generalizability across
tasks and number of input images with varying time intervals, highlighting its
capacity for robust performance across clinical applications. We release our
code and model publicly at https://github.com/emilykaczmarek/SSL-AD.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [65] [Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs](https://arxiv.org/abs/2509.09699)
*Mingyang Li,Viktor Schlegel,Tingting Mu,Warren Del-Pinto,Goran Nenadic*

Main category: cs.CL

TL;DR: 本文提出使用知识图谱结构化表示临床文档，用于自动化ICD编码任务，相比纯文本方法在Macro-F1分数上提升3.20%，同时提高训练效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 临床文档标准化编码是重要但耗时的任务，现有方法主要关注输出编码表示而忽视了输入文档的外部知识利用，需要探索如何有效利用文档级知识图谱来提升自动化编码性能。

Method: 构建文档级知识图谱来结构化表示患者状况，将原始文本压缩至23%同时保留90%信息，并将该图谱集成到最先进的PLM-ICD编码架构中进行ICD-9自动化编码。

Result: 在流行基准测试中Macro-F1分数最高提升3.20%，训练效率得到改善，知识图谱中的不同实体和关系类型对性能提升有贡献，方法相比纯文本基线具有更好的可解释性。

Conclusion: 利用知识图谱结构化表示临床文档能有效提升自动化ICD编码性能，不仅提高准确率还增强训练效率和结果可解释性，为临床文档处理提供了新的有效途径。

Abstract: Mapping clinical documents to standardised clinical vocabularies is an
important task, as it provides structured data for information retrieval and
analysis, which is essential to clinical research, hospital administration and
improving patient care. However, manual coding is both difficult and
time-consuming, making it impractical at scale. Automated coding can
potentially alleviate this burden, improving the availability and accuracy of
structured clinical data. The task is difficult to automate, as it requires
mapping to high-dimensional and long-tailed target spaces, such as the
International Classification of Diseases (ICD). While external knowledge
sources have been readily utilised to enhance output code representation, the
use of external resources for representing the input documents has been
underexplored. In this work, we compute a structured representation of the
input documents, making use of document-level knowledge graphs (KGs) that
provide a comprehensive structured view of a patient's condition. The resulting
knowledge graph efficiently represents the patient-centred input documents with
23\% of the original text while retaining 90\% of the information. We assess
the effectiveness of this graph for automated ICD-9 coding by integrating it
into the state-of-the-art ICD coding architecture PLM-ICD. Our experiments
yield improved Macro-F1 scores by up to 3.20\% on popular benchmarks, while
improving training efficiency. We attribute this improvement to different types
of entities and relationships in the KG, and demonstrate the improved
explainability potential of the approach over the text-only baseline.

</details>


### [66] [Cross-Layer Attention Probing for Fine-Grained Hallucination Detection](https://arxiv.org/abs/2509.09700)
*Malavika Suresh,Rahaf Aljundi,Ikechukwu Nkisi-Orji,Nirmalie Wiratunga*

Main category: cs.CL

TL;DR: 提出Cross-Layer Attention Probing (CLAP)方法，通过处理LLM整个残差流的激活作为联合序列，显著提升幻觉检测能力，支持细粒度检测和检测后缓解策略。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在各种应用中的大规模采用，其生成不准确文本（幻觉）的可靠性问题日益突出，需要有效的检测和缓解方法。

Method: 提出跨层注意力探测(CLAP)技术，将LLM整个残差流的激活作为联合序列进行处理，用于幻觉检测。

Result: 在五个LLM和三个任务上的实验表明，CLAP相比基线方法在贪婪解码和高温采样响应中都显著提升了幻觉检测能力，支持细粒度检测，并能有效应用于分布外场景。

Conclusion: CLAP提供了一种有效的幻觉检测方法，支持检测后缓解策略，相比直接缓解方法能更好地减少幻觉并提高LLM可靠性，且在分布外场景下仍保持高可靠性。

Abstract: With the large-scale adoption of Large Language Models (LLMs) in various
applications, there is a growing reliability concern due to their tendency to
generate inaccurate text, i.e. hallucinations. In this work, we propose
Cross-Layer Attention Probing (CLAP), a novel activation probing technique for
hallucination detection, which processes the LLM activations across the entire
residual stream as a joint sequence. Our empirical evaluations using five LLMs
and three tasks show that CLAP improves hallucination detection compared to
baselines on both greedy decoded responses as well as responses sampled at
higher temperatures, thus enabling fine-grained detection, i.e. the ability to
disambiguate hallucinations and non-hallucinations among different sampled
responses to a given prompt. This allows us to propose a detect-then-mitigate
strategy using CLAP to reduce hallucinations and improve LLM reliability
compared to direct mitigation approaches. Finally, we show that CLAP maintains
high reliability even when applied out-of-distribution.

</details>


### [67] [Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task](https://arxiv.org/abs/2509.09701)
*JungHo Jung,Junhyun Lee*

Main category: cs.CL

TL;DR: 本文从正则化角度研究端到端语音翻译中的多任务学习，通过一致性正则化、R-drop和机器翻译损失系数三种正则化源，提出了正则化视界概念，在MuST-C数据集上达到接近SOTA的性能。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译面临配对语音-文本数据稀缺的问题，需要利用机器翻译任务的双语文本数据进行多任务学习来克服这一局限性。

Method: 从正则化视角制定多任务学习框架，探索序列在模态内和跨模态的正则化方法，包括一致性正则化（不同模态）、R-drop（相同模态）和机器翻译损失系数作为正则化源。

Result: 实验表明，在正则化视界内调整超参数可以在MuST-C数据集上达到接近最先进的性能。

Conclusion: 通过三种正则化源的协同作用，提出了正则化视界概念，为多任务学习中的正则化提供了新的理论框架和实践指导。

Abstract: End-to-end speech-to-text translation typically suffers from the scarcity of
paired speech-text data. One way to overcome this shortcoming is to utilize the
bitext data from the Machine Translation (MT) task and perform Multi-Task
Learning (MTL). In this paper, we formulate MTL from a regularization
perspective and explore how sequences can be regularized within and across
modalities. By thoroughly investigating the effect of consistency
regularization (different modality) and R-drop (same modality), we show how
they respectively contribute to the total regularization. We also demonstrate
that the coefficient of MT loss serves as another source of regularization in
the MTL setting. With these three sources of regularization, we introduce the
optimal regularization contour in the high-dimensional space, called the
regularization horizon. Experiments show that tuning the hyperparameters within
the regularization horizon achieves near state-of-the-art performance on the
MuST-C dataset.

</details>


### [68] [Creativity Benchmark: A benchmark for marketing creativity for LLM models](https://arxiv.org/abs/2509.09702)
*Ninad Bhat,Kieran Browne,Pip Bingemann*

Main category: cs.CL

TL;DR: Creativity Benchmark是一个评估大语言模型在营销创意领域表现的框架，通过人类专家对11,012次匿名比较的分析显示，不同模型表现相近，没有明显优势者，自动评估与人类评价相关性弱。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门针对营销创意领域的大语言模型评估标准，需要建立系统性的基准测试来评估LLM在品牌营销创意任务中的表现。

Method: 构建包含100个品牌（12个类别）和三种提示类型的评估框架，收集678位专业创意人员的11,012次匿名配对偏好数据，使用Bradley-Terry模型分析，并计算余弦距离来评估模型多样性。

Result: 模型表现紧密聚集，最高和最低模型之间的胜率仅为61%；自动评估与人类排名相关性弱且不一致；传统创造力测试在品牌约束任务中仅部分适用。

Conclusion: 需要专家人类评估和多样性感知的工作流程，自动评估方法无法替代人类专业判断。

Abstract: We introduce Creativity Benchmark, an evaluation framework for large language
models (LLMs) in marketing creativity. The benchmark covers 100 brands (12
categories) and three prompt types (Insights, Ideas, Wild Ideas). Human
pairwise preferences from 678 practising creatives over 11,012 anonymised
comparisons, analysed with Bradley-Terry models, show tightly clustered
performance with no model dominating across brands or prompt types: the
top-bottom spread is $\Delta\theta \approx 0.45$, which implies a head-to-head
win probability of $0.61$; the highest-rated model beats the lowest only about
$61\%$ of the time. We also analyse model diversity using cosine distances to
capture intra- and inter-model variation and sensitivity to prompt reframing.
Comparing three LLM-as-judge setups with human rankings reveals weak,
inconsistent correlations and judge-specific biases, underscoring that
automated judges cannot substitute for human evaluation. Conventional
creativity tests also transfer only partially to brand-constrained tasks.
Overall, the results highlight the need for expert human evaluation and
diversity-aware workflows.

</details>


### [69] [CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor](https://arxiv.org/abs/2509.09703)
*Zhenhua Xu,Xixiang Zhao,Xubin Yue,Shengwei Tian,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: CTCC是一种新颖的基于规则的语言模型指纹框架，通过多轮对话中的上下文关联来嵌入所有权验证痕迹，解决了现有方法在隐蔽性、鲁棒性和泛化性方面的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)的广泛部署加剧了知识产权保护担忧，现有指纹方法存在可检测性、易受对抗攻击和一旦泄露即失效等问题，需要更可靠的解决方案。

Method: 提出CTCC框架，采用规则驱动的方法在多轮对话中编码上下文关联（如反事实关系），而非依赖词级或单轮触发，支持黑盒访问下的指纹验证。

Result: 在多个LLM架构上的广泛实验表明，CTCC相比现有方法在隐蔽性和鲁棒性方面表现更优，能够有效减少误报和指纹泄露风险。

Conclusion: CTCC为现实世界LLM部署场景中的所有权验证提供了一个可靠且实用的解决方案，支持在部分触发暴露情况下基于共享语义规则的持续构建。

Abstract: The widespread deployment of large language models (LLMs) has intensified
concerns around intellectual property (IP) protection, as model theft and
unauthorized redistribution become increasingly feasible. To address this,
model fingerprinting aims to embed verifiable ownership traces into LLMs.
However, existing methods face inherent trade-offs between stealthness,
robustness, and generalizability, being either detectable via distributional
shifts, vulnerable to adversarial modifications, or easily invalidated once the
fingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven
fingerprinting framework that encodes contextual correlations across multiple
dialogue turns, such as counterfactual, rather than relying on token-level or
single-turn triggers. CTCC enables fingerprint verification under black-box
access while mitigating false positives and fingerprint leakage, supporting
continuous construction under a shared semantic rule even if partial triggers
are exposed. Extensive experiments across multiple LLM architectures
demonstrate that CTCC consistently achieves stronger stealth and robustness
than prior work. Our findings position CTCC as a reliable and practical
solution for ownership verification in real-world LLM deployment scenarios. Our
code and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.

</details>


### [70] [Temporal Preferences in Language Models for Long-Horizon Assistance](https://arxiv.org/abs/2509.09704)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Hossein Setareh*

Main category: cs.CL

TL;DR: 本研究探讨语言模型在跨期选择中是否表现出未来导向偏好，以及这些偏好是否可被系统性操纵。通过引入MTO指标，发现推理型模型在未来导向提示下更倾向于选择延迟选项，但个性化程度有限。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型的时间偏好特征及其可操纵性，为AI助手与人类长期目标的对齐提供设计依据，推动个性化情境校准和社会意识部署的研究议程。

Method: 采用改编的人类实验协议，在时间权衡任务中评估多个语言模型，并与人类决策者进行基准比较。引入操作化指标MTO（时间取向可操纵性），衡量模型在未来导向和现在导向提示下时间偏好的变化。

Result: 推理型模型（如DeepSeek-Reasoner和grok-3-mini）在未来导向提示下更倾向于选择延迟选项，但在跨身份或地理位置的个性化决策方面表现有限。能够正确推理时间取向的模型会内化作为AI决策者的未来导向。

Conclusion: 研究强调了AI助手需要与异质性的长期目标对齐的重要性，提出了个性化情境校准和社会意识部署的研究方向，为AI决策系统的设计提供了重要启示。

Abstract: We study whether language models (LMs) exhibit future- versus
present-oriented preferences in intertemporal choice and whether those
preferences can be systematically manipulated. Using adapted human experimental
protocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them
against a sample of human decision makers. We introduce an operational metric,
the Manipulability of Time Orientation (MTO), defined as the change in an LM's
revealed time preference between future- and present-oriented prompts. In our
tests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)
choose later options under future-oriented prompts but only partially
personalize decisions across identities or geographies. Moreover, models that
correctly reason about time orientation internalize a future orientation for
themselves as AI decision makers. We discuss design implications for AI
assistants that should align with heterogeneous, long-horizon goals and outline
a research agenda on personalized contextual calibration and socially aware
deployment.

</details>


### [71] [The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks](https://arxiv.org/abs/2509.09705)
*Claudio Pinhanez,Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Yago Primerano*

Main category: cs.CL

TL;DR: 本研究探讨了小型LLM（2B-8B参数）在多次回答相同问题时的响应一致性，分析了不同温度设置、模型大小、微调状态等因素对一致性和准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 评估小型开源LLM在重复回答相同问题时的响应一致性，研究一致性要求对准确性的影响，以及在不同参数设置下的权衡关系。

Method: 使用MMLU-Redux和MedQA多选基准测试，让模型重复回答10次相同问题，分析不同推理温度（0.0-1.0）、小型vs中型模型（50B-80B）、基础vs微调模型的表现。

Result: 小型模型在低推理温度下，能够一致回答的问题比例通常在50%-80%之间；一致性答案的准确性与总体准确性呈合理相关性；中型模型显示出更高的一致性水平。

Conclusion: 小型LLM在一致性方面存在显著差异，低温度设置可提高一致性但可能影响其他性能；中型模型在一致性方面表现更优，为模型选择提供了重要参考依据。

Abstract: This work explores the consistency of small LLMs (2B-8B parameters) in
answering multiple times the same question. We present a study on known,
open-source LLMs responding to 10 repetitions of questions from the
multiple-choice benchmarks MMLU-Redux and MedQA, considering different
inference temperatures, small vs. medium models (50B-80B), finetuned vs. base
models, and other parameters. We also look into the effects of requiring
multi-trial answer consistency on accuracy and the trade-offs involved in
deciding which model best provides both of them. To support those studies, we
propose some new analytical and graphical tools. Results show that the number
of questions which can be answered consistently vary considerably among models
but are typically in the 50%-80% range for small models at low inference
temperatures. Also, accuracy among consistent answers seems to reasonably
correlate with overall accuracy. Results for medium-sized models seem to
indicate much higher levels of answer consistency.

</details>


### [72] [Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal](https://arxiv.org/abs/2509.09708)
*Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee*

Main category: cs.CL

TL;DR: 本研究通过稀疏自编码器分析指令调优大语言模型的安全拒绝行为机制，发现并操纵关键特征可实现越狱，揭示了安全行为的冗余特征机制。


<details>
  <summary>Details</summary>
Motivation: 理解指令调优大语言模型中安全拒绝行为的内部机制，尽管这是关键安全行为，但其内部原因仍不清楚。

Method: 使用稀疏自编码器分析残差流激活，通过三阶段搜索流程（拒绝方向识别、贪婪过滤、交互发现）寻找导致拒绝行为翻转的关键特征集。

Result: 成功识别出 jailbreak-critical 特征集，能够通过特征消融将模型从拒绝转为服从，并发现存在冗余特征机制。

Conclusion: 研究表明通过操纵可解释的潜在空间可以实现细粒度审计和针对性干预安全行为，为模型安全机制理解提供了新视角。

Abstract: Refusal on harmful prompts is a key safety behaviour in instruction-tuned
large language models (LLMs), yet the internal causes of this behaviour remain
poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT
and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on
residual-stream activations. Given a harmful prompt, we search the SAE latent
space for feature sets whose ablation flips the model from refusal to
compliance, demonstrating causal influence and creating a jailbreak. Our search
proceeds in three stages: (1) Refusal Direction: find a refusal-mediating
direction and collect SAE features near that direction; (2) Greedy Filtering:
prune to a minimal set; and (3) Interaction Discovery: fit a factorization
machine (FM) that captures nonlinear interactions among the remaining active
features and the minimal set. This pipeline yields a broad set of
jailbreak-critical features, offering insight into the mechanistic basis of
refusal. Moreover, we find evidence of redundant features that remain dormant
unless earlier features are suppressed. Our findings highlight the potential
for fine-grained auditing and targeted intervention in safety behaviours by
manipulating the interpretable latent space.

</details>


### [73] [Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement](https://arxiv.org/abs/2509.09709)
*Jing Ren,Weiqi Wang*

Main category: cs.CL

TL;DR: 本研究提出两个评估指标（内容质量和参考文献有效性）以及基于这些指标的迭代提示方法，用于定量评估和提升大型语言模型在学术写作中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在学术写作中日益普及，但存在引用错误或捏造等伦理问题，且当前的内容质量评估主要依赖主观人工判断，缺乏客观性和一致性。

Method: 提出内容质量和参考文献有效性两个评估指标，并基于这些指标的得分设计迭代提示方法，通过实验验证其效果。

Result: 实验结果表明，所提指标为ChatGPT写作表现提供了客观的定量评估框架，迭代提示显著提升了内容质量并减少了引用错误和捏造问题。

Conclusion: 该方法有效解决了学术写作中的伦理挑战，为大型语言模型的学术应用提供了可靠的评估和改进手段。

Abstract: Large language models (LLMs) like ChatGPT are increasingly used in academic
writing, yet issues such as incorrect or fabricated references raise ethical
concerns. Moreover, current content quality evaluations often rely on
subjective human judgment, which is labor-intensive and lacks objectivity,
potentially compromising the consistency and reliability. In this study, to
provide a quantitative evaluation and enhance research proposal writing
capabilities of LLMs, we propose two key evaluation metrics--content quality
and reference validity--and an iterative prompting method based on the scores
derived from these two metrics. Our extensive experiments show that the
proposed metrics provide an objective, quantitative framework for assessing
ChatGPT's writing performance. Additionally, iterative prompting significantly
enhances content quality while reducing reference inaccuracies and
fabrications, addressing critical ethical challenges in academic contexts.

</details>


### [74] [Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data](https://arxiv.org/abs/2509.09710)
*Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan*

Main category: cs.CL

TL;DR: 本研究提出了一种基于大语言模型（LLM）的个体出行日记生成方案，通过开源数据生成虚拟人物并合成出行记录，在零样本条件下与传统方法表现相当。


<details>
  <summary>Details</summary>
Motivation: 传统基于专有家庭出行调查的方法数据获取困难且成本高昂，需要开发一种能够利用开源数据生成真实出行日记的新方法。

Method: 使用美国社区调查（ACS）和智能位置数据库（SLD）数据随机生成虚拟人物，通过直接提示LLM合成出行日记，并采用包含四个指标（出行次数、时间间隔、目的、方式）的复合真实性评分体系进行验证。

Result: LLM生成的日记与传统方法（负二项式出行生成+多项Logit模式/目的选择）相比，整体真实性相当（LLM平均0.485 vs 0.455），在出行目的确定方面表现更优，且一致性更好。

Conclusion: LLM方法在零样本条件下可行，为未来合成出行日记评估系统建立了可量化的真实性度量标准，展示了在交通建模中的应用潜力。

Abstract: This study introduces a Large Language Model (LLM) scheme for generating
individual travel diaries in agent-based transportation models. While
traditional approaches rely on large quantities of proprietary household travel
surveys, the method presented in this study generates personas stochastically
from open-source American Community Survey (ACS) and Smart Location Database
(SLD) data, then synthesizes diaries through direct prompting. This study
features a novel one-to-cohort realism score: a composite of four metrics (Trip
Count Score, Interval Score, Purpose Score, and Mode Score) validated against
the Connecticut Statewide Transportation Study (CSTS) diaries, matched across
demographic variables. The validation utilizes Jensen-Shannon Divergence to
measure distributional similarities between generated and real diaries. When
compared to diaries generated with classical methods (Negative Binomial for
trip generation; Multinomial Logit for mode/purpose) calibrated on the
validation set, LLM-generated diaries achieve comparable overall realism (LLM
mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and
demonstrates greater consistency (narrower realism score distribution), while
classical models lead in numerical estimates of trip count and activity
duration. Aggregate validation confirms the LLM's statistical
representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot
viability and establishing a quantifiable metric of diary realism for future
synthetic diary evaluation systems.

</details>


### [75] [Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry](https://arxiv.org/abs/2509.09711)
*Aya E. Fouda,Abdelrahamn A. Hassan,Radwa J. Hanafy,Mohammed E. Fouda*

Main category: cs.CL

TL;DR: PsychiatryBench是一个基于权威精神病学教科书和案例构建的基准测试，包含11个问答任务和5300多个专家标注项目，用于评估LLM在精神病学实践中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有评估资源主要依赖小型临床访谈语料库、社交媒体帖子或合成对话，临床有效性有限，无法捕捉精神病学推理的复杂性，需要更权威的评估基准。

Method: 基于专家验证的精神病学教科书和案例构建基准测试，包含诊断推理、治疗计划等11个任务类型，使用传统指标和"LLM-as-judge"相似性评分框架评估多种前沿LLM。

Result: 结果显示在临床一致性和安全性方面存在显著差距，特别是在多轮随访和管理任务中，表明需要专门的模型调优和更强大的评估范式。

Conclusion: PsychiatryBench为高风险心理健康应用中的LLM性能基准测试和改进提供了模块化、可扩展的平台。

Abstract: Large language models (LLMs) hold great promise in enhancing psychiatric
practice, from improving diagnostic accuracy to streamlining clinical
documentation and therapeutic support. However, existing evaluation resources
heavily rely on small clinical interview corpora, social media posts, or
synthetic dialogues, which limits their clinical validity and fails to capture
the full complexity of psychiatric reasoning. In this work, we introduce
PsychiatryBench, a rigorously curated benchmark grounded exclusively in
authoritative, expert-validated psychiatric textbooks and casebooks.
PsychiatryBench comprises eleven distinct question-answering tasks ranging from
diagnostic reasoning and treatment planning to longitudinal follow-up,
management planning, clinical approach, sequential case analysis, and
multiple-choice/extended matching formats totaling over 5,300 expert-annotated
items. We evaluate a diverse set of frontier LLMs (including Google Gemini,
DeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models
(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an
"LLM-as-judge" similarity scoring framework. Our results reveal substantial
gaps in clinical consistency and safety, particularly in multi-turn follow-up
and management tasks, underscoring the need for specialized model tuning and
more robust evaluation paradigms. PsychiatryBench offers a modular, extensible
platform for benchmarking and improving LLM performance in high-stakes mental
health applications.

</details>


### [76] [The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization](https://arxiv.org/abs/2509.09712)
*Talha Tahir*

Main category: cs.CL

TL;DR: 本研究比较了SFT和ORPO两种训练方法对小型LLM进行ACT治疗的能力影响，发现ORPO方法在治疗忠诚度和共情方面显著优于SFT和基础模型，而思维链推理仅对SFT模型有显著帮助。


<details>
  <summary>Details</summary>
Motivation: 探索不同后训练方法和显式推理对小型开源大语言模型提供接纳承诺疗法(ACT)能力的影响，以提升心理治疗AI助手的效能。

Method: 使用Mistral-Large生成的50组合成ACT转录本，对Llama-3.2-3b-Instruct进行两种训练：监督微调(SFT)和odds ratio策略优化(ORPO)，每种方法都包含有无思维链推理(COT)的变体。通过模拟治疗会话评估性能，使用ACT忠诚度量表和治疗师共情量表由经过人类评估微调的LLM法官进行量化评估。

Result: ORPO训练模型在ACT忠诚度(χ²=185.15, p<.001)和治疗共情(χ²=140.37, p<.001)方面显著优于SFT和基础模型。COT对SFT模型有显著益处(平均提升2.68分，p<.001)，但对ORPO模型无显著优势。

Conclusion: 偏好对齐策略优化能有效在小LLM中培养ACT能力，显式推理的效用高度依赖于底层训练范式，ORPO通过学习治疗过程而非模仿内容来实现优势。

Abstract: Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral
therapy with emerging evidence of efficacy in several psychiatric conditions.
This study investigates the impact of post-training methodology and explicit
reasoning on the ability of a small open-weight large language model (LLM) to
deliver ACT. Using 50 sets of synthetic ACT transcripts generated by
Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,
supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each
with and without an explicit chain-of-thought (COT) reasoning step. Performance
was evaluated by comparing these four post-trained variants against the base
Instruct model. These models were benchmarked in simulated therapy sessions,
with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)
and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned
on human evaluations. Our findings demonstrate that the ORPO-trained models
significantly outperformed both their SFT and Instruct counterparts on ACT
fidelity ($\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\chi^2(5) =
140.37, p < .001$). The effect of COT was conditional as it provided a
significant benefit to SFT models, improving ACT-FM scores by an average of
2.68 points ($p < .001$), while offering no discernible advantage to the
superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO
stems from its ability to learn the therapeutic `process' over imitating
`content,' a key aspect of ACT, while COT acts as a necessary scaffold for
models trained only via imitation. This study establishes that
preference-aligned policy optimization can effectively instill ACT competencies
in small LLMs, and that the utility of explicit reasoning is highly dependent
on the underlying training paradigm.

</details>


### [77] [HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2509.09713)
*Duolin Sun,Dan Yang,Yue Shen,Yihan Jiao,Zhehao Tan,Jie Feng,Lianzhen Zhong,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: HANRAG是一个基于启发式的RAG框架，通过查询路由、子查询分解和噪声过滤，有效解决多跳查询中的迭代检索浪费和噪声积累问题，在单跳和多跳问答任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法在处理多跳查询时面临挑战：过度依赖迭代检索浪费步骤，原始复杂查询检索可能无法捕获相关子查询内容，导致噪声积累问题。

Method: 提出HANRAG框架，使用强大的揭示器驱动，进行查询路由、子查询分解，并从检索文档中过滤噪声，增强系统适应性和抗噪声能力。

Result: 在多个基准测试中与行业领先方法比较，结果显示该框架在单跳和多跳问答任务中都获得了优越性能。

Conclusion: HANRAG框架通过创新的启发式方法有效解决了RAG在多跳查询中的关键问题，显著提升了问答系统的处理能力和准确性。

Abstract: The Retrieval-Augmented Generation (RAG) approach enhances question-answering
systems and dialogue generation tasks by integrating information retrieval (IR)
technologies with large language models (LLMs). This strategy, which retrieves
information from external knowledge bases to bolster the response capabilities
of generative models, has achieved certain successes. However, current RAG
methods still face numerous challenges when dealing with multi-hop queries. For
instance, some approaches overly rely on iterative retrieval, wasting too many
retrieval steps on compound queries. Additionally, using the original complex
query for retrieval may fail to capture content relevant to specific
sub-queries, resulting in noisy retrieved content. If the noise is not managed,
it can lead to the problem of noise accumulation. To address these issues, we
introduce HANRAG, a novel heuristic-based framework designed to efficiently
tackle problems of varying complexity. Driven by a powerful revelator, HANRAG
routes queries, decomposes them into sub-queries, and filters noise from
retrieved documents. This enhances the system's adaptability and noise
resistance, making it highly capable of handling diverse queries. We compare
the proposed framework against other leading industry methods across various
benchmarks. The results demonstrate that our framework obtains superior
performance in both single-hop and multi-hop question-answering tasks.

</details>


### [78] [How Small Transformation Expose the Weakness of Semantic Similarity Measures](https://arxiv.org/abs/2509.09714)
*Serge Lionel Nikiema,Albérick Euraste Djire,Abdoul Aziz Bonkoungou,Micheline Bénédicte Moumoula,Jordan Samhi,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyande*

Main category: cs.CL

TL;DR: 本研究系统评估了18种语义相似度测量方法，发现常用指标存在严重问题，某些嵌入方法将语义对立内容误判为相似的概率高达99.9%，而转换距离计算方法可显著改善性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在代码搜索、API推荐等软件工程应用中广泛用于语义相似度评估，需要验证这些方法是否真正理解语义关系还是仅识别表面模式。

Method: 创建系统化测试框架，对文本和代码应用受控变化，评估18种不同方法（包括基于词的方法、嵌入技术、LLM系统和结构感知算法）处理不同类型语义关系的能力。

Result: 嵌入方法错误地将语义对立内容识别为相似的概率高达99.9%；某些基于transformer的方法偶尔将相反含义评为比同义词更相似；从欧几里得距离切换到余弦相似度使结果改善24-66%；LLM方法在区分语义差异方面表现更好。

Conclusion: 当前常用的语义相似度测量方法存在显著缺陷，需要更可靠的评估指标和计算方法来确保语义理解的准确性。

Abstract: This research examines how well different methods measure semantic
similarity, which is important for various software engineering applications
such as code search, API recommendations, automated code reviews, and
refactoring tools. While large language models are increasingly used for these
similarity assessments, questions remain about whether they truly understand
semantic relationships or merely recognize surface patterns.
  The study tested 18 different similarity measurement approaches, including
word-based methods, embedding techniques, LLM-based systems, and
structure-aware algorithms. The researchers created a systematic testing
framework that applies controlled changes to text and code to evaluate how well
each method handles different types of semantic relationships.
  The results revealed significant issues with commonly used metrics. Some
embedding-based methods incorrectly identified semantic opposites as similar up
to 99.9 percent of the time, while certain transformer-based approaches
occasionally rated opposite meanings as more similar than synonymous ones. The
study found that embedding methods' poor performance often stemmed from how
they calculate distances; switching from Euclidean distance to cosine
similarity improved results by 24 to 66 percent. LLM-based approaches performed
better at distinguishing semantic differences, producing low similarity scores
(0.00 to 0.29) for genuinely different meanings, compared to embedding methods
that incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.

</details>


### [79] [Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA](https://arxiv.org/abs/2509.09715)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 本研究识别并表征了导致大语言模型产生幻觉的关键符号属性，发现即使模型规模增大，符号元素（如修饰词和命名实体）仍然是导致幻觉的主要原因。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型的幻觉问题已被广泛研究，但导致模型内在易产生幻觉的属性尚未被识别和研究。本研究旨在找出这些关键属性并分析模型内部机制的脆弱性。

Method: 使用HaluEval和TruthfulQA两个数据集，将原有的问答格式转换为多种其他格式，以确定导致幻觉的属性。测试了Gemma-2系列不同规模的模型（2B、9B、27B）。

Result: Gemma-2-2B的平均幻觉率为79.0%，随着模型规模增大，Gemma-2-9B降至73.6%，Gemma-2-27B降至63.9%。但修饰词（84.76%-94.98%）和命名实体（83.87%-93.96%）的幻觉率在所有模型和数据集上都保持很高水平。

Conclusion: 符号元素持续混淆大语言模型，这表明无论模型规模如何，这些模型在处理此类输入时存在根本性弱点，符号属性是导致幻觉的内在脆弱性来源。

Abstract: Hallucination in Large Language Models (LLMs) is a well studied problem.
However, the properties that make LLM intrinsically vulnerable to
hallucinations have not been identified and studied. This research identifies
and characterizes the key properties, allowing us to pinpoint vulnerabilities
within the model's internal mechanisms. To solidify on these properties, we
utilized two established datasets, HaluEval and TruthfulQA and convert their
existing format of question answering into various other formats to narrow down
these properties as the reason for the hallucinations. Our findings reveal that
hallucination percentages across symbolic properties are notably high for
Gemma-2-2B, averaging 79.0% across tasks and datasets. With increased model
scale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,
reflecting a 15 percentage point reduction overall. Although the hallucination
rate decreases as the model size increases, a substantial amount of
hallucination caused by symbolic properties still persists. This is especially
evident for modifiers (ranging from 84.76% to 94.98%) and named entities
(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.
These findings indicate that symbolic elements continue to confuse the models,
pointing to a fundamental weakness in how these LLMs process such
inputs--regardless of their scale.

</details>


### [80] [ALIGNS: Unlocking nomological networks in psychological measurement through a large language model](https://arxiv.org/abs/2509.09723)
*Kai R. Larsen,Sen Yan,Roland Müller,Lan Sang,Mikko Rönkkö,Ravi Starzl,Donald Edmondson*

Main category: cs.CL

TL;DR: ALIGNS是一个基于大语言模型的系统，用于构建包含55万+指标的综合理论网络，解决心理学测量中理论网络构建的长期挑战，并在三个评估中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决70年来心理学测量中理论网络构建的难题，传统方法难以建立有效的效度验证网络，导致临床试验可能无法检测治疗效果，公共政策可能针对错误结果。

Method: 开发基于大语言模型的ALIGNS系统，使用经过验证的问卷测量数据进行训练，生成包含心理学、医学、社会政策等领域的综合理论网络。

Result: 构建了三个包含超过55万个指标的综合理论网络；验证显示NIH PROMIS焦虑和抑郁工具收敛为单一情绪困扰维度；发现儿童气质测量的四个新潜在维度并质疑现有维度；专家评估确认系统的重要性、可访问性和适用性。

Conclusion: ALIGNS是大语言模型在测量验证基础问题上的首次应用，为传统验证方法提供了大规模理论分析补充，系统已在nomologicalnetwork.org免费提供。

Abstract: Psychological measurement is critical to many disciplines. Despite advances
in measurement, building nomological networks, theoretical maps of how concepts
and measures relate to establish validity, remains a challenge 70 years after
Cronbach and Meehl proposed them as fundamental to validation. This limitation
has practical consequences: clinical trials may fail to detect treatment
effects, and public policy may target the wrong outcomes. We introduce Analysis
of Latent Indicators to Generate Nomological Structures (ALIGNS), a large
language model-based system trained with validated questionnaire measures.
ALIGNS provides three comprehensive nomological networks containing over
550,000 indicators across psychology, medicine, social policy, and other
fields. This represents the first application of large language models to solve
a foundational problem in measurement validation. We report classification
accuracy tests used to develop the model, as well as three evaluations. In the
first evaluation, the widely used NIH PROMIS anxiety and depression instruments
are shown to converge into a single dimension of emotional distress. The second
evaluation examines child temperament measures and identifies four potential
dimensions not captured by current frameworks, and questions one existing
dimension. The third evaluation, an applicability check, engages expert
psychometricians who assess the system's importance, accessibility, and
suitability. ALIGNS is freely available at nomologicalnetwork.org,
complementing traditional validation methods with large-scale nomological
analysis.

</details>


### [81] [DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model](https://arxiv.org/abs/2509.09724)
*Wonyoung Kim,Sujeong Seo,Juhyun Lee*

Main category: cs.CL

TL;DR: 提出基于技术间时间关系的框架来识别新兴技术机会，利用大语言模型从专利数据中提取主题并追踪其随时间变化，实验证明AI技术正朝着日常可访问性发展


<details>
  <summary>Details</summary>
Motivation: 技术机会是推动技术进步、产业发展和创新的关键信息，需要系统性的方法来识别新兴技术机会

Method: 从专利数据集中提取文本，将基于文本的主题映射以发现技术间关系，通过追踪这些主题随时间的变化来识别技术机会，利用大语言模型提取主题并使用提示工程支持机会发现

Result: 使用美国专利商标局提供的人工智能专利数据集进行评估，实验结果表明人工智能技术正在向促进日常可访问性的形式演进

Conclusion: 该方法展示了所提出框架在识别未来技术机会方面的潜力

Abstract: Technology opportunities are critical information that serve as a foundation
for advancements in technology, industry, and innovation. This paper proposes a
framework based on the temporal relationships between technologies to identify
emerging technology opportunities. The proposed framework begins by extracting
text from a patent dataset, followed by mapping text-based topics to discover
inter-technology relationships. Technology opportunities are then identified by
tracking changes in these topics over time. To enhance efficiency, the
framework leverages a large language model to extract topics and employs a
prompt for a chat-based language model to support the discovery of technology
opportunities. The framework was evaluated using an artificial intelligence
patent dataset provided by the United States Patent and Trademark Office. The
experimental results suggest that artificial intelligence technology is
evolving into forms that facilitate everyday accessibility. This approach
demonstrates the potential of the proposed framework to identify future
technology opportunities.

</details>


### [82] [BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025](https://arxiv.org/abs/2509.09725)
*Chunyu Li,Xindi Zheng,Siqi Liu*

Main category: cs.CL

TL;DR: 提出了一个轻量级的两阶段实体链接系统BIBERT-Pipe，用于处理生物医学文本中的多语言嵌套命名实体链接任务，在BioNNE 2025多语言赛道中排名第三


<details>
  <summary>Details</summary>
Motivation: 现有的生物医学实体链接基准主要针对英语和平坦提及，缺乏对多语言和嵌套提及的现实场景探索

Method: 采用两阶段检索-排序框架：检索阶段使用原始预训练模型，排序阶段进行领域特定微调；使用可学习的[Ms]/[Me]标签包装提及；通过三个补充数据源自动扩展训练语料

Result: 在BioNNE 2025多语言排行榜上排名第三，证明了这些最小但原则性修改的有效性和竞争力

Conclusion: 该方法通过保持原始EL模型完整并仅修改三个任务对齐组件，成功解决了多语言生物医学嵌套实体链接的挑战

Abstract: Entity linking (EL) for biomedical text is typically benchmarked on
English-only corpora with flat mentions, leaving the more realistic scenario of
nested and multilingual mentions largely unexplored. We present our system for
the BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task
(English & Russian), closing this gap with a lightweight pipeline that keeps
the original EL model intact and modifies only three task-aligned components:
Two-stage retrieval-ranking. We leverage the same base encoder model in both
stages: the retrieval stage uses the original pre-trained model, while the
ranking stage applies domain-specific fine-tuning. Boundary cues. In the
ranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing
the encoder with an explicit, language-agnostic span before robustness to
overlap and nesting. Dataset augmentation. We also automatically expand the
ranking training corpus with three complementary data sources, enhancing
coverage without extra manual annotation. On the BioNNE 2025 leaderboard, our
two stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual
track, demonstrating the effectiveness and competitiveness of these minimal yet
principled modifications. Code are publicly available at
https://github.com/Kaggle-Competitions-Code/BioNNE-L.

</details>


### [83] [Natural Language Translation of Formal Proofs through Informalization of Proof Steps and Recursive Summarization along Proof Structure](https://arxiv.org/abs/2509.09726)
*Seiji Hattori,Takuya Matsuzaki,Makoto Fujiwara*

Main category: cs.CL

TL;DR: 提出了一种利用LLM的非形式化和摘要能力，将机器可验证的形式证明翻译为自然语言的方法，并在教科书证明和Lean证明库上验证了其可读性和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决形式证明难以被人类理解和阅读的问题，需要将机器可验证的形式证明转换为自然语言表述，提高证明的可读性和可理解性。

Method: 利用大型语言模型（LLMs）的非形式化（将形式语言证明步骤口语化）和摘要能力，开发自然语言翻译方法，应用于教科书形式证明数据和Lean证明助手的形式证明库。

Result: 方法能够生成高质量的自然语言证明，与原始自然语言证明相比具有良好质量，在Lean证明库上验证了方法能够输出高可读性和准确性的自然语言证明。

Conclusion: 该方法成功实现了形式证明到自然语言的转换，生成的证明具有高可读性和准确性，为形式证明的人类可理解性提供了有效解决方案。

Abstract: This paper proposes a natural language translation method for
machine-verifiable formal proofs that leverages the informalization
(verbalization of formal language proof steps) and summarization capabilities
of LLMs. For evaluation, it was applied to formal proof data created in
accordance with natural language proofs taken from an undergraduate-level
textbook, and the quality of the generated natural language proofs was analyzed
in comparison with the original natural language proofs. Furthermore, we will
demonstrate that this method can output highly readable and accurate natural
language proofs by applying it to existing formal proof library of the Lean
proof assistant.

</details>


### [84] [A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](https://arxiv.org/abs/2509.09727)
*Andy Zhu,Yingjun Du*

Main category: cs.CL

TL;DR: 提出了一种基于多智能体框架的金融问答系统，通过角色提示和检索增强生成技术，显著提升了金融领域问答的准确性


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在金融问答中难以处理复杂的多步定量推理和领域专业术语，需要专门的方法来提升金融问题解决能力

Method: 使用多智能体框架，包含基础生成器、证据检索器和专家评审器，结合检索增强生成(RAG)从6本金融教科书获取上下文证据，采用单次迭代生成精炼答案

Result: 相比零-shot思维链基线，批判性精炼使答案准确率提升6.6-8.3%，Gemini-2.0-Flash表现最佳，GPT-4o-mini达到与专门调优的FinGPT相当的性能

Conclusion: 该方法提供了一种成本效益高的金融问答增强方案，为多智能体金融LLM系统的进一步研究提供了见解

Abstract: Question answering (QA) plays a central role in financial education, yet
existing large language model (LLM) approaches often fail to capture the
nuanced and specialized reasoning required for financial problem-solving. The
financial domain demands multistep quantitative reasoning, familiarity with
domain-specific terminology, and comprehension of real-world scenarios. We
present a multi-agent framework that leverages role-based prompting to enhance
performance on domain-specific QA. Our framework comprises a Base Generator, an
Evidence Retriever, and an Expert Reviewer agent that work in a single-pass
iteration to produce a refined answer. We evaluated our framework on a set of
3,532 expert-designed finance education questions from Study.com, an online
learning platform. We leverage retrieval-augmented generation (RAG) for
contextual evidence from 6 finance textbooks and prompting strategies for a
domain-expert reviewer. Our experiments indicate that critique-based refinement
improves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,
with the highest performance from Gemini-2.0-Flash. Furthermore, our method
enables GPT-4o-mini to achieve performance comparable to the finance-tuned
FinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to
enhancing financial QA and offer insights for further research in multi-agent
financial LLM systems.

</details>


### [85] [A meta-analysis on the performance of machine-learning based language models for sentiment analysis](https://arxiv.org/abs/2509.09728)
*Elena Rohde,Jonas Klingwort,Christian Borgs*

Main category: cs.CL

TL;DR: 对Twitter情感分析中机器学习性能的元分析，发现平均准确率为0.80，指出总体准确率指标存在误导性，需要标准化报告规范


<details>
  <summary>Details</summary>
Motivation: 评估Twitter情感分析中机器学习模型的平均性能，分析研究间的异质性，探讨研究特征如何影响模型性能

Method: 采用PRISMA指南检索学术数据库，选取20项研究中的195个试验，使用双反正弦变换和三层次随机效应模型分析总体准确率

Result: AIC优化模型的平均总体准确率为0.80 [0.76, 0.84]，发现总体准确率因类别不平衡和情感类别数量而容易产生误导

Conclusion: 需要规范模型性能报告标准，包括报告独立测试集的混淆矩阵，以实现跨研究的可靠比较

Abstract: This paper presents a meta-analysis evaluating ML performance in sentiment
analysis for Twitter data. The study aims to estimate the average performance,
assess heterogeneity between and within studies, and analyze how study
characteristics influence model performance. Using PRISMA guidelines, we
searched academic databases and selected 195 trials from 20 studies with 12
study features. Overall accuracy, the most reported performance metric, was
analyzed using double arcsine transformation and a three-level random effects
model. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,
0.84]. This paper provides two key insights: 1) Overall accuracy is widely used
but often misleading due to its sensitivity to class imbalance and the number
of sentiment classes, highlighting the need for normalization. 2) Standardized
reporting of model performance, including reporting confusion matrices for
independent test sets, is essential for reliable comparisons of ML classifiers
across studies, which seems far from common practice.

</details>


### [86] [MultimodalHugs: Enabling Sign Language Processing in Hugging Face](https://arxiv.org/abs/2509.09729)
*Gerard Sant,Zifan Jiang,Carlos Escolano,Amit Moryossef,Mathias Müller,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: MultimodalHugs是一个基于Hugging Face构建的框架，旨在解决手语处理研究中的可复现性和不公平比较问题，支持更多样化的数据模态和任务。


<details>
  <summary>Details</summary>
Motivation: 手语处理研究面临复杂的临时代码、低可复现性和不公平比较等问题，现有的工具如Hugging Face无法灵活集成手语实验。

Method: 在Hugging Face基础上构建MultimodalHugs框架，增加抽象层以支持更多数据模态（如姿态估计数据、像素数据）和任务。

Result: 通过定量实验证明MultimodalHugs能够适应多种模态，包括手语姿态估计数据和文本字符像素数据。

Conclusion: MultimodalHugs为手语处理研究提供了更灵活、可复现的实验框架，同时也可广泛应用于其他非标准模板的多模态用例。

Abstract: In recent years, sign language processing (SLP) has gained importance in the
general field of Natural Language Processing. However, compared to research on
spoken languages, SLP research is hindered by complex ad-hoc code,
inadvertently leading to low reproducibility and unfair comparisons. Existing
tools that are built for fast and reproducible experimentation, such as Hugging
Face, are not flexible enough to seamlessly integrate sign language
experiments. This view is confirmed by a survey we conducted among SLP
researchers.
  To address these challenges, we introduce MultimodalHugs, a framework built
on top of Hugging Face that enables more diverse data modalities and tasks,
while inheriting the well-known advantages of the Hugging Face ecosystem. Even
though sign languages are our primary focus, MultimodalHugs adds a layer of
abstraction that makes it more widely applicable to other use cases that do not
fit one of the standard templates of Hugging Face. We provide quantitative
experiments to illustrate how MultimodalHugs can accommodate diverse modalities
such as pose estimation data for sign languages, or pixel data for text
characters.

</details>


### [87] [Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning](https://arxiv.org/abs/2509.09731)
*Haiyang Yu,Yuchuan Wu,Fan Shi,Lei Liao,Jinghui Lu,Xiaodong Ge,Han Wang,Minghan Zhuo,Xuecheng Wu,Xiang Fei,Hao Feng,Guozhi Tang,An-Lan Wang,Hanshen Zhu,Yangfan He,Quanhuan Liang,Liyuan Meng,Chao Feng,Can Huang,Jingqun Tang,Bin Li*

Main category: cs.CL

TL;DR: AncientDoc是首个针对中文古籍文档的基准测试，包含5个任务，涵盖14种文档类型、100多本书籍和约3000页内容，用于评估视觉语言模型在OCR到知识推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 中文古籍作为中华历史文化的重要载体，在数字化和理解方面面临挑战。传统方法仅扫描图像，而现有视觉语言模型难以处理其视觉和语言复杂性。现有文档基准主要关注英文印刷文本或简体中文，缺乏对中文古籍文档的评估标准。

Method: 构建AncientDoc基准测试，包含五个任务：页面级OCR、白话翻译、基于推理的问答、基于知识的问答、语言变体问答。涵盖14种文档类型、100多本书籍和约3000页内容。使用多指标评估主流视觉语言模型，并辅以人工对齐的大语言模型进行评分。

Result: 开发了首个专门针对中文古籍文档的综合基准测试AncientDoc，为评估视觉语言模型在复杂古籍文档处理能力方面提供了标准化的测试平台。

Conclusion: AncientDoc填补了中文古籍文档评估的空白，为促进视觉语言模型在文化遗产数字化和理解方面的发展提供了重要工具和基准。

Abstract: Chinese ancient documents, invaluable carriers of millennia of Chinese
history and culture, hold rich knowledge across diverse fields but face
challenges in digitization and understanding, i.e., traditional methods only
scan images, while current Vision-Language Models (VLMs) struggle with their
visual and linguistic complexity. Existing document benchmarks focus on English
printed texts or simplified Chinese, leaving a gap for evaluating VLMs on
ancient Chinese documents. To address this, we present AncientDoc, the first
benchmark for Chinese ancient documents, designed to assess VLMs from OCR to
knowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular
translation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and
covers 14 document types, over 100 books, and about 3,000 pages. Based on
AncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by
a human-aligned large language model for scoring.

</details>


### [88] [MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools](https://arxiv.org/abs/2509.09734)
*Zikang Guo,Benfeng Xu,Chiwei Zhu,Wentao Hong,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: MCP-AgentBench是一个专门针对MCP协议的综合基准测试，包含33个服务器、188个工具和600个查询，用于评估语言代理在工具交互中的真实性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试无法准确评估在MCP新范式下的真实代理性能，导致对其实际操作价值的误解和无法可靠区分能力差异。

Method: 建立了包含33个操作服务器和188个不同工具的MCP测试床；开发了600个系统设计的查询，分布在6个不同复杂度的交互类别；引入了MCP-Eval这种以结果为导向的新评估方法。

Result: 通过对领先语言代理的广泛实证评估，提供了基础性见解，展示了不同代理在MCP环境下的性能差异。

Conclusion: MCP-AgentBench为研究社区提供了一个标准化和可靠的框架，用于构建、验证和推进能够充分利用MCP变革性优势的代理，加速真正能力和互操作性AI系统的发展。

Abstract: The Model Context Protocol (MCP) is rapidly emerging as a pivotal open
standard, designed to enhance agent-tool integration and interoperability, and
is positioned to unlock a new era of powerful, interconnected, and genuinely
utilitarian agentic AI. However, despite MCP's growing adoption, existing
benchmarks often fail to capture real-world agent performance within this new
paradigm, leading to a distorted perception of their true operational value and
an inability to reliably differentiate proficiencies. To bridge this critical
evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark
specifically engineered to rigorously assess language agent capabilities in
MCP-mediated tool interactions. Core contributions of MCP-AgentBench include:
the establishment of a robust MCP testbed comprising 33 operational servers
with 188 distinct tools; the development of a benchmark featuring 600
systematically designed queries distributed across 6 distinct categories of
varying interaction complexity; and the introduction of MCP-Eval, a novel
outcome-oriented evaluation methodology prioritizing real-world task success.
Through extensive empirical evaluation of leading language agents, we provide
foundational insights. MCP-AgentBench aims to equip the research community with
a standardized and reliable framework to build, validate, and advance agents
capable of fully leveraging MCP's transformative benefits, thereby accelerating
progress toward truly capable and interoperable AI systems.

</details>


### [89] [Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in Decision-Making and Summarisation](https://arxiv.org/abs/2509.09735)
*Willem Huijzer,Jieying Chen*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型在背景、性别和年龄方面的偏见，发现GPT-3.5和GPT-4o在决策任务中存在显著偏见，偏好女性、年轻年龄和特定背景，而摘要任务偏见较小。跨语言分析显示英语和荷兰语的偏见模式相似，新提出的缓解指令能减少27%的偏见差距。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在各领域的快速集成，引发了对其可能加剧社会不平等和信息偏见的担忧，需要系统研究模型偏见及其缓解策略。

Method: 使用Tamkin等人(2023)数据集的荷兰语翻译版本，创建了151,200个决策任务提示和176,400个摘要任务提示，测试不同人口统计变量、指令、显著度水平和语言在GPT-3.5和GPT-4o上的表现。

Result: 决策任务中两个模型都存在显著偏见，偏好女性、年轻年龄和非裔美国人背景；摘要任务偏见较小；跨语言偏见模式相似但存在差异；缓解指令能平均减少27%的偏见差距；GPT-4o在英语中表现出更低的偏见。

Conclusion: 研究强调了谨慎采用LLM和针对具体情境进行偏见测试的重要性，需要持续开发有效的缓解策略以确保AI的负责任部署，新模型在基于提示的缓解方面具有特定潜力。

Abstract: The rapid integration of Large Language Models (LLMs) into various domains
raises concerns about societal inequalities and information bias. This study
examines biases in LLMs related to background, gender, and age, with a focus on
their impact on decision-making and summarization tasks. Additionally, the
research examines the cross-lingual propagation of these biases and evaluates
the effectiveness of prompt-instructed mitigation strategies. Using an adapted
version of the dataset by Tamkin et al. (2023) translated into Dutch, we
created 151,200 unique prompts for the decision task and 176,400 for the
summarisation task. Various demographic variables, instructions, salience
levels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed
that both models were significantly biased during decision-making, favouring
female gender, younger ages, and certain backgrounds such as the
African-American background. In contrast, the summarisation task showed minimal
evidence of bias, though significant age-related differences emerged for
GPT-3.5 in English. Cross-lingual analysis showed that bias patterns were
broadly similar between English and Dutch, though notable differences were
observed across specific demographic categories. The newly proposed mitigation
instructions, while unable to eliminate biases completely, demonstrated
potential in reducing them. The most effective instruction achieved a 27\% mean
reduction in the gap between the most and least favorable demographics.
Notably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts
in English, indicating the specific potential for prompt-based mitigation
within newer models. This research underscores the importance of cautious
adoption of LLMs and context-specific bias testing, highlighting the need for
continued development of effective mitigation strategies to ensure responsible
deployment of AI.

</details>


### [90] [HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning](https://arxiv.org/abs/2509.09801)
*Brennen Hill*

Main category: cs.CL

TL;DR: HEFT是一种分层高效微调策略，结合LoRA和ReFT两种PEFT方法，在BoolQ基准测试中仅用3个epoch就达到85.17%的准确率，优于单独使用LoRA或ReFT方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专门推理任务上的适配受计算资源限制，虽然参数高效微调(PEFT)方法提供了解决方案，但不同方法在权重空间和表示空间中运作，需要探索协同组合的可能性。

Method: 提出HEFT分层适配策略：先在权重空间使用LoRA进行广泛基础适配，然后在表示空间使用ReFT进行精确细化，形成从粗到细的层次化微调。

Result: 在Llama-2-7B模型和BoolQ基准测试中，HEFT仅用3个epoch就达到85.17%准确率，超过LoRA-only(85.05%)和ReFT-only(83.36%)方法训练20个epoch的性能。

Conclusion: PEFT方法的精心组合是一种强大的算法创新，为提升语言模型推理能力提供了更高效有效的途径，能以更少计算预算获得更优结果。

Abstract: The adaptation of large language models (LLMs) to specialized reasoning tasks
is fundamentally constrained by computational resources. Parameter-Efficient
Fine-Tuning (PEFT) methods have emerged as a powerful solution, yet the
landscape of these techniques is diverse, with distinct methods operating in
either the model's weight space or its representation space. This paper
investigates the hypothesis that a synergistic combination of these paradigms
can unlock superior performance and efficiency. We introduce HEFT (Hierarchical
Efficient Fine-Tuning), a novel hierarchical adaptation strategy that composes
two distinct PEFT methods in a coarse-to-fine manner: first, a broad,
foundational adaptation in the weight space using Low-Rank Adaptation (LoRA),
followed by a precise, surgical refinement of internal activations using
Representation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a
Llama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential
reasoning. Our results reveal a profound synergistic effect. A model fine-tuned
for only three epochs with our HEFT strategy achieves an accuracy of 85.17\%,
exceeding the performance of models trained for 20 epochs with either LoRA-only
(85.05\%) or ReFT-only (83.36\%) methodologies. This work demonstrates that the
thoughtful composition of PEFT methods is a potent algorithmic innovation,
offering a more efficient and effective path toward advancing the reasoning
capabilities of language models. By achieving superior results with a fraction
of the computational budget, our findings present a principled approach to
overcoming the obstacles inherent in adapting large-scale models for complex
cognitive tasks.

</details>


### [91] [Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization](https://arxiv.org/abs/2509.09804)
*Helen de Andrade Abreu,Tiago Timponi Torrent,Ely Edison da Silva Matos*

Main category: cs.CL

TL;DR: 提出了一个通过语言和交互手势相关性来建模多模态对话轮次组织的框架，基于对语用框架如何被概念化和唤起的分析


<details>
  <summary>Details</summary>
Motivation: 填补对话轮次组织中特定策略（尤其是手势）在机器学习可用数据集中的编码空白，研究面对面对话中手势在轮次传递、获取和保持中的作用

Method: 开发了注释方法，在Frame2多模态数据集（已标注语义框架）基础上增加语用框架注释，分析巴西电视剧中的10集内容，观察非实验室环境下的交互手势使用

Result: 确认了面对面对话中手势作为轮次管理工具的作用，发现了之前未记录的手势变体，证明了语用框架注释有助于更深入理解人类认知和语言

Conclusion: 手势使用源于语用框架的概念化，涉及心理空间、概念整合和概念隐喻，语用框架注释对理解人类认知和语言有重要贡献

Abstract: This paper proposes a framework for modeling multimodal conversational turn
organization via the proposition of correlations between language and
interactive gestures, based on analysis as to how pragmatic frames are
conceptualized and evoked by communicators. As a means to provide evidence for
the analysis, we developed an annotation methodology to enrich a multimodal
dataset (annotated for semantic frames) with pragmatic frames modeling
conversational turn organization. Although conversational turn organization has
been studied by researchers from diverse fields, the specific strategies,
especially gestures used by communicators, had not yet been encoded in a
dataset that can be used for machine learning. To fill this gap, we enriched
the Frame2 dataset with annotations of gestures used for turn organization. The
Frame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo
Mundo annotated for semantic frames evoked in both video and text. This dataset
allowed us to closely observe how communicators use interactive gestures
outside a laboratory, in settings, to our knowledge, not previously recorded in
related literature. Our results have confirmed that communicators involved in
face-to-face conversation make use of gestures as a tool for passing, taking
and keeping conversational turns, and also revealed variations of some gestures
that had not been documented before. We propose that the use of these gestures
arises from the conceptualization of pragmatic frames, involving mental spaces,
blending and conceptual metaphors. In addition, our data demonstrate that the
annotation of pragmatic frames contributes to a deeper understanding of human
cognition and language.

</details>


### [92] [Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization](https://arxiv.org/abs/2509.09852)
*Chuyuan Li,Austin Xu,Shafiq Joty,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 提出基于主题引导的强化学习方法，通过主题奖励机制在多文档摘要中提升内容选择效果


<details>
  <summary>Details</summary>
Motivation: 多文档摘要中如何有效整合多个来源的信息同时保持连贯性和主题相关性是一个关键挑战，现有大语言模型在多文档摘要方面仍有改进空间

Method: 首先展示显式提示模型使用主题标签可以增强生成摘要的信息性，然后提出在GRPO框架内使用新颖的主题奖励来衡量生成摘要与源文档之间的主题对齐

Result: 在Multi-News和Multi-XScience数据集上的实验结果表明，该方法持续优于强基线

Conclusion: 利用主题线索在多文档摘要中是有效的，主题引导的强化学习方法能够显著提升多文档摘要的性能

Abstract: A key challenge in Multi-Document Summarization (MDS) is effectively
integrating information from multiple sources while maintaining coherence and
topical relevance. While Large Language Models have shown impressive results in
single-document summarization, their performance on MDS still leaves room for
improvement. In this paper, we propose a topic-guided reinforcement learning
approach to improve content selection in MDS. We first show that explicitly
prompting models with topic labels enhances the informativeness of the
generated summaries. Building on this insight, we propose a novel topic reward
within the Group Relative Policy Optimization (GRPO) framework to measure topic
alignment between the generated summary and source documents. Experimental
results on the Multi-News and Multi-XScience datasets demonstrate that our
method consistently outperforms strong baselines, highlighting the
effectiveness of leveraging topical cues in MDS.

</details>


### [93] [Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case](https://arxiv.org/abs/2509.09871)
*Bastián González-Bustamante,Nando Verelst,Carla Cisternas*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）在生成合成调查响应方面的可靠性，通过与智利概率抽样调查的人类真实响应对比，发现LLMs在信任类问题上表现优异，但在捕捉公众意见的细微差别方面仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: LLMs为调查研究提供了使用合成受访者模拟人类答案和行为的新方法，可能减少测量和代表性误差，但其恢复聚合项目分布的程度尚不确定，且存在复制社会刻板印象和偏见的风险。

Method: 研究评估了128个提示-模型-问题三元组，生成了189,696个合成配置文件，并在128个问题-子样本对上进行元分析，测试关键社会人口维度上的偏见，涵盖了OpenAI的GPT系列、o系列推理模型以及Llama和Qwen检查点。

Result: 合成响应在信任项目上表现出色（F1分数和准确率>0.90）；GPT-4o、GPT-4o-mini和Llama 4 Maverick在此任务上表现相当；45-59岁受访者的合成-人类对齐度最高。

Conclusion: 基于LLM的合成样本能够近似概率样本的响应，但存在显著的项目级异质性。要捕捉公众意见的全部细微差别仍然具有挑战性，需要仔细校准和额外的分布测试以确保算法保真度和减少误差。

Abstract: Large Language Models (LLMs) offer promising avenues for methodological and
applied innovations in survey research by using synthetic respondents to
emulate human answers and behaviour, potentially mitigating measurement and
representation errors. However, the extent to which LLMs recover aggregate item
distributions remains uncertain and downstream applications risk reproducing
social stereotypes and biases inherited from training data. We evaluate the
reliability of LLM-generated synthetic survey responses against ground-truth
human responses from a Chilean public opinion probabilistic survey.
Specifically, we benchmark 128 prompt-model-question triplets, generating
189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,
precision, recall, and F1-score) in a meta-analysis across 128
question-subsample pairs to test for biases along key sociodemographic
dimensions. The evaluation spans OpenAI's GPT family and o-series reasoning
models, as well as Llama and Qwen checkpoints. Three results stand out. First,
synthetic responses achieve excellent performance on trust items (F1-score and
accuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform
comparably on this task. Third, synthetic-human alignment is highest among
respondents aged 45-59. Overall, LLM-based synthetic samples approximate
responses from a probabilistic sample, though with substantial item-level
heterogeneity. Capturing the full nuance of public opinion remains challenging
and requires careful calibration and additional distributional tests to ensure
algorithmic fidelity and reduce errors.

</details>


### [94] [Large Language Models Meet Legal Artificial Intelligence: A Survey](https://arxiv.org/abs/2509.09969)
*Zhitian Hou,Zihan Ye,Nanli Zeng,Tianyong Hao,Kun Zeng*

Main category: cs.CL

TL;DR: 本文对基于大语言模型的法律人工智能进行了全面综述，涵盖了16个法律LLM系列、47个LLM法律任务框架、15个基准测试和29个数据集，并分析了挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 推动大语言模型在法律领域的研究和应用，为初学者提供系统性的介绍，并促进该领域的未来发展。

Method: 通过系统性综述方法，收集和分析现有的法律LLM模型、框架、基准测试和数据集，并进行综合评估和分析。

Result: 提供了全面的法律LLM资源汇总，包括模型、框架、评估工具和数据资源，为研究者和实践者提供了宝贵的参考。

Conclusion: 大语言模型在法律AI领域具有巨大潜力，但仍面临挑战，需要进一步研究和发展，本文为后续研究提供了重要基础和方向指引。

Abstract: Large Language Models (LLMs) have significantly advanced the development of
Legal Artificial Intelligence (Legal AI) in recent years, enhancing the
efficiency and accuracy of legal tasks. To advance research and applications of
LLM-based approaches in legal domain, this paper provides a comprehensive
review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and
also gather 15 benchmarks and 29 datasets to evaluate different legal
capabilities. Additionally, we analyse the challenges and discuss future
directions for LLM-based approaches in the legal domain. We hope this paper
provides a systematic introduction for beginners and encourages future research
in this field. Resources are available at
https://github.com/ZhitianHou/LLMs4LegalAI.

</details>


### [95] [CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China](https://arxiv.org/abs/2509.09990)
*Guixian Xu,Zeli Su,Ziyin Zhang,Jianing Liu,XU Han,Ting Zhang,Yushuang Dong*

Main category: cs.CL

TL;DR: 该论文提出了一个针对中国少数民族语言（藏语、维吾尔语、蒙古语）的新闻标题生成数据集CMHG，包含20万条数据，并提供了由母语者标注的高质量测试集作为基准。


<details>
  <summary>Details</summary>
Motivation: 中国少数民族语言由于书写系统与国际标准不同，导致相关语料库严重缺乏，特别是在监督任务如标题生成方面存在明显空白。

Method: 构建了包含10万条藏语、5万条维吾尔语和5万条蒙古语数据的CMHG数据集，专门用于标题生成任务，并创建了由母语者标注的高质量测试集。

Result: 成功创建了首个专门针对中国少数民族语言标题生成的大规模数据集，为相关研究提供了宝贵的资源。

Conclusion: 该数据集将成为推动中国少数民族语言标题生成研究的重要资源，并为相关基准测试的发展做出贡献。

Abstract: Minority languages in China, such as Tibetan, Uyghur, and Traditional
Mongolian, face significant challenges due to their unique writing systems,
which differ from international standards. This discrepancy has led to a severe
lack of relevant corpora, particularly for supervised tasks like headline
generation. To address this gap, we introduce a novel dataset, Chinese Minority
Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and
50,000 entries each for Uyghur and Mongolian, specifically curated for headline
generation tasks. Additionally, we propose a high-quality test set annotated by
native speakers, designed to serve as a benchmark for future research in this
domain. We hope this dataset will become a valuable resource for advancing
headline generation in Chinese minority languages and contribute to the
development of related benchmarks.

</details>


### [96] [Unsupervised Hallucination Detection by Inspecting Reasoning Processes](https://arxiv.org/abs/2509.10004)
*Ponhvoan Srey,Xiaobao Wu,Anh Tuan Luu*

Main category: cs.CL

TL;DR: IRIS是一个无监督的幻觉检测框架，利用LLM内部表示来识别生成内容的事实正确性，无需标注数据，在计算成本低的情况下优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法依赖与事实正确性无关的代理信号，导致检测偏向表面特征，限制了跨数据集和场景的泛化能力

Method: 通过提示LLM仔细验证给定陈述的真实性，获取其情境化嵌入作为特征，并将每个响应的不确定性作为真实性的软伪标签

Result: 实验结果表明IRIS在无监督方法中表现一致优于现有方法，计算成本低，即使训练数据少也能良好工作

Conclusion: IRIS是一个完全无监督、计算成本低的框架，适用于实时检测，能够有效利用LLM内部表示进行幻觉检测

Abstract: Unsupervised hallucination detection aims to identify hallucinated content
generated by large language models (LLMs) without relying on labeled data.
While unsupervised methods have gained popularity by eliminating
labor-intensive human annotations, they frequently rely on proxy signals
unrelated to factual correctness. This misalignment biases detection probes
toward superficial or non-truth-related aspects, limiting generalizability
across datasets and scenarios. To overcome these limitations, we propose IRIS,
an unsupervised hallucination detection framework, leveraging internal
representations intrinsic to factual correctness. IRIS prompts the LLM to
carefully verify the truthfulness of a given statement, and obtain its
contextualized embedding as informative features for training. Meanwhile, the
uncertainty of each response is considered a soft pseudolabel for truthfulness.
Experimental results demonstrate that IRIS consistently outperforms existing
unsupervised methods. Our approach is fully unsupervised, computationally low
cost, and works well even with few training data, making it suitable for
real-time detection.

</details>


### [97] [Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs](https://arxiv.org/abs/2509.10010)
*Adnan Ahmad,Philine Kowol,Stefan Hillmann,Sebastian Möller*

Main category: cs.CL

TL;DR: 本文对开源大语言模型在MultiWOZ 2.1数据集上的多标签意图分类性能进行了全面分析，比较了LLama2-7B、Mistral-7B和Yi-6B模型在少样本设置下的表现，并与BERT监督学习基线进行对比。


<details>
  <summary>Details</summary>
Motivation: 研究开源大语言模型在消费级硬件上处理复杂多意图对话分类任务的有效性，为任务导向聊天机器人的自然语言理解提供实用框架。

Method: 使用MultiWOZ 2.1数据集，在少样本设置下（提示中包含20个示例）测试三个开源LLM模型，并与BERT监督分类器进行性能对比，评估指标包括准确率、精确率、召回率和多种F1分数。

Result: Mistral-7B-v0.1在14个意图类别中的11个上F分数表现最佳，加权平均F分数为0.50，但在整体性能上仍逊于基于BERT的监督分类器。

Conclusion: 虽然开源LLM在少样本多标签意图分类中展现潜力，但监督学习方法仍具有性能优势，研究为小规模开源模型处理复杂多意图对话提供了评估框架。

Abstract: In this paper, we provide an extensive analysis of multi-label intent
classification using Large Language Models (LLMs) that are open-source,
publicly available, and can be run in consumer hardware. We use the MultiWOZ
2.1 dataset, a benchmark in the dialogue system domain, to investigate the
efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,
Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot
setup, giving 20 examples in the prompt with some instructions. Our approach
focuses on the differences in performance of these models across several
performance metrics by methodically assessing these models on multi-label
intent classification tasks. Additionally, we compare the performance of the
instruction-based fine-tuning approach with supervised learning using the
smaller transformer model BertForSequenceClassification as a baseline. To
evaluate the performance of the models, we use evaluation metrics like
accuracy, precision, and recall as well as micro, macro, and weighted F1 score.
We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1
outperforms two other generative models on 11 intent classes out of 14 in terms
of F-Score, with a weighted average of 0.50. It also has relatively lower
Humming Loss and higher Jaccard Similarity, making it the winning model in the
few-shot setting. We find BERT based supervised classifier having superior
performance compared to the best performing few-shot generative LLM. The study
provides a framework for small open-source LLMs in detecting complex
multi-intent dialogues, enhancing the Natural Language Understanding aspect of
task-oriented chatbots.

</details>


### [98] [Linguistic trajectories of bipolar disorder on social media](https://arxiv.org/abs/2509.10035)
*Laurin Plank,Armin Zlomuzica*

Main category: cs.CL

TL;DR: 该研究通过社交媒体语言分析，开发了一种确定双相障碍诊断时间的方法，并分析了诊断前后21年的语言轨迹变化，发现双相障碍伴随广泛的语言改变和周期性情绪波动。


<details>
  <summary>Details</summary>
Motivation: 传统临床评估规模有限，而社交媒体语言分析具有高时间分辨率和纵向范围的优势，可用于大规模心理健康监测。

Method: 引入确定用户诊断时间的方法，对比分析双相障碍、单相抑郁和非受影响用户从诊断前3年到诊断后21年的社交媒体语言轨迹。

Result: 发现双相障碍诊断伴随反映情绪障碍、精神共病、物质滥用、住院治疗等的语言改变，以及诊断后20年内反复出现的情绪相关语言变化，具有明显的12个月周期性。

Conclusion: 研究结果证实了双相障碍急性和慢性期的语言改变，验证并扩展了利用社交媒体进行可扩展心理健康监测的最新努力。

Abstract: Language provides valuable markers of affective disorders such as bipolar
disorder (BD), yet clinical assessments remain limited in scale. In response,
analyses of social media (SM) language have gained prominence due to their high
temporal resolution and longitudinal scope. Here, we introduce a method to
determine the timing of users' diagnoses and apply it to study language
trajectories from 3 years before to 21 years after BD diagnosis - contrasted
with uses reporting unipolar depression (UD) and non-affected users (HC). We
show that BD diagnosis is accompanied by pervasive linguistic alterations
reflecting mood disturbance, psychiatric comorbidity, substance abuse,
hospitalization, medical comorbidities, unusual thought content, and
disorganized thought. We further observe recurring mood-related language
changes across two decades after the diagnosis, with a pronounced 12-month
periodicity suggestive of seasonal mood episodes. Finally, trend-level evidence
suggests an increased periodicity in users estimated to be female. In sum, our
findings provide evidence for language alterations in the acute and chronic
phase of BD. This validates and extends recent efforts leveraging SM for
scalable monitoring of mental health.

</details>


### [99] [!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment](https://arxiv.org/abs/2509.10040)
*Mohamed Basem,Mohamed Younes,Seif Ahmed,Abdelrahman Moustafa*

Main category: cs.CL

TL;DR: MSA团队在BAREC 2025阿拉伯语细粒度可读性评估任务中获胜，使用四个Transformer模型的置信度加权集成方法，通过加权训练、数据增强和后处理技术，在六个赛道中均获得第一名。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语可读性评估中的严重类别不平衡和数据稀缺问题，提升细粒度可读性预测的准确性。

Method: 使用AraBERTv2、AraELECTRA、MARBERT和CAMeLBERT四个Transformer模型，采用不同损失函数进行微调；应用加权训练、SAMER语料库重新标注、通过Gemini 2.5 Flash生成约10,000个稀有级别样本的合成数据；采用置信度加权集成和针对性后处理。

Result: 在句子级别达到87.5%的二次加权Kappa（QWK），在文档级别达到87.4%的QWK；后处理步骤带来6.3%的QWK增益；在六个赛道中均获得第一名。

Conclusion: 模型和损失函数的多样性、置信度信息融合以及智能数据增强对于构建鲁棒的阿拉伯语可读性预测系统具有强大效果。

Abstract: We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained
Arabic readability assessment, achieving first place in six of six tracks. Our
approach is a confidence-weighted ensemble of four complementary transformer
models (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with
distinct loss functions to capture diverse readability signals. To tackle
severe class imbalance and data scarcity, we applied weighted training,
advanced preprocessing, SAMER corpus relabeling with our strongest model, and
synthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level
samples. A targeted post-processing step corrected prediction distribution
skew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system
reached 87.5 percent QWK at the sentence level and 87.4 percent at the document
level, demonstrating the power of model and loss diversity, confidence-informed
fusion, and intelligent augmentation for robust Arabic readability prediction.

</details>


### [100] [Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models](https://arxiv.org/abs/2509.10078)
*Dongmin Choi,Woojung Song,Jongwook Han,Eun-Ju Lee,Yohan Jo*

Main category: cs.CL

TL;DR: 本文比较了传统心理测量问卷与生态效度问卷在测量大语言模型个性特征时的差异，发现传统问卷存在测量不稳定、产生误导性结果等问题，建议避免使用传统心理问卷评估LLMs。


<details>
  <summary>Details</summary>
Motivation: 现有研究使用传统心理问卷（如BFI、PVQ）测量大语言模型的个性特征和价值观，但这些人类设计的问卷可能缺乏生态效度，无法反映LLMs在真实用户查询场景中的表现。需要明确两种问卷的差异及其带来的启示。

Method: 对两种类型的问卷进行全面的比较分析，包括传统心理测量问卷和生态效度问卷，评估它们在测量LLMs个性特征时的表现差异。

Result: 分析显示传统问卷：1）产生与生态效度问卷显著不同的LLMs特征剖面，偏离了在用户查询上下文中表达的心理特征；2）项目数量不足导致测量不稳定；3）造成LLMs具有稳定构念的误导印象；4）对角色提示的LLMs产生夸大的特征剖面。

Conclusion: 研究警告不要使用传统的心理问卷来评估大语言模型，建议开发更适合LLMs特性的评估方法。

Abstract: Researchers have applied established psychometric questionnaires (e.g., BFI,
PVQ) to measure the personality traits and values reflected in the responses of
Large Language Models (LLMs). However, concerns have been raised about applying
these human-designed questionnaires to LLMs. One such concern is their lack of
ecological validity--the extent to which survey questions adequately reflect
and resemble real-world contexts in which LLMs generate texts in response to
user queries. However, it remains unclear how established questionnaires and
ecologically valid questionnaires differ in their outcomes, and what insights
these differences may provide. In this paper, we conduct a comprehensive
comparative analysis of the two types of questionnaires. Our analysis reveals
that established questionnaires (1) yield substantially different profiles of
LLMs from ecologically valid ones, deviating from the psychological
characteristics expressed in the context of user queries, (2) suffer from
insufficient items for stable measurement, (3) create misleading impressions
that LLMs possess stable constructs, and (4) yield exaggerated profiles for
persona-prompted LLMs. Overall, our work cautions against the use of
established psychological questionnaires for LLMs. Our code will be released
upon publication.

</details>


### [101] [Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery](https://arxiv.org/abs/2509.10087)
*Mustapha Adamu,Qi Zhang,Huitong Pan,Longin Jan Latecki,Eduard C. Dragut*

Main category: cs.CL

TL;DR: 本文构建了一个面向气候科学领域的知识图谱，支持语义查询和LLM集成，帮助研究人员更精确地发现气候模型、数据集和区域间的关联。


<details>
  <summary>Details</summary>
Motivation: 气候科学文献的复杂性和数量快速增长，使得研究人员难以跨模型、数据集、区域和变量找到相关信息。传统关键词搜索无法满足精确的语义查询需求。

Method: 构建领域特定的知识图谱，从气候出版物和科学文献中提取知识，支持Cypher查询语言，并与大型语言模型在RAG系统中集成。

Result: 知识图谱能够回答精确的语义查询，如特定区域验证的模型、与特定遥相关模式相关的数据集等，提高了气候信息检索的准确性和可靠性。

Conclusion: 该知识图谱为气候研究人员、模型开发者等提供了实用的工具，超越了传统知识图谱构建，展示了在实际气候研究中的实际应用价值。

Abstract: The growing complexity and volume of climate science literature make it
increasingly difficult for researchers to find relevant information across
models, datasets, regions, and variables. This paper introduces a
domain-specific Knowledge Graph (KG) built from climate publications and
broader scientific texts, aimed at improving how climate knowledge is accessed
and used. Unlike keyword based search, our KG supports structured, semantic
queries that help researchers discover precise connections such as which models
have been validated in specific regions or which datasets are commonly used
with certain teleconnection patterns. We demonstrate how the KG answers such
questions using Cypher queries, and outline its integration with large language
models in RAG systems to improve transparency and reliability in
climate-related question answering. This work moves beyond KG construction to
show its real world value for climate researchers, model developers, and others
who rely on accurate, contextual scientific information.

</details>


### [102] [Arabic Large Language Models for Medical Text Generation](https://arxiv.org/abs/2509.10095)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 本研究提出了一种针对阿拉伯语医疗文本生成的LLM微调方法，通过收集社交媒体真实医患对话数据，微调Mistral-7B等模型，在阿拉伯语医疗咨询中取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有医院管理系统缺乏对不规则输入和少数语言提供准确实时医疗建议的能力，特别是在阿拉伯语等资源匮乏语言环境中。

Method: 收集社交媒体医患对话数据集，清理预处理多阿拉伯方言数据，微调Mistral-7B-Instruct-v0.2、LLaMA-2-7B和GPT-2 Medium等生成模型。

Result: 微调后的Mistral-7B模型表现最佳，BERT Score在精确率、召回率和F1分数上分别达到68.5%、69.08%和68.5%。

Conclusion: 生成式AI在医院管理系统中具有巨大潜力，为全球医疗挑战提供了可扩展的解决方案，特别适用于语言文化多样环境。

Abstract: Efficient hospital management systems (HMS) are critical worldwide to address
challenges such as overcrowding, limited resources, and poor availability of
urgent health care. Existing methods often lack the ability to provide
accurate, real-time medical advice, particularly for irregular inputs and
underrepresented languages. To overcome these limitations, this study proposes
an approach that fine-tunes large language models (LLMs) for Arabic medical
text generation. The system is designed to assist patients by providing
accurate medical advice, diagnoses, drug recommendations, and treatment plans
based on user input. The research methodology required the collection of a
unique dataset from social media platforms, capturing real-world medical
conversations between patients and doctors. The dataset, which includes patient
complaints together with medical advice, was properly cleaned and preprocessed
to account for multiple Arabic dialects. Fine-tuning state-of-the-art
generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2
Medium, optimized the system's ability to generate reliable medical text.
Results from evaluations indicate that the fine-tuned Mistral-7B model
outperformed the other models, achieving average BERT (Bidirectional Encoder
Representations from Transformers) Score values in precision, recall, and
F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative
benchmarking and qualitative assessments validate the system's ability to
produce coherent and relevant medical replies to informal input. This study
highlights the potential of generative artificial intelligence (AI) in
advancing HMS, offering a scalable and adaptable solution for global healthcare
challenges, especially in linguistically and culturally diverse environments.

</details>


### [103] [Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records](https://arxiv.org/abs/2509.10108)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Khaled Shaban*

Main category: cs.CL

TL;DR: 本文提出了一种可扩展的合成数据增强策略，使用ChatGPT-4o和Gemini 2.5 Pro生成8万条阿拉伯语医疗问答对，将训练语料扩展到10万条记录，显著提升了阿拉伯语医疗聊天机器人的性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语医疗聊天机器人的发展受到大规模高质量标注数据集稀缺的限制，现有模型的可扩展性和泛化能力有限。

Method: 使用ChatGPT-4o和Gemini 2.5 Pro生成合成数据，经过语义过滤和人工验证后整合到训练流程中，对包括Mistral-7B和AraGPT2在内的五个大语言模型进行微调。

Result: ChatGPT-4o生成的数据在所有模型中始终获得更高的F1分数和更少的幻觉现象，合成数据增强有效提升了模型性能。

Conclusion: 合成数据增强是提升低资源医疗NLP领域特定语言模型性能的可行解决方案，为构建更具包容性、可扩展性和准确性的阿拉伯语医疗聊天机器人系统铺平了道路。

Abstract: The development of medical chatbots in Arabic is significantly constrained by
the scarcity of large-scale, high-quality annotated datasets. While prior
efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from
social media to fine-tune large language models (LLMs), model scalability and
generalization remained limited. In this study, we propose a scalable synthetic
data augmentation strategy to expand the training corpus to 100,000 records.
Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated
80,000 contextually relevant and medically coherent synthetic question-answer
pairs grounded in the structure of the original dataset. These synthetic
samples were semantically filtered, manually validated, and integrated into the
training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,
and evaluated their performance using BERTScore metrics and expert-driven
qualitative assessments. To further analyze the effectiveness of synthetic
sources, we conducted an ablation study comparing ChatGPT-4o and
Gemini-generated data independently. The results showed that ChatGPT-4o data
consistently led to higher F1-scores and fewer hallucinations across all
models. Overall, our findings demonstrate the viability of synthetic
augmentation as a practical solution for enhancing domain-specific language
models in-low resource medical NLP, paving the way for more inclusive,
scalable, and accurate Arabic healthcare chatbot systems.

</details>


### [104] [Prominence-aware automatic speech recognition for conversational speech](https://arxiv.org/abs/2509.10116)
*Julian Linke,Barbara Schuppler*

Main category: cs.CL

TL;DR: 该论文研究了结合重音检测和语音识别的奥地利德语对话语音识别系统，通过微调wav2vec2模型开发重音检测器，并训练同时转录单词和重音水平的ASR系统。


<details>
  <summary>Details</summary>
Motivation: 研究如何将韵律重音信息整合到自动语音识别系统中，以提升对奥地利德语对话语音的理解和处理能力。

Method: 首先微调wav2vec2模型开发单词级重音检测器，然后用其自动标注大型语料库中的韵律重音，最后基于这些标注训练同时进行单词转录和重音级别识别的ASR系统。

Result: 集成重音信息后ASR性能与基线系统相当，在识别正确的语句中重音检测准确率达到85.53%。

Conclusion: 基于transformer的模型能有效编码韵律信息，为韵律增强的ASR系统提供了新方法，在语言研究和基于韵律的对话系统中有应用潜力。

Abstract: This paper investigates prominence-aware automatic speech recognition (ASR)
by combining prominence detection and speech recognition for conversational
Austrian German. First, prominence detectors were developed by fine-tuning
wav2vec2 models to classify word-level prominence. The detector was then used
to automatically annotate prosodic prominence in a large corpus. Based on those
annotations, we trained novel prominence-aware ASR systems that simultaneously
transcribe words and their prominence levels. The integration of prominence
information did not change performance compared to our baseline ASR system,
while reaching a prominence detection accuracy of 85.53% for utterances where
the recognized word sequence was correct. This paper shows that
transformer-based models can effectively encode prosodic information and
represents a novel contribution to prosody-enhanced ASR, with potential
applications for linguistic research and prosody-informed dialogue systems.

</details>


### [105] [Population-Aligned Persona Generation for LLM-based Social Simulation](https://arxiv.org/abs/2509.10127)
*Zhengyu Hu,Zheyuan Xiao,Max Xiong,Yuxuan Lei,Tianfu Wang,Jianxun Lian,Kaize Ding,Ziang Xiao,Nicholas Jing Yuan,Xing Xie*

Main category: cs.CL

TL;DR: 提出一个系统框架，用于生成高质量、与人口分布对齐的LLM驱动社交模拟角色集，通过社交媒体数据生成、质量评估、重要性采样和心理测量分布对齐来减少偏差。


<details>
  <summary>Details</summary>
Motivation: 现有LLM社交模拟研究主要关注代理框架和模拟环境设计，忽视了角色生成的复杂性和非代表性角色集引入的潜在偏差，需要构建能真实反映现实人群多样性和分布的角色集。

Method: 利用LLM从长期社交媒体数据生成叙事角色，进行严格质量评估过滤低质量档案，应用重要性采样实现与参考心理测量分布（如大五人格特质）的全局对齐，并引入任务特定模块针对特定子人群进行适配。

Result: 广泛实验表明该方法显著减少了人口层面的偏差，能够为广泛的研究和政策应用实现准确、灵活的社交模拟。

Conclusion: 提出的系统框架能够生成高质量、人口对齐的角色集，有效解决LLM社交模拟中的偏差问题，为计算社会科学提供更真实的模拟基础。

Abstract: Recent advances in large language models (LLMs) have enabled human-like
social simulations at unprecedented scale and fidelity, offering new
opportunities for computational social science. A key challenge, however, is
the construction of persona sets that authentically represent the diversity and
distribution of real-world populations. Most existing LLM-based social
simulation studies focus primarily on designing agentic frameworks and
simulation environments, often overlooking the complexities of persona
generation and the potential biases introduced by unrepresentative persona
sets. In this paper, we propose a systematic framework for synthesizing
high-quality, population-aligned persona sets for LLM-driven social simulation.
Our approach begins by leveraging LLMs to generate narrative personas from
long-term social media data, followed by rigorous quality assessment to filter
out low-fidelity profiles. We then apply importance sampling to achieve global
alignment with reference psychometric distributions, such as the Big Five
personality traits. To address the needs of specific simulation contexts, we
further introduce a task-specific module that adapts the globally aligned
persona set to targeted subpopulations. Extensive experiments demonstrate that
our method significantly reduces population-level bias and enables accurate,
flexible social simulation for a wide range of research and policy
applications.

</details>


### [106] [Towards Reliable and Interpretable Document Question Answering via VLMs](https://arxiv.org/abs/2509.10129)
*Alessio Chen,Simone Giovannini,Andrea Gemelli,Fabio Coppini,Simone Marinai*

Main category: cs.CL

TL;DR: DocExplainerV0是一个即插即用的边界框预测模块，将答案生成与空间定位解耦，解决了现有视觉语言模型在文档理解中答案定位不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在文档理解方面表现出色，但准确地在文档中定位答案仍然是一个主要挑战，这限制了模型的可解释性和实际应用。

Method: 引入DocExplainerV0模块，该模块与现有VLM解耦，专门负责边界框预测，可应用于包括专有系统在内的各种VLM，无需微调。

Result: 系统评估显示文本准确性与空间定位之间存在显著差距，正确答案往往缺乏可靠的空间定位。该框架为未来研究建立了基准。

Conclusion: DocExplainerV0为解决VLM在文档信息提取中的空间定位问题提供了有效方案，推动了更可解释和鲁棒的文档理解模型的发展。

Abstract: Vision-Language Models (VLMs) have shown strong capabilities in document
understanding, particularly in identifying and extracting textual information
from complex documents. Despite this, accurately localizing answers within
documents remains a major challenge, limiting both interpretability and
real-world applicability. To address this, we introduce
\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that
decouples answer generation from spatial localization. This design makes it
applicable to existing VLMs, including proprietary systems where fine-tuning is
not feasible. Through systematic evaluation, we provide quantitative insights
into the gap between textual accuracy and spatial grounding, showing that
correct answers often lack reliable localization. Our standardized framework
highlights these shortcomings and establishes a benchmark for future research
toward more interpretable and robust document information extraction VLMs.

</details>


### [107] [Benchmark of stylistic variation in LLM-generated texts](https://arxiv.org/abs/2509.10179)
*Jiří Milička,Anna Marklová,Václav Cvrček*

Main category: cs.CL

TL;DR: 本研究使用Biber的多维分析法比较人类写作与大型语言模型生成文本的语域差异，创建了AI-Brown和AI-Koditex语料库进行英语和捷克语分析，并建立了可解释的模型评估基准。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型生成文本与人类写作在语域特征上的系统性差异，特别是在英语和资源较少的捷克语中的表现，为模型评估提供新的维度。

Method: 采用Biber多维分析法，使用AI-Brown语料库（对应BE-21布朗家族语料库）和AI-Koditex捷克语料库，分析16个前沿LLM在不同设置和提示下的文本生成特征。

Result: 研究发现LLM与人类写作在多个维度上存在显著系统性差异，特别是基础模型与指令调优模型之间的区别明显，为模型比较提供了可解释的评估标准。

Conclusion: 该研究建立了基于语域分析的LLM评估基准，能够系统性地比较不同模型的表现并对其进行排名，为理解AI文本生成特征提供了重要工具。

Abstract: This study investigates the register variation in texts written by humans and
comparable texts produced by large language models (LLMs). Biber's
multidimensional analysis (MDA) is applied to a sample of human-written texts
and AI-created texts generated to be their counterparts to find the dimensions
of variation in which LLMs differ most significantly and most systematically
from humans. As textual material, a new LLM-generated corpus AI-Brown is used,
which is comparable to BE-21 (a Brown family corpus representing contemporary
British English). Since all languages except English are underrepresented in
the training data of frontier LLMs, similar analysis is replicated on Czech
using AI-Koditex corpus and Czech multidimensional model. Examined were 16
frontier models in various settings and prompts, with emphasis placed on the
difference between base models and instruction-tuned models. Based on this, a
benchmark is created through which models can be compared with each other and
ranked in interpretable dimensions.

</details>


### [108] [Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations](https://arxiv.org/abs/2509.10184)
*Leen Almajed,Abeer ALdayel*

Main category: cs.CL

TL;DR: 论文研究了情感支持对话中不协调的积极回应问题，发现在高风险情境下LLM更容易产生不切实际的乐观回应，开发了分类器来检测这种不协调的积极性，并提出了需要平衡积极情感与情感认同的协调支持方法。


<details>
  <summary>Details</summary>
Motivation: 研究情感支持对话中善意但可能适得其反的积极回应现象，特别是在高情感强度情境下，LLM生成的回应容易出现不协调的积极性问题，这可能导致回应显得轻描淡写或不切实际。

Method: 收集Reddit真实用户-助手对话数据，按情感强度分为轻度（关系紧张和一般建议）和重度（悲伤和焦虑对话）两类；使用大语言模型生成额外回应；微调LLM在不同情感反应数据集上；开发基于DeBERTa和MentalBERT的弱监督多标签分类器集成。

Result: 分析发现LLM在高风险情境下更容易通过轻描淡写和最小化语气表现出不切实际的积极性；开发的分类器在检测两种关切类型（轻度和重度）的不协调积极性方面表现改善。

Conclusion: 需要超越仅仅生成通用积极回应，研究协调支持措施来平衡积极情感与情感认同，这为在线支持性对话中使大语言模型与情感期望对齐提供了见解，为构建情境感知和信任保持的在线对话系统铺平了道路。

Abstract: In emotionally supportive conversations, well-intended positivity can
sometimes misfire, leading to responses that feel dismissive, minimizing, or
unrealistically optimistic. We examine this phenomenon of incongruent
positivity as miscalibrated expressions of positive support in both human and
LLM generated responses. To this end, we collected real user-assistant
dialogues from Reddit across a range of emotional intensities and generated
additional responses using large language models for the same context. We
categorize these conversations by intensity into two levels: Mild, which covers
relationship tension and general advice, and Severe, which covers grief and
anxiety conversations. This level of categorization enables a comparative
analysis of how supportive responses vary across lower and higher stakes
contexts. Our analysis reveals that LLMs are more prone to unrealistic
positivity through dismissive and minimizing tone, particularly in high-stakes
contexts. To further study the underlying dimensions of this phenomenon, we
finetune LLMs on datasets with strong and weak emotional reactions. Moreover,
we developed a weakly supervised multilabel classifier ensemble (DeBERTa and
MentalBERT) that shows improved detection of incongruent positivity types
across two sorts of concerns (Mild and Severe). Our findings shed light on the
need to move beyond merely generating generic positive responses and instead
study the congruent support measures to balance positive affect with emotional
acknowledgment. This approach offers insights into aligning large language
models with affective expectations in the online supportive dialogue, paving
the way toward context-aware and trust preserving online conversation systems.

</details>


### [109] [Beyond Token Limits: Assessing Language Model Performance on Long Text Classification](https://arxiv.org/abs/2509.10199)
*Miklós Sebők,Viktor Kovács,Martin Bánóczy,Daniel Møller Eriksen,Nathalie Neptune,Philippe Roussille*

Main category: cs.CL

TL;DR: 本文比较了多种语言模型在处理长文本分类任务（特别是法律文件）时的性能，发现专门为长文本设计的Longformer模型并无明显优势，开源模型表现优于GPT变体。


<details>
  <summary>Details</summary>
Motivation: 解决BERT等主流语言模型在处理长文本（如数百页的法律草案）时的输入长度限制问题，这些模型通常只能处理512个token，无法满足长文本分类需求。

Method: 使用XLM-RoBERTa、Longformer、GPT-3.5和GPT-4等模型，在5种语言上进行多类别分类实验，采用比较议程项目的21个政策主题标签代码本。

Result: Longformer模型在处理长文本方面没有显示出特别优势；开源模型的表现优于GPT变体；类别级别的分析显示特定类别之间的支持度和内容重叠对长文本性能有重要影响。

Conclusion: 专门为长文本预训练的模型不一定优于通用模型，开源模型在处理长文本分类任务时具有竞争力，类别间的语义重叠是影响长文本分类性能的关键因素。

Abstract: The most widely used large language models in the social sciences (such as
BERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text
length that they can process to produce predictions. This is a particularly
pressing issue for some classification tasks, where the aim is to handle long
input texts. One such area deals with laws and draft laws (bills), which can
have a length of multiple hundred pages and, therefore, are not particularly
amenable for processing with models that can only handle e.g. 512 tokens. In
this paper, we show results from experiments covering 5 languages with
XLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass
classification task of the Comparative Agendas Project, which has a codebook of
21 policy topic labels from education to health care. Results show no
particular advantage for the Longformer model, pre-trained specifically for the
purposes of handling long inputs. The comparison between the GPT variants and
the best-performing open model yielded an edge for the latter. An analysis of
class-level factors points to the importance of support and substance overlaps
between specific categories when it comes to performance on long text inputs.

</details>


### [110] [SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning](https://arxiv.org/abs/2509.10208)
*Shengqiang Fu*

Main category: cs.CL

TL;DR: 提出Self Improving Faithfulness Aware Contrastive Tuning框架，通过自指导机制自动生成对比学习数据，提升LLM在知识冲突任务中的忠实性


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在知识密集型任务中因知识冲突而生成不忠实响应的问题，即模型倾向于依赖内部参数知识而非提供的上下文

Method: 使用自指导机制让基础LLM自动生成高质量的对比学习数据（锚样本、语义等价正样本、模拟不忠实场景的负样本），然后应用对比学习训练模型

Result: 在ECARE KRE和COSE KRE基准测试中，基于Llama3 8B Instruct的SI FACT模型比最佳基线方法提升上下文召回率6.2%，显著减少对内部记忆的依赖

Conclusion: SI FACT在增强LLM上下文忠实性方面具有强有效性和高数据效率，为构建更主动和可信的语言模型提供了实用途径

Abstract: Large Language Models often generate unfaithful responses in knowledge
intensive tasks due to knowledge conflict,that is,a preference for relying on
internal parametric knowledge rather than the provided context.To address this
issue,we propose a novel self improving framework,Self Improving Faithfulness
Aware Contrastive Tuning.The framework uses a self instruct mechanism that
allows the base LLM to automatically generate high quality,structured
contrastive learning data,including anchor samples,semantically equivalent
positive samples,and negative samples simulating unfaithful scenarios.This
approach significantly reduces the cost of manual
annotation.Subsequently,contrastive learning is applied to train the
model,enabling it to pull faithful responses closer and push unfaithful
responses farther apart in the representation space.Experiments on knowledge
conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT
model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%
over the best baseline method,while significantly reducing dependence on
internal memory.The results indicate that SI FACT provides strong effectiveness
and high data efficiency in enhancing the contextual faithfulness of
LLMs,offering a practical pathway toward building more proactive and
trustworthy language models.

</details>


### [111] [Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs](https://arxiv.org/abs/2509.10377)
*Yixiao Zhou,Ziyu Zhao,Dongzhou Cheng,zhiliang wu,Jie Gui,Yi Yang,Fei Wu,Yu Cheng,Hehe Fan*

Main category: cs.CL

TL;DR: DERN是一种无需重新训练的任务无关框架，通过专家剪枝和神经元重组来减少稀疏专家混合模型的内存使用，在保持性能的同时显著降低部署成本。


<details>
  <summary>Details</summary>
Motivation: 稀疏专家混合模型(SMoE)虽然计算高效，但仍需要加载所有专家参数，导致内存使用高且部署困难。现有方法主要关注专家级操作，忽视了神经元级结构的优化潜力。

Method: DERN采用三步框架：1)基于路由器统计剪枝冗余专家；2)将专家分解为神经元级片段并分配到最兼容的保留专家；3)在保留专家内合并片段构建紧凑表示。整个过程无需重新训练。

Result: 在Mixtral、Qwen和DeepSeek SMoE模型上的实验表明，DERN在50%专家稀疏度下，常识推理和MMLU基准性能提升超过5%，同时大幅减少专家数量和内存使用。

Conclusion: DERN通过神经元级重组有效解决了专家间语义冲突问题，提供了一种高效、无需重新训练的SMoE模型压缩方法，显著提升了实际部署的可行性。

Abstract: Sparse Mixture-of-Experts (SMoE) architectures are widely used in large
language models (LLMs) due to their computational efficiency. However, though
only a few experts are activated for each token, SMoE still requires loading
all expert parameters, leading to high memory usage and challenges in
deployment. Previous work has tried to reduce the overhead by pruning and
merging experts, but primarily focused on expert-level operations, leaving
neuron-level structure underexplored. We propose DERN (Dropping Experts,
Recombining Neurons), a task-agnostic and retraining-free framework for expert
pruning and reconstruction. We observe that experts are often misaligned and
contain semantic conflicts at the neuron level, which poses challenges for
direct merging. To solve this, DERN works in three steps: it first prunes
redundant experts using router statistics; then it decomposes them into
neuron-level expert segments, assigning each segment to its most compatible
retained expert; and finally, it merges segments within each retained expert to
build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE
models show that DERN improves performance by more than 5% on commonsense
reasoning and MMLU benchmarks under 50% expert sparsity, without extra
training. It also greatly reduces the number of experts and memory usage,
making SMoE LLMs easier to deploy in practice.

</details>


### [112] [Is In-Context Learning Learning?](https://arxiv.org/abs/2509.10414)
*Adrian de Wynter*

Main category: cs.CL

TL;DR: 本文通过大规模实证分析发现，上下文学习(ICL)确实构成学习机制，但其学习能力有限，对未见任务的泛化能力不足，且对提示格式和分布变化敏感。


<details>
  <summary>Details</summary>
Motivation: 研究上下文学习(ICL)是否真正构成学习机制，以及其在各种条件下的表现和局限性。

Method: 进行大规模ICL分析，通过消融实验排除记忆效应，考虑预训练、分布偏移、提示风格和措辞等因素的影响。

Result: ICL是一种有效的学习范式，但学习能力有限；当示例增多时，准确率对示例分布、模型和提示风格不敏感；ICL主要从提示中的规律性推断模式，导致分布敏感性。

Conclusion: 自回归模型的临时编码机制不够鲁棒，表明其通用泛化能力有限。

Abstract: In-context learning (ICL) allows some autoregressive models to solve tasks
via next-token prediction and without needing further training. This has led to
claims about these model's ability to solve (learn) unseen tasks with only a
few shots (exemplars) in the prompt. However, deduction does not always imply
learning, as ICL does not explicitly encode a given observation. Instead, the
models rely on their prior knowledge and the exemplars given, if any. We argue
that, mathematically, ICL does constitute learning, but its full
characterisation requires empirical work. We then carry out a large-scale
analysis of ICL ablating out or accounting for memorisation, pretraining,
distributional shifts, and prompting style and phrasing. We find that ICL is an
effective learning paradigm, but limited in its ability to learn and generalise
to unseen tasks. We note that, in the limit where exemplars become more
numerous, accuracy is insensitive to exemplar distribution, model, prompt
style, and the input's linguistic features. Instead, it deduces patterns from
regularities in the prompt, which leads to distributional sensitivity,
especially in prompting styles such as chain-of-thought. Given the varied
accuracies on formally similar tasks, we conclude that autoregression's ad-hoc
encoding is not a robust mechanism, and suggests limited all-purpose
generalisability.

</details>


### [113] [Long Context Automated Essay Scoring with Language Models](https://arxiv.org/abs/2509.10417)
*Christopher Ormerod,Gitit Kehat*

Main category: cs.CL

TL;DR: 本研究评估了多种改进的Transformer架构模型（XLNet、Longformer、ModernBERT、Mamba、Llama）来解决传统模型在自动作文评分中因文本长度限制而需要截断输入的问题，使用Kaggle ASAP 2.0数据集进行验证。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型有固定的最大文本长度限制，而高年级学生的作文经常超过这个限制。在自动作文评分中截断输入文本会严重影响模型对评分标准中组织结构要素的完整评估能力，存在有效性担忧。

Method: 研究评估了多种改进架构的模型，包括微调版本的XLNet、Longformer、ModernBERT、Mamba和Llama模型，这些模型都对标准Transformer架构进行了修改以克服长度限制。使用Kaggle ASAP 2.0数据集进行实验验证。

Result: 通过使用能够处理更长文本的改进模型，避免了输入截断问题，使模型能够完整捕获和评估作文的组织结构要素。

Conclusion: 采用经过架构改进的长文本处理模型可以有效解决自动作文评分中的文本长度限制问题，确保评分过程的完整性和有效性，为长文本自动评分提供了可行的技术方案。

Abstract: Transformer-based language models are architecturally constrained to process
text of a fixed maximum length. Essays written by higher-grade students
frequently exceed the maximum allowed length for many popular open-source
models. A common approach to addressing this issue when using these models for
Automated Essay Scoring is to truncate the input text. This raises serious
validity concerns as it undermines the model's ability to fully capture and
evaluate organizational elements of the scoring rubric, which requires long
contexts to assess. In this study, we evaluate several models that incorporate
architectural modifications of the standard transformer architecture to
overcome these length limitations using the Kaggle ASAP 2.0 dataset. The models
considered in this study include fine-tuned versions of XLNet, Longformer,
ModernBERT, Mamba, and Llama models.

</details>


### [114] [RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment](https://arxiv.org/abs/2509.10436)
*Shadikur Rahman,Aroosa Hameed,Gautam Srivastava,Syed Muhammad Danish*

Main category: cs.CL

TL;DR: 提出了一种云边协同的多智能体提示框架，包含GuideLLM、SolverLLM和JudgeLLM三个组件，并创建了RefactorCoderQA基准测试，在多个技术领域实现了76.84%的最优准确率。


<details>
  <summary>Details</summary>
Motivation: 为了优化大型语言模型的推理和问题解决能力，解决现有基准测试的局限性，需要更全面的多领域编码任务评估框架。

Method: 采用云边协同架构，包含三个专门组件：边缘部署的轻量级GuideLLM提供方法指导，云端SolverLLM生成代码解决方案，以及自动评估器JudgeLLM。使用RefactorCoderQA基准测试进行评估。

Result: 微调模型RefactorCoder-MoE实现了76.84%的整体准确率，显著优于领先的开源和商业基线模型。人类评估验证了生成解决方案的可解释性、准确性和实用性。

Conclusion: 提出的云边协同多智能体框架有效提升了LLM的编码能力，RefactorCoderQA基准测试为多领域编码任务提供了全面的评估标准，系统级指标分析揭示了架构的性能特征和权衡。

Abstract: To optimize the reasoning and problem-solving capabilities of Large Language
Models (LLMs), we propose a novel cloud-edge collaborative architecture that
enables a structured, multi-agent prompting framework. This framework comprises
three specialized components: GuideLLM, a lightweight model deployed at the
edge to provide methodological guidance; SolverLLM, a more powerful model
hosted in the cloud responsible for generating code solutions; and JudgeLLM, an
automated evaluator for assessing solution correctness and quality. To evaluate
and demonstrate the effectiveness of this architecture in realistic settings,
we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate
and enhance the performance of Large Language Models (LLMs) across multi-domain
coding tasks. Motivated by the limitations of existing benchmarks,
RefactorCoderQA systematically covers various technical domains, including
Software Engineering, Data Science, Machine Learning, and Natural Language
Processing, using authentic coding challenges from Stack Overflow. Extensive
experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves
state-of-the-art performance, significantly outperforming leading open-source
and commercial baselines with an overall accuracy of 76.84%. Human evaluations
further validate the interpretability, accuracy, and practical relevance of the
generated solutions. In addition, we evaluate system-level metrics, such as
throughput and latency, to gain deeper insights into the performance
characteristics and trade-offs of the proposed architecture.

</details>


### [115] [DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL](https://arxiv.org/abs/2509.10446)
*Rui Lu,Zhenyu Hou,Zihan Wang,Hanchen Zhang,Xiao Liu,Yujiang Li,Shi Feng,Jie Tang,Yuxiao Dong*

Main category: cs.CL

TL;DR: DeepDive是一个通过自动合成复杂问题和多轮强化学习来增强大语言模型深度搜索能力的系统，在BrowseComp基准测试中取得了开源竞争性结果。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在浏览工具辅助下进行深度搜索时表现不佳，主要受限于长时程推理能力和缺乏足够难度的监督数据。

Method: 1) 从开放知识图谱自动合成复杂难找的问题；2) 应用端到端多轮强化学习来增强LLMs的长时程深度搜索推理能力。

Result: DeepDive-32B在BrowseComp基准测试中超越了WebSailor、DeepSeek-R1-Browse和Search-o1等竞争对手，多轮RL训练显著提升了深度搜索能力。

Conclusion: DeepDive通过自动数据合成和多轮强化学习的结合，有效提升了开源大语言模型的深度搜索性能，支持测试时的工具调用扩展和并行采样。

Abstract: Augmenting large language models (LLMs) with browsing tools substantially
improves their potential as deep search agents to solve complex, real-world
tasks. Yet, open LLMs still perform poorly in such settings due to limited
long-horizon reasoning capacity with browsing tools and the lack of
sufficiently difficult supervised data. To address these challenges, we present
DeepDive to advance deep search agents. First, we propose a strategy to
automatically synthesize complex, difficult, and hard-to-find questions from
open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement
learning (RL) to enhance LLMs' long-horizon reasoning with deep search.
Experiments show that DeepDive-32B achieves a new open-source competitive
result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and
Search-o1. We demonstrate that multi-turn RL training improves deep search
ability and significantly contributes to the performance improvements across
multiple benchmarks. We observe that DeepDive enables test-time scaling of tool
calls and parallel sampling. All datasets, models, and code are publicly
available at https://github.com/THUDM/DeepDive.

</details>


### [116] [WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers](https://arxiv.org/abs/2509.10452)
*Akshat Pandey,Karun Kumar,Raphael Tang*

Main category: cs.CL

TL;DR: WhisTLE是一种仅使用文本数据进行预训练ASR模型领域适应的深度监督方法，通过变分自编码器建模编码器输出，结合TTS技术，在推理时不增加额外计算成本，显著降低词错误率。


<details>
  <summary>Details</summary>
Motivation: 预训练ASR模型如Whisper在未见过的词汇和语言风格上表现不佳，但在实际应用中收集语音数据困难，需要仅使用文本数据进行领域适应。

Method: 提出WhisTLE方法：1）训练VAE从文本建模编码器输出；2）使用学习的文本到潜在编码器微调解码器；3）可选结合TTS适应；4）推理时恢复原始编码器。

Result: 在4个领域外数据集和4个ASR模型上，WhisTLE结合TTS相比仅使用TTS的适应方法相对降低WER 12.3%，在32个场景中的27个优于所有非WhisTLE基线方法。

Conclusion: WhisTLE提供了一种有效的文本only领域适应方案，在不增加推理成本的情况下显著提升ASR模型在未知领域的性能。

Abstract: Pretrained automatic speech recognition (ASR) models such as Whisper perform
well but still need domain adaptation to handle unseen vocabulary and parlance.
In many real-world settings, collecting speech data is impractical,
necessitating text-only adaptation. We propose WhisTLE, a deeply supervised,
text-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE
trains a variational autoencoder (VAE) to model encoder outputs from text and
fine-tunes the decoder using the learned text-to-latent encoder, optionally
combined with text-to-speech (TTS) adaptation. At inference, the original
encoder is restored, incurring no extra runtime cost. Across four out-of-domain
datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by
12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines
in 27 of 32 scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [117] [Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis](https://arxiv.org/abs/2509.09744)
*Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia*

Main category: cs.LG

TL;DR: SAM-BG是一个两阶段的自监督学习框架，通过结构语义保护来学习脑图表示，在精神病诊断中优于现有方法，特别是在小样本数据场景下。


<details>
  <summary>Details</summary>
Motivation: 标记脑网络数据的稀缺性限制了精神病诊断的准确性和可解释性，现有自监督学习方法的数据增强策略可能会破坏脑图的关键结构语义。

Method: 提出两阶段框架：预训练阶段在小标记子集上训练边缘掩码器捕捉关键结构语义；自监督学习阶段使用结构先验指导结构感知的数据增强过程。

Result: 在两个真实精神病数据集上的实验表明，SAM-BG优于最先进方法，特别是在小标记数据设置下，并能发现临床相关的连接模式增强可解释性。

Conclusion: SAM-BG通过结构语义保护成功解决了脑图表示学习中的关键挑战，为精神病诊断提供了更准确和可解释的解决方案。

Abstract: The limited availability of labeled brain network data makes it challenging
to achieve accurate and interpretable psychiatric diagnoses. While
self-supervised learning (SSL) offers a promising solution, existing methods
often rely on augmentation strategies that can disrupt crucial structural
semantics in brain graphs. To address this, we propose SAM-BG, a two-stage
framework for learning brain graph representations with structural semantic
preservation. In the pre-training stage, an edge masker is trained on a small
labeled subset to capture key structural semantics. In the SSL stage, the
extracted structural priors guide a structure-aware augmentation process,
enabling the model to learn more semantically meaningful and robust
representations. Experiments on two real-world psychiatric datasets demonstrate
that SAM-BG outperforms state-of-the-art methods, particularly in small-labeled
data settings, and uncovers clinically relevant connectivity patterns that
enhance interpretability. Our code is available at
https://github.com/mjliu99/SAM-BG.

</details>


### [118] [D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference](https://arxiv.org/abs/2509.09747)
*Leen Daher,Zhaobo Wang,Malcolm Mielle*

Main category: cs.LG

TL;DR: 提出D-CAT框架，通过解耦的跨注意力转移实现跨模态知识迁移，无需推理时配对传感器数据，在资源受限环境中提升单模态分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态迁移学习方法在训练和推理时都需要配对传感器数据，限制了在资源受限环境中的部署，因为完整传感器套件在经济和技术上不可行。

Method: D-CAT框架结合自注意力模块进行特征提取和新型跨注意力对齐损失，强制对齐不同传感器的特征空间，而不需要耦合两种模态的分类管道。

Result: 在三个多模态人类活动数据集上评估，在分布内场景中从高性能模态（如视频到IMU）迁移可获得10% F1分数提升；在分布外场景中，即使较弱的源模态也能改善目标性能。

Conclusion: D-CAT通过跨模态知识实现单传感器推理，减少了感知系统的硬件冗余，同时保持准确性，对成本敏感或自适应部署至关重要。

Abstract: Cross-modal transfer learning is used to improve multi-modal classification
models (e.g., for human activity recognition in human-robot collaboration).
However, existing methods require paired sensor data at both training and
inference, limiting deployment in resource-constrained environments where full
sensor suites are not economically and technically usable. To address this, we
propose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns
modality-specific representations without requiring joint sensor modality
during inference. Our approach combines a self-attention module for feature
extraction with a novel cross-attention alignment loss, which enforces the
alignment of sensors' feature spaces without requiring the coupling of the
classification pipelines of both modalities. We evaluate D-CAT on three
multi-modal human activity datasets (IMU, video, and audio) under both
in-distribution and out-of-distribution scenarios, comparing against uni-modal
models. Results show that in in-distribution scenarios, transferring from
high-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains
over uni-modal training. In out-of-distribution scenarios, even weaker source
modalities (e.g., IMU to video) improve target performance, as long as the
target model isn't overfitted on the training data. By enabling single-sensor
inference with cross-modal knowledge, D-CAT reduces hardware redundancy for
perception systems while maintaining accuracy, which is critical for
cost-sensitive or adaptive deployments (e.g., assistive robots in homes with
variable sensor availability). Code is available at
https://github.com/Schindler-EPFL-Lab/D-CAT.

</details>


### [119] [Meta-Learning Reinforcement Learning for Crypto-Return Prediction](https://arxiv.org/abs/2509.09751)
*Junqiao Wang,Zhaoyang Guan,Guanyu Liu,Tianze Xia,Xianzhi Li,Shuo Yin,Xinyuan Song,Chuhan Cheng,Tianyu Shi,Alex Lee*

Main category: cs.LG

TL;DR: Meta-RL-Crypto是一个基于Transformer的统一架构，结合元学习和强化学习，创建了一个完全自改进的加密货币交易代理，无需人工监督，在多种市场环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 加密货币回报预测极其困难，价格变动由快速变化的链上活动、新闻流和社交情绪驱动，且标记训练数据稀缺昂贵。需要一种能够自我改进的交易代理来处理这种复杂环境。

Method: 从指令调优的LLM开始，代理在闭环架构中迭代交替扮演三个角色（行动者、评判者和元评判者），利用多模态市场输入和内部偏好反馈，持续改进交易策略和评估标准。

Result: 在多样化市场环境下的实验表明，Meta-RL-Crypto在真实市场的技术指标上表现良好，并且优于其他基于LLM的基线方法。

Conclusion: 该研究提出了一种创新的自监督学习框架，成功地将元学习和强化学习结合，为加密货币交易创建了一个能够持续自我改进的智能代理系统。

Abstract: Predicting cryptocurrency returns is notoriously difficult: price movements
are driven by a fast-shifting blend of on-chain activity, news flow, and social
sentiment, while labeled training data are scarce and expensive. In this paper,
we present Meta-RL-Crypto, a unified transformer-based architecture that
unifies meta-learning and reinforcement learning (RL) to create a fully
self-improving trading agent. Starting from a vanilla instruction-tuned LLM,
the agent iteratively alternates between three roles-actor, judge, and
meta-judge-in a closed-loop architecture. This learning process requires no
additional human supervision. It can leverage multimodal market inputs and
internal preference feedback. The agent in the system continuously refines both
the trading policy and evaluation criteria. Experiments across diverse market
regimes demonstrate that Meta-RL-Crypto shows good performance on the technical
indicators of the real market and outperforming other LLM-based baselines.

</details>


### [120] [LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation](https://arxiv.org/abs/2509.09754)
*Yiqun Shen,Song Yuan,Zhengze Zhang,Xiaoliang Wang,Daxin Jiang,Nguyen Cam-Tu*

Main category: cs.LG

TL;DR: LAVa是一个统一的KV缓存压缩框架，通过最小化Transformer残差流中的信息损失来实现动态预算分配，无需训练或多策略组合，在多种基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的KV缓存压缩方法大多是启发式的，缺乏动态预算分配机制，无法根据任务需求灵活调整不同层和头的缓存预算。

Method: 通过分析层注意力输出损失，推导出新指标来比较不同头的缓存条目，实现层级的动态头预算分配；通过对比跨层信息，实现动态层预算分配。

Result: 在LongBench、Needle-In-A-Haystack、Ruler和InfiniteBench等基准测试中表现出优越性能，发现动态层预算对生成任务关键，动态头预算对抽取任务重要。

Conclusion: LAVa是首个统一的缓存淘汰和动态预算分配策略，无需训练，在各种任务类型中保持顶级性能，为KV缓存压缩提供了新的解决方案。

Abstract: KV Cache is commonly used to accelerate LLM inference with long contexts, yet
its high memory demand drives the need for cache compression. Existing
compression methods, however, are largely heuristic and lack dynamic budget
allocation. To address this limitation, we introduce a unified framework for
cache compression by minimizing information loss in Transformer residual
streams. Building on it, we analyze the layer attention output loss and derive
a new metric to compare cache entries across heads, enabling layer-wise
compression with dynamic head budgets. Additionally, by contrasting cross-layer
information, we also achieve dynamic layer budgets. LAVa is the first unified
strategy for cache eviction and dynamic budget allocation that, unlike prior
methods, does not rely on training or the combination of multiple strategies.
Experiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and
InfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a
new insight: dynamic layer budgets are crucial for generation tasks (e.g., code
completion), while dynamic head budgets play a key role in extraction tasks
(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently
maintains top performance across task types. Our code is available at
https://github.com/MGDDestiny/Lava.

</details>


### [121] [Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management](https://arxiv.org/abs/2509.09772)
*Sanjay Basu,Sadiq Y. Patel,Parth Sheth,Bhairavi Muralidharan,Namrata Elamaran,Aakriti Kinra,Rajaie Batniji*

Main category: cs.LG

TL;DR: 提出了HACO框架，将风险校准与偏好优化分离，为医疗补助人群的健康管理提供安全、公平且可审计的决策支持


<details>
  <summary>Details</summary>
Motivation: 医疗补助人群的健康管理项目需要协调纵向服务，必须确保安全、公平和可审计性，需要一种能够控制不良事件风险的方法

Method: 混合自适应符合离线强化学习框架：训练轻量级风险模型、推导符合阈值来屏蔽不安全行动、在安全子集上学习偏好策略

Result: 实现了强大的风险区分能力（AUC约0.81），校准阈值良好，保持高安全覆盖率，子组分析显示人口统计学特征之间存在系统性价值差异

Conclusion: 符合风险门控与离线强化学习相结合，能够为人口健康管理团队提供保守且可审计的决策支持

Abstract: Population health management programs for Medicaid populations coordinate
longitudinal outreach and services (e.g., benefits navigation, behavioral
health, social needs support, and clinical scheduling) and must be safe, fair,
and auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement
Learning (HACO) framework that separates risk calibration from preference
optimization to generate conservative action recommendations at scale. In our
setting, each step involves choosing among common coordination actions (e.g.,
which member to contact, by which modality, and whether to route to a
specialized service) while controlling the near-term risk of adverse
utilization events (e.g., unplanned emergency department visits or
hospitalizations). Using a de-identified operational dataset from Waymark
comprising 2.77 million sequential decisions across 168,126 patients, HACO (i)
trains a lightweight risk model for adverse events, (ii) derives a conformal
threshold to mask unsafe actions at a target risk level, and (iii) learns a
preference policy on the resulting safe subset. We evaluate policies with a
version-agnostic fitted Q evaluation (FQE) on stratified subsets and audit
subgroup performance across age, sex, and race. HACO achieves strong risk
discrimination (AUC ~0.81) with a calibrated threshold ( {\tau} ~0.038 at
{\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses
reveal systematic differences in estimated value across demographics,
underscoring the importance of fairness auditing. Our results show that
conformal risk gating integrates cleanly with offline RL to deliver
conservative, auditable decision support for population health management
teams.

</details>


### [122] [One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection](https://arxiv.org/abs/2509.09782)
*Roshini Pulishetty,Mani Kishan Ghantasala,Keerthy Kaushik Dasoju,Niti Mangwani,Vishal Garimella,Aditya Mate,Somya Chatterjee,Yue Kang,Ehi Nosakhare,Sadid Hasan,Soundar Srinivasan*

Main category: cs.LG

TL;DR: 提出基于单头交叉注意力机制的统一路由框架，动态选择最优LLM，在RouterBench基准上实现6.6%的质量提升和2.9%的性能提升


<details>
  <summary>Details</summary>
Motivation: 解决不同计算成本和性能的大型语言模型在现实应用中规模化、成本效益部署的挑战

Method: 使用单头交叉注意力机制联合建模查询和模型嵌入，通过指数奖励函数平衡性能与成本

Result: 在RouterBench基准测试中，平均质量提升6.6%，最大性能提升2.9%，架构轻量且跨域泛化效果好

Conclusion: 建立了一个新的成本感知LLM路由标准，实现了高效、稳定的模型选择框架

Abstract: The proliferation of large language models (LLMs) with varying computational
costs and performance profiles presents a critical challenge for scalable,
cost-effective deployment in real-world applications. We introduce a unified
routing framework that leverages a single-head cross-attention mechanism to
jointly model query and model embeddings, enabling dynamic selection of the
optimal LLM for each input query. Our approach is evaluated on RouterBench, a
large-scale, publicly available benchmark encompassing diverse LLM pools and
domains. By explicitly capturing fine-grained query-model interactions, our
router predicts both response quality and generation cost, achieving up to 6.6%
improvement in Average Improvement in Quality (AIQ) and 2.9% in maximum
performance over existing routers. To robustly balance performance and cost, we
propose an exponential reward function that enhances stability across user
preferences. The resulting architecture is lightweight, generalizes effectively
across domains, and demonstrates improved efficiency compared to prior methods,
establishing a new standard for cost-aware LLM routing.

</details>


### [123] [From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms](https://arxiv.org/abs/2509.09793)
*Vincent Herfeld,Baudouin Denis de Senneville,Arthur Leclaire,Nicolas Papadakis*

Main category: cs.LG

TL;DR: 分析梯度步长去噪器及其在即插即用算法中的应用，该去噪器被训练为显式函数梯度的精确算子，同时保持最先进的去噪能力


<details>
  <summary>Details</summary>
Motivation: 即插即用优化算法使用现成的去噪器替代图像先验的邻近算子或梯度下降算子，但通常这些图像先验是隐式的且无法表达

Method: 训练梯度步长去噪器，使其成为显式函数梯度的精确算子（梯度下降算子或邻近算子）

Result: 梯度步长去噪器能够在保持最先进去噪能力的同时，作为显式函数梯度的精确算子

Conclusion: 梯度步长去噪器为即插即用算法提供了显式的图像先验表达方式，同时保持了优秀的去噪性能

Abstract: In this paper we analyze the Gradient-Step Denoiser and its usage in
Plug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms
uses off the shelf denoisers to replace a proximity operator or a gradient
descent operator of an image prior. Usually this image prior is implicit and
cannot be expressed, but the Gradient-Step Denoiser is trained to be exactly
the gradient descent operator or the proximity operator of an explicit
functional while preserving state-of-the-art denoising capabilities.

</details>


### [124] [Distinguishing Startle from Surprise Events Based on Physiological Signals](https://arxiv.org/abs/2509.09799)
*Mansi Sharma,Alexandre Duchevet,Florian Daiber,Jean-Paul Imbert,Maurice Rekrut*

Main category: cs.LG

TL;DR: 本研究使用机器学习和多模态融合策略，基于生理信号区分惊吓和惊讶反应，在航空等高危环境中实现可靠的事件预测，最高准确率达85.7%。


<details>
  <summary>Details</summary>
Motivation: 意外事件会损害注意力并延迟决策，在航空等高危环境中造成严重安全风险。惊吓和惊讶反应以不同方式影响飞行员表现，但实践中难以区分。现有研究大多单独研究这些反应，缺乏对其综合效应或如何通过生理数据区分它们的关注。

Method: 使用机器学习和多模态融合策略，基于生理信号区分惊吓和惊讶事件。采用SVM和XGBoost等算法，结合Late Fusion多模态融合方法。

Result: 惊吓和惊讶事件可以可靠预测，SVM和Late Fusion组合达到最高平均准确率85.7%。在包含基线条件的扩展评估中，XGBoost和Late Fusion组合能区分惊吓、惊讶和基线状态，最高平均准确率达74.9%。

Conclusion: 通过生理信号和机器学习方法可以有效区分惊吓和惊讶反应，为高危环境中的安全风险评估提供了可靠的技术手段，多模态融合策略显示出良好的性能。

Abstract: Unexpected events can impair attention and delay decision-making, posing
serious safety risks in high-risk environments such as aviation. In particular,
reactions like startle and surprise can impact pilot performance in different
ways, yet are often hard to distinguish in practice. Existing research has
largely studied these reactions separately, with limited focus on their
combined effects or how to differentiate them using physiological data. In this
work, we address this gap by distinguishing between startle and surprise events
based on physiological signals using machine learning and multi-modal fusion
strategies. Our results demonstrate that these events can be reliably
predicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.
To further validate the robustness of our model, we extended the evaluation to
include a baseline condition, successfully differentiating between Startle,
Surprise, and Baseline states with a highest mean accuracy of 74.9% with
XGBoost and Late Fusion.

</details>


### [125] [Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning](https://arxiv.org/abs/2509.09838)
*Reza Asad,Reza Babanezhad,Sharan Vaswani*

Main category: cs.LG

TL;DR: 本文提出了一种解耦actor和critic熵的离散动作actor-critic框架，在Atari游戏中达到了与DQN相当的性能，且无需熵正则化或显式探索。


<details>
  <summary>Details</summary>
Motivation: 现有的离散动作强化学习方法中，基于价值的方法（如DQN）是主流，而基于策略的方法要么无法有效利用离策略数据（如PPO），要么在离散动作设置中表现不佳（如SAC）。DSAC性能差的主要原因是actor和critic熵的耦合。

Method: 提出了一个灵活的离策略actor-critic框架，解耦了actor和critic的熵组件，允许使用m步Bellman算子进行critic更新，并将标准策略优化方法与熵正则化相结合来实例化actor目标。

Result: 理论证明在表格设置中可以保证收敛到最优正则化价值函数。实证表明在标准Atari游戏中可以达到DQN的性能水平，且无需熵正则化或显式探索。

Conclusion: 通过解耦actor和critic的熵组件，离散动作actor-critic方法可以达到与价值方法相当的性能，为离散动作环境提供了有效的离策略学习方案。

Abstract: Value-based approaches such as DQN are the default methods for off-policy
reinforcement learning with discrete-action environments such as Atari. Common
policy-based methods are either on-policy and do not effectively learn from
off-policy data (e.g. PPO), or have poor empirical performance in the
discrete-action setting (e.g. SAC). Consequently, starting from discrete SAC
(DSAC), we revisit the design of actor-critic methods in this setting. First,
we determine that the coupling between the actor and critic entropy is the
primary reason behind the poor performance of DSAC. We demonstrate that by
merely decoupling these components, DSAC can have comparable performance as
DQN. Motivated by this insight, we introduce a flexible off-policy actor-critic
framework that subsumes DSAC as a special case. Our framework allows using an
m-step Bellman operator for the critic update, and enables combining standard
policy optimization methods with entropy regularization to instantiate the
resulting actor objective. Theoretically, we prove that the proposed methods
can guarantee convergence to the optimal regularized value function in the
tabular setting. Empirically, we demonstrate that these methods can approach
the performance of DQN on standard Atari games, and do so even without entropy
regularization or explicit exploration.

</details>


### [126] [HGEN: Heterogeneous Graph Ensemble Networks](https://arxiv.org/abs/2509.09843)
*Jiajun Shen,Yufei Jin,Yi He,Xingquan Zhu*

Main category: cs.LG

TL;DR: HGEN是首个用于异质图的集成学习框架，通过元路径和随机丢弃创建等位GNN，利用残差注意力机制和相关性正则化提升分类精度


<details>
  <summary>Details</summary>
Motivation: 异质图中节点类型、特征和局部拓扑的异质性给集成学习带来挑战，需要适应多样化的图学习器

Method: 使用元路径结合随机丢弃创建等位GNN，采用残差注意力机制校准不同元路径的GNN，并通过相关性正则化项增大嵌入矩阵差异

Result: 在五个异质网络上的实验验证HGEN始终大幅优于最先进的竞争对手

Conclusion: HGEN通过有效的集成学习框架成功解决了异质图学习中的挑战，显著提升了分类性能

Abstract: This paper presents HGEN that pioneers ensemble learning for heterogeneous
graphs. We argue that the heterogeneity in node types, nodal features, and
local neighborhood topology poses significant challenges for ensemble learning,
particularly in accommodating diverse graph learners. Our HGEN framework
ensembles multiple learners through a meta-path and transformation-based
optimization pipeline to uplift classification accuracy. Specifically, HGEN
uses meta-path combined with random dropping to create Allele Graph Neural
Networks (GNNs), whereby the base graph learners are trained and aligned for
later ensembling. To ensure effective ensemble learning, HGEN presents two key
components: 1) a residual-attention mechanism to calibrate allele GNNs of
different meta-paths, thereby enforcing node embeddings to focus on more
informative graphs to improve base learner accuracy, and 2) a
correlation-regularization term to enlarge the disparity among embedding
matrices generated from different meta-paths, thereby enriching base learner
diversity. We analyze the convergence of HGEN and attest its higher
regularization magnitude over simple voting. Experiments on five heterogeneous
networks validate that HGEN consistently outperforms its state-of-the-art
competitors by substantial margin.

</details>


### [127] [Latency and Token-Aware Test-Time Compute](https://arxiv.org/abs/2509.09864)
*Jenny Y. Huang,Mehul Damani,Yousef El-Kurdi,Ramon Astudillo,Wei Sun*

Main category: cs.LG

TL;DR: 本文提出了一个推理时计算动态分配框架，同时考虑token成本和延迟时间，在推理基准测试中优于静态策略。


<details>
  <summary>Details</summary>
Motivation: 现有的推理时扩展方法主要关注并行生成方法（如best-of-N），忽略了增量解码方法（如beam search），并且主要关注token使用而忽略了延迟时间，这对于用户体验和智能体工作流至关重要。

Method: 将推理时扩展制定为动态计算分配和方法选择问题，系统需要基于每个查询决定应用哪种策略以及分配多少计算资源，明确纳入token成本和时钟延迟两个因素。

Result: 在推理基准测试中，该方法持续优于静态策略，实现了有利的准确率-成本权衡，同时保持实际部署的可行性。

Conclusion: 提出的动态计算分配框架能够有效平衡模型性能和推理效率，特别适用于需要高效处理多个查询的智能体工作流场景。

Abstract: Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.

</details>


### [128] [SciML Agents: Write the Solver, Not the Solution](https://arxiv.org/abs/2509.09936)
*Saarth Gaonkar,Xiang Zheng,Haocheng Xi,Rishabh Tiwari,Kurt Keutzer,Dmitriy Morozov,Michael W. Mahoney,Amir Gholami*

Main category: cs.LG

TL;DR: 本文探索使用LLMs生成科学计算代码的新方法，通过将自然语言ODE描述转换为可执行代码，并自动选择合适的数值求解器和稳定性检查，替代传统的科学机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 传统的科学机器学习方法（如物理信息神经网络、神经ODE等）在准确性和鲁棒性方面面临挑战，本文旨在探索LLMs作为科学计算代理的潜力，利用成熟的数值算法库来解决科学问题。

Method: 引入两个新数据集：诊断性误导问题和1000个多样化ODE任务的大规模基准测试。评估开源和闭源LLM模型在无引导vs领域知识引导提示、现成vs微调变体等方面的表现，测量代码可执行性和数值有效性。

Result: 研究发现，在提供足够上下文和引导提示的情况下，较新的指令跟随模型在两个评估标准上都达到高准确率。开源系统无需微调即可表现良好，而较老或较小的模型仍能从微调中受益。

Conclusion: 精心设计的提示和微调可以产生能够可靠解决简单ODE问题的专用LLM代理，为科学计算任务提供了新的解决方案路径。

Abstract: Recent work in scientific machine learning aims to tackle scientific tasks
directly by predicting target values with neural networks (e.g.,
physics-informed neural networks, neural ODEs, neural operators, etc.), but
attaining high accuracy and robustness has been challenging. We explore an
alternative view: use LLMs to write code that leverages decades of numerical
algorithms. This shifts the burden from learning a solution function to making
domain-aware numerical choices. We ask whether LLMs can act as SciML agents
that, given a natural-language ODE description, generate runnable code that is
scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),
and enforcing stability checks. There is currently no benchmark to measure this
kind of capability for scientific computing tasks. As such, we first introduce
two new datasets: a diagnostic dataset of adversarial "misleading" problems;
and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set
contains problems whose superficial appearance suggests stiffness, and that
require algebraic simplification to demonstrate non-stiffness; and the
large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-
and closed-source LLM models along two axes: (i) unguided versus guided
prompting with domain-specific knowledge; and (ii) off-the-shelf versus
fine-tuned variants. Our evaluation measures both executability and numerical
validity against reference solutions. We find that with sufficient context and
guided prompts, newer instruction-following models achieve high accuracy on
both criteria. In many cases, recent open-source systems perform strongly
without fine-tuning, while older or smaller models still benefit from
fine-tuning. Overall, our preliminary results indicate that careful prompting
and fine-tuning can yield a specialized LLM agent capable of reliably solving
simple ODE problems.

</details>


### [129] [Variational Neural Networks for Observable Thermodynamics (V-NOTS)](https://arxiv.org/abs/2509.09899)
*Christopher Eldred,François Gay-Balmaz,Vakhtang Putkaradze*

Main category: cs.LG

TL;DR: 提出了一种基于可观测变量的数据驱动计算方法，通过热力学拉格朗日量和神经网络来预测耗散动力系统的演化，确保熵不减性质。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要相空间变量数据，但实际中动量、熵等变量往往无法直接观测，需要开发仅基于可观测变量的计算方法。

Method: 构建热力学拉格朗日量框架，设计神经网络结构来保持热力学约束，确保熵不减演化，仅使用有限数据点和少量参数。

Result: 该方法能够有效描述相空间演化，基于有限数据点和相对较少的系统参数实现准确预测。

Conclusion: 所提出的基于可观测变量的热力学拉格朗日神经网络框架为耗散动力系统的数据驱动计算提供了有效解决方案，克服了传统方法对不可观测变量的依赖。

Abstract: Much attention has recently been devoted to data-based computing of evolution
of physical systems. In such approaches, information about data points from
past trajectories in phase space is used to reconstruct the equations of motion
and to predict future solutions that have not been observed before. However, in
many cases, the available data does not correspond to the variables that define
the system's phase space. We focus our attention on the important example of
dissipative dynamical systems. In that case, the phase space consists of
coordinates, momenta and entropies; however, the momenta and entropies cannot,
in general, be observed directly. To address this difficulty, we develop an
efficient data-based computing framework based exclusively on observable
variables, by constructing a novel approach based on the \emph{thermodynamic
Lagrangian}, and constructing neural networks that respect the thermodynamics
and guarantees the non-decreasing entropy evolution. We show that our network
can provide an efficient description of phase space evolution based on a
limited number of data points and a relatively small number of parameters in
the system.

</details>


### [130] [Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss](https://arxiv.org/abs/2509.10011)
*Antoine Orioua,Philipp Krah,Julian Koellermeier*

Main category: cs.LG

TL;DR: IDEA是一种能够估计数据集内在维度的自编码器，既能识别线性/非线性流形的内在维度，又能重建原始数据集，通过投影重建损失项指导训练。


<details>
  <summary>Details</summary>
Motivation: 现有方法在估计数据集内在维度时往往无法同时保持重建能力，需要一种既能准确估计内在维度又能有效重建原始数据的统一框架。

Method: 使用重新加权的双CancelOut层构建潜在空间，引入投影重建损失项，通过连续评估去除额外潜在维度后的重建质量来指导模型训练。

Result: 在理论基准测试中表现出良好的准确性和高通用性，在垂直解析的一维自由表面流数值解数据上成功估计内在维度并重建原始解。

Conclusion: IDEA提供了一个统一的框架，既能准确估计各种数据集的内在维度，又能保持高质量的数据重建能力，在理论和实际应用中都表现出色。

Abstract: This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),
which identifies the underlying intrinsic dimension of a wide range of datasets
whose samples lie on either linear or nonlinear manifolds. Beyond estimating
the intrinsic dimension, IDEA is also able to reconstruct the original dataset
after projecting it onto the corresponding latent space, which is structured
using re-weighted double CancelOut layers. Our key contribution is the
introduction of the projected reconstruction loss term, guiding the training of
the model by continuously assessing the reconstruction quality under the
removal of an additional latent dimension. We first assess the performance of
IDEA on a series of theoretical benchmarks to validate its robustness. These
experiments allow us to test its reconstruction ability and compare its
performance with state-of-the-art intrinsic dimension estimators. The
benchmarks show good accuracy and high versatility of our approach.
Subsequently, we apply our model to data generated from the numerical solution
of a vertically resolved one-dimensional free-surface flow, following a
pointwise discretization of the vertical velocity profile in the horizontal
direction, vertical direction, and time. IDEA succeeds in estimating the
dataset's intrinsic dimension and then reconstructs the original solution by
working directly within the projection space identified by the network.

</details>


### [131] [LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios](https://arxiv.org/abs/2509.09926)
*Jiahao Chen,Zhiyuan Huang,Yurou Liu,Bing Su*

Main category: cs.LG

TL;DR: 提出了LoFT框架，通过参数高效微调基础模型来解决长尾半监督学习问题，并在开放世界场景下扩展为LoFT-OW，显著提升了性能


<details>
  <summary>Details</summary>
Motivation: 现有的长尾半监督学习方法大多从零开始训练模型，存在过自信和伪标签质量低的问题，需要探索基础模型微调范式来解决这些挑战

Method: 提出LoFT框架，通过参数高效微调预训练基础模型来生成更可靠的伪标签，并针对开放世界场景提出LoFT-OW来提升判别能力

Result: 在多个基准测试中取得了优于先前方法的性能，即使仅使用1%的未标注数据也能获得良好效果

Conclusion: 基础模型微调范式能够有效提升长尾半监督学习的性能，特别是在开放世界场景下具有重要应用价值

Abstract: Long-tailed learning has garnered increasing attention due to its wide
applicability in real-world scenarios. Among existing approaches, Long-Tailed
Semi-Supervised Learning (LTSSL) has emerged as an effective solution by
incorporating a large amount of unlabeled data into the imbalanced labeled
dataset. However, most prior LTSSL methods are designed to train models from
scratch, which often leads to issues such as overconfidence and low-quality
pseudo-labels. To address these challenges, we extend LTSSL into the foundation
model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed
semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate
that fine-tuned foundation models can generate more reliable pseudolabels,
thereby benefiting imbalanced learning. Furthermore, we explore a more
practical setting by investigating semi-supervised learning under open-world
conditions, where the unlabeled data may include out-of-distribution (OOD)
samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World
scenarios) to improve the discriminative ability. Experimental results on
multiple benchmarks demonstrate that our method achieves superior performance
compared to previous approaches, even when utilizing only 1\% of the unlabeled
data compared with previous works.

</details>


### [132] [Physics-informed sensor coverage through structure preserving machine learning](https://arxiv.org/abs/2509.10363)
*Benjamin David Shaffer,Brooks Kinch,Joseph Klobusicky,M. Ani Hsieh,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种基于结构保持数字孪生的自适应源定位机器学习框架，结合条件神经Whitney形式和Transformer算子学习，实现实时轨迹规划和数据同化


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂流体输运系统中源定位问题，需要开发能够保持物理约束、适应实时传感器数据并保证数值稳定性的自适应方法

Method: 使用条件神经Whitney形式(CNWF)构建数字孪生，耦合有限元外微积分(FEEC)的数值保证和基于Transformer的算子学习，采用交错方案结合Lloyd算法进行传感器布局优化

Result: 在复杂几何形状中相比物理不可知的Transformer架构提高了精度，实现了点源的恢复，证明了正则性作为定位的充分条件

Conclusion: 结构保持为源识别提供了有效的归纳偏置，物理约束的强制执行在复杂几何中显著提升了准确性

Abstract: We present a machine learning framework for adaptive source localization in
which agents use a structure-preserving digital twin of a coupled
hydrodynamic-transport system for real-time trajectory planning and data
assimilation. The twin is constructed with conditional neural Whitney forms
(CNWF), coupling the numerical guarantees of finite element exterior calculus
(FEEC) with transformer-based operator learning. The resulting model preserves
discrete conservation, and adapts in real time to streaming sensor data. It
employs a conditional attention mechanism to identify: a reduced Whitney-form
basis; reduced integral balance equations; and a source field, each compatible
with given sensor measurements. The induced reduced-order environmental model
retains the stability and consistency of standard finite-element simulation,
yielding a physically realizable, regular mapping from sensor data to the
source field. We propose a staggered scheme that alternates between evaluating
the digital twin and applying Lloyd's algorithm to guide sensor placement, with
analysis providing conditions for monotone improvement of a coverage
functional. Using the predicted source field as an importance function within
an optimal-recovery scheme, we demonstrate recovery of point sources under
continuity assumptions, highlighting the role of regularity as a sufficient
condition for localization. Experimental comparisons with physics-agnostic
transformer architectures show improved accuracy in complex geometries when
physical constraints are enforced, indicating that structure preservation
provides an effective inductive bias for source identification.

</details>


### [133] [Multi-Play Combinatorial Semi-Bandit Problem](https://arxiv.org/abs/2509.09933)
*Shintaro Nakamura,Yuko Kuroki,Wei Chen*

Main category: cs.LG

TL;DR: 提出了多臂组合半赌博机(MP-CSB)模型，扩展了传统组合半赌博机以支持非负整数动作空间，并开发了两种算法：基于Thompson采样的算法和最佳两界算法，在随机和对抗环境中都取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 传统组合半赌博机(CSB)仅限于二元决策空间，无法处理包含非负整数流或分配的重要应用场景，如最优传输和背包问题，因此需要扩展模型来克服这一限制。

Method: 提出了MP-CSB模型，允许选择非负整数动作并从单个臂观察多个反馈。开发了两种算法：1)基于Thompson采样的算法，计算可行且达到O(log T)遗憾；2)最佳两界算法，在随机环境中实现方差依赖遗憾，在对抗环境中实现数据依赖遗憾。

Result: Thompson采样算法在随机环境中达到O(log T)分布依赖遗憾，最佳两界算法在随机环境中实现O(log T)方差依赖遗憾，在对抗环境中实现Õ(√T)最坏情况遗憾，且对抗环境中的遗憾是数据依赖的。数值实验显示所提算法优于现有CSB方法。

Conclusion: MP-CSB成功扩展了组合半赌博机框架，提出的两种算法在理论和实验上都表现出色，为处理非负整数动作空间的组合优化问题提供了有效解决方案。

Abstract: In the combinatorial semi-bandit (CSB) problem, a player selects an action
from a combinatorial action set and observes feedback from the base arms
included in the action. While CSB is widely applicable to combinatorial
optimization problems, its restriction to binary decision spaces excludes
important cases involving non-negative integer flows or allocations, such as
the optimal transport and knapsack problems.To overcome this limitation, we
propose the multi-play combinatorial semi-bandit (MP-CSB), where a player can
select a non-negative integer action and observe multiple feedbacks from a
single arm in each round. We propose two algorithms for the MP-CSB. One is a
Thompson-sampling-based algorithm that is computationally feasible even when
the action space is exponentially large with respect to the number of arms, and
attains $O(\log T)$ distribution-dependent regret in the stochastic regime,
where $T$ is the time horizon. The other is a best-of-both-worlds algorithm,
which achieves $O(\log T)$ variance-dependent regret in the stochastic regime
and the worst-case $\tilde{\mathcal{O}}\left( \sqrt{T} \right)$ regret in the
adversarial regime. Moreover, its regret in adversarial one is data-dependent,
adapting to the cumulative loss of the optimal action, the total quadratic
variation, and the path-length of the loss sequence. Finally, we numerically
show that the proposed algorithms outperform existing methods in the CSB
literature.

</details>


### [134] [DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition](https://arxiv.org/abs/2509.09940)
*Yifei Wang,Wenbin Wang,Yong Luo*

Main category: cs.LG

TL;DR: DyKen-Hyena模型通过将音频-视觉线索转换为动态的逐标记卷积核来直接调制文本特征提取，解决了多模态意图识别中模态间信息冲突和噪声问题，在MIntRec基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 多模态意图识别中，来自不同模态的意图无关和冲突信息可能会阻碍性能提升。现有模型通过多头注意力等机制融合模态特征，但这种方法可能会用噪声或无关的非语言信号污染主要语言特征，无法捕捉细粒度的标记级影响。

Method: 提出DyKen-Hyena模型，将问题从特征融合重新定义为处理调制。模型将音频-视觉线索转换为动态的逐标记卷积核，直接调制文本特征提取过程，实现细粒度的模态交互。

Result: 在MIntRec和MIntRec2.0基准测试中取得了最先进的结果，特别是在范围外检测方面获得了+10.46%的F1分数提升，验证了该方法能够创建更鲁棒的意图表示。

Conclusion: DyKen-Hyena通过将非语言线索作为处理调制器而非简单的特征增强器，实现了更有效的多模态意图识别，为处理模态间信息冲突提供了新的解决方案。

Abstract: Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich
information from multiple sources (e.g., language, video, and audio), the
potential for intent-irrelevant and conflicting information across modalities
may hinder performance from being further improved. Most current models attempt
to fuse modalities by applying mechanisms like multi-head attention to unimodal
feature sequences and then adding the result back to the original
representation. This process risks corrupting the primary linguistic features
with noisy or irrelevant non-verbal signals, as it often fails to capture the
fine-grained, token-level influence where non-verbal cues should modulate, not
just augment, textual meaning. To address this, we introduce DyKen-Hyena, which
reframes the problem from feature fusion to processing modulation. Our model
translates audio-visual cues into dynamic, per-token convolutional kernels that
directly modulate textual feature extraction. This fine-grained approach
achieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.
Notably, it yields a +10.46% F1-score improvement in out-of-scope detection,
validating that our method creates a fundamentally more robust intent
representation.

</details>


### [135] [Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge](https://arxiv.org/abs/2509.09955)
*Omar Erak,Omar Alhussein,Hatem Abou-Zeid,Mehdi Bennis,Sami Muhaidat*

Main category: cs.LG

TL;DR: 提出了一种无需训练的token合并框架，通过自适应合并语义冗余token来压缩transformer表示，在保持精度的同时显著降低计算和通信成本


<details>
  <summary>Details</summary>
Motivation: 大规模transformer在语义通信中计算和通信成本过高，难以部署在资源受限的边缘设备上

Method: 基于每层相似度阈值选择性合并语义冗余token，将合并策略发现建模为多目标优化问题，使用贝叶斯优化寻找帕累托最优解

Result: 在ImageNet分类中减少30% FLOPs和80%通信成本，在VQA任务中以不到1/3计算量和1/10带宽达到与完整模型相当的性能

Conclusion: 该框架为资源受限的边缘智能场景提供了实用且通用的transformer部署解决方案，同时具有隐私保护优势

Abstract: Large-scale transformers are central to modern semantic communication, yet
their high computational and communication costs hinder deployment on
resource-constrained edge devices. This paper introduces a training-free
framework for adaptive token merging, a novel mechanism that compresses
transformer representations at runtime by selectively merging semantically
redundant tokens under per-layer similarity thresholds. Unlike prior
fixed-ratio reduction, our approach couples merging directly to input
redundancy, enabling data-dependent adaptation that balances efficiency and
task relevance without retraining. We cast the discovery of merging strategies
as a multi-objective optimization problem and leverage Bayesian optimization to
obtain Pareto-optimal trade-offs between accuracy, inference cost, and
communication cost. On ImageNet classification, we match the accuracy of the
unmodified transformer with 30\% fewer floating-point operations per second and
under 20\% of the original communication cost, while for visual question
answering our method achieves performance competitive with the full LLaVA model
at less than one-third of the compute and one-tenth of the bandwidth. Finally,
we show that our adaptive merging is robust across varying channel conditions
and provides inherent privacy benefits, substantially degrading the efficacy of
model inversion attacks. Our framework provides a practical and versatile
solution for deploying powerful transformer models in resource-limited edge
intelligence scenarios.

</details>


### [136] [Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes](https://arxiv.org/abs/2509.09960)
*Mingxuan Jiang,Yongxin Wang,Ziyue Dai,Yicun Liu,Hongyi Nie,Sen Liu,Hongfeng Chai*

Main category: cs.LG

TL;DR: ReFine是一个合成表格数据生成框架，通过从可解释模型提取符号规则嵌入提示词来指导生成，并采用双重粒度过滤策略减少分布不平衡，在数据稀缺场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有表格生成方法（GANs、扩散模型、微调LLMs）需要充足参考数据，在领域特定数据库记录稀缺时效果有限。基于提示的LLMs虽然灵活但难以捕捉数据集特定的特征-标签依赖关系，且生成冗余数据导致下游任务性能下降。

Method: 提出ReFine框架：(i)从可解释模型推导符号"if-then"规则并嵌入提示词，显式指导生成符合领域特定特征分布；(ii)应用双重粒度过滤策略，抑制过采样模式并选择性精炼稀有但信息丰富的样本以减少分布不平衡。

Result: 在多个回归和分类基准测试上的广泛实验表明，ReFine始终优于最先进方法，回归任务中R平方绝对提升达0.44，分类任务中F1分数相对提升10.0%。

Conclusion: ReFine通过规则引导和双重过滤策略，有效解决了数据稀缺场景下的表格数据生成问题，显著提升了生成数据的质量和下游任务性能。

Abstract: Synthetic tabular data generation is increasingly essential in data
management, supporting downstream applications when real-world and high-quality
tabular data is insufficient. Existing tabular generation approaches, such as
generative adversarial networks (GANs), diffusion models, and fine-tuned Large
Language Models (LLMs), typically require sufficient reference data, limiting
their effectiveness in domain-specific databases with scarce records. While
prompt-based LLMs offer flexibility without parameter tuning, they often fail
to capture dataset-specific feature-label dependencies and generate redundant
data, leading to degradation in downstream task performance. To overcome these
issues, we propose ReFine, a framework that (i) derives symbolic "if-then"
rules from interpretable models and embeds them into prompts to explicitly
guide generation toward domain-specific feature distribution, and (ii) applies
a dual-granularity filtering strategy that suppresses over-sampling patterns
and selectively refines rare but informative samples to reduce distributional
imbalance. Extensive experiments on various regression and classification
benchmarks demonstrate that ReFine consistently outperforms state-of-the-art
methods, achieving up to 0.44 absolute improvement in R-squared for regression
and 10.0 percent relative improvement in F1 score for classification tasks.

</details>


### [137] [Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning](https://arxiv.org/abs/2509.09991)
*Amandip Sangha*

Main category: cs.LG

TL;DR: 提出一种基于机器学习的虚拟服务器能耗估计方法，无需物理功率测量接口，仅使用虚拟机资源利用率指标即可准确预测能耗


<details>
  <summary>Details</summary>
Motivation: 解决虚拟化环境（如云平台）中无法直接测量能耗的关键问题，实现无需特权主机访问的能耗估计

Method: 使用梯度提升回归器（Gradient Boosting Regressor），基于客户虚拟机收集的资源利用率指标来预测通过RAPL在主机上测量的能耗

Result: 在多样化工作负载实验中实现了高预测精度（R²在0.90到0.97之间），证明了仅使用客户端资源进行能耗估计的可行性

Conclusion: 该方法可为虚拟化环境中的能量感知调度、成本优化和物理主机独立的能耗估计提供支持

Abstract: This paper presents a machine learning-based approach to estimate the energy
consumption of virtual servers without access to physical power measurement
interfaces. Using resource utilization metrics collected from guest virtual
machines, we train a Gradient Boosting Regressor to predict energy consumption
measured via RAPL on the host. We demonstrate, for the first time, guest-only
resource-based energy estimation without privileged host access with
experiments across diverse workloads, achieving high predictive accuracy and
variance explained ($0.90 \leq R^2 \leq 0.97$), indicating the feasibility of
guest-side energy estimation. This approach can enable energy-aware scheduling,
cost optimization and physical host independent energy estimates in virtualized
environments. Our approach addresses a critical gap in virtualized environments
(e.g. cloud) where direct energy measurement is infeasible.

</details>


### [138] [Neural Scaling Laws for Deep Regression](https://arxiv.org/abs/2509.10000)
*Tilen Cadez,Kyoung-Min Kim*

Main category: cs.LG

TL;DR: 本文实证研究了深度回归模型中的神经缩放定律，发现在扭曲范德瓦尔斯磁体参数估计任务中，损失与训练数据集大小和模型容量之间存在幂律关系，缩放指数范围为1到2。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型成功证明了神经缩放定律的重要性，但这些定律在深度回归模型中的应用仍未被充分探索。研究旨在填补这一空白，为深度回归模型的资源管理和性能优化提供指导。

Method: 使用扭曲范德瓦尔斯磁体的参数估计模型，在不同架构（全连接网络、残差网络、视觉变换器）上实证研究损失与训练数据集大小和模型容量之间的幂律关系。

Result: 观察到在广泛数值范围内，损失与训练数据集大小和模型容量之间存在幂律关系，缩放指数范围为1到2，具体值取决于回归参数和模型细节。

Conclusion: 一致的缩放行为和大缩放指数表明，深度回归模型的性能可以随着数据量的增加而显著提升，这为模型开发和资源管理提供了重要指导。

Abstract: Neural scaling laws--power-law relationships between generalization errors
and characteristics of deep learning models--are vital tools for developing
reliable models while managing limited resources. Although the success of large
language models highlights the importance of these laws, their application to
deep regression models remains largely unexplored. Here, we empirically
investigate neural scaling laws in deep regression using a parameter estimation
model for twisted van der Waals magnets. We observe power-law relationships
between the loss and both training dataset size and model capacity across a
wide range of values, employing various architectures--including fully
connected networks, residual networks, and vision transformers. Furthermore,
the scaling exponents governing these relationships range from 1 to 2, with
specific values depending on the regressed parameters and model details. The
consistent scaling behaviors and their large scaling exponents suggest that the
performance of deep regression models can improve substantially with increasing
data size.

</details>


### [139] [Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts](https://arxiv.org/abs/2509.10025)
*Strahinja Nikolic,Ilker Oguz,Demetri Psaltis*

Main category: cs.LG

TL;DR: SMoE-VAE架构通过无监督专家路由在QuickDraw数据集上实现了比有监督基线更好的重建性能，专家学习到了超越人工类别边界的有意义子类别结构。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络内部组织是深度学习可解释性的基本挑战，探索稀疏混合专家变分自编码器架构来解决这一挑战。

Method: 在QuickDraw数据集上测试SMoE-VAE模型，比较无监督专家路由与基于真实标签的有监督基线，使用t-SNE可视化和重建分析研究MoE模型如何发现与模型目标更一致的基础数据结构。

Result: 无监督路由始终实现更优的重建性能，专家学习识别有意义子类别结构，这些结构经常超越人工定义的类别边界。数据集大小研究揭示了数据量与专家专业化之间的权衡关系。

Conclusion: SMoE-VAE能够发现比预定义标签更符合模型目标的基础数据结构，为设计高效MoE架构提供了指导。

Abstract: Understanding the internal organization of neural networks remains a
fundamental challenge in deep learning interpretability. We address this
challenge by exploring a novel Sparse Mixture of Experts Variational
Autoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw
dataset, comparing unsupervised expert routing against a supervised baseline
guided by ground-truth labels. Surprisingly, we find that unsupervised routing
consistently achieves superior reconstruction performance. The experts learn to
identify meaningful sub-categorical structures that often transcend
human-defined class boundaries. Through t-SNE visualizations and reconstruction
analysis, we investigate how MoE models uncover fundamental data structures
that are more aligned with the model's objective than predefined labels.
Furthermore, our study on the impact of dataset size provides insights into the
trade-offs between data quantity and expert specialization, offering guidance
for designing efficient MoE architectures.

</details>


### [140] [Sparse Coding Representation of 2-way Data](https://arxiv.org/abs/2509.10033)
*Boya Ma,Abram Magner,Maxwell McNeil,Petko Bogdanov*

Main category: cs.LG

TL;DR: 提出AODL方法，通过低秩编码模型解决多字典学习中的数据复杂度问题，在保持重建质量的同时获得高达90%更稀疏的解，并展示可解释性


<details>
  <summary>Details</summary>
Motivation: 解决多字典场景下同时学习字典和编码系数的挑战，特别是编码系数对应所有字典原子组合时的高复杂度问题

Method: 提出低秩编码模型，采用凸松弛解决方案AODL，通过稀疏编码矩阵和学习字典之间的交替优化实现收敛

Result: 在合成和真实数据集上，AODL在固定重建质量下比非低秩和固定字典基线学习到高达90%更稀疏的解，学习到的字典揭示了训练样本中的可解释模式

Conclusion: AODL方法有效解决了多字典学习的数据复杂度问题，提供了更稀疏、更准确且具有可解释性的解决方案

Abstract: Sparse dictionary coding represents signals as linear combinations of a few
dictionary atoms. It has been applied to images, time series, graph signals and
multi-way spatio-temporal data by jointly employing temporal and spatial
dictionaries. Data-agnostic analytical dictionaries, such as the discrete
Fourier transform, wavelets and graph Fourier, have seen wide adoption due to
efficient implementations and good practical performance. On the other hand,
dictionaries learned from data offer sparser and more accurate solutions but
require learning of both the dictionaries and the coding coefficients. This
becomes especially challenging for multi-dictionary scenarios since encoding
coefficients correspond to all atom combinations from the dictionaries. To
address this challenge, we propose a low-rank coding model for 2-dictionary
scenarios and study its data complexity. Namely, we establish a bound on the
number of samples needed to learn dictionaries that generalize to unseen
samples from the same distribution. We propose a convex relaxation solution,
called AODL, whose exact solution we show also solves the original problem. We
then solve this relaxation via alternating optimization between the sparse
coding matrices and the learned dictionaries, which we prove to be convergent.
We demonstrate its quality for data reconstruction and missing value imputation
in both synthetic and real-world datasets. For a fixed reconstruction quality,
AODL learns up to 90\% sparser solutions compared to non-low-rank and
analytical (fixed) dictionary baselines. In addition, the learned dictionaries
reveal interpretable insights into patterns present within the samples used for
training.

</details>


### [141] [Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability](https://arxiv.org/abs/2509.10034)
*Sahil Rajesh Dhayalkar*

Main category: cs.LG

TL;DR: 本文提出了一个形式化理论，证明概率有限自动机(PFAs)可以通过符号前馈神经网络精确模拟。通过将状态分布表示为向量、转移表示为随机矩阵，实现了无需循环的并行可解释概率状态传播。


<details>
  <summary>Details</summary>
Motivation: 弥合符号计算与深度学习之间的差距，统一概率自动机理论与神经网络架构，建立严格的代数框架来连接这两个领域。

Method: 使用符号前馈神经网络架构，将状态分布编码为向量，转移表示为随机矩阵，通过矩阵-向量乘积实现概率状态传播，采用软更新而非循环机制。

Result: 证明了PFAs与特定类别神经网络的等价性，展示了符号模拟器不仅具有表达力而且可学习：通过标准梯度下降优化，能够从标注序列数据中恢复真实PFAs的精确行为。

Conclusion: 该工作为概率自动机理论与神经架构的统一提供了严格的理论基础，Proposition 5.1中的可学习性证明是核心贡献，成功桥接了符号计算与深度学习领域。

Abstract: We present a formal and constructive theory showing that probabilistic finite
automata (PFAs) can be exactly simulated using symbolic feedforward neural
networks. Our architecture represents state distributions as vectors and
transitions as stochastic matrices, enabling probabilistic state propagation
via matrix-vector products. This yields a parallel, interpretable, and
differentiable simulation of PFA dynamics using soft updates-without
recurrence. We formally characterize probabilistic subset construction,
$\varepsilon$-closure, and exact simulation via layered symbolic computation,
and prove equivalence between PFAs and specific classes of neural networks. We
further show that these symbolic simulators are not only expressive but
learnable: trained with standard gradient descent-based optimization on labeled
sequence data, they recover the exact behavior of ground-truth PFAs. This
learnability, formalized in Proposition 5.1, is the crux of this work. Our
results unify probabilistic automata theory with neural architectures under a
rigorous algebraic framework, bridging the gap between symbolic computation and
deep learning.

</details>


### [142] [FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection](https://arxiv.org/abs/2509.10041)
*Mohammad Hasan Narimani,Mostafa Tavassolipour*

Main category: cs.LG

TL;DR: FedRP是一种新颖的联邦学习算法，通过结合随机投影和ADMM优化框架，在保护隐私的同时降低通信成本，并提供强差分隐私保证。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在保护用户隐私方面面临挑战，特别是在对抗潜在攻击和管理通信成本方面。需要一种既能保持模型准确性又能增强隐私保护的方法。

Method: 提出FedRP算法，集成随机投影技术和ADMM优化框架。使用随机投影降低模型参数的维度后再传输到中央服务器，减少通信成本。

Result: 实验结果显示FedRP不仅保持高模型准确性，而且在隐私保护和通信效率方面优于现有方法，包括传统差分隐私方法和FedADMM。

Conclusion: FedRP算法通过随机投影和ADMM的结合，有效解决了联邦学习中的隐私保护和通信成本问题，提供了强大的隐私保证和优异的性能表现。

Abstract: Federated learning (FL) offers an innovative paradigm for collaborative model
training across decentralized devices, such as smartphones, balancing enhanced
predictive performance with the protection of user privacy in sensitive areas
like Internet of Things (IoT) and medical data analysis. Despite its
advantages, FL encounters significant challenges related to user privacy
protection against potential attacks and the management of communication costs.
This paper introduces a novel federated learning algorithm called FedRP, which
integrates random projection techniques with the Alternating Direction Method
of Multipliers (ADMM) optimization framework. This approach enhances privacy by
employing random projection to reduce the dimensionality of model parameters
prior to their transmission to a central server, reducing the communication
cost. The proposed algorithm offers a strong $(\epsilon, \delta)$-differential
privacy guarantee, demonstrating resilience against data reconstruction
attacks. Experimental results reveal that FedRP not only maintains high model
accuracy but also outperforms existing methods, including conventional
differential privacy approaches and FedADMM, in terms of both privacy
preservation and communication efficiency.

</details>


### [143] [Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data](https://arxiv.org/abs/2509.10048)
*Madhushan Ramalingam*

Main category: cs.LG

TL;DR: 评估VBLL与TabPFN集成在不确定性校准中的性能，发现原始TabPFN在三个医疗表格数据集上始终优于VBLL集成版本


<details>
  <summary>Details</summary>
Motivation: 在医疗诊断等安全关键应用中，可靠的不确定性估计至关重要。TabPFN是新兴的表格数据基础模型，VBLL是最先进的轻量级变分方法，本研究旨在评估两者集成在不确定性校准中的表现

Method: 在三个基准医疗表格数据集上进行实验，比较原始TabPFN和VBLL集成版本在不确定性校准方面的性能

Result: 与预期相反，原始TabPFN在所有数据集上的不确定性校准表现都优于VBLL集成版本

Conclusion: VBLL集成并未改善TabPFN的不确定性校准性能，原始TabPFN在此任务上表现更佳

Abstract: Predictive models are being increasingly used across a wide range of domains,
including safety-critical applications such as medical diagnosis and criminal
justice. Reliable uncertainty estimation is a crucial task in such settings.
Tabular Prior-data Fitted Network (TabPFN) is a recently proposed machine
learning foundation model for tabular dataset, which uses a generative
transformer architecture. Variational Bayesian Last Layers (VBLL) is a
state-of-the-art lightweight variational formulation that effectively improves
uncertainty estimation with minimal computational overhead. In this work we aim
to evaluate the performance of VBLL integrated with the recently proposed
TabPFN in uncertainty calibration. Our experiments, conducted on three
benchmark medical tabular datasets, compare the performance of the original
TabPFN and the VBLL-integrated version. Contrary to expectations, we observed
that original TabPFN consistently outperforms VBLL integrated TabPFN in
uncertainty calibration across all datasets.

</details>


### [144] [KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework](https://arxiv.org/abs/2509.10089)
*Marco Andrea Bühler,Gonzalo Guillén-Gosálbez*

Main category: cs.LG

TL;DR: KAN-SR是一个基于Kolmogorov Arnold Networks的新型符号回归框架，采用分治方法，结合深度学习技术和简化策略，能够准确恢复Feynman SRSD数据集的真实方程，并能精确建模生物过程系统动力学。


<details>
  <summary>Details</summary>
Motivation: 传统符号回归通常使用遗传编程方法，本文旨在利用深度学习技术、特定KAN网络和简化策略来改进符号回归的准确性和效率，特别是在科学发现和工程系统动态建模方面。

Method: 采用Kolmogorov Arnold Networks（KANs）构建符号回归框架，结合分治方法、深度学习技术、平移对称性和可分离性等简化策略，并与神经控制微分方程结合进行动态建模。

Result: 成功恢复了Feynman SRSD数据集的真实方程，并能够精确建模硅内生物过程系统的动力学，为其他工程系统的动态建模开辟了新途径。

Conclusion: KAN-SR框架在符号回归方面表现出色，不仅能够准确发现数学方程，还能有效处理动态系统建模问题，具有广泛的应用前景。

Abstract: We introduce a novel symbolic regression framework, namely KAN-SR, built on
Kolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.
Symbolic regression searches for mathematical equations that best fit a given
dataset and is commonly solved with genetic programming approaches. We show
that by using deep learning techniques, more specific KANs, and combining them
with simplification strategies such as translational symmetries and
separabilities, we are able to recover ground-truth equations of the Feynman
Symbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we
show that by combining the proposed framework with neural controlled
differential equations, we are able to model the dynamics of an in-silico
bioprocess system precisely, opening the door for the dynamic modeling of other
engineering systems.

</details>


### [145] [Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning](https://arxiv.org/abs/2509.10132)
*Nour Jamoussi,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.LG

TL;DR: 提出了一种基于信息几何投影的贝叶斯联邦学习个性化框架，通过将全局模型投影到用户本地模型的邻域，实现全局泛化与本地特化的可调权衡，计算成本低且性能优异


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯联邦学习方法通常依赖MCMC采样或变分推断，需要个性化机制来适应本地数据分布，但计算成本较高。本文旨在开发一种更高效的个人化方法

Method: 采用信息几何投影框架，将全局模型投影到用户本地模型的统计流形邻域，证明该投影等价于计算统计流形上的重心，从而获得闭式解和零成本个性化。结合IVON优化器应用于变分学习，并扩展到BFL中的通用聚合方案

Result: 在异构数据分布下的实证评估表明，该方法能有效平衡全局和本地性能，且计算开销极小

Conclusion: 提出的信息几何投影框架为贝叶斯联邦学习提供了一种高效的个人化方法，实现了全局泛化与本地特化的最优权衡，计算成本低且性能优越

Abstract: Bayesian Federated Learning (BFL) combines uncertainty modeling with
decentralized training, enabling the development of personalized and reliable
models under data heterogeneity and privacy constraints. Existing approaches
typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational
inference, often incorporating personalization mechanisms to better adapt to
local data distributions. In this work, we propose an information-geometric
projection framework for personalization in parametric BFL. By projecting the
global model onto a neighborhood of the user's local model, our method enables
a tunable trade-off between global generalization and local specialization.
Under mild assumptions, we show that this projection step is equivalent to
computing a barycenter on the statistical manifold, allowing us to derive
closed-form solutions and achieve cost-free personalization. We apply the
proposed approach to a variational learning setup using the Improved
Variational Online Newton (IVON) optimizer and extend its application to
general aggregation schemes in BFL. Empirical evaluations under heterogeneous
data distributions confirm that our method effectively balances global and
local performance with minimal computational overhead.

</details>


### [146] [BenchECG and xECG: a benchmark and baseline for ECG foundation models](https://arxiv.org/abs/2509.10151)
*Riccardo Lunelli,Angus Nicolson,Samuel Martin Pröll,Sebastian Johannes Reinstadler,Axel Bauer,Clemens Dlaska*

Main category: cs.LG

TL;DR: 提出了BenchECG标准化基准和xECG模型，通过统一的评估框架解决ECG基础模型缺乏公平比较的问题，xECG在多个数据集和任务上表现最佳


<details>
  <summary>Details</summary>
Motivation: 现有ECG基础模型研究缺乏一致的评估标准，使用不同的任务选择和数据集，阻碍了公平比较和进展

Method: 开发BenchECG标准化基准套件，包含多个公开ECG数据集和多样化任务；提出基于xLSTM和SimDINOv2自监督学习的xECG循环模型

Result: xECG在BenchECG基准测试中获得最佳分数，是唯一在所有数据集和任务上都表现优异的公开可用模型

Conclusion: BenchECG标准化评估框架促进了ECG表示学习的严格比较，xECG为未来ECG基础模型设立了新的性能基准

Abstract: Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to
deep learning. Recently, interest has grown in developing foundation models for
ECGs - models that generalise across diverse downstream tasks. However,
consistent evaluation has been lacking: prior work often uses narrow task
selections and inconsistent datasets, hindering fair comparison. Here, we
introduce BenchECG, a standardised benchmark comprising a comprehensive suite
of publicly available ECG datasets and versatile tasks. We also propose xECG,
an xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,
which achieves the best BenchECG score compared to publicly available
state-of-the-art models. In particular, xECG is the only publicly available
model to perform strongly on all datasets and tasks. By standardising
evaluation, BenchECG enables rigorous comparison and aims to accelerate
progress in ECG representation learning. xECG achieves superior performance
over earlier approaches, defining a new baseline for future ECG foundation
models.

</details>


### [147] [FedBiF: Communication-Efficient Federated Learning via Bits Freezing](https://arxiv.org/abs/2509.10161)
*Shiwei Li,Qunwei Li,Haozhao Wang,Ruixuan Li,Jianbin Lin,Wenliang Zhong*

Main category: cs.LG

TL;DR: FedBiF是一种新颖的联邦学习框架，通过在本地训练期间直接学习量化模型参数，逐位更新参数来大幅减少通信开销，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能实现分布式协作训练，但存在显著的通信开销问题。现有方法通常在本地训练后进行量化，这会将量化误差引入训练参数并可能降低模型精度。

Method: 提出Federated Bit Freezing (FedBiF)框架：服务器先量化模型参数并传输给客户端；每个客户端每次只更新多比特参数表示中的单个比特，冻结其余比特；这种逐位更新策略将每个参数更新减少到1比特。

Result: 在5个常用数据集上的IID和非IID设置下进行实验，FedBiF不仅实现了优异的通信压缩，还促进了模型的稀疏性。在使用仅1bpp上行和3bpp下行通信时，仍能达到与FedAvg相当的精度。

Conclusion: FedBiF通过直接在训练过程中学习量化参数和逐位更新策略，有效解决了联邦学习的通信开销问题，在保持精度的同时实现了显著的通信压缩。

Abstract: Federated learning (FL) is an emerging distributed machine learning paradigm
that enables collaborative model training without sharing local data. Despite
its advantages, FL suffers from substantial communication overhead, which can
affect training efficiency. Recent efforts have mitigated this issue by
quantizing model updates to reduce communication costs. However, most existing
methods apply quantization only after local training, introducing quantization
errors into the trained parameters and potentially degrading model accuracy. In
this paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework
that directly learns quantized model parameters during local training. In each
communication round, the server first quantizes the model parameters and
transmits them to the clients. FedBiF then allows each client to update only a
single bit of the multi-bit parameter representation, freezing the remaining
bits. This bit-by-bit update strategy reduces each parameter update to one bit
while maintaining high precision in parameter representation. Extensive
experiments are conducted on five widely used datasets under both IID and
Non-IID settings. The results demonstrate that FedBiF not only achieves
superior communication compression but also promotes sparsity in the resulting
models. Notably, FedBiF attains accuracy comparable to FedAvg, even when using
only 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.
The code is available at https://github.com/Leopold1423/fedbif-tpds25.

</details>


### [148] [Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks](https://arxiv.org/abs/2509.10163)
*Francisco Javier Esono Nkulu Andong,Qi Min*

Main category: cs.LG

TL;DR: 提出了一种联邦多智能体强化学习框架Fed-MARL，用于6G超密集边缘网络中的隐私保护、实时资源管理，通过跨层协调和加密聚合实现能效优化。


<details>
  <summary>Details</summary>
Motivation: 6G网络向超密集智能边缘环境发展，需要在严格隐私、移动性和能耗约束下实现高效的资源管理，传统集中式方法面临隐私泄露和可扩展性问题。

Method: 采用联邦多智能体强化学习框架，每个智能体使用深度循环Q网络学习分散式策略，结合椭圆曲线Diffie Hellman密钥交换的安全聚合协议保护隐私，将问题建模为部分可观测多智能体马尔可夫决策过程。

Result: 仿真结果表明Fed-MARL在任务成功率、延迟、能效和公平性方面优于集中式MARL和启发式基线方法，同时确保强大的隐私保护和动态6G边缘网络中的可扩展性。

Conclusion: Fed-MARL框架为6G边缘网络提供了一种有效的隐私保护资源管理解决方案，能够在满足多样化服务需求的同时实现多目标优化。

Abstract: As sixth-generation (6G) networks move toward ultra-dense, intelligent edge
environments, efficient resource management under stringent privacy, mobility,
and energy constraints becomes critical. This paper introduces a novel
Federated Multi-Agent Reinforcement Learning (Fed-MARL) framework that
incorporates cross-layer orchestration of both the MAC layer and application
layer for energy-efficient, privacy-preserving, and real-time resource
management across heterogeneous edge devices. Each agent uses a Deep Recurrent
Q-Network (DRQN) to learn decentralized policies for task offloading, spectrum
access, and CPU energy adaptation based on local observations (e.g., queue
length, energy, CPU usage, and mobility). To protect privacy, we introduce a
secure aggregation protocol based on elliptic curve Diffie Hellman key
exchange, which ensures accurate model updates without exposing raw data to
semi-honest adversaries. We formulate the resource management problem as a
partially observable multi-agent Markov decision process (POMMDP) with a
multi-objective reward function that jointly optimizes latency, energy
efficiency, spectral efficiency, fairness, and reliability under 6G-specific
service requirements such as URLLC, eMBB, and mMTC. Simulation results
demonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines
in task success rate, latency, energy efficiency, and fairness, while ensuring
robust privacy protection and scalability in dynamic, resource-constrained 6G
edge networks.

</details>


### [149] [A Symmetry-Integrated Approach to Surface Code Decoding](https://arxiv.org/abs/2509.10164)
*Hoshitaro Ohnishi,Hideo Mukai*

Main category: cs.LG

TL;DR: 提出了一种通过神经网络连续函数近似来重新优化表面码解码器的方法，解决了传统方法因非唯一性预测只能获取误差概率分布的问题，在多种网络架构和码距下均提升了解码精度。


<details>
  <summary>Details</summary>
Motivation: 量子纠错码中表面码虽然具有高错误阈值，但传统解码器由于输入的非唯一性只能获取误差概率分布，无法进行唯一正确预测，需要改进解码方法。

Method: 使用神经网络构建连续函数来数学插值近似综合征测量，将表面码解码问题重新构建为回归问题，通过深度学习进行重新优化解码器模型。

Result: 在码距5和7的多层感知机解码器，以及基于卷积神经网络、循环神经网络和Transformer的解码器上，重新优化的解码器在所有情况下都比原始模型具有更好的准确性。

Conclusion: 将表面码解码问题重新构建为可通过深度学习处理的回归问题是一种有效的策略，所提出的方法具有通用有效性，不受码距或网络架构的限制。

Abstract: Quantum error correction, which utilizes logical qubits that are encoded as
redundant multiple physical qubits to find and correct errors in physical
qubits, is indispensable for practical quantum computing. Surface code is
considered to be a promising encoding method with a high error threshold that
is defined by stabilizer generators. However, previous methods have suffered
from the problem that the decoder acquires solely the error probability
distribution because of the non-uniqueness of correct prediction obtained from
the input. To circumvent this problem, we propose a technique to reoptimize the
decoder model by approximating syndrome measurements with a continuous function
that is mathematically interpolated by neural network. We evaluated the
improvement in accuracy of a multilayer perceptron based decoder for code
distances of 5 and 7 as well as for decoders based on convolutional and
recurrent neural networks and transformers for a code distance of 5. In all
cases, the reoptimized decoder gave better accuracy than the original models,
demonstrating the universal effectiveness of the proposed method that is
independent of code distance or network architecture. These results suggest
that re-framing the problem of surface code decoding into a regression problem
that can be tackled by deep learning is a useful strategy.

</details>


### [150] [The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams](https://arxiv.org/abs/2509.10167)
*Lénaïc Chizat*

Main category: cs.LG

TL;DR: 该论文研究了深度残差网络在标准随机初始化下的梯度训练动态，证明了当深度L趋于无穷时，训练动态收敛到神经平均ODE，并分析了不同残差缩放因子对特征学习的影响。


<details>
  <summary>Details</summary>
Motivation: 研究深度残差网络的训练动态，特别是当网络深度趋于无穷时的极限行为，以及不同参数缩放对特征学习能力的影响，为理解Transformer等实际模型提供理论依据。

Method: 采用数学分析方法，通过随机初始化的前向和后向传播行为作为随机近似，利用传播混沌理论证明训练动态收敛到平均ODE，并对不同残差缩放因子进行理论分析和实验验证。

Result: 证明了深度残差网络训练动态收敛到神经平均ODE，获得了模型输出与极限之间的误差界O(1/L + α/√(LM))，并验证了该速率的紧性。发现α=Θ(1)时实现完整特征学习，而α→∞时进入懒惰ODE机制。

Conclusion: 深度残差网络在适当缩放下能够实现完整的非线性特征学习，为理解深度网络训练动态提供了新的数学视角，对实际模型设计具有指导意义。

Abstract: We study the gradient-based training of large-depth residual networks
(ResNets) from standard random initializations. We show that with a diverging
depth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,
the training dynamics converges to a Neural Mean ODE training dynamics.
Remarkably, the limit is independent of the scaling of $M$, covering practical
cases of, say, Transformers, where $M$ (the number of hidden units or attention
heads per layer) is typically of the order of $D$. For a residual scale
$\Theta_D\big(\frac{\alpha}{LM}\big)$, we obtain the error bound
$O_D\big(\frac{1}{L}+ \frac{\alpha}{\sqrt{LM}}\big)$ between the model's output
and its limit after a fixed number gradient of steps, and we verify empirically
that this rate is tight. When $\alpha=\Theta(1)$, the limit exhibits complete
feature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In
contrast, we show that $\alpha \to \infty$ yields a \lazy ODE regime where the
Mean ODE is linearly parameterized. We then focus on the particular case of
ResNets with two-layer perceptron blocks, for which we study how these scalings
depend on the embedding dimension $D$. We show that for this model, the only
residual scale that leads to complete feature learning is
$\Theta\big(\frac{\sqrt{D}}{LM}\big)$. In this regime, we prove the error bound
$O\big(\frac{1}{L}+ \frac{\sqrt{D}}{\sqrt{LM}}\big)$ between the ResNet and its
limit after a fixed number of gradient steps, which is also empirically tight.
Our convergence results rely on a novel mathematical perspective on ResNets :
(i) due to the randomness of the initialization, the forward and backward pass
through the ResNet behave as the stochastic approximation of certain mean ODEs,
and (ii) by propagation of chaos (that is, asymptotic independence of the
units) this behavior is preserved through the training dynamics.

</details>


### [151] [P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context](https://arxiv.org/abs/2509.10186)
*Benjamin Holzschuh,Georg Kohl,Florian Redinger,Nils Thuerey*

Main category: cs.LG

TL;DR: 提出了一个可扩展的框架，用于学习高分辨率3D物理模拟的确定性和概率性神经代理模型，通过混合CNN-Transformer架构在速度和精度上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决高分辨率3D物理模拟的计算成本高和内存需求大的问题，开发一种能够有效学习多种偏微分方程动态的神经代理模型。

Method: 采用混合CNN-Transformer骨干架构，支持在小块模拟域上进行预训练，然后融合获得全局解，可选地通过序列到序列模型引入长程依赖关系。

Result: 在14种不同类型3D PDE的动态学习任务中显著优于基线方法，能够扩展到512^3空间分辨率的高分辨率各向同性湍流，并能作为扩散模型生成不同雷诺数下高度湍流3D通道流的概率样本。

Conclusion: 该框架提供了一种高效且可扩展的方法来构建高分辨率3D物理模拟的神经代理模型，在保持准确性的同时大幅降低了计算和内存需求。

Abstract: We present a scalable framework for learning deterministic and probabilistic
neural surrogates for high-resolution 3D physics simulations. We introduce a
hybrid CNN-Transformer backbone architecture targeted for 3D physics
simulations, which significantly outperforms existing architectures in terms of
speed and accuracy. Our proposed network can be pretrained on small patches of
the simulation domain, which can be fused to obtain a global solution,
optionally guided via a fast and scalable sequence-to-sequence model to include
long-range dependencies. This setup allows for training large-scale models with
reduced memory and compute requirements for high-resolution datasets. We
evaluate our backbone architecture against a large set of baseline methods with
the objective to simultaneously learn the dynamics of 14 different types of
PDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic
turbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate
the versatility of our network by training it as a diffusion model to produce
probabilistic samples of highly turbulent 3D channel flows across varying
Reynolds numbers, accurately capturing the underlying flow statistics.

</details>


### [152] [Hadamard-Riemannian Optimization for Margin-Variance Ensemble](https://arxiv.org/abs/2509.10189)
*Zexu Jin*

Main category: cs.LG

TL;DR: 提出了一种新的集成学习框架，通过将边际方差显式纳入损失函数来提升模型泛化能力和鲁棒性，并通过权重重参数化提高计算效率


<details>
  <summary>Details</summary>
Motivation: 传统基于边际的集成方法主要关注最大化期望边际而忽视边际方差的重要性，这限制了模型的泛化能力并在噪声或不平衡数据集中容易过拟合。同时，传统方法在概率单纯形中优化集成权重存在计算效率低和可扩展性差的问题

Method: 提出新的集成学习框架，将边际方差显式纳入损失函数，联合优化负期望边际及其方差。通过将集成权重重新参数化到单位球面上来简化优化过程和提高计算效率

Result: 在多个基准数据集上的广泛实验表明，该方法 consistently 优于传统的基于边际的集成技术

Conclusion: 该方法通过考虑边际方差和优化权重参数化，有效提升了集成学习的泛化性能、鲁棒性和计算效率，具有实际应用价值

Abstract: Ensemble learning has been widely recognized as a pivotal technique for
boosting predictive performance by combining multiple base models.
Nevertheless, conventional margin-based ensemble methods predominantly focus on
maximizing the expected margin while neglecting the critical role of margin
variance, which inherently restricts the generalization capability of the model
and heightens its vulnerability to overfitting, particularly in noisy or
imbalanced datasets. Additionally, the conventional approach of optimizing
ensemble weights within the probability simplex often introduces computational
inefficiency and scalability challenges, complicating its application to
large-scale problems. To tackle these limitations, this paper introduces a
novel ensemble learning framework that explicitly incorporates margin variance
into the loss function. Our method jointly optimizes the negative expected
margin and its variance, leading to enhanced robustness and improved
generalization performance. Moreover, by reparameterizing the ensemble weights
onto the unit sphere, we substantially simplify the optimization process and
improve computational efficiency. Extensive experiments conducted on multiple
benchmark datasets demonstrate that the proposed approach consistently
outperforms traditional margin-based ensemble techniques, underscoring its
effectiveness and practical utility.

</details>


### [153] [A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures](https://arxiv.org/abs/2509.10227)
*Ángel Ladrón,Miguel Sánchez-Domínguez,Javier Rozalén,Fernando R. Sánchez,Javier de Vicente,Lucas Lacasa,Eusebio Valero,Gonzalo Rubio*

Main category: cs.LG

TL;DR: 提出基于机器学习的飞机机翼疲劳寿命预测管道，替代传统有限元模拟和循环计数方法，提高预测效率并降低计算资源需求


<details>
  <summary>Details</summary>
Motivation: 传统疲劳寿命预测方法耗时且复杂，需要多团队协作和大量计算资源。机器学习可以提供快速估计，作为传统方法的补充，提高航空航天安全性

Method: 开发基于机器学习的管道，根据飞行参数预测飞机机翼不同位置的疲劳寿命，包括统计验证和不确定性量化

Result: 在真实疲劳寿命估计用例中验证了管道的准确性，能够提供精确预测

Conclusion: 该机器学习管道是传统方法的有力补充，能够显著减少昂贵模拟的数量，降低计算和人力资源需求

Abstract: Fatigue life prediction is essential in both the design and operational
phases of any aircraft, and in this sense safety in the aerospace industry
requires early detection of fatigue cracks to prevent in-flight failures.
Robust and precise fatigue life predictors are thus essential to ensure safety.
Traditional engineering methods, while reliable, are time consuming and involve
complex workflows, including steps such as conducting several Finite Element
Method (FEM) simulations, deriving the expected loading spectrum, and applying
cycle counting techniques like peak-valley or rainflow counting. These steps
often require collaboration between multiple teams and tools, added to the
computational time and effort required to achieve fatigue life predictions.
Machine learning (ML) offers a promising complement to traditional fatigue life
estimation methods, enabling faster iterations and generalization, providing
quick estimates that guide decisions alongside conventional simulations.
  In this paper, we present a ML-based pipeline that aims to estimate the
fatigue life of different aircraft wing locations given the flight parameters
of the different missions that the aircraft will be operating throughout its
operational life. We validate the pipeline in a realistic use case of fatigue
life estimation, yielding accurate predictions alongside a thorough statistical
validation and uncertainty quantification. Our pipeline constitutes a
complement to traditional methodologies by reducing the amount of costly
simulations and, thereby, lowering the required computational and human
resources.

</details>


### [154] [Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](https://arxiv.org/abs/2509.10248)
*Janis Keuper*

Main category: cs.LG

TL;DR: 本文通过系统评估发现，简单的提示注入攻击对LLM同行评审高度有效（可达100%接受率），且LLM评审普遍存在接受偏见（>95%）。


<details>
  <summary>Details</summary>
Motivation: 针对科学同行评审中LLM使用增加以及作者使用隐藏提示注入操纵评审分数的报道，研究此类攻击的可行性和技术成功率。

Method: 使用多种LLM对2024年ICLR论文的1000篇评审进行系统评估，分析提示注入攻击的效果和LLM评审偏见。

Result: 1) 简单提示注入攻击高度有效，最高可达100%接受率；2) LLM评审普遍偏向接受，许多模型接受率超过95%。

Conclusion: 研究结果对LLM在同行评审中使用的持续讨论具有重大影响，揭示了系统漏洞和固有偏见。

Abstract: The ongoing intense discussion on rising LLM usage in the scientific
peer-review process has recently been mingled by reports of authors using
hidden prompt injections to manipulate review scores. Since the existence of
such "attacks" - although seen by some commentators as "self-defense" - would
have a great impact on the further debate, this paper investigates the
practicability and technical success of the described manipulations. Our
systematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide
range of LLMs shows two distinct results: I) very simple prompt injections are
indeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews
are generally biased toward acceptance (>95% in many models). Both results have
great impact on the ongoing discussions on LLM usage in peer-review.

</details>


### [155] [Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning](https://arxiv.org/abs/2509.10273)
*Sahil Sethi,Kai Sundmacher,Caroline Ganzer*

Main category: cs.LG

TL;DR: 提出了一个基于神经推荐系统的迁移学习框架，利用COSMO-RS模拟数据和稀疏实验数据，准确预测离子液体的五种关键热物理性质。


<details>
  <summary>Details</summary>
Motivation: 离子液体具有可定制的物理化学性质，但由于化学设计空间巨大和实验数据有限，准确预测其热物理性质仍然具有挑战性。

Method: 采用两阶段方法：首先在固定温度和压力下使用COSMO-RS模拟数据预训练神经推荐系统模型，学习阳离子和阴离子的性质特异性结构嵌入；然后使用这些嵌入和不同温度压力下的实验数据微调简单前馈神经网络。

Result: 该框架支持性质内和跨性质知识迁移，预训练模型显著提升了四个目标性质的预测性能，能够稳健地外推到未见过的离子液体，并为超过70万种离子液体组合提供性质预测。

Conclusion: 这项工作展示了结合模拟数据和迁移学习来克服实验数据稀疏性的有效性，为离子液体筛选提供了可扩展的解决方案。

Abstract: Ionic liquids (ILs) have emerged as versatile replacements for traditional
solvents because their physicochemical properties can be precisely tailored to
various applications. However, accurately predicting key thermophysical
properties remains challenging due to the vast chemical design space and the
limited availability of experimental data. In this study, we present a
data-driven transfer learning framework that leverages a neural recommender
system (NRS) to enable reliable property prediction for ILs using sparse
experimental datasets. The approach involves a two-stage process: first,
pre-training NRS models on COSMO-RS-based simulated data at fixed temperature
and pressure to learn property-specific structural embeddings for cations and
anions; and second, fine-tuning simple feedforward neural networks using these
embeddings with experimental data at varying temperatures and pressures. In
this work, five essential IL properties are considered: density, viscosity,
surface tension, heat capacity, and melting point. The framework supports both
within-property and cross-property knowledge transfer. Notably, pre-trained
models for density, viscosity, and heat capacity are used to fine-tune models
for all five target properties, achieving improved performance by a substantial
margin for four of them. The model exhibits robust extrapolation to previously
unseen ILs. Moreover, the final trained models enable property prediction for
over 700,000 IL combinations, offering a scalable solution for IL screening in
process design. This work highlights the effectiveness of combining simulated
data and transfer learning to overcome sparsity in the experimental data.

</details>


### [156] [Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case](https://arxiv.org/abs/2509.10291)
*Salih Toprak,Muge Erel-Ozcevik*

Main category: cs.LG

TL;DR: 提出Proof of AutoML架构，利用机器学习回归器生成随机数作为区块链nonce，用于灾难场景下的安全能源交易


<details>
  <summary>Details</summary>
Motivation: 在灾难场景中传统能源基础设施受损时，需要安全可追溯的能源交易，而区块链网络需要强大的随机nonce生成机制

Method: 采用SDN架构，使用五种AutoML选择的回归模型（梯度提升、LightGBM、随机森林、额外树、K近邻），通过9000样本数据集评估其生成随机输出的能力

Result: 随机森林和额外树回归器表现出完全的随机性依赖，梯度提升、K近邻和LightGBM分别达到97.6%、98.8%和99.9%的随机性得分

Conclusion: 基于树的集成机器学习模型可作为轻量级nonce生成器，用于区块链安全的SDN能源交易基础设施

Abstract: In disaster scenarios where conventional energy infrastructure is
compromised, secure and traceable energy trading between solar-powered
households and mobile charging units becomes a necessity. To ensure the
integrity of such transactions over a blockchain network, robust and
unpredictable nonce generation is vital. This study proposes an SDN-enabled
architecture where machine learning regressors are leveraged not for their
accuracy, but for their potential to generate randomized values suitable as
nonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN
allows flexible control over data flows and energy routing policies even in
fragmented or degraded networks, ensuring adaptive response during emergencies.
Using a 9000-sample dataset, we evaluate five AutoML-selected regression models
- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest
Neighbors - not by their prediction accuracy, but by their ability to produce
diverse and non-deterministic outputs across shuffled data inputs. Randomness
analysis reveals that Random Forest and Extra Trees regressors exhibit complete
dependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and
LightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and
99.9%, respectively). These findings highlight that certain machine learning
models, particularly tree-based ensembles, may serve as effective and
lightweight nonce generators within blockchain-secured, SDN-based energy
trading infrastructures resilient to disaster conditions.

</details>


### [157] [Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data](https://arxiv.org/abs/2509.10303)
*Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang*

Main category: cs.LG

TL;DR: 提出CDQAC离线强化学习算法，直接从历史数据学习作业车间调度策略，无需在线交互，在样本效率和质量上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统在线RL方法需要大量模拟交互且样本效率低，希望开发能从历史数据直接学习高质量调度策略的离线RL方法

Method: CDQAC算法结合分位数critic和延迟策略更新，估计每个机器-操作对的回报分布而非直接选择

Result: CDQAC显著优于原始数据生成启发式算法和现有离线/在线RL基准，仅需10-20个训练实例即可学习高质量策略

Conclusion: CDQAC是高效的离线RL调度方法，意外发现在随机启发式生成的数据上训练效果优于高质量算法生成的数据

Abstract: The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling
Problem (FJSP), are canonical combinatorial optimization problems with
wide-ranging applications in industrial operations. In recent years, many
online reinforcement learning (RL) approaches have been proposed to learn
constructive heuristics for JSP and FJSP. Although effective, these online RL
methods require millions of interactions with simulated environments that may
not capture real-world complexities, and their random policy initialization
leads to poor sample efficiency. To address these limitations, we introduce
Conservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL
algorithm that learns effective scheduling policies directly from historical
data, eliminating the need for costly online interactions, while maintaining
the ability to improve upon suboptimal training data. CDQAC couples a
quantile-based critic with a delayed policy update, estimating the return
distribution of each machine-operation pair rather than selecting pairs
outright. Our extensive experiments demonstrate CDQAC's remarkable ability to
learn from diverse data sources. CDQAC consistently outperforms the original
data-generating heuristics and surpasses state-of-the-art offline and online RL
baselines. In addition, CDQAC is highly sample efficient, requiring only 10-20
training instances to learn high-quality policies. Surprisingly, we find that
CDQAC performs better when trained on data generated by a random heuristic than
when trained on higher-quality data from genetic algorithms and priority
dispatching rules.

</details>


### [158] [GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction](https://arxiv.org/abs/2509.10308)
*Joshua Dimasaka,Christian Geiß,Robert Muir-Wood,Emily So*

Main category: cs.LG

TL;DR: 提出了GraphCSVAE框架，通过结合深度学习、图表示和分类概率推理来建模物理脆弱性，填补了灾害风险评估中物理脆弱性建模的空白


<details>
  <summary>Details</summary>
Motivation: 灾害后机构难以持续监测灾害风险变化，限制了评估联合国仙台框架进展的能力。现有方法在大规模建模灾害和暴露方面有进展，但物理脆弱性建模仍有限

Method: GraphCSVAE概率数据驱动框架，整合深度学习、图表示和分类概率推理，使用时序卫星数据和专家先验知识，引入弱监督一阶转移矩阵

Result: 在孟加拉国飓风影响的Khurushkul社区和塞拉利昂泥石流影响的弗里敦市揭示了灾后物理脆弱性的区域动态

Conclusion: 为局部时空审计和灾后风险减少的可持续策略提供了有价值的见解

Abstract: In the aftermath of disasters, many institutions worldwide face challenges in
continually monitoring changes in disaster risk, limiting the ability of key
decision-makers to assess progress towards the UN Sendai Framework for Disaster
Risk Reduction 2015-2030. While numerous efforts have substantially advanced
the large-scale modeling of hazard and exposure through Earth observation and
data-driven methods, progress remains limited in modeling another equally
important yet challenging element of the risk equation: physical vulnerability.
To address this gap, we introduce Graph Categorical Structured Variational
Autoencoder (GraphCSVAE), a novel probabilistic data-driven framework for
modeling physical vulnerability by integrating deep learning, graph
representation, and categorical probabilistic inference, using time-series
satellite-derived datasets and prior expert belief systems. We introduce a
weakly supervised first-order transition matrix that reflects the changes in
the spatiotemporal distribution of physical vulnerability in two
disaster-stricken and socioeconomically disadvantaged areas: (1) the
cyclone-impacted coastal Khurushkul community in Bangladesh and (2) the
mudslide-affected city of Freetown in Sierra Leone. Our work reveals
post-disaster regional dynamics in physical vulnerability, offering valuable
insights into localized spatiotemporal auditing and sustainable strategies for
post-disaster risk reduction.

</details>


### [159] [ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting](https://arxiv.org/abs/2509.10324)
*Myung Jin Kim,YeongHyeon Park,Il Dong Yun*

Main category: cs.LG

TL;DR: 提出基于ARIMA启发的简单卷积模块ARMA，用于长期时间序列预测，包含趋势捕捉和局部变化精炼两个组件，直接进行多步预测，在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统ARIMA模型需要迭代多步预测且难以扩展到多变量设置，需要一种简单有效的直接多步预测方法。

Method: 设计包含两个卷积组件的模块：一个用于捕捉趋势（自回归），另一个用于精炼局部变化（移动平均），直接进行多步预测。

Result: 在9个基准数据集上取得竞争性精度，特别是在具有强趋势变化的数据集上表现优异，同时保持架构简单性。

Conclusion: ARMA模块不仅实现了有效的长期时间序列预测，还天然编码了绝对位置信息，有潜力作为序列模型中位置嵌入的轻量级替代方案。

Abstract: This paper proposes a simple yet effective convolutional module for long-term
time series forecasting. The proposed block, inspired by the Auto-Regressive
Integrated Moving Average (ARIMA) model, consists of two convolutional
components: one for capturing the trend (autoregression) and the other for
refining local variations (moving average). Unlike conventional ARIMA, which
requires iterative multi-step forecasting, the block directly performs
multi-step forecasting, making it easily extendable to multivariate settings.
Experiments on nine widely used benchmark datasets demonstrate that our method
ARMA achieves competitive accuracy, particularly on datasets exhibiting strong
trend variations, while maintaining architectural simplicity. Furthermore,
analysis shows that the block inherently encodes absolute positional
information, suggesting its potential as a lightweight replacement for
positional embeddings in sequential models.

</details>


### [160] [A Discrepancy-Based Perspective on Dataset Condensation](https://arxiv.org/abs/2509.10367)
*Tong Chen,Raghavendra Selvan*

Main category: cs.LG

TL;DR: 本文提出了一个统一框架来形式化数据集压缩问题，使用差异度量来量化概率分布之间的距离，将目标从泛化扩展到鲁棒性、隐私等更多属性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集压缩方法缺乏统一的理论框架，且主要关注泛化性能，需要扩展到更广泛的目标如鲁棒性和隐私保护。

Method: 建立基于差异度量的统一框架，使用概率分布距离来形式化数据集压缩问题，涵盖现有方法并扩展目标范围。

Result: 提出了一个理论框架，能够统一现有数据集压缩方法，并将压缩目标从单纯的泛化性能扩展到包括鲁棒性、隐私保护等多个维度。

Conclusion: 该框架为数据集压缩提供了更严格的形式化定义和理论基础，使压缩数据集不仅能保持泛化性能，还能具备其他重要属性。

Abstract: Given a dataset of finitely many elements $\mathcal{T} = \{\mathbf{x}_i\}_{i
= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic
dataset $\mathcal{S} = \{\tilde{\mathbf{x}}_j\}_{j = 1}^M$ which is
significantly smaller ($M \ll N$) such that a model trained from scratch on
$\mathcal{S}$ achieves comparable or even superior generalization performance
to a model trained on $\mathcal{T}$. Recent advances in DC reveal a close
connection to the problem of approximating the data distribution represented by
$\mathcal{T}$ with a reduced set of points. In this work, we present a unified
framework that encompasses existing DC methods and extend the task-specific
notion of DC to a more general and formal definition using notions of
discrepancy, which quantify the distance between probability distribution in
different regimes. Our framework broadens the objective of DC beyond
generalization, accommodating additional objectives such as robustness,
privacy, and other desirable properties.

</details>


### [161] [Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms](https://arxiv.org/abs/2509.10369)
*Gul Rukh Khattak,Konstantinos Patlatzoglou,Joseph Barker,Libor Pastika,Boroumand Zeidaabadi,Ahmed El-Medany,Hesham Aggour,Yixiu Liang,Antonio H. Ribeiro,Jeffrey Annis,Antonio Luiz Pinho Ribeiro,Junbo Ge,Daniel B. Kramer,Jonathan W. Waks,Evan Brittain,Nicholas Peters,Fu Siong Ng,Arunashis Sau*

Main category: cs.LG

TL;DR: 本研究探讨了对比学习在ECG预训练中队列组成的影响，发现多中心多样化队列虽然提高分布内准确性，但会编码队列特异性伪影降低OOD泛化能力，并提出了IDB策略来增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 对比学习作为广泛采用的自监督预训练策略，其性能对队列组成的依赖性尚未得到充分探索，特别是在临床公平性和泛化性方面需要深入研究。

Method: 提出了CAPE基础模型，在四大洲五个队列（n=5,203,352）上进行预训练，系统评估队列人口统计学、健康状况和多样性对下游性能的影响，并提出了In-Distribution Batch (IDB)策略来保持队列内一致性。

Result: 发现下游性能取决于预训练队列的分布特性，包括人口统计学和健康状况。多中心多样化队列提高了分布内准确性，但通过编码队列特异性伪影降低了对比学习方法的OOD泛化能力。

Conclusion: IDB策略能够有效保持预训练期间的队列内一致性并增强OOD鲁棒性，为开发临床公平和可泛化的基础模型提供了重要见解。

Abstract: Contrastive learning is a widely adopted self-supervised pretraining
strategy, yet its dependence on cohort composition remains underexplored. We
present Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation
model and pretrain on four cohorts (n = 5,203,352), from diverse populations
across three continents (North America, South America, Asia). We systematically
assess how cohort demographics, health status, and population diversity
influence the downstream performance for prediction tasks also including two
additional cohorts from another continent (Europe). We find that downstream
performance depends on the distributional properties of the pretraining cohort,
including demographics and health status. Moreover, while pretraining with a
multi-centre, demographically diverse cohort improves in-distribution accuracy,
it reduces out-of-distribution (OOD) generalisation of our contrastive approach
by encoding cohort-specific artifacts. To address this, we propose the
In-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency
during pretraining and enhances OOD robustness. This work provides important
insights for developing clinically fair and generalisable foundation models.

</details>


### [162] [Flow Straight and Fast in Hilbert Space: Functional Rectified Flow](https://arxiv.org/abs/2509.10384)
*Jianxin Zhang,Clayton Scott*

Main category: cs.LG

TL;DR: 本文建立了无限维希尔伯特空间中整流流的严格函数式表述，扩展了整流流到无限维空间的框架，并展示了其在函数式流匹配和概率流ODE中的自然应用。


<details>
  <summary>Details</summary>
Motivation: 许多在有限维欧几里得空间中开发的生成模型在无限维设置中都有函数式推广，但整流流向无限维空间的扩展仍未被探索。

Method: 基于无限维空间中连续性方程的叠加原理，建立了整流流的函数式表述框架，并将其扩展到函数式流匹配和函数式概率流ODE。

Result: 实验证明该方法相比现有函数式生成模型具有更优越的性能，并且移除了现有理论中限制性的测度论假设。

Conclusion: 成功建立了无限维空间中整流流的严格数学框架，为函数式生成模型提供了新的理论基础和实践方法。

Abstract: Many generative models originally developed in finite-dimensional Euclidean
space have functional generalizations in infinite-dimensional settings.
However, the extension of rectified flow to infinite-dimensional spaces remains
unexplored. In this work, we establish a rigorous functional formulation of
rectified flow in an infinite-dimensional Hilbert space. Our approach builds
upon the superposition principle for continuity equations in an
infinite-dimensional space. We further show that this framework extends
naturally to functional flow matching and functional probability flow ODEs,
interpreting them as nonlinear generalizations of rectified flow. Notably, our
extension to functional flow matching removes the restrictive measure-theoretic
assumptions in the existing theory of \citet{kerrigan2024functional}.
Furthermore, we demonstrate experimentally that our method achieves superior
performance compared to existing functional generative models.

</details>


### [163] [Vendi Information Gain for Active Learning and its Application to Ecology](https://arxiv.org/abs/2509.10390)
*Quan Nguyen,Adji Bousso Dieng*

Main category: cs.LG

TL;DR: 提出Vendi信息增益(VIG)主动学习策略，通过考虑数据集整体预测不确定性来选择最具信息量和多样性的图像进行标注，在Snapshot Serengeti数据集上仅用不到10%的标签就达到了接近全监督的预测精度。


<details>
  <summary>Details</summary>
Motivation: 相机陷阱监测生物多样性时，物种识别因标注资源有限成为主要瓶颈。传统主动学习方法只关注个体预测不确定性，而忽略了整个数据集的不确定性。

Method: 引入Vendi信息增益(VIG)主动学习策略，选择能最大程度降低数据集整体预测不确定性的图像，同时考虑信息量和多样性。

Result: 在Snapshot Serengeti数据集上，VIG使用不到10%的标签就达到了接近全监督的预测精度，在各种指标和批次大小下均优于标准基线方法，并在特征空间中收集到更多样化的数据。

Conclusion: VIG方法在数据有限的环境中对生物多样性监测具有重要价值，且具有超越生态学领域的广泛适用性。

Abstract: While monitoring biodiversity through camera traps has become an important
endeavor for ecological research, identifying species in the captured image
data remains a major bottleneck due to limited labeling resources. Active
learning -- a machine learning paradigm that selects the most informative data
to label and train a predictive model -- offers a promising solution, but
typically focuses on uncertainty in the individual predictions without
considering uncertainty across the entire dataset. We introduce a new active
learning policy, Vendi information gain (VIG), that selects images based on
their impact on dataset-wide prediction uncertainty, capturing both
informativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG
achieves impressive predictive accuracy close to full supervision using less
than 10% of the labels. It consistently outperforms standard baselines across
metrics and batch sizes, collecting more diverse data in the feature space. VIG
has broad applicability beyond ecology, and our results highlight its value for
biodiversity monitoring in data-limited environments.

</details>


### [164] [Inpainting-Guided Policy Optimization for Diffusion Large Language Models](https://arxiv.org/abs/2509.10396)
*Siyan Zhao,Mengchen Liu,Jing Huang,Miao Liu,Chenyu Wang,Bo Liu,Yuandong Tian,Guan Pang,Sean Bell,Aditya Grover,Feiyu Chen*

Main category: cs.LG

TL;DR: IGPO是一个针对掩码扩散大语言模型的强化学习框架，通过部分真实推理轨迹的inpainting技术来引导探索，提高样本效率，在数学推理任务上取得了SOTA效果


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中对齐LLM时的探索挑战：稀疏奖励信号和样本浪费问题，利用dLLM的inpainting能力来指导探索

Method: 提出IGPO框架，在在线采样时策略性地插入部分真实推理轨迹，使用inpainting技术引导探索；同时提出基于合成重写的简洁轨迹进行监督微调，以及基于熵的过滤技术

Result: 在GSM8K、Math500和AMC三个数学基准测试中取得了显著提升，为全注意力掩码dLLM实现了新的最先进结果

Conclusion: IGPO成功地将监督微调和强化学习连接起来，通过inpainting指导的探索解决了RL中的梯度问题，显著提高了dLLM在数学推理任务上的性能

Abstract: Masked diffusion large language models (dLLMs) are emerging as promising
alternatives to autoregressive LLMs, offering competitive performance while
supporting unique generation capabilities such as inpainting. We explore how
inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with
reinforcement learning faces an exploration challenge: sparse reward signals
and sample waste when models fail to discover correct solutions. While this
inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their
inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided
Policy Optimization), an RL framework that strategically inserts partial
ground-truth reasoning traces during online sampling. Unlike providing full
solutions, inpainting steers exploration toward promising trajectory spaces
while preserving self-generated reasoning, bridging supervised fine-tuning and
reinforcement learning. We apply IGPO to group-based optimization methods such
as GRPO, where exploration failures cause zero advantages and gradients. IGPO
restores meaningful gradients while improving sample efficiency. We also
propose supervised fine-tuning on synthetically rewritten concise traces that
better align with dLLM generation patterns. With additional techniques
including entropy-based filtering, our training recipe yields substantial gains
across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new
state-of-the-art results for full-attention masked dLLMs.

</details>


### [165] [Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining](https://arxiv.org/abs/2509.10406)
*Rupert Mitchell,Kristian Kersting*

Main category: cs.LG

TL;DR: MuSe是一种高效的softmax注意力近似方法，通过语义聚类和多极展开技术降低Transformer的二次计算复杂度，实现3倍加速且性能损失极小


<details>
  <summary>Details</summary>
Motivation: 解决Transformer在长序列处理中的二次计算复杂度问题，传统方法要么只对key聚类要么使用统一聚类，无法保持注意力机制中query和key空间的不对称性

Method: 在学习的表示空间中分别对query和key进行语义聚类，采用层次化两阶段注意力机制，使用中心点近似加偶极子修正来捕捉簇内方向方差

Result: 在8k上下文长度下比CUDNN Flash Attention快3倍，相对平方误差低于20%；在16k上下文长度的30M参数模型预训练中实现12.2%运行时间减少，仅0.36%性能损失

Conclusion: 多极近似方法对于高效Transformer预训练是可行的，能够显著降低计算复杂度同时保持模型性能

Abstract: We present Multipole Semantic Attention (MuSe), an efficient approximation of
softmax attention that combines semantic clustering with multipole expansions
from computational physics. Our method addresses the quadratic computational
complexity of transformers in the context length by clustering queries and keys
separately in their learned representation spaces, enabling a hierarchical
two-stage attention mechanism. Unlike prior clustering approaches that group
only keys or use unified clustering, we maintain separate clusterings that
respect attention's asymmetric treatment of these spaces. We augment
centroid-based (monopole) approximations with dipole corrections that capture
directional variance within clusters, preserving richer information during
training. The method operates as a drop-in replacement for standard attention,
requiring only hyperparameter specification without architectural
modifications. Our approach achieves $\mathcal{O}(NCD)$ complexity for acausal
attention with $C$ clusters and $\mathcal{O}(NCD \log N)$ for causal attention.
On isolated attention layers, we demonstrate $3\times$ speedup over CUDNN Flash
Attention at 8k context length, with relative squared errors below 20%. For
causal attention, we develop a hierarchical block decomposition that combines
exact local computation with efficient long-range approximation. In end-to-end
pretraining of a 30M parameter model on book-length texts with 16k context, we
achieve 12.2% runtime reduction with only 0.36% loss degradation, establishing
the viability of multipole approximations for efficient transformer
pretraining.

</details>


### [166] [Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining](https://arxiv.org/abs/2509.10419)
*Francesco Vitale,Tommaso Zoppi,Francesco Flammini,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 本文探讨使用过程挖掘技术进行运行时控制流异常检测，以增强ERTMS/ETCS L2铁路系统的弹性。通过从执行轨迹学习实际控制流，实现在线一致性检查，并结合无监督机器学习进行异常定位。


<details>
  <summary>Details</summary>
Motivation: 随着铁路系统复杂性和关键性的增加，确保其弹性变得至关重要。尽管软件遵循严格的验证和认证标准，但运行时仍可能出现残余故障、系统环境变化或新兴网络威胁导致的异常。

Method: 采用过程挖掘技术从系统执行轨迹中学习实际控制流，进行在线一致性检查的运行时监控。同时使用无监督机器学习方法进行异常定位，将相关偏差关联到关键系统组件。

Result: 在ERTMS/ETCS L2的RBC/RBC切换参考场景中测试，该方法能够以高准确性、高效性和可解释性检测和定位异常。

Conclusion: 过程挖掘结合无监督机器学习为铁路系统提供了一种有效的运行时异常检测和定位方法，能够增强系统的弹性和安全性。

Abstract: Ensuring the resilience of computer-based railways is increasingly crucial to
account for uncertainties and changes due to the growing complexity and
criticality of those systems. Although their software relies on strict
verification and validation processes following well-established best-practices
and certification standards, anomalies can still occur at run-time due to
residual faults, system and environmental modifications that were unknown at
design-time, or other emergent cyber-threat scenarios. This paper explores
run-time control-flow anomaly detection using process mining to enhance the
resilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European
Train Control System Level 2). Process mining allows learning the actual
control flow of the system from its execution traces, thus enabling run-time
monitoring through online conformance checking. In addition, anomaly
localization is performed through unsupervised machine learning to link
relevant deviations to critical system components. We test our approach on a
reference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its
capability to detect and localize anomalies with high accuracy, efficiency, and
explainability.

</details>


### [167] [Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration](https://arxiv.org/abs/2509.10439)
*Ahmed Khaled,Satyen Kale,Arthur Douillard,Chi Jin,Rob Fergus,Manzil Zaheer*

Main category: cs.LG

TL;DR: 本文研究了Local SGD中外层优化器的作用，证明了新的收敛保证，发现调节外层学习率可以在优化误差和随机梯度噪声方差之间权衡，并弥补内层学习率的不良调节。理论表明外层学习率有时应大于1，且外层动量加速可改善收敛率。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习需要大批次训练和分布式计算，通信成为主要瓶颈。Local SGD可减少通信开销，但现有研究主要关注本地优化过程的超参数，而外层优化器及其超参数的选择不够明确。

Method: 通过理论分析证明Local SGD的收敛保证，研究外层学习率调节的作用机制，扩展到外层动量优化器，并引入数据依赖性分析。使用标准语言模型和各种外层优化器进行综合实验验证。

Result: 理论表明调节外层学习率可以权衡优化误差和随机梯度噪声方差，弥补内层学习率的不良调节，外层学习率有时应大于1。外层动量加速改善了基于通信轮数的收敛率。实验验证了理论发现。

Conclusion: 外层优化器在Local SGD中扮演关键角色，适当调节外层学习率和动量参数可以显著改善分布式训练的通信效率和收敛性能，为大规模分布式机器学习提供了重要的理论指导。

Abstract: Modern machine learning often requires training with large batch size,
distributed data, and massively parallel compute hardware (like mobile and
other edge devices or distributed data centers). Communication becomes a major
bottleneck in such settings but methods like Local Stochastic Gradient Descent
(Local SGD) show great promise in reducing this additional communication
overhead. Local SGD consists of three parts: a local optimization process, an
aggregation mechanism, and an outer optimizer that uses the aggregated updates
from the nodes to produce a new model. While there exists an extensive
literature on understanding the impact of hyperparameters in the local
optimization process, the choice of outer optimizer and its hyperparameters is
less clear. We study the role of the outer optimizer in Local SGD, and prove
new convergence guarantees for the algorithm. In particular, we show that
tuning the outer learning rate allows us to (a) trade off between optimization
error and stochastic gradient noise variance, and (b) make up for ill-tuning of
the inner learning rate. Our theory suggests that the outer learning rate
should sometimes be set to values greater than $1$. We extend our results to
settings where we use momentum in the outer optimizer, and we show a similar
role for the momentum-adjusted outer learning rate. We also study acceleration
in the outer optimizer and show that it improves the convergence rate as a
function of the number of communication rounds, improving upon the convergence
rate of prior algorithms that apply acceleration locally. Finally, we also
introduce a novel data-dependent analysis of Local SGD that yields further
insights on outer learning rate tuning. We conduct comprehensive experiments
with standard language models and various outer optimizers to validate our
theory.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [168] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: AutoIND LLM平台可将IND申请文件起草时间减少约97%，从约100小时缩短至3-4小时，质量评分达70-78%，无关键监管错误，但仍需专家完善以提高提交质量。


<details>
  <summary>Details</summary>
Motivation: 解决IND申请准备过程耗时且依赖专家经验的问题，加速早期临床开发进程。

Method: 通过AutoIND LLM平台生成IND非临床书面总结，记录起草时间并与人工起草时间对比，由盲审监管写作评估员使用7个预设类别进行质量评估。

Result: 起草时间减少97%（从~100小时降至3.7小时和2.6小时），质量评分分别为69.6%和77.9%，无关键监管错误，但在强调、简洁性和清晰度方面存在不足。

Conclusion: AutoIND能显著加速IND起草过程，但需要专家监管写作者将输出完善至提交就绪质量，系统缺陷为针对性模型改进提供了路线图。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [169] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: Boldsea是一个基于语义事件方法的架构，使用可执行本体来建模复杂动态系统，通过将事件语义与数据流架构集成来解决传统BPM系统和面向对象语义技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统业务流程管理系统和面向对象语义技术在动态系统建模中的局限性，提供更灵活和实时的系统控制能力。

Method: 提出BSL（boldsea语义语言）及其BNF语法，设计boldsea-engine架构，直接解释语义模型作为可执行算法，无需编译，支持运行时修改事件模型。

Result: 实现了时间透明性，在统一的语义框架内无缝合并数据和业务逻辑，能够直接控制流程执行。

Conclusion: Boldsea架构通过可执行本体和语义事件方法，为复杂动态系统建模提供了更有效和灵活的解决方案，克服了传统方法的限制。

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [170] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 本文评估了大型语言模型和视觉语言模型在各种环境中提供规划反馈的能力，发现基础模型能够提供高质量反馈，但复杂动态或连续空间会降低反馈质量。


<details>
  <summary>Details</summary>
Motivation: 减少规划学习中奖励函数设计和标注演示的需求，利用预训练基础模型中的背景知识来辅助规划决策。

Method: 在符号、语言和连续控制环境中评估LLMs和VLMs的反馈能力，包括二进制反馈、偏好反馈、动作建议、目标建议和增量动作反馈等多种反馈类型，并测试不同的推理方法。

Result: 基础模型能够跨领域提供多样化高质量反馈，更大和具备推理能力的模型反馈更准确、偏见更少，且能从增强推理方法中获益更多。

Conclusion: 基础模型是规划反馈的有效来源，但反馈质量在复杂动态或连续状态动作空间中会下降，模型规模和推理能力对反馈性能有重要影响。

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [171] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 提出基于生成式AI的模块化多模态框架，从公开的住宅信息和图像生成能源建模所需数据，解决数据获取难、成本高和隐私问题


<details>
  <summary>Details</summary>
Motivation: 计算模型在能源建模研究中需要大量数据，但部分数据难以获取、成本高昂或存在隐私问题，需要寻找替代方案

Method: 开发模块化多模态框架，利用生成式人工智能从公开可获取的住宅信息和图像中生成所需数据，并提供完整的实现管道

Result: 实验表明该框架能避免生成模型的常见问题，产生真实且标注良好的数据

Conclusion: 通过减少对昂贵或受限数据源的依赖，为更易获取和可重复的研究铺平道路

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [172] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 本文综述了自动形式化（autoformalization）领域的研究现状，提出了统一框架来整合数学形式化和更广泛的非正式语言到形式逻辑表示的转换研究，旨在促进不同领域间的交叉融合。


<details>
  <summary>Details</summary>
Motivation: 由于深度学习和大语言模型的快速发展，自动形式化在数学形式化和更广泛的非正式语言到形式逻辑转换方面取得了显著进展，但这些研究领域相对独立发展，缺乏共享的方法论、基准和理论框架，限制了整体进展。

Method: 通过回顾显性或隐性的自动形式化实例，分析不同领域的研究成果，提出统一的框架来整合这些分散的研究方向。

Result: 识别了自动形式化在数学定理证明、推理、规划和知识表示等多个领域的应用实例，揭示了这些领域之间的内在联系和共同挑战。

Conclusion: 建立统一的自动形式化框架可以促进不同研究领域之间的交叉融合，加速下一代人工智能系统的发展，需要共享的方法论、基准测试和理论支持。

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [173] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 该研究开发了一个基于检索增强生成(RAG)的智能知识助手系统，专门用于山羊养殖健康管理，通过表格文本化和决策树文本化方法处理异构数据，在验证集和测试集上分别达到87.90%和84.22%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在畜牧业应用受限，主要由于知识源的可用性、多样性和复杂性不足，需要开发专门的知识处理方法来提升LLM在异构数据格式下的理解能力。

Method: 采用检索增强生成(RAG)技术，提出表格文本化和决策树文本化两种结构化知识处理方法，建立覆盖疾病防治、营养管理、饲养管理等五个关键领域的山羊养殖知识库，并集成在线搜索模块实现实时信息检索。

Result: 异构知识融合方法效果最佳，验证集准确率87.90%，测试集准确率84.22%。在文本、表格、决策树问答任务中准确率均超过85%，错误分析显示遗漏是主要错误类型。

Conclusion: 该系统在山羊养殖实际应用中表现出良好的鲁棒性和可靠性，结构化知识融合的模块化设计有效，为进一步提升检索覆盖率和上下文整合提供了改进方向。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [174] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: 本文研究了LLM在UNO纸牌游戏中作为助手的能力，发现虽然所有模型都能超越随机基线表现，但只有少数模型能显著帮助其他玩家获胜。


<details>
  <summary>Details</summary>
Motivation: 测试大型语言模型是否能作为主动参与者真正帮助用户实现目标，特别是在协作性游戏环境中评估其辅助能力。

Method: 构建工具让仅解码器LLM在RLCard游戏环境中作为代理参与UNO游戏，提供完整游戏状态信息，使用两种不同的提示策略，评估从1B到70B参数的不同规模模型。

Result: 所有模型在玩UNO时都能成功超越随机基线表现，但只有少数模型能够显著帮助其他玩家获胜，模型规模对性能有影响。

Conclusion: LLM在游戏环境中具备基本能力，但作为有效助手的能力有限，需要进一步研究如何提升其协作和辅助能力。

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [175] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: 该论文提出了一个概念框架，将科学工作流从静态单系统演进到智能群体系统，旨在实现完全自主的分布式科学实验室，加速科学发现。


<details>
  <summary>Details</summary>
Motivation: 现代科学发现需要协调分布式设施和异构资源，研究人员被迫成为手动工作流协调者而非科学家。AI智能体技术为加速科学发现提供了新机遇，但需要明确如何在实际中实现和集成。

Method: 提出一个二维演进框架：智能维度（从静态到智能）和组合维度（从单系统到群体），并提供了一个架构蓝图来指导社区向自主科学发展。

Result: 提出了从当前工作流管理系统到完全自主分布式科学实验室的演进路径，为利用AI智能体加速科学发现提供了系统性框架。

Conclusion: 该框架有潜力实现100倍的发现加速和变革性科学工作流，为自主科学领域的发展指明了方向。

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [176] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 将WaveFunctionCollapse重构为马尔可夫决策过程，分离局部约束满足和全局目标优化，相比传统联合优化方法在复杂任务中表现更优


<details>
  <summary>Details</summary>
Motivation: 解决程序化内容生成中需要同时满足设计者指定目标和瓦片集隐含邻接约束的挑战，传统联合优化方法在任务复杂度增加时表现不佳

Method: 将WaveFunctionCollapse重新表述为马尔可夫决策过程(MDP)，利用WFC的传播机制强制执行约束满足，让外部优化算法专注于目标最大化

Result: 在多个不同难度的领域中，联合优化方法随着任务复杂度增加而表现下降，且始终不如在WFC-MDP上进行优化的方法

Conclusion: 将局部约束满足与全局目标优化解耦具有明显优势，WFC-MDP方法在程序化内容生成中优于传统联合优化方法

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [177] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 该论文提出了基于实际因果关系的变量重要性度量方法，用于评估可解释AI工具在布尔函数预测中的表现，并开发了新的XAI工具B-ReX，在大型基准测试中优于其他黑盒XAI工具。


<details>
  <summary>Details</summary>
Motivation: 由于解释的主观性，评估可解释AI(XAI)方法具有挑战性。本文专注于表格数据和布尔函数预测的特定用例，旨在提供更精确的评估标准。

Method: 提出了基于实际因果关系的正式变量重要性度量方法，并开发了新的XAI工具B-ReX（基于现有ReX工具的改进）。

Result: B-ReX在随机10值布尔公式上实现了0.072±0.012的Jensen-Shannon散度，优于其他黑盒XAI工具。

Conclusion: 基于实际因果关系的度量方法为XAI评估提供了更精确的标准，B-ReX工具在布尔函数预测任务中表现出色，为黑盒XAI工具提供了有效的解决方案。

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [178] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: GAMA是一个保护隐私的多智能体系统，通过将工作空间分为私有和公共区域，使用匿名化机制处理敏感数据，结合知识增强和逻辑增强模块来减少语义损失。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多智能体系统中的广泛应用，当任务涉及隐私数据时，需要在不牺牲性能的前提下实现隐私保护，避免敏感信息泄露。

Method: 提出GAMA系统，将智能体工作空间划分为私有空间（处理敏感数据）和公共空间（仅使用匿名化数据），并引入基于领域规则的知识增强(DRKE)和基于反证的逻辑增强(DLE)模块来缓解匿名化带来的语义损失。

Result: 在两个公开问答数据集(Trivia Creative Writing和Logic Grid Puzzle)上表现优于最先进模型，在新设计的隐私保护数据集(Knowledge Privacy Preservation和Logic Privacy Preservation)上展现出卓越的隐私保护能力。

Conclusion: GAMA系统在保持任务处理性能的同时，有效实现了隐私保护，为大语言模型在多智能体系统中的安全应用提供了可行解决方案。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [179] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents是一个基于多极任务处理图和IF-THEN规则的多智能体协作框架，通过动态任务规划和规则约束来解决复杂任务中的不确定性，在知识型和逻辑型问答任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然提升了多智能体系统的能力，但在处理高度复杂且具有不确定性的任务时，仍然存在任务规划效果不佳的问题，容易产生误导性输出阻碍任务执行。

Method: 提出XAgents框架，使用多极任务处理图实现动态任务规划并处理任务不确定性，在子任务处理中集成领域特定的IF-THEN规则约束智能体行为，同时使用全局规则增强智能体间协作。

Result: 在三个不同数据集上的评估表明，XAgents在知识型和逻辑型问答任务中持续超越最先进的单智能体和多智能体方法。

Conclusion: XAgents通过创新的多极任务处理图和规则集成机制，有效解决了复杂任务规划中的不确定性挑战，为多智能体系统提供了更可靠的任务执行能力。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [180] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: 提出了AI Harmonics框架，这是一种基于实证事件数据的人类中心、危害严重性自适应AI风险评估方法，使用新的AI危害评估指标(AIH)来识别和优先处理AI危害


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估模型主要关注内部合规性，忽视了不同利益相关者视角和现实世界后果，需要转向更关注实际危害的人类中心方法

Method: 开发AI Harmonics框架，包括新颖的AIH指标，利用序数严重性数据捕捉相对影响而无需精确数值估计，结合稳健的通用方法和数据驱动的利益相关者感知框架

Result: 在标注事件数据上的实验证实政治和物理危害具有最高集中度，需要紧急缓解：政治危害侵蚀公众信任，物理危害构成严重甚至危及生命的风险

Conclusion: AI Harmonics能够持续识别不均匀的危害分布，使政策制定者和组织能够有效针对性地开展缓解工作，证明了该方法在现实世界中的相关性

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [181] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: 提出了"沙盒经济"框架来分析新兴的AI代理经济，将其分为涌现vs有意设计和可渗透vs不可渗透两个维度，讨论了当前趋势下的机遇与挑战，并提出了可引导AI代理市场的设计选择。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理的快速采用，正在形成超越人类直接监督规模的新经济层，需要框架来分析和引导这一新兴系统的发展。

Method: 提出沙盒经济分析框架，从起源（涌现/有意）和分离程度（可渗透/不可渗透）两个维度进行特征化分析，并探讨拍卖机制、AI"使命经济"设计和社会技术基础设施等解决方案。

Result: 识别出当前趋势指向自发涌现的大规模高度可渗透AI代理经济，既带来前所未有的协调机遇，也面临系统性经济风险和加剧不平等的挑战。

Conclusion: 主张通过主动设计可引导的代理市场，确保技术变革与人类长期集体繁荣相一致，需要采取拍卖机制、使命经济设计和社会技术基础设施等措施。

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [182] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 提出了Robust Sparse Sampling (RSS)算法，这是第一个具有有限样本理论性能保证的鲁棒MDP在线规划算法，能够在模型不确定环境下实现实时鲁棒规划。


<details>
  <summary>Details</summary>
Motivation: 传统在线规划方法如Sparse Sampling和MCTS在有限数据学习的生成模型中存在近似误差，可能导致性能下降或不安全行为。鲁棒MDP虽然提供了理论框架，但现有方法计算量大，不适合实时应用。

Method: RSS算法通过Sample Average Approximation (SAA)计算鲁棒价值函数，而不是名义价值函数。该方法适用于无限或连续状态空间，样本和计算复杂度与状态空间大小无关。

Result: RSS在动态不确定的环境中优于标准Sparse Sampling方法，具有理论性能保证，能够实现可处理的在线鲁棒策略计算。

Conclusion: RSS是第一个适用于鲁棒MDP的在线规划算法，解决了模型不确定性下的实时规划问题，为大规模动态环境中的安全决策提供了有效解决方案。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [183] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 提出基于LLM的多智能体框架，用于自动化多孔材料表征，包括文献提取力场和自动RASPA模拟设置


<details>
  <summary>Details</summary>
Motivation: 自动化多孔材料表征能加速材料发现，但目前受限于模拟设置和力场选择的复杂性

Method: 使用基于LLM的多智能体框架，让智能体自主理解表征任务、规划模拟、组装力场、执行模拟并解释结果

Result: 初步评估显示该方法具有高正确性和可重现性

Conclusion: 该方法有望实现完全自主、可扩展的材料表征

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [184] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: CARENLI是一个用于临床自然语言推理的模块化代理推理框架，通过将知识访问与原则推理分离，显著提高了推理准确性和可审计性


<details>
  <summary>Details</summary>
Motivation: 挑战数据规模和参数扩展会自动产生结构化、可泛化内部表示的假设，特别是在临床NLI领域需要更安全、可审计的推理方法

Method: 开发CARENLI框架，将前提-陈述对路由到四个特定推理家族的求解器，通过规划器、验证器和精炼器强制执行可审计程序

Result: 在四个LLM上，CARENLI将保真度提高了多达42个百分点，在因果归因中达到98.0%，在风险状态抽象中达到81.2%，验证器以接近完美的可靠性标记违规

Conclusion: LLMs通常保留相关事实但在推理未明确指定时默认使用启发式方法，CARENLI明确揭示了这种分离，同时提供了更安全、可审计的推理框架

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [185] [Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering](https://arxiv.org/abs/2509.10249)
*Hanna Abi Akl*

Main category: cs.AI

TL;DR: 研究表明用紧凑的逻辑语言替代自然语言可以在保持推理性能的同时提升小语言模型在推理任务中的表现，为小语言模型在ontology工程中的应用提供新方向


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在推理领域存在明显局限，特别是在ontology工程任务中表现不佳。研究旨在探索如何通过引入形式化方法来提升小语言模型在推理任务中的性能

Method: 通过一系列初步实验，研究不同语法表达逻辑问题对小语言模型在预定义推理任务中性能的影响，比较自然语言与紧凑逻辑语言的效果

Result: 研究发现使用更紧凑的逻辑语言替代自然语言可以在保持推理任务强性能的同时提升效率，这为小语言模型的应用提供了新可能

Conclusion: 该研究为小语言模型在ontology工程中的角色细化提供了基础，证明了形式化方法在提升语言模型推理能力方面的潜力

Abstract: Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.

</details>


### [186] [The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis](https://arxiv.org/abs/2509.10297)
*Eoin O'Doherty,Nicole Weinrauch,Andrew Talone,Uri Klempner,Xiaoyuan Yi,Xing Xie,Yi Zeng*

Main category: cs.AI

TL;DR: 本研究通过量化实验分析6个大型语言模型在18个道德困境中的表现，发现AI系统普遍偏向关怀和美德价值观，而惩罚自由主义选择，推理模型展现更好的情境敏感性和解释能力。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能快速发展，需要解决机器决策与人类道德价值观对齐的紧迫问题，探索AI系统如何优先考虑道德结果以及人类-AI共生的前景。

Method: 对6个大型语言模型进行定量实验，在代表5种道德框架的18个困境中对结果进行排序和评分，分析模型架构、文化起源和可解释性对道德偏好的影响。

Result: 发现所有模型都存在显著一致的价值偏见：关怀和美德价值观结果被评为最道德，自由主义选择被一致惩罚。推理模型对情境更敏感且提供更丰富的解释，非推理模型产生更统一但不透明的判断。

Conclusion: 研究在实证上提供了跨文化LLM道德推理的大规模比较，理论上将概率模型行为与基础价值编码联系起来，实践上强调可解释性和文化意识作为指导AI走向透明、对齐和共生未来的关键设计原则。

Abstract: Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.

</details>


### [187] [State Algebra for Propositional Logic](https://arxiv.org/abs/2509.10326)
*Dmitry Lesnik,Tobias Schäfer*

Main category: cs.AI

TL;DR: State Algebra是一个使用代数方法表示和操作命题逻辑的新框架，包含Set、Coordinate和Row Decomposition三种层次化表示，在保持语义清晰的同时提供计算灵活性。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够灵活表示命题逻辑并支持高效计算的代数框架，为搜索算法和知识编译提供统一工具，并扩展到概率逻辑和加权模型计数。

Method: 构建三层表示层次结构，通过代数引擎进行计算，采用固定变量顺序获得规范形式，在规范性和灵活性之间取得平衡。

Result: 框架虽然默认状态向量约简不是规范的，但通过固定变量顺序可以获得唯一规范形式，为特定问题类别提供更紧凑的表示。

Conclusion: State Algebra提供了一个强大而灵活的代数框架，能够统一表示和操作命题逻辑，为多种算法提供支持并具有向概率领域扩展的潜力。

Abstract: This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.

</details>


### [188] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: A2P Scaffolding是一个新的多智能体系统故障归因框架，通过结构化因果推理（反事实推理）将故障归因从模式识别任务转变为因果推理任务，显著提高了步骤级准确率。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统中的故障归因方法准确率极低（低于17%），无法进行有效的反事实推理来确定纠正单个动作是否能避免任务失败，这限制了复杂系统的调试能力。

Method: 提出了Abduct-Act-Predict（A2P）Scaffolding框架，通过三步推理过程：1）溯因推理推断行动背后的隐藏原因；2）定义最小纠正干预；3）模拟后续轨迹验证干预是否解决问题。

Result: 在Algorithm-Generated数据集上达到47.46%的步骤级准确率（比基线的16.67%提高2.85倍），在Hand-Crafted数据集上达到29.31%准确率（比基线的12.07%提高2.43倍）。

Conclusion: 通过因果推理的视角重构问题，A2P Scaffolding为自动化故障归因提供了更稳健、可验证且准确度显著更高的解决方案。

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


### [189] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 提出基于信息论的框架，通过分析状态-动作互信息模式来诊断RL系统部署时的异常，能够区分传感器故障和执行器故障，为自适应RL系统提供自主故障检测基础


<details>
  <summary>Details</summary>
Motivation: 现实世界中部署的RL智能体面临传感器故障、执行器磨损和环境变化等问题，但缺乏内在机制来检测和诊断这些故障

Method: 信息论框架，分析状态-动作互信息模式，通过控制扰动实验验证诊断能力

Result: 成功学习表现出特征性信息特征：状态-动作互信息从0.84增长到2.83比特（238%增长）；信息指标能够区分系统故障类型：状态噪声导致所有信息通道崩溃，动作噪声则选择性地破坏动作-结果可预测性

Conclusion: 信息模式既是学习的特征，也是系统健康的诊断工具，为基于信息论原理的自适应RL系统提供自主故障检测和策略调整的基础

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [190] [The high-order Hermite discrete correction function method for surface-driven electromagnetic problems](https://arxiv.org/abs/2509.09857)
*Yann-Meing Law*

Main category: math.NA

TL;DR: 提出了一种新的离散校正函数方法，用于解决Hermite-Taylor方法在边界和界面条件处理上的挑战，实现了高阶收敛精度。


<details>
  <summary>Details</summary>
Motivation: Hermite-Taylor方法虽然能实现高阶收敛，但在交错笛卡尔网格上处理边界和界面条件时面临数据需求挑战，需要一种有效的方法来提供边界附近所需的所有数据。

Method: 提出了离散校正函数方法，为Hermite方法在边界条件执行表面附近提供所有必需数据，该方法可处理变系数、界面处不连续解和广义薄层过渡条件等问题。

Result: 通过二维空间中的多个数值算例验证了方法的性能，包括长时间模拟，证明了该方法的高阶精度和灵活性。

Conclusion: 离散校正函数方法成功解决了Hermite-Taylor方法的边界处理难题，虽然主要针对麦克斯韦方程，但可推广到其他线性波系统，具有很好的适应性和扩展性。

Abstract: The Hermite-Taylor method evolves all the variables and their derivatives
through order $m$ in time to achieve a $2m+1$ order rate of convergence. The
data required at each node of the staggered Cartesian meshes used by this
method makes the enforcement of boundary and interface conditions challenging.
In this work, we propose a novel correction function method, referred to as the
discrete correction function method, which provides all the data required by
the Hermite method near the surface where a condition is enforced. The
flexibility of the resulting Hermite-Taylor discrete correction function method
is demonstrated by considering a wide range of problems, including those with
variable coefficients, discontinuous solutions at the interface, and
generalized sheet transition conditions. Although the focus of this work is on
Maxwell's equations, this high-order method can be adapted to other linear wave
systems. Several numerical examples in two space dimensions are performed to
verify the properties of the proposed method, including long-time simulations.

</details>


### [191] [A streamline upwind/Petrov-Galerkin method for the magnetic advection-diffusion problem](https://arxiv.org/abs/2509.09913)
*Haochen Li,Yangfan Luo,Jindong Wang,Shuonan Wu*

Main category: math.NA

TL;DR: 本文开发了一种用于磁对流-扩散问题的流线迎风/Petrov-Galerkin (SUPG) 方法，通过引入提升算子和基于残差的稳定化项，建立了稳定的数值格式并获得了最优误差估计。


<details>
  <summary>Details</summary>
Motivation: 磁对流-扩散问题在数值模拟中容易出现数值振荡，特别是在尖锐层区域。需要开发有效的稳定化方法来抑制这些数值不稳定性，提高计算精度。

Method: 提出基于残差和加权对流项的SUPG型稳定化项，引入提升算子来刻画有限元函数在单元界面上的跳跃，定义离散磁对流算子，进而构建SUPG方法。还提出了依赖残差的非线性稳定化扩展。

Result: 在温和假设下建立了格式的稳定性，推导了最优误差估计。二维和三维数值算例验证了理论收敛性和稳定化特性，非线性扩展能更有效地减少尖锐层中的数值振荡。

Conclusion: 所提出的SUPG方法为磁对流-扩散问题提供了有效的数值求解方案，具有理论保证的稳定性和收敛性，非线性扩展进一步提升了在复杂流动情况下的数值性能。

Abstract: This paper presents the development and analysis of a streamline
upwind/Petrov-Galerkin (SUPG) method for the magnetic advection-diffusion
problem. A key feature of the method is an SUPG-type stabilization term based
on the residuals and weighted advection terms of the test function. By
introducing a lifting operator to characterize the jumps of finite element
functions across element interfaces, we define a discrete magnetic advection
operator, which subsequently enables the formulation of the desired SUPG
method. Under mild assumptions, we establish the stability of the scheme and
derive optimal error estimates. Furthermore, by introducing a stabilization
term that depends on the residual, we propose a nonlinear extension aimed at
more effectively reducing numerical oscillations in sharp layers. Numerical
examples in both two and three dimensions are provided to demonstrate the
theoretical convergence and stabilization properties of the proposed method.

</details>


### [192] [Perfectly transparent boundary conditions and wave propagation in lattice Boltzmann schemes](https://arxiv.org/abs/2509.10066)
*Thomas Bellotti*

Main category: math.NA

TL;DR: 本文提出了一种为晶格玻尔兹曼方法开发完美透明边界条件的系统方法，能够吸收所有物理波和寄生波，解决有界域模拟中的边界反射问题。


<details>
  <summary>Details</summary>
Motivation: 双曲守恒律系统在有限域模拟时，人工边界会像镜子一样产生污染性反射波。现有方法难以同时处理物理波和数值寄生波，需要开发能够完全吸收所有频率波的透明边界条件。

Method: 采用"标量"方法，通过计算体格式色散关系根在无穷远处的洛朗级数系数来构造边界条件。利用解析组合学的渐近分析指导边界条件的截断和数值计算。

Result: 在1D和2D问题中进行了大量数值实验，验证了所提边界条件的有效性，能够完美吸收物理波和寄生波。

Conclusion: 该方法为晶格玻尔兹曼方法提供了一种系统构建完美透明边界条件的途径，特别适用于处理q>N情况下的多步格式，具有重要的理论和实用价值。

Abstract: Systems of N = 1, 2, . . . first-order hyperbolic conservation laws feature N
undamped waves propagating at finite speeds. On their own hand, multi-step
Finite Difference and lattice Boltzmann schemes with q = N + 1, N + 2, . . .
unknowns involve N ''physical'' waves, which are aimed at being as
closely-looking as possible to the ones of the PDEs, and q-N
''numerical-spurious-parasitic'' waves, which are subject to their own speed of
propagation, and either damped or undamped. The whole picture is even more
complicated in the discrete setting-as numerical schemes act as dispersive
media, thus propagate different harmonics at different phase (and group)
velocities. For compelling practical reasons, simulations must always be
conducted on bounded domains, even when the target problem is unbounded in
space. The importance of transparent boundary conditions, preventing artificial
boundaries from acting as mirrors producing polluting ricochets, naturally
follows. This work presents, building on Besse, Coulombel, and Noble [ESAIM:
M2AN, 55 (2021)], a systematic way of developing perfectly transparent boundary
conditions for lattice Boltzmann schemes tackling linear problems in one and
two space dimensions. Our boundary conditions are ''perfectly'' transparent, at
least for 1D problems, as they absorb both physical and spurious waves
regardless of their frequency. After presenting, in a simple framework, several
approaches to handle the fact that q > N , we elect the so-called ''scalar''
approach (which despite its name, also works when N > 1) as method of choice
for more involved problems. This method solely relies on computing the
coefficients of the Laurent series at infinity of the roots of the dispersion
relation of the bulk scheme. We insist on asymptotics for these coefficients in
the spirit of analytic combinatorics. The reason is two-fold: asymptotics guide
truncation of boundary conditions to make them depending on a fixed number of
past time-steps, and make it clearduring the process of computing
coefficients-whether intermediate quantities can be safely stored using
floating-point arithmetic or not. Numerous numerical investigations in 1D and
2D with N = 1 and 2 are carried out, and show the effectiveness of the proposed
boundary conditions.

</details>


### [193] [A Spectral Localization Method for Time-Fractional Integro-Differential Equations with Nonsmooth Data](https://arxiv.org/abs/2509.10091)
*Lijing Zhao,Rui Zhao,Wenyi Tian,Yufeng Nie*

Main category: math.NA

TL;DR: 提出了一个针对时间分数阶积分-微分方程的低正则性局部数值格式，结合轮廓积分法(CIM)和有限元法(FEM)，实现了时间上的谱精度和空间上的二阶收敛


<details>
  <summary>Details</summary>
Motivation: 时间分数阶积分-微分方程具有非局部特性，传统数值方法对解的正则性要求较高，且计算成本大。需要开发低正则性要求、高精度且计算高效的数值方法

Method: 采用轮廓积分法(CIM)进行时间离散化，使用参数化双曲轮廓逼近非局部算子；空间离散化采用标准分段线性Galerkin有限元法(FEM)；构建完全离散数值格式并进行严格误差分析

Result: 数值格式对非光滑/消失初值或低正则性解问题仍能实现高精度，时间上具有谱精度，空间上达到二阶收敛；1-D和2-D数值实验验证了理论结果，算法兼具谱精度、低计算成本和高效内存使用的优势

Conclusion: 所提出的局部数值格式成功解决了时间分数阶积分-微分方程的低正则性计算问题，为处理此类非局部问题提供了高效可靠的数值工具

Abstract: In this work, we develop a localized numerical scheme with low regularity
requirements for solving time-fractional integro-differential equations. First,
a fully discrete numerical scheme is constructed. Specifically, for temporal
discretization, we employ the contour integral method (CIM) with parameterized
hyperbolic contours to approximate the nonlocal operators. For spatial
discretization, the standard piecewise linear Galerkin finite element method
(FEM) is used. We then provide a rigorous error analysis, demonstrating that
the proposed scheme achieves high accuracy even for problems with
nonsmooth/vanishing initial values or low-regularity solutions, featuring
spectral accuracy in time and second-order convergence in space. Finally, a
series of numerical experiments in both 1-D and 2-D validate the theoretical
findings and confirm that the algorithm combines the advantages of spectral
accuracy, low computational cost, and efficient memory usage.

</details>


### [194] [Neural network-based singularity detection and applications](https://arxiv.org/abs/2509.10110)
*Nadiia Derevianko,Ioannis G. Kevrekidis,Felix Dietrich*

Main category: math.NA

TL;DR: 提出一种构建浅层神经网络的方法，用于学习具有极点型奇点的单变量亚纯函数，通过Laurent系数和自适应有理激活函数来定位奇点并实现函数逼近。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络在处理具有奇点的亚纯函数时存在困难，需要一种能够有效捕捉函数奇点特性并实现精确逼近的新方法。

Method: 基于FFT计算Laurent系数，使用具有单极点的有理激活函数，通过无反向传播的方法确定隐藏层权重偏置，输出层采用最小二乘拟合，利用Laurent-Padé有理逼近概念。

Result: 方法能够有效定位函数奇点，实现局部一致收敛，在数值实验中成功构建非线性自治PDE时间相关解的复平面延拓，并研究其奇点动力学。

Conclusion: 该方法为学习具有奇点的亚纯函数提供了一种有效的神经网络架构，突破了传统有理激活函数的限制，在函数逼近和奇点分析方面表现出色。

Abstract: We present a method for constructing a special type of shallow neural network
that learns univariate meromorphic functions with pole-type singularities. Our
method is based on using a finite set of Laurent coefficients as input
information, which we compute by FFT, employing values of the investigated
function on some contour $\Gamma$ in the complex plane. The primary components
of our methodology are the following: (1) the adaptive construction of rational
polynomial activation functions, (2) a novel backpropagation-free method for
determining the weights and biases of the hidden layer, and (3) the computation
of the weights and biases of the output layer through least-squares fitting.
Breaking with the idea of "safe" rational activation functions, we introduce a
rational activation function as a meromorphic function with a single pole
situated within the domain of investigation. Employing the weights and biases
of the hidden layer, we then scale and shift the pole of the activation
function to find the estimated locations of the singularities; this implies
that the number of neurons in the hidden layer is determined by the number of
singularities of the function that is being approximated. While the weights and
biases of the hidden layer are tuned so as to capture the singularities, the
least-squares fitting for the computation of weights and biases of the output
layer ensures approximation of the function in the rest of the domain. Through
the use of Laurent-Pad\'e rational approximation concepts, we prove locally
uniform convergence of our method. We illustrate the effectiveness of our
method through numerical experiments, including the construction of extensions
of the time-dependent solutions of nonlinear autonomous PDEs into the complex
plane, and study the dynamics of their singularities.

</details>


### [195] [The low-rank tensor-train finite difference method for three-dimensional parabolic equations](https://arxiv.org/abs/2509.10142)
*Gianmarco Manzini,Tommaso Sorgente*

Main category: math.NA

TL;DR: 本文提出了一个基于张量列格式的三维抛物问题低秩近似数值框架，结合有限差分法和时间推进方案，通过矩阵自由预条件共轭梯度法高效求解，显著节省时间和内存。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在处理高维抛物问题时面临的计算复杂度和内存需求过高的问题，寻求一种既能保持精度又能大幅降低计算成本的新方法。

Method: 采用张量列重构的二阶精确有限差分法，结合显式/隐式欧拉法和Crank-Nicolson法进行时间推进，使用专门设计的矩阵自由预条件共轭梯度法求解线性系统。

Result: 数值实验表明该方法在保证与传统方法几乎相同精度的同时，实现了巨大的时间和内存节省，特别适合处理高维挑战性问题。

Conclusion: 张量列格式为三维抛物问题提供了鲁棒且高效的替代方案，在高维问题中具有显著优势。

Abstract: This paper presents a numerical framework for the low-rank approximation of
the solution to three-dimensional parabolic problems. The key contribution of
this work is the tensorization process based on a tensor-train reformulation of
the second-order accurate finite difference method. We advance the solution in
time by combining the finite difference method with an explicit and implicit
Euler method and with the Crank-Nicolson method. We solve the linear system
arising at each time step from the implicit and semi-implicit time-marching
schemes through a matrix-free preconditioned conjugate gradient (PCG) method,
appositely designed to exploit the separation of variables induced by the
tensor-train format. We assess the performance of our method through extensive
numerical experimentation, demonstrating that the tensor-train design offers a
robust and highly efficient alternative to the traditional approach. Indeed,
the usage of this type of representation leads to massive time and memory
savings while guaranteeing almost identical accuracy with respect to the
traditional one. These features make the method particularly suitable to tackle
challenging high-dimensional problems.

</details>


### [196] [The unified gas kinetic wave-particle method for the neutron transport equation](https://arxiv.org/abs/2509.10178)
*Guangwei Liu,Shuang Tan,Yanli Wang*

Main category: math.NA

TL;DR: 提出了统一的动理学波-粒子方法(UGKWP)用于中子输运方程，该方法能够处理中子传播在光学薄和厚区域的多尺度特性，在统一的时间相关框架中耦合宏观扩散和微观输运过程。


<details>
  <summary>Details</summary>
Motivation: 解决中子输运方程中固有的多尺度特性问题，特别是在光学薄和厚区域的中子传播，需要一种能够在自由输运和扩散机制之间平滑过渡的统一方法。

Method: UGKWP方法在统一的时间相关框架中耦合宏观扩散和微观输运过程，可以扩展到多群中子输运模型，适用于稳态和本征值问题。

Result: 通过1D和3D单群以及3D多群问题的数值算例验证，表明UGKWP是一个有前景的框架，能够在复杂几何中进行可扩展且准确的多群中子输运模拟。

Conclusion: UGKWP方法为多尺度中子输运问题提供了一个有效的统一框架，在复杂几何中展现出良好的可扩展性和计算精度。

Abstract: The unified gas-kinetic wave-particle (UGKWP) method is proposed for the
neutron transport equation, addressing the inherent multiscale nature of
neutron propagation in both optically thin and thick regimes. UGKWP couples
macroscopic diffusion and microscopic transport processes within a unified
time-dependent framework, allowing a smooth transition between the free
transport and diffusion regimes. This method is readily extended to multi-group
neutron transport models and is applicable to both steady-state and eigenvalue
problems. Several numerical examples, including the 1D and 3D single-group and
3D multi-group problems, are studied, indicating UGKWP a promising framework
for scalable and accurate simulation of multigroup neutron transport in complex
geometries.

</details>


### [197] [Convergence to equilibrium for fully discretizations of nonlocal Cahn-Hilliard equation](https://arxiv.org/abs/2509.10180)
*Danni Zhang,Dongling Wang*

Main category: math.NA

TL;DR: 本文研究了非局部Cahn-Hilliard方程的数值离散方法，构建了能量稳定的全离散格式，并证明了数值解在时间趋于无穷时收敛到平衡态


<details>
  <summary>Details</summary>
Motivation: 非局部Cahn-Hilliard方程能更准确描述材料微观结构相变现象，但由于非局部积分项的复杂性和缺乏高阶扩散项，研究其长期渐近行为具有挑战性

Method: 分别采用一阶和二阶时间离散方法，结合二阶有限差分空间近似，构建能量稳定的全离散数值格式

Result: 基于能量稳定性和Łojasiewicz不等式，严格证明了这些全离散数值格式的数值解随时间趋于无穷收敛到平衡态

Conclusion: 成功建立了非局部Cahn-Hilliard方程的能量稳定数值格式，并证明了其长期收敛性，为该类方程的计算研究提供了理论基础

Abstract: The study of long-term dynamics for numerical solutions of nonlinear
evolution equations, particularly phase field models, has consistently garnered
considerable attention. The Cahn-Hilliard (CH) equation is one of the most
important phase field models and is widely applied in materials science. In
order to more accurately describe the practical phenomena in material
microstructural phase transitions, the Nonlocal Cahn-Hilliard (N-CH) equation
incorporates a finite range of spatial nonlocal interactions is introduced,
which is a generalization of the classic CH equation. However, compared to its
classic counterpart, it is very challenging to investigate the long-term
asymptotic behavior of solution to the N-CH equation due to the complexity of
the nonlocal integral term and the lack of high-order diffusion term. In this
paper, we consider first-order and second-order temporal discretization methods
for the N-CH equation, respectively, while utilizing a second-order finite
difference method for spatial approximation to construct the energy stable
fully discrete numerical schemes. Based on energy stability and the
{\L}ojasiewicz inequality, we rigorously prove that the numerical solutions of
these fully discrete numerical schemes converge to equilibrium as time goes to
infinity.

</details>


### [198] [Matrix-Free Evaluation Strategies for Continuous and Discontinuous Galerkin Discretizations on Unstructured Tetrahedral Grids](https://arxiv.org/abs/2509.10226)
*Dominik Still,Niklas Fehn,Wolfgang A. Wall,Martin Kronbichler*

Main category: math.NA

TL;DR: 该研究提出了改进非结构化四面体网格上连续和不连续Galerkin空间离散化矩阵自由评估节点级性能的新策略，通过密集矩阵-矩阵乘积和层次网格重排序算法，实现了比全局稀疏矩阵方法高达6倍的加速。


<details>
  <summary>Details</summary>
Motivation: 提高有限元算子在非结构化四面体网格上的计算效率，特别是针对低到中阶多项式度的矩阵自由评估，以解决大规模实际问题的计算需求。

Method: 采用单元级数值积分方法，使用形状函数的密集局部矩阵表，通过密集矩阵-矩阵乘积代替矩阵-向量乘积进行单元插值，结合层次网格重排序算法改善数据局部性，并在预处理器中混合使用矩阵自由和矩阵基策略。

Result: 该方法达到了峰值性能的60%以上，在多项式度为三时比全局稀疏矩阵方法快6倍，通过Poisson和Navier-Stokes方程的数值实验验证了有效性，并展示了良好的强扩展性能。

Conclusion: 所提出的矩阵自由方法通过优化计算策略和数据局部性，显著提高了有限元离散化的计算效率，具有解决大规模实际问题的潜力，特别是在混合多网格预处理器中灵活使用不同策略可获得最佳效率。

Abstract: This study presents novel strategies for improving the node-level performance
of matrix-free evaluation of continuous and discontinuous Galerkin spatial
discretizations on unstructured tetrahedral grids. In our approach the
underlying integrals of a generic finite-element operator are computed
cell-by-cell through numerical quadrature using tabulated dense local matrices
of shape functions, achieving high throughput for low to moderate-order
polynomial degrees. By employing dense matrix-matrix products instead of
matrix-vector products for the cell-wise interpolation, the method reaches over
$60\%$ of peak performance. The optimization strategies exploit explicit data
parallelism to enhance computational efficiency, complemented by a hierarchical
mesh reordering algorithm that improves data locality. The matrix-free
implementation achieves up to a $6\times$ speedup compared to a global sparse
matrix-based approach at a polynomial degree of three. The effectiveness of the
method is demonstrated through numerical experiments on the Poisson and
Navier--Stokes equations. The Poisson operator is preconditioned by a hybrid
multigrid scheme that combines auxiliary continuous finite-element spaces,
polynomial and geometric coarsening where possible while employing algebraic
multigrid on the coarse mesh. Within the preconditioner, the implementation
transitions between the matrix-free and matrix-based strategies for optimal
efficiency. Finally, we analyze the strong scaling behavior of the Poisson and
Helmholtz operators, demonstrating the method's potential to solve large
real-world problems.

</details>


### [199] [Near-Optimal Recovery Performance of PhaseLift for Phase Retrieval from Coded Diffraction Patterns](https://arxiv.org/abs/2509.10300)
*Meng Huang,Jinming Wen,Ran Zhang*

Main category: math.NA

TL;DR: 本文针对PhaseLift算法在噪声CDP测量下的恢复稳定性问题，证明了近乎最优的恢复误差界，验证了Soltanolkotabi关于误差按平均噪声幅度缩放的猜想。


<details>
  <summary>Details</summary>
Motivation: 现有PhaseLift算法在噪声情况下的恢复误差界为O(‖w‖₂)，被认为不是最优的。Soltanolkotabi猜想最优界应为O(‖w‖₂/√m)，即按平均噪声幅度缩放，但理论证明一直是个开放问题。

Method: 通过理论分析，针对对抗性噪声建立了O(log n · ‖w‖₂/√m)的上界和O(1/√log n · ‖w‖₂/√m)的下界；对于零均值次高斯噪声，建立了O(σ√(n log⁴n/m))的上界并提供了相应的极小极大下界。

Result: 证明了在对抗性噪声下，PhaseLift的恢复误差界为O(log n · ‖w‖₂/√m)，且存在噪声向量使得误差下界超过O(1/√log n · ‖w‖₂/√m)。对于次高斯噪声，获得了O(σ√(n log⁴n/m))的误差界。

Conclusion: 研究结果在log因子范围内验证了Soltanolkotabi的猜想，为PhaseLift在噪声CDP测量下的稳定性提供了新的理论见解，表明恢复误差确实按平均噪声幅度缩放。

Abstract: The PhaseLift algorithm is an effective convex method for solving the phase
retrieval problem from Fourier measurements with coded diffraction patterns
(CDP). While exact reconstruction guarantees are well-established in the
noiseless case, the stability of recovery under noise remains less well
understood. In particular, when the measurements are corrupted by an additive
noise vector $\mathbf{w} \in \mathbb{R}^m$, existing recovery bounds scale on
the order of $\|\mathbf{w}\|_2$, which is conjectured to be suboptimal. More
recently, Soltanolkotabi conjectured that the optimal PhaseLift recovery bound
should scale with the average noise magnitude, that is, on the order of
$\|\mathbf{w}\|_2/\sqrt m$. However, establishing this theoretically is
considerably more challenging and has remained an open problem. In this paper,
we focus on this conjecture and provide a nearly optimal recovery bound for it.
We prove that under adversarial noise, the recovery error of PhaseLift is
bounded by $O(\log n \cdot \|\mathbf{w}\|_2/\sqrt m)$, and further show that
there exists a noise vector for which the error lower bound exceeds
$O\bigl(\frac{1}{\sqrt{\log n}} \cdot \frac{\|\mathbf{w}\|_2}{\sqrt m}\bigr)$.
Here, $n$ is the dimension of the signals we aim to recover. Moreover, for
mean-zero sub-Gaussian noise vector $\mathbf{w} \in \mathbb R^m$ with
sub-Gaussian norm $\sigma$, we establish a bound of order $O\bigl(\sigma
\sqrt{\frac{n \log^4 n}{m}}\bigr)$, and also provide a corresponding minimax
lower bound. Our results affirm Soltanolkotabi's conjecture up to logarithmic
factors, providing a new insight into the stability of PhaseLift under noisy
CDP measurements.

</details>


### [200] [Structure-Preserving High-Order Methods for the Compressible Euler Equations in Potential Temperature Formulation for Atmospheric Flows](https://arxiv.org/abs/2509.10311)
*Marco Artiano,Oswald Knoth,Peter Spichtinger,Hendrik Ranocha*

Main category: math.NA

TL;DR: 本文开发了可压缩欧拉方程的结构保持数值方法，使用位温作为预报变量，构建了三种数值通量来确保在一般曲线网格上的不连续伽辽金框架中的熵和总能守恒。


<details>
  <summary>Details</summary>
Motivation: 开发能够保持物理结构（如熵和能量守恒）的数值方法，特别是在存在重力势能项的情况下，为大气模拟提供更准确和稳定的数值方案。

Method: 采用位温作为预报变量，构建三种数值通量，使用通量差分方法离散源项（作为非保守乘积处理），在一般曲线网格上实现不连续伽辽金离散。

Result: 提出了针对不同常数背景状态的平衡格式，验证了位温公式与传统欧拉方程公式在多种经典大气场景中的性能。

Conclusion: 所开发的数值方法能够有效保持熵和能量守恒特性，在复杂大气模拟场景中表现出良好的性能，为高精度大气数值模拟提供了可靠的工具。

Abstract: We develop structure-preserving numerical methods for the compressible Euler
equations, employing potential temperature as a prognostic variable.We
construct three numerical fluxes designed to ensure the conservation of entropy
and total energy within the discontinuous Galerkin framework on general
curvilinear meshes.Furthermore, we introduce a generalization for the kinetic
energy preservation property and total energy conservation in the presence of a
gravitational potential term. To this end, we adopt a flux-differencing
approach for the discretization of the source term, treated as non-conservative
product. We present well-balanced schemes for different constant background
states for both formulations (total energy and potential temperature) on
curvilinear meshes. Finally, we validate the methods by comparing the potential
temperature formulation with the traditional Euler equations formulation across
a range of classical atmospheric scenarios.

</details>


### [201] [Numerical analysis of the large deviation regime of a kinetic equation with a nonlocal Hamilton-Jacobi limit](https://arxiv.org/abs/2509.10323)
*Hélène Hivert,Tino Laidin*

Main category: math.NA

TL;DR: 本文开发了一种渐近保持(AP)数值格式，用于处理大偏差区域中的线性动力学方程，通过Hopf-Cole变换处理稀有事件行为，有效克服尺度刚度问题。


<details>
  <summary>Details</summary>
Motivation: 针对线性动力学方程在大偏差区域中的数值求解问题，传统方法在处理尺度刚度时计算成本高且难以保持渐近性质，需要开发能够统一处理不同尺度且计算成本恒定的数值方法。

Method: 采用Hopf-Cole变换处理分布函数，利用原始动力学模型的守恒性质设计数值格式，满足离散最大值原理，保持平衡状态，并通过离散表示公式建立数值格式与连续设置的联系。

Result: 所提方案能够有效处理尺度引入的刚度问题，计算成本相对于小参数保持恒定，正确捕捉渐近极限，恢复极限非局部Hamilton-Jacobi方程的粘性解。

Conclusion: 该渐近保持格式在理论和数值上均表现出色，为处理非标准极限问题提供了新的分析工具，数值测试验证了方案的鲁棒性和极限系统的原始行为。

Abstract: We develop and study an asymptotic-preserving (AP) numerical scheme for a
linear kinetic equation in a large deviation regime. After applying a Hopf-Cole
transform to the distribution function, the system exhibits the behavior of
rare events, which in the limit is governed by a non-standard, nonlocal
Hamilton-Jacobi equation, as identified in [E. Bouin et al., J. Lond. Math.
Soc., II. Ser., 2023].
  The proposed scheme efficiently handles the stiffness introduced by scaling,
with a computational cost that remains uniform with respect to the small
parameter. It takes advantage of the conservation properties of the original
kinetic model to overcome the numerical challenges posed by stiffness. The
scheme satisfies a discrete maximum principle, preserves equilibrium states,
and correctly captures the asymptotic limit, recovering the viscosity solution
of the limit nonlocal Hamilton-Jacobi equation.
  As the limit problem is non-standard, convergence results from the literature
are not directly applicable. We introduce new analytical tools based on a
discrete representation formula that links the numerical scheme with the
continuous setting. This allows us to prove the convergence and establish key
structural properties of the method. Numerical tests support the analysis and
illustrate the robustness of the scheme and the original behavior of the limit
system.

</details>


### [202] [Mathematical and numerical study of symmetry and positivity of the tensor-valued spring constant defined from P1-FEM for two- and three-dimensional linear elasticity](https://arxiv.org/abs/2509.10335)
*Oussama Ounissi,Masato Kimura,Hirofumi Notsu*

Main category: math.NA

TL;DR: 本文通过P1有限元方法推导了弹簧-块体系统中弹簧常数的对称性和正定性，为2D和3D弹性体断裂模拟提供了理论保证。


<details>
  <summary>Details</summary>
Motivation: 研究弹簧-块体系统中弹簧常数的数学性质，为弹性体断裂模拟提供理论基础，特别是对称性和正定性对数值模拟的稳定性至关重要。

Method: 使用P1有限元方法和三角形网格处理线性弹性方程，推导d×d矩阵作为弹簧常数，并对其进行数学分析。

Result: 成功证明了弹簧常数矩阵的对称性（统一适用于2D和3D），并给出了各向同性弹性张量下正定性的充要条件以及基于网格规则性和泊松比的充分条件。

Conclusion: 理论分析得到数值实验支持，证明了有限元方法导出的弹簧常数在弹性体断裂模拟中的正定性具有重要作用。

Abstract: In this study, we consider a spring-block system that approximates a
$d$-dimensional linear elastic body, where $d=2$ or $d=3$. We derive a $d\times
d$ matrix as the spring constant using the P1 finite element method with a
triangular mesh for the linear elasticity equations. We mathematically analyze
the symmetry and positive-definiteness of the spring constant. Even if we
assume full symmetry of the elasticity tensor, the symmetry of the matrix
obtained as the spring constant is not trivial. However, we have succeeded in
proving this in a unified manner for both 2D and 3D cases. This is an
alternative proof for the 2D case in Notsu-Kimura (2014) and is a new result
for the 3D case. We provide a necessary and sufficient condition for the spring
constant to be positive-definite in the case of an isotropic elasticity tensor,
along with a sufficient condition in terms of mesh regularity and the Poisson
ratio. These theoretical results are supported by several numerical
experiments. The positive-definiteness of the spring constant derived from the
finite element method plays a vital role in fracture simulations of elastic
bodies using the spring-block system.

</details>


### [203] [Multiscaling in Wasserstein Spaces](https://arxiv.org/abs/2509.10415)
*Wael Mattar,Nir Sharon*

Main category: math.NA

TL;DR: 提出了一种基于Wasserstein空间的多尺度分析框架，用于分析概率测度序列，通过最优传输的几何结构构建多尺度变换，并引入最优性数来检测异常和动态不规则性。


<details>
  <summary>Details</summary>
Motivation: 现有的多尺度分析方法主要针对函数空间，而概率测度序列在Wasserstein空间中的分析缺乏有效的多尺度工具。需要一种能够保持测度流几何结构并检测异常动态的方法。

Method: 利用最优传输的固有几何结构，构建基于McCann插值的细化算子作为上采样机制，创建多尺度变换。引入最优性数量化序列与Wasserstein测地线的偏差。

Result: 建立了变换的稳定性和系数几何衰减等理论保证，通过数值实验验证了方法在高斯流去噪、点云动态分析和神经网络学习轨迹多尺度表征中的有效性。

Conclusion: 该框架为Wasserstein空间中的概率测度序列分析提供了强大的多尺度工具，能够有效检测异常和表征复杂动态，具有广泛的应用前景。

Abstract: We present a novel multiscale framework for analyzing sequences of
probability measures in Wasserstein spaces over Euclidean domains. Exploiting
the intrinsic geometry of optimal transport, we construct a multiscale
transform applicable to both absolutely continuous and discrete measures.
Central to our approach is a refinement operator based on McCann's
interpolants, which preserves the geodesic structure of measure flows and
serves as an upsampling mechanism. Building on this, we introduce the
optimality number, a scalar that quantifies deviations of a sequence from
Wasserstein geodesicity across scales, enabling the detection of irregular
dynamics and anomalies. We establish key theoretical guarantees, including
stability of the transform and geometric decay of coefficients, ensuring
robustness and interpretability of the multiscale representation. Finally, we
demonstrate the versatility of our methodology through numerical experiments:
denoising and anomaly detection in Gaussian flows, analysis of point cloud
dynamics under vector fields, and the multiscale characterization of neural
network learning trajectories.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [204] [Pump-driven droplet electrohydrodynamics: deformation, pinch-off and recoalescence](https://arxiv.org/abs/2509.09834)
*Yuzhe Qin,Huaxiong Huang,Zilong Song,Shixin Xu*

Main category: physics.flu-dyn

TL;DR: 本文研究了泵驱动液滴的电流体动力学，重点关注变形、断裂和再聚结现象。通过建立热力学一致的相场框架，揭示了界面离子泵如何通过内部驱动机制控制液滴形态和动力学。


<details>
  <summary>Details</summary>
Motivation: 研究泵驱动液滴电流体动力学的动机在于探索内部驱动机制如何影响液滴的形态变化和动态行为，特别是在电场作用下的变形、断裂和再聚结过程。

Method: 开发了热力学一致的相场框架，耦合了Nernst-Planck-Poisson电扩散与不可压缩Navier-Stokes-Cahn-Hilliard流动，并引入了界面离子泵作为预设表面通量。

Result: 研究发现：无泵情况下液滴仅被极化而变形可忽略；泵驱动导致正离子在液滴内积累，产生不均匀电场和洛伦兹应力，引发拉伸、断裂和再聚结；多液滴系统中产生静电排斥和不对称变形；在几何约束下出现新月形弯曲和星状形态；剪切流测试显示泵驱动液滴可被固定和破裂。

Conclusion: 界面泵作为一种内部驱动机制，能够稳健地控制各种配置下液滴的形态和动力学，为液滴分选等应用提供了新途径。

Abstract: We investigate pump-driven droplet electrohydrodynamics with an emphasis on
deformation, pinch-off, and recoalescence. A thermodynamically consistent
phase-field framework is developed that couples Nernst--Planck--Poisson
electrodiffusion with incompressible Navier--Stokes--Cahn--Hilliard flow, and
incorporates interfacial ionic pumps as prescribed surface fluxes. In the
pump-free baseline, applied fields merely polarise the droplet and deformation
is negligible. By contrast, surface-localised pumping drives the accumulation
of positive ions within the droplet, elevates the interior potential, and
generates non-uniform electric fields. The resulting Lorentz stresses stretch
and displace the droplet, thin interfacial necks, and trigger pinch-off; the
daughter droplets subsequently recoalesce, often after wall contact, yielding
flattened remnants. In multiple-droplet settings, pump-induced charging
produces lateral electrostatic repulsion and asymmetric deformation; under
geometric confinement, crescent bending and star-like morphologies emerge.
Shear-flow tests further show that a pumped droplet can be immobilised and
ruptured while an unpumped neighbour is advected downstream, suggesting a route
to sorting. Taken together, the results establish interfacial pumping as an
internal actuation mechanism that robustly controls droplet morphology and
dynamics across configurations.

</details>


### [205] [Nonlinear optimal perturbation growth in pulsatile pipe flow](https://arxiv.org/abs/2509.10103)
*Patrick Keuchel,Marc Avila*

Main category: physics.flu-dyn

TL;DR: 本文开发了基于GPU的伴随优化代码，研究脉动管流中的非线性不稳定性，发现减速相和加速相存在两种不同的失稳路径，其中减速相的局部斜向扰动能量增益可达9个数量级。


<details>
  <summary>Details</summary>
Motivation: 脉动流体在直管中流动时会突然转变为湍流，这种转变难以预测。主要困难在于层流的线性Floquet稳定性在远高于实验观测到湍流的雷诺数下仍然存在，使得不稳定性问题完全非线性，依赖于扰动形状和振幅等多种因素。

Method: 开发了基于GPU伪谱Navier-Stokes求解器nsPipe的伴随优化代码，采用自动最优检查点策略，在允许的扰动空间中进行优化，研究脉动管流的不稳定性机制。

Result: 发现脉动管流存在两种不同的失稳路径：减速相中流动容易发生斜向不稳定性，加速相中机制与稳态管流相似。减速相中局部斜向扰动可最优利用非线性效应，在峰值雷诺数Re_max≈4000时能量增益超过9个数量级。这些扰动会饱和形成规则流动模式，在加速相衰减或破裂为湍流。加速相中的最优扰动放大程度较小，但振幅足够大时通常触发湍流。

Conclusion: 脉动管流的不稳定性强烈依赖于流动相位，减速相比加速相更容易发生能量不稳定性，局部斜向扰动是触发湍流转变的关键机制，这为预测和控制脉动流动中的湍流转变提供了重要见解。

Abstract: Pulsatile fluid flows through straight pipes undergo a sudden transition to
turbulence that is extremely difficult to predict. The difficulty stems here
from the linear Floquet stability of the laminar flow up to large Reynolds
numbers, well above experimental observations of turbulent flow. This makes the
instability problem fully nonlinear and thus dependent on the shape and
amplitude of the flow perturbation, in addition to the Reynolds and Womersley
numbers and the pulsation amplitude. This problem can be tackled by optimizing
over the space of all admissible perturbations to the laminar flow. In this
paper, we present an adjoint optimization code, based on a GPU implementation
of the pseudo-spectral Navier-Stokes solver nsPipe, which incorporates an
automatic, optimal check-pointing strategy. We leverage this code to show that
the flow is susceptible to two distinct instability routes: One in the
deceleration phase, where the flow is prone to oblique instabilities, and
another during the acceleration phase with similar mechanisms as in steady pipe
flow. Instability is energetically more likely in the deceleration phase.
Specifically, localised oblique perturbations can optimally exploit nonlinear
effects to gain over nine orders of magnitude in energy at a peak Reynolds
number of $Re_{\max}\approx 4000$. These oblique perturbations saturate into
regular flow patterns that decay in the acceleration phase or break down to
turbulence depending on the flow parameters. In the acceleration phase, optimal
perturbations are substantially less amplified, but generally trigger
turbulence if their amplitude is sufficiently large.

</details>


### [206] [A three-dimensional numerical scheme for modeling three-phase contact line pinning using Smoothed Particle Hydrodynamics](https://arxiv.org/abs/2509.10159)
*Subrat Kumar Nayak,Amitabh Bhattacharya,Prapanch Nair*

Main category: physics.flu-dyn

TL;DR: 本文提出了一种在无网格SPH方法中实现三相接触线钉扎的模型，用于模拟液滴在非均匀基底上的毛细动力学行为。


<details>
  <summary>Details</summary>
Motivation: 在毛细动力学实验中，液体域通常通过将三相接触线钉扎在基底的尖锐边缘或不连续处来限制。然而，欧拉多相流求解器通常无法直接实现接触线的钉扎，需要开发新的数值方法。

Method: 采用更新的拉格朗日无网格SPH方法，基于连续表面力方案开发了接触线钉扎模型，假设液-气界面为自由表面，可以在任意钉扎曲线上实现接触线钉扎。

Result: 通过多个涉及固定和动态基底上钉扎三相接触线的毛细动力学实验验证，证明了求解器的鲁棒性和准确性。

Conclusion: 所提出的钉扎模型能够有效模拟非均匀基底上的毛细流动现象，为研究接触线钉扎相关的毛细动力学问题提供了可靠的数值工具。

Abstract: In several capillary dynamics experiments, the liquid domain is confined by
pinning the three-phase contact line along a sharp edge or a discontinuity on
the substrate. Simulating the dynamics of pinned droplets can offer valuable
insights into capillary flow phenomena involving wetting of inhomogeneous
substrates. However, Eulerian multi-phase flow solvers are usually not able to
directly implement pinning of three-phase contact lines. We present the
implementation of a model for pinning the contact line of a liquid along an
arbitrary pinning curve on the substrate, in an updated Lagrangian, meshless
flow solver based on the smoothed particle hydrodynamics (SPH) method. We
develop the pinning model for a continuum surface force scheme and assume a
free surface for the liquid-gas interface. We validate the model against
several capillary dynamics experiments involving pinned three phase contact
lines with fixed and dynamic substrates to demonstrate the robustness and
accuracy of the solver.

</details>


### [207] [Convective flux analysis on the instability of one-dimensional detonation](https://arxiv.org/abs/2509.10169)
*Yunfeng Liu*

Main category: physics.flu-dyn

TL;DR: 一维数值模拟研究气体爆轰不稳定性机制，通过增加活化能识别了稳定爆轰、周期性爆轰、脉动爆轰和爆轰熄灭的特征，首次对对流通量、动能通量和化学反应热通量进行定量分析。


<details>
  <summary>Details</summary>
Motivation: 研究一维气体爆轰的不稳定性机制，通过定量分析三种关键通量（对流通量、动能通量、化学反应热通量）来揭示爆轰不稳定性、再点火和熄灭过程的物理机制。

Method: 使用欧拉方程和不可逆单步Arrhenius动力学进行一维数值模拟，通过增加活化能参数来研究不同爆轰状态，首次对三种通量进行定量分析。

Result: 识别了稳定爆轰、周期性爆轰、脉动爆轰和爆轰熄灭的特征状态，发现这三种通量在爆轰前沿发生剧烈变化，流场特性取决于它们的代数和。

Conclusion: 通过对对流通量、动能通量和化学反应热通量的定量分析，可以揭示爆轰不稳定性、再点火和熄灭过程的物理机制，为理解爆轰动力学提供了新的定量研究方法。

Abstract: One-dimensional numerical simulations using the Euler equations and
irreversible one-step Arrhenius kinetics are conducted to study the instability
mechanism of a one-dimensional gaseous detonation. By increasing the activation
energy, this study identifies the characteristics of stable detonation,
periodic detonation, pulsating detonation, and detonation quenching. The key
difference between this study and previous research is that it is the first
quantitative analysis of convective flux, kinetic energy flux, and chemical
reaction heat flux. These three fluxes undergo intensive change on the
detonation front and the flow field at each time step depends on the algebra
summation of them. The mechanisms of detonation instability, detonation
reignition and detonation quenching process can be revealed quantitatively by
analyzing these fluxes.

</details>


### [208] [Experimental study of turbulent mixing in a T-shaped mixer](https://arxiv.org/abs/2509.10264)
*Huixin Li,Mohammad Mehdi Zamani Asl,Bastian Bäuerlein,Kerstin Avila,Duo Xu,Marc Avila*

Main category: physics.flu-dyn

TL;DR: 本文介绍了一种新型实验装置，用于研究T型混合器中湍流混合的小尺度特性，通过粒子图像测速和平面激光诱导荧光测量，分析了湍流动能、耗散率、标量浓度方差等参数，并与模型预测和直接数值模拟结果进行了比较。


<details>
  <summary>Details</summary>
Motivation: T型混合器作为流体混合的典型设备，其层流稳态和周期性流动已被深入研究，但湍流流动在应用中普遍存在却研究较少，需要开发新的实验方法来研究小尺度湍流混合特性。

Method: 开发了水力直径为4厘米的新型实验装置，采用二维粒子图像测速(PIV)和平面激光诱导荧光(PLIF)测量技术，同时进行了直接数值模拟(DNS)作为对比。

Result: 成功复制了微尺度T型混合器在低雷诺数下的特征流态，测量了湍流动能、耗散率、标量浓度方差及其概率密度函数和频谱，发现了初期的Batchelor标度，估算了机械-标量时间尺度比。

Conclusion: 实验数据与工程实践中使用的模型预测和相关关系进行了比较，验证了新型实验装置的有效性，为湍流混合研究提供了重要的小尺度测量数据。

Abstract: One of the most widespread canonical devices for fluid mixing is the T-shaped
mixer, in which two opposing miscible liquid streams meet at a junction and
then mix along a main channel. Laminar steady and time-periodic flows in
T-shaped mixers have been thoroughly studied, but turbulent flows have received
much less scrutiny despite their prevalence in applications. We here introduce
a novel experimental setup with a hydraulic diameter of four centimetres that
enables the optical study of turbulent mixing at small scales. Using this
setup, we perform two-dimensional particle image velocimetry and planar
laser-induced fluorescence measurements. First, we successfully replicate
characteristic flow regimes observed in micro-scale T-shaped mixers at low
Reynolds numbers. We then focus on the turbulent regime and characterize the
turbulent kinetic energy and dissipation along the mixing channel. Further, we
measure the scalar concentration variance and its corresponding probability
density function and spectra. The latter exhibits an incipient Batchelor
scaling. We estimate the mechanical-to-scalar timescale ratio and examine the
link between the turbulent velocity and scalar fields. The measurement data are
compared with model predictions and correlations used in engineering practice,
and with our own direct numerical simulations performed with a spectral-element
code.

</details>


### [209] [Lagrangian Stability Analysis Technique for Fluid Flows](https://arxiv.org/abs/2509.10316)
*Vilas J. Shinde*

Main category: physics.flu-dyn

TL;DR: 基于拉格朗日参考系的数据驱动稳定性分析技术，避免传统温动力学稳定性分析的线性化和简化限制


<details>
  <summary>Details</summary>
Motivation: 传统温动力学稳定性分析需要在稳态基流上进行微激动态力学分析，通常需要线性化流动方程和流动/几何简化，这些方法繁琐且有限制

Method: 采用拉格朗日模态/非模态分析，特别是前向时间方向的拉格朗日动力学模态分解的共轭形式，将欧拉参考系中的稳态非均匀流在拉格朗日参考系中视为非稳态流

Result: 在经典基流上进行了验证，包括自相似Blasius/Falkner-Skan边界层、2D可压缩流绕圆柱和2D可压缩盖驱动室流，生成了中性稳定曲线、N因子估计和过渡能量增长

Conclusion: 该方法自然适用于具有多物理效应的大型/复杂数值/实验基流的全局分析，提供了一种免微激的数据驱动稳定性分析方法

Abstract: Flow transition from a stable to unstable states and eventually to turbulence
is a classical fluid mechanics phenomenon with a strong practical relevance.
Conventional hydrodynamic stability deals with perturbation dynamics on a
steady baseflow, typically in Eulerian reference frame. Common modal
techniques, e.g., linear stability theory, involve linearization of governing
flow equations and flow/geometrical simplifications, which can be tedious and
restrictive. This paper presents a perturbation-free data-driven stability
analysis technique by employing Lagrangian modal/non-modal analysis (Shinde &
Gaitonde 2021), particularly the adjoint form of Lagrangian dynamics mode
decomposition in the forward time direction. The proposed Lagrangian stability
analysis technique (LagSAT) builds on the fact that a steady non-uniform fluid
flow in the Eulerian reference frame can be perceived as an unsteady flow in
the Lagrangian reference frame. LagSAT is demonstrated on classical baseflows
that exhibit convective/absolute instabilities, namely, the self-similar
Blasius/Falkner-Skan boundary layers, a 2D compressible flow past a cylinder,
and a 2D compressible lid-driven cavity flow, producing neutral stability
curves, N-factor estimate, and transient energy growth. LagSAT is naturally
suitable for the global analysis of large/complex numerical/experimental
baseflows with multiphysics effects.

</details>


### [210] [A Review of the Design of Cone-Cylinder-Flare Geometries for Stability Analyses and Conventional/Quiet Wind Tunnel Tests](https://arxiv.org/abs/2509.10411)
*Sebastien Esquieu,Steven P. Schneider,Elizabeth K. Benitez,Jean-Philippe Brazier*

Main category: physics.flu-dyn

TL;DR: 研究压力梯度、流动膨胀和再压缩对高超声速边界层稳定性的影响，通过设计锥-柱-裙构型进行风洞实验，使用LST和PSE方法预测扰动放大率，并与实验数据对比验证。


<details>
  <summary>Details</summary>
Motivation: 研究高超声速边界层在压力梯度、流动膨胀和再压缩条件下的稳定性特性，为高超声速层流-湍流转捩分析提供合适的几何构型，并能够生成附着流和分离流。

Method: 设计轴对称锥-柱-裙构型进行风洞实验，在Ma=6、零攻角、全层流条件下分析气动流动特性。使用线性稳定性理论(LST)和线性抛物化稳定性方程(PSE)预测边界层扰动放大率，并与BAM6QT风洞测量结果对比。采用基于N因子的半经验方法关联转捩与线性不稳定波的积分增长。

Result: 获得了高超声速边界层在压力梯度、流动膨胀和再压缩条件下的稳定性特性数据，验证了LST和PSE方法在预测扰动放大率方面的有效性，建立了转捩与线性不稳定波增长的相关性。

Conclusion: 成功设计了适用于高超声速层流-湍流转捩分析的几何构型，验证了线性稳定性理论在预测高超声速边界层稳定性方面的适用性，为高超声速飞行器设计提供了重要的实验和理论依据。

Abstract: In order to study the effects of pressure gradients, flow expansion, and
recompression on the stability of hypersonic boundary-layers, axisymmetric
cone-cylinder-flare configurations have been specifically designed for wind
tunnel experiments. The objective is to create well-suited geometries for
hypersonic laminar-turbulent transition analyses, while also adding the
capability to generate attached and separated flows. After a thorough review of
the aerodynamic flows obtained at Mach 6 and zero degree angle of attack in
fully laminar conditions on each configuration, linear stability theory (LST)
and linear parabolized stability equations (PSE) are used to predict the
amplification rates of the boundary-layer disturbances for the case without
flow separation since local stability analysis cannot handle highly
non-parallel flows. For this attached flow case, the numerical stability
results are compared to wind tunnel measurements obtained in the BAM6QT (Boeing
AFOSR Mach-6 Quiet Tunnel). The semi-empirical method based on N-factor allows
to correlate transition with the integrated growth of the linear instability
waves. The influence of tunnel noise is also investigated, using conventional
and quiet experiments.

</details>
