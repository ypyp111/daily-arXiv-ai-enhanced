<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 43]
- [cs.CL](#cs.CL) [Total: 37]
- [cs.AI](#cs.AI) [Total: 28]
- [cs.LG](#cs.LG) [Total: 69]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 11]
- [math.NA](#math.NA) [Total: 8]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GRAFNet: Multiscale Retinal Processing via Guided Cortical Attention Feedback for Enhancing Medical Image Polyp Segmentation](https://arxiv.org/abs/2602.15072)
*Abdul Joseph Fofanah,Lian Wen,Alpha Alimamy Kamara,Zhongyi Zhang,David Chen,Albert Patrick Sankoh*

Main category: cs.CV

TL;DR: GRAFNet：一种受生物启发的息肉分割网络，通过模拟人类视觉系统的分层组织，结合导向注意力、多尺度视网膜模块和皮层反馈机制，在多个公开基准上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜息肉分割对癌症预防至关重要，但面临三大挑战：息肉形态多变（从平坦到突出病变）、与正常结构（褶皱、血管）视觉相似度高、需要鲁棒的多尺度检测。现有深度学习方法存在单向处理、多尺度融合弱、缺乏解剖约束等问题，导致假阳性（正常结构过分割）和假阴性（漏检平坦病变）。

Method: 提出GRAFNet，模拟人类视觉系统的分层组织，包含三个核心模块：1) 导向非对称注意力模块(GAAM)，模拟方向调谐皮层神经元以增强息肉边界；2) 多尺度视网膜模块(MSRM)，模拟视网膜神经节细胞通路进行并行多特征分析；3) 导向皮层注意力反馈模块(GCAFM)，应用预测编码进行迭代优化。这些模块通过息肉编码器-解码器模块(PEDM)统一，通过分辨率自适应反馈强制空间语义一致性。

Result: 在五个公开基准（Kvasir-SEG、CVC-300、CVC-ColonDB、CVC-Clinic、PolypGen）上的广泛实验显示，GRAFNet实现了稳定的SOTA性能，Dice系数提升3-8%，泛化能力比领先方法高10-20%，同时提供可解释的决策路径。

Conclusion: 这项工作建立了一个新范式，通过神经计算原理弥合AI准确性与临床可信推理之间的差距，为医学图像分析提供了受生物启发的可靠解决方案。

Abstract: Accurate polyp segmentation in colonoscopy is essential for cancer prevention but remains challenging due to: (1) high morphological variability (from flat to protruding lesions), (2) strong visual similarity to normal structures such as folds and vessels, and (3) the need for robust multi-scale detection. Existing deep learning approaches suffer from unidirectional processing, weak multi-scale fusion, and the absence of anatomical constraints, often leading to false positives (over-segmentation of normal structures) and false negatives (missed subtle flat lesions). We propose GRAFNet, a biologically inspired architecture that emulates the hierarchical organisation of the human visual system. GRAFNet integrates three key modules: (1) a Guided Asymmetric Attention Module (GAAM) that mimics orientation-tuned cortical neurones to emphasise polyp boundaries, (2) a MultiScale Retinal Module (MSRM) that replicates retinal ganglion cell pathways for parallel multi-feature analysis, and (3) a Guided Cortical Attention Feedback Module (GCAFM) that applies predictive coding for iterative refinement. These are unified in a Polyp Encoder-Decoder Module (PEDM) that enforces spatial-semantic consistency via resolution-adaptive feedback. Extensive experiments on five public benchmarks (Kvasir-SEG, CVC-300, CVC-ColonDB, CVC-Clinic, and PolypGen) demonstrate consistent state-of-the-art performance, with 3-8% Dice improvements and 10-20% higher generalisation over leading methods, while offering interpretable decision pathways. This work establishes a paradigm in which neural computation principles bridge the gap between AI accuracy and clinically trustworthy reasoning. Code is available at https://github.com/afofanah/GRAFNet.

</details>


### [2] [Zero-shot HOI Detection with MLLM-based Detector-agnostic Interaction Recognition](https://arxiv.org/abs/2602.15124)
*Shiyu Xuan,Dongkai Wang,Zechao Li,Jinhui Tang*

Main category: cs.CV

TL;DR: 提出了一种解耦的零样本人-物交互检测框架，将目标检测与交互识别分离，利用多模态大语言模型进行零样本交互识别，无需训练即可工作，同时支持微调以提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人-物交互检测方法通常将交互识别与特定检测器紧密耦合，依赖粗粒度的视觉-语言模型特征，限制了模型对未见交互的泛化能力。需要一种更灵活、泛化性更强的零样本交互识别方法。

Method: 1. 解耦框架：将目标检测与交互识别分离；2. 确定性生成方法：将交互识别建模为视觉问答任务，强制确定性输出，实现无需训练的零样本交互识别；3. 空间感知池化模块：整合外观特征和成对空间线索；4. 一次性确定性匹配方法：在单次前向传播中预测所有候选交互。

Result: 在HICO-DET和V-COCO数据集上的实验表明，该方法实现了优越的零样本性能、强大的跨数据集泛化能力，并且能够灵活集成任何目标检测器而无需重新训练。

Conclusion: 提出的解耦框架通过分离目标检测与交互识别，并利用多模态大语言模型进行零样本交互识别，显著提升了模型的泛化能力和灵活性，为开放词汇的人-物交互检测提供了有效解决方案。

Abstract: Zero-shot Human-object interaction (HOI) detection aims to locate humans and objects in images and recognize their interactions. While advances in open-vocabulary object detection provide promising solutions for object localization, interaction recognition (IR) remains challenging due to the combinatorial diversity of interactions. Existing methods, including two-stage methods, tightly couple IR with a specific detector and rely on coarse-grained vision-language model (VLM) features, which limit generalization to unseen interactions. In this work, we propose a decoupled framework that separates object detection from IR and leverages multi-modal large language models (MLLMs) for zero-shot IR. We introduce a deterministic generation method that formulates IR as a visual question answering task and enforces deterministic outputs, enabling training-free zero-shot IR. To further enhance performance and efficiency by fine-tuning the model, we design a spatial-aware pooling module that integrates appearance and pairwise spatial cues, and a one-pass deterministic matching method that predicts all candidate interactions in a single forward pass. Extensive experiments on HICO-DET and V-COCO demonstrate that our method achieves superior zero-shot performance, strong cross-dataset generalization, and the flexibility to integrate with any object detectors without retraining. The codes are publicly available at https://github.com/SY-Xuan/DA-HOI.

</details>


### [3] [MB-DSMIL-CL-PL: Scalable Weakly Supervised Ovarian Cancer Subtype Classification and Localisation Using Contrastive and Prototype Learning with Frozen Patch Features](https://arxiv.org/abs/2602.15138)
*Marcus Jenkins,Jasenka Mazibrada,Bogdan Leahu,Michal Mackiewicz*

Main category: cs.CV

TL;DR: 提出一种基于对比学习和原型学习的卵巢癌组织病理学图像亚型分类与定位方法，使用预计算冻结特征，在保持可扩展性的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 卵巢癌组织病理学亚型研究对个性化治疗至关重要，但诊断工作量增加给病理科带来挑战。传统方法依赖预计算冻结特征，而端到端特征提取方法虽提升精度但牺牲了训练可扩展性和实验效率。

Method: 采用对比学习和原型学习，结合预计算冻结特征，通过特征空间增强技术进行卵巢癌组织病理学图像的亚型分类与定位。

Result: 相比DSMIL方法，在实例级分类F1分数提升70.4%，切片级分类F1分数提升15.3%，实例定位AUC提升16.9%，切片分类AUC提升2.3%，同时保持使用冻结特征。

Conclusion: 该方法在保持使用预计算冻结特征的可扩展性优势的同时，显著提升了卵巢癌组织病理学图像亚型分类与定位的性能，平衡了精度与效率。

Abstract: The study of histopathological subtypes is valuable for the personalisation of effective treatment strategies for ovarian cancer. However, increasing diagnostic workloads present a challenge for UK pathology departments, leading to the rise in AI approaches. While traditional approaches in this field have relied on pre-computed, frozen image features, recent advances have shifted towards end-to-end feature extraction, providing an improvement in accuracy but at the expense of significantly reduced scalability during training and time-consuming experimentation. In this paper, we propose a new approach for subtype classification and localisation in ovarian cancer histopathology images using contrastive and prototype learning with pre-computed, frozen features via feature-space augmentations. Compared to DSMIL, our method achieves an improvement of 70.4\% and 15.3\% in F1 score for instance- and slide-level classification, respectively, along with AUC gains of 16.9\% for instance localisation and 2.3\% for slide classification, while maintaining the use of frozen patch features.

</details>


### [4] [Loss Knows Best: Detecting Annotation Errors in Videos via Loss Trajectories](https://arxiv.org/abs/2602.15154)
*Praditha Alwis,Soumyadeep Chandra,Deepak Ravikumar,Kaushik Roy*

Main category: cs.CV

TL;DR: 提出基于累积样本损失（CSL）的视频标注错误检测方法，通过分析帧级损失轨迹识别错误标注和时序错乱


<details>
  <summary>Details</summary>
Motivation: 现实世界视频数据集常存在标注错误（错误标签和时序错乱），这些错误在需要时序一致性的任务中特别有害，但缺乏有效的自动检测方法

Method: 提出模型无关的CSL方法：训练视频分割模型并保存每个epoch的权重，用这些检查点评估测试视频中每帧的损失，计算累积样本损失作为帧级可学习性的动态指纹

Result: 在EgoPER和Cholec80数据集上实验显示强大的检测性能，能有效识别错误标签和帧错乱等细微不一致性

Conclusion: 该方法为数据集审计和提升视频机器学习训练可靠性提供了强大工具，无需标注错误的地面真值且具有跨数据集泛化能力

Abstract: High-quality video datasets are foundational for training robust models in tasks like action recognition, phase detection, and event segmentation. However, many real-world video datasets suffer from annotation errors such as *mislabeling*, where segments are assigned incorrect class labels, and *disordering*, where the temporal sequence does not follow the correct progression. These errors are particularly harmful in phase-annotated tasks, where temporal consistency is critical. We propose a novel, model-agnostic method for detecting annotation errors by analyzing the Cumulative Sample Loss (CSL)--defined as the average loss a frame incurs when passing through model checkpoints saved across training epochs. This per-frame loss trajectory acts as a dynamic fingerprint of frame-level learnability. Mislabeled or disordered frames tend to show consistently high or irregular loss patterns, as they remain difficult for the model to learn throughout training, while correctly labeled frames typically converge to low loss early. To compute CSL, we train a video segmentation model and store its weights at each epoch. These checkpoints are then used to evaluate the loss of each frame in a test video. Frames with persistently high CSL are flagged as likely candidates for annotation errors, including mislabeling or temporal misalignment. Our method does not require ground truth on annotation errors and is generalizable across datasets. Experiments on EgoPER and Cholec80 demonstrate strong detection performance, effectively identifying subtle inconsistencies such as mislabeling and frame disordering. The proposed approach provides a powerful tool for dataset auditing and improving training reliability in video-based machine learning.

</details>


### [5] [Distributional Deep Learning for Super-Resolution of 4D Flow MRI under Domain Shift](https://arxiv.org/abs/2602.15167)
*Xiaoyi Wen,Fei Jiang*

Main category: cs.CV

TL;DR: 提出一种分布深度学习框架，用于提升4D Flow MRI超分辨率性能，通过CFD模拟训练和少量真实数据微调来解决临床数据域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 传统超分辨率方法依赖简单下采样的配对数据训练，但临床低分辨率数据往往来自不同的采集机制，导致域偏移和模型泛化能力差。需要解决真实临床场景中的域适应问题。

Method: 提出分布深度学习框架：1）首先在高分辨率CFD模拟及其下采样版本上训练；2）然后在少量配对的4D Flow MRI和CFD样本上进行微调；3）推导分布估计器的理论性质。

Result: 框架显著优于传统深度学习方法，在真实数据应用中表现出色，证明了分布学习在解决域偏移和提升临床超分辨率性能方面的有效性。

Conclusion: 分布深度学习框架能有效解决临床超分辨率中的域偏移问题，提高模型鲁棒性和泛化能力，为4D Flow MRI等医学成像提供了实用的超分辨率解决方案。

Abstract: Super-resolution is widely used in medical imaging to enhance low-quality data, reducing scan time and improving abnormality detection. Conventional super-resolution approaches typically rely on paired datasets of downsampled and original high resolution images, training models to reconstruct high resolution images from their artificially degraded counterparts. However, in real-world clinical settings, low resolution data often arise from acquisition mechanisms that differ significantly from simple downsampling. As a result, these inputs may lie outside the domain of the training data, leading to poor model generalization due to domain shift. To address this limitation, we propose a distributional deep learning framework that improves model robustness and domain generalization. We develop this approch for enhancing the resolution of 4D Flow MRI (4DF). This is a novel imaging modality that captures hemodynamic flow velocity and clinically relevant metrics such as vessel wall stress. These metrics are critical for assessing aneurysm rupture risk. Our model is initially trained on high resolution computational fluid dynamics (CFD) simulations and their downsampled counterparts. It is then fine-tuned on a small, harmonized dataset of paired 4D Flow MRI and CFD samples. We derive the theoretical properties of our distributional estimators and demonstrate that our framework significantly outperforms traditional deep learning approaches through real data applications. This highlights the effectiveness of distributional learning in addressing domain shift and improving super-resolution performance in clinically realistic scenarios.

</details>


### [6] [Time-Archival Camera Virtualization for Sports and Visual Performances](https://arxiv.org/abs/2602.15181)
*Yunxiao Zhang,William Stone,Suryansh Kumar*

Main category: cs.CV

TL;DR: 提出基于神经体积渲染的相机虚拟化方法，支持动态场景的时间归档功能，适用于体育直播等应用


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法在处理快速动态场景、多主体非刚性运动时存在局限，且缺乏时间归档能力，无法满足体育直播等应用需求

Method: 采用神经体积渲染框架，将动态场景建模为多相机视角下的刚性变换，进行神经表示学习，支持时间归档功能

Result: 实现了高质量的动态场景渲染，支持用户回溯任意时间点进行新视角合成，具备体育直播回放、分析和归档能力

Conclusion: 神经体积渲染框架在相机虚拟化中具有优势，特别适合需要时间归档功能的动态场景应用，如体育广播

Abstract: Camera virtualization -- an emerging solution to novel view synthesis -- holds transformative potential for visual entertainment, live performances, and sports broadcasting by enabling the generation of photorealistic images from novel viewpoints using images from a limited set of calibrated multiple static physical cameras. Despite recent advances, achieving spatially and temporally coherent and photorealistic rendering of dynamic scenes with efficient time-archival capabilities, particularly in fast-paced sports and stage performances, remains challenging for existing approaches. Recent methods based on 3D Gaussian Splatting (3DGS) for dynamic scenes could offer real-time view-synthesis results. Yet, they are hindered by their dependence on accurate 3D point clouds from the structure-from-motion method and their inability to handle large, non-rigid, rapid motions of different subjects (e.g., flips, jumps, articulations, sudden player-to-player transitions). Moreover, independent motions of multiple subjects can break the Gaussian-tracking assumptions commonly used in 4DGS, ST-GS, and other dynamic splatting variants. This paper advocates reconsidering a neural volume rendering formulation for camera virtualization and efficient time-archival capabilities, making it useful for sports broadcasting and related applications. By modeling a dynamic scene as rigid transformations across multiple synchronized camera views at a given time, our method performs neural representation learning, providing enhanced visual rendering quality at test time. A key contribution of our approach is its support for time-archival, i.e., users can revisit any past temporal instance of a dynamic scene and can perform novel view synthesis, enabling retrospective rendering for replay, analysis, and archival of live events, a functionality absent in existing neural rendering approaches and novel view synthesis...

</details>


### [7] [How to Train Your Long-Context Visual Document Model](https://arxiv.org/abs/2602.15257)
*Austin Veselka*

Main category: cs.CV

TL;DR: 首个大规模长上下文视觉语言模型研究，训练至344K上下文，在长文档视觉问答任务中取得SOTA，并发现视觉长上下文训练可迁移到文本长上下文任务。


<details>
  <summary>Details</summary>
Motivation: 现有开源长上下文视觉语言模型（如Qwen3 VL和GLM 4.5/6V）的训练方法和数据流程不可复现，需要系统研究长上下文视觉语言模型的训练方法以填补这一空白。

Method: 系统研究了24B和32B参数模型的持续预训练、监督微调和偏好优化，使用合成数据管道进行自改进，并在训练和评估中引入页面索引机制。

Result: 在MMLongBenchDoc基准测试中两个参数规模都达到最先进性能，并发现：(1)训练上下文长度与评估长度匹配时效果最佳；(2)页面索引显著提升长文档性能；(3)视觉长上下文训练可迁移到文本长上下文任务。

Conclusion: 该研究填补了长上下文视觉语言模型训练方法的空白，提供了可复现的训练框架，并发布了改进版基准MMLBD-C，为后续研究奠定基础。

Abstract: We present the first comprehensive, large-scale study of training long-context vision language models up to 344K context, targeting long-document visual question answering with measured transfer to long-context text. While several such strong are open-weight, namely Qwen3 VL and GLM 4.5/6V, their training recipes and data pipelines are not reproducible. We systematically study continued pretraining, supervised finetuning, and preference optimization for 24B and 32B parameter models, backed by extensive LC evaluations and ablations to bridge this gap, and achieve state-of-the-art performance on MMLongBenchDoc for both parameter scales. In addition to this, our key findings include: (i) training on context lengths that match evaluation context lengths outperforms training on longer contexts, (ii) training and evaluating with page indices provides a simple, high-impact boost to long-document performance, (iii) our synthetic data pipelines enable self-improvement via continued pretraining and supervised finetuning, and (iv) we extend the known text-to-visual long context transfer to the reverse, showing that visual long context training transfers to long-context text performance. We also release MMLBD-C, a manually corrected version of MMLongBenchDoc to reduce erroneous and low quality examples in the benchmark.

</details>


### [8] [Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization](https://arxiv.org/abs/2602.15277)
*Muhammad J. Alahmadi,Peng Gao,Feiyi Wang,Dongkuan,Xu*

Main category: cs.CV

TL;DR: E^2D是一种探索-利用蒸馏方法，通过两阶段优化策略减少冗余计算，在保持高精度的同时显著提升大规模数据集蒸馏效率。


<details>
  <summary>Details</summary>
Motivation: 现有解耦式数据集蒸馏方法面临效率与精度之间的权衡：基于优化的方法精度高但计算密集，无优化方法效率高但精度低。需要克服这一矛盾。

Method: 提出E^2D方法：1）全图像初始化保持语义完整性和特征多样性；2）两阶段优化策略：探索阶段进行均匀更新并识别高损失区域，利用阶段聚焦更新这些区域以加速收敛。

Result: 在ImageNet-1K上超越SOTA且快18倍，在ImageNet-21K上显著提升精度且快4.3倍。

Conclusion: 针对性的、减少冗余的更新策略（而非暴力优化）能够弥合大规模数据集蒸馏中精度与效率之间的差距。

Abstract: Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large-scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration-Exploitation Distillation (E^2D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E^2D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being 18x faster, and on ImageNet-21K, our method substantially improves accuracy while remaining 4.3x faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at https://github.com/ncsu-dk-lab.

</details>


### [9] [Visual Persuasion: What Influences Decisions of Vision-Language Models?](https://arxiv.org/abs/2602.15278)
*Manuel Cherep,Pranav M R,Pattie Maes,Nikhil Singh*

Main category: cs.CV

TL;DR: 研究者开发了一个框架来研究视觉语言模型（VLMs）的视觉偏好，通过系统编辑图像并观察模型的选择行为来推断其潜在的视觉效用函数，从而揭示AI代理的视觉决策模式和安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型在网页图像理解中广泛应用，AI代理大规模进行视觉决策（如点击、推荐、购买），但我们对这些代理的视觉偏好结构知之甚少，需要系统方法来研究其决策模式和安全漏洞。

Method: 提出一个框架：将VLMs置于受控的图像选择任务中，系统扰动其输入。核心思想是将代理的决策函数视为可通过显示偏好推断的潜在视觉效用。从常见图像（如产品照片）出发，采用视觉提示优化方法，将文本优化技术适配到视觉领域，使用图像生成模型迭代提出并应用视觉上合理的修改（如构图、照明、背景）。然后评估哪些编辑能提高选择概率。

Result: 通过对前沿VLMs的大规模实验证明，优化后的编辑在头对头比较中显著改变了选择概率。开发了自动可解释性流程来解释这些偏好，识别驱动选择的一致视觉主题。

Conclusion: 该方法提供了一种实用高效的方式来揭示视觉漏洞和安全问题，支持对基于图像的AI代理进行更主动的审计和治理，避免这些问题在现实世界中隐式被发现。

Abstract: The web is littered with images, once created for human consumption and now increasingly interpreted by agents using vision-language models (VLMs). These agents make visual decisions at scale, deciding what to click, recommend, or buy. Yet, we know little about the structure of their visual preferences. We introduce a framework for studying this by placing VLMs in controlled image-based choice tasks and systematically perturbing their inputs. Our key idea is to treat the agent's decision function as a latent visual utility that can be inferred through revealed preference: choices between systematically edited images. Starting from common images, such as product photos, we propose methods for visual prompt optimization, adapting text optimization methods to iteratively propose and apply visually plausible modifications using an image generation model (such as in composition, lighting, or background). We then evaluate which edits increase selection probability. Through large-scale experiments on frontier VLMs, we demonstrate that optimized edits significantly shift choice probabilities in head-to-head comparisons. We develop an automatic interpretability pipeline to explain these preferences, identifying consistent visual themes that drive selection. We argue that this approach offers a practical and efficient way to surface visual vulnerabilities, safety concerns that might otherwise be discovered implicitly in the wild, supporting more proactive auditing and governance of image-based AI agents.

</details>


### [10] [Consistency-Preserving Diverse Video Generation](https://arxiv.org/abs/2602.15287)
*Xinshuang Liu,Runfa Blark Li,Truong Nguyen*

Main category: cs.CV

TL;DR: 提出一种用于流匹配视频生成的联合采样框架，在保持时间一致性的同时提高批次多样性，避免视频解码和反向传播开销。


<details>
  <summary>Details</summary>
Motivation: 文本到视频生成成本高昂，通常每个提示只能生成少量样本。在低样本情况下，最大化每个批次的价值需要高跨视频多样性。现有方法虽然能提高图像生成的多样性，但对视频生成往往损害时间一致性且需要昂贵的反向传播计算。

Method: 提出联合采样框架：首先应用多样性驱动的更新，然后移除会降低时间一致性目标的分量。为避免图像空间梯度，使用轻量级潜在空间模型计算两个目标，避免视频解码和解码器反向传播。

Result: 在最先进的文本到视频流匹配模型上的实验显示，该方法在保持与强联合采样基线相当的多样性的同时，显著提高了时间一致性和色彩自然度。

Conclusion: 该方法在低样本情况下有效平衡了视频生成的多样性和时间一致性需求，避免了昂贵的计算开销，为高效文本到视频生成提供了实用解决方案。

Abstract: Text-to-video generation is expensive, so only a few samples are typically produced per prompt. In this low-sample regime, maximizing the value of each batch requires high cross-video diversity. Recent methods improve diversity for image generation, but for videos they often degrade within-video temporal consistency and require costly backpropagation through a video decoder. We propose a joint-sampling framework for flow-matching video generators that improves batch diversity while preserving temporal consistency. Our approach applies diversity-driven updates and then removes only the components that would decrease a temporal-consistency objective. To avoid image-space gradients, we compute both objectives with lightweight latent-space models, avoiding video decoding and decoder backpropagation. Experiments on a state-of-the-art text-to-video flow-matching model show diversity comparable to strong joint-sampling baselines while substantially improving temporal consistency and color naturalness. Code will be released.

</details>


### [11] [Training-Free Zero-Shot Anomaly Detection in 3D Brain MRI with 2D Foundation Models](https://arxiv.org/abs/2602.15315)
*Tai Le-Gia,Jaehyun Ahn*

Main category: cs.CV

TL;DR: 提出一种无需训练、基于2D基础模型的3D脑MRI零样本异常检测框架，通过多轴切片聚合构建局部体素标记，实现3D异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常检测方法主要局限于2D医学图像，扩展到3D医学图像面临挑战。现有方法依赖切片级特征和视觉语言模型，无法捕捉体积结构信息。

Method: 通过2D基础模型处理多轴切片，聚合构建局部体素标记，恢复立方空间上下文，直接与基于距离的批处理级异常检测流程集成。

Result: 无需训练、基于批处理的零样本异常检测可以从2D编码器有效扩展到完整3D MRI体积，为体积异常检测提供简单鲁棒的方法。

Conclusion: 该框架提供紧凑的3D表示，可在标准GPU上计算，无需微调、提示或监督，成功将零样本异常检测扩展到3D医学图像领域。

Abstract: Zero-shot anomaly detection (ZSAD) has gained increasing attention in medical imaging as a way to identify abnormalities without task-specific supervision, but most advances remain limited to 2D datasets. Extending ZSAD to 3D medical images has proven challenging, with existing methods relying on slice-wise features and vision-language models, which fail to capture volumetric structure. In this paper, we introduce a fully training-free framework for ZSAD in 3D brain MRI that constructs localized volumetric tokens by aggregating multi-axis slices processed by 2D foundation models. These 3D patch tokens restore cubic spatial context and integrate directly with distance-based, batch-level anomaly detection pipelines. The framework provides compact 3D representations that are practical to compute on standard GPUs and require no fine-tuning, prompts, or supervision. Our results show that training-free, batch-based ZSAD can be effectively extended from 2D encoders to full 3D MRI volumes, offering a simple and robust approach for volumetric anomaly detection.

</details>


### [12] [Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs](https://arxiv.org/abs/2602.15318)
*Libo Zhang,Zhaoning Zhang,Wangyang Hong,Peng Qiao,Dongsheng Li*

Main category: cs.CV

TL;DR: Sparrow框架通过视觉感知文本锚定窗口注意力、中间层视觉状态桥接和多token预测策略，解决了视频大语言模型中推测解码的性能崩溃问题，实现了2.82倍的平均加速。


<details>
  <summary>Details</summary>
Motivation: 推测解码在加速视觉语言模型推理时，应用于视频大语言模型会出现严重性能崩溃。草案模型因键值缓存爆炸和上下文窗口不匹配而陷入注意力稀释和负面视觉增益的陷阱。观察到Vid-LLMs中存在视觉语义内化现象，关键视觉语义在深层交互中被隐式编码到文本隐藏状态中，导致原始视觉输入在深度推理中结构冗余。

Method: 1) 通过隐藏状态重用实现视觉感知文本锚定窗口注意力，将视觉计算完全卸载到目标模型；2) 利用中间层视觉状态桥接，用语义丰富的中间状态训练草案模型，过滤低级视觉噪声；3) 引入多token预测策略来弥合训练-推理分布偏移。

Result: Sparrow在即使有25k视觉token的情况下，实现了平均2.82倍的加速，有效解决了长序列中的性能下降问题，为实时长视频任务提供了实用解决方案。

Conclusion: Sparrow框架通过创新的注意力机制和训练策略，成功解决了视频大语言模型中推测解码的性能崩溃问题，实现了显著的推理加速，为长视频实时处理提供了有效解决方案。

Abstract: Although speculative decoding is widely used to accelerate Vision-Language Models (VLMs) inference, it faces severe performance collapse when applied to Video Large Language Models (Vid-LLMs). The draft model typically falls into the trap of attention dilution and negative visual gain due to key-value cache explosion and context window mismatches. We observe a visual semantic internalization phenomenon in Vid-LLMs, indicating that critical visual semantics are implicitly encoded into text hidden states during deep-layer interactions, which renders raw visual inputs structurally redundant during deep inference. To address this, we propose the Sparrow framework, which first utilizes visually-aware text-anchored window attention via hidden state reuse to fully offload visual computation to the target model, and leverages intermediate-layer visual state bridging to train the draft model with semantic-rich intermediate states, thereby filtering out low-level visual noise. Additionally, a multi-token prediction strategy is introduced to bridge the training-inference distribution shift. Experiments show that Sparrow achieves an average speedup of 2.82x even with 25k visual tokens, effectively resolving the performance degradation in long sequences and offering a practical solution for real-time long video tasks.

</details>


### [13] [EventMemAgent: Hierarchical Event-Centric Memory for Online Video Understanding with Adaptive Tool Use](https://arxiv.org/abs/2602.15329)
*Siwei Wen,Zhangcheng Wang,Xingjian Zhang,Lei Huang,Wenjun Wu*

Main category: cs.CV

TL;DR: EventMemAgent：基于分层记忆模块的主动在线视频理解框架，通过短时记忆检测事件边界、长时记忆结构化归档，结合多粒度感知工具和Agentic RL，解决流媒体无限输入与MLLM有限上下文窗口的矛盾。


<details>
  <summary>Details</summary>
Motivation: 在线视频理解面临流媒体输入无限性与多模态大语言模型（MLLM）有限上下文窗口的根本矛盾。现有被动处理方法在保持长程上下文与捕捉细粒度细节之间存在权衡，难以满足复杂任务需求。

Method: 提出EventMemAgent框架：1）短时记忆层动态检测事件边界，使用事件粒度水库采样处理流视频帧；2）长时记忆层按事件结构化归档历史观察；3）集成多粒度感知工具包进行主动迭代证据捕获；4）采用Agentic强化学习端到端内化推理和工具使用策略。

Result: 实验表明EventMemAgent在在线视频基准测试中取得了有竞争力的结果。

Conclusion: EventMemAgent通过分层记忆架构和主动感知策略，有效解决了在线视频理解中无限流输入与有限上下文窗口的矛盾，为复杂视频理解任务提供了新框架。

Abstract: Online video understanding requires models to perform continuous perception and long-range reasoning within potentially infinite visual streams. Its fundamental challenge lies in the conflict between the unbounded nature of streaming media input and the limited context window of Multimodal Large Language Models (MLLMs). Current methods primarily rely on passive processing, which often face a trade-off between maintaining long-range context and capturing the fine-grained details necessary for complex tasks. To address this, we introduce EventMemAgent, an active online video agent framework based on a hierarchical memory module. Our framework employs a dual-layer strategy for online videos: short-term memory detects event boundaries and utilizes event-granular reservoir sampling to process streaming video frames within a fixed-length buffer dynamically; long-term memory structuredly archives past observations on an event-by-event basis. Furthermore, we integrate a multi-granular perception toolkit for active, iterative evidence capture and employ Agentic Reinforcement Learning (Agentic RL) to end-to-end internalize reasoning and tool-use strategies into the agent's intrinsic capabilities. Experiments show that EventMemAgent achieves competitive results on online video benchmarks. The code will be released here: https://github.com/lingcco/EventMemAgent.

</details>


### [14] [Effective and Robust Multimodal Medical Image Analysis](https://arxiv.org/abs/2602.15346)
*Joy Dhar,Nayyar Zaidi,Maryam Haghighat*

Main category: cs.CV

TL;DR: 提出MAIL和Robust-MAIL网络，解决多模态融合学习中的泛化性、计算效率和对抗鲁棒性问题，在20个公开数据集上取得显著性能提升和计算成本降低。


<details>
  <summary>Details</summary>
Motivation: 现有多模态融合学习方法存在三个主要问题：1) 专注于特定模态，忽视跨模态的互补信息，限制多疾病分析的泛化能力；2) 计算成本高，在资源有限环境中适用性差；3) 缺乏对抗攻击鲁棒性，影响医疗AI应用的可靠性。

Method: 提出MAIL网络，包含两个关键组件：1) 高效残差学习注意力块，用于捕捉细化的模态特定多尺度模式；2) 高效多模态交叉注意力模块，用于学习跨模态的丰富互补共享表示。进一步扩展为Robust-MAIL，通过随机投影滤波器和调制注意力噪声增强对抗鲁棒性。

Result: 在20个公开数据集上的广泛评估显示，MAIL和Robust-MAIL均优于现有方法，性能提升最高达9.34%，同时计算成本降低最高达78.3%。

Conclusion: 提出的MAIL和Robust-MAIL方法在多模态融合学习中表现出优越性，解决了泛化性、计算效率和对抗鲁棒性等关键问题，确保了比顶级竞争对手更可靠的预测。

Abstract: Multimodal Fusion Learning (MFL), leveraging disparate data from various imaging modalities (e.g., MRI, CT, SPECT), has shown great potential for addressing medical problems such as skin cancer and brain tumor prediction. However, existing MFL methods face three key limitations: a) they often specialize in specific modalities, and overlook effective shared complementary information across diverse modalities, hence limiting their generalizability for multi-disease analysis; b) they rely on computationally expensive models, restricting their applicability in resource-limited settings; and c) they lack robustness against adversarial attacks, compromising reliability in medical AI applications. To address these limitations, we propose a novel Multi-Attention Integration Learning (MAIL) network, incorporating two key components: a) an efficient residual learning attention block for capturing refined modality-specific multi-scale patterns and b) an efficient multimodal cross-attention module for learning enriched complementary shared representations across diverse modalities. Furthermore, to ensure adversarial robustness, we extend MAIL network to design Robust-MAIL by incorporating random projection filters and modulated attention noise. Extensive evaluations on 20 public datasets show that both MAIL and Robust-MAIL outperform existing methods, achieving performance gains of up to 9.34% while reducing computational costs by up to 78.3%. These results highlight the superiority of our approaches, ensuring more reliable predictions than top competitors. Code: https://github.com/misti1203/MAIL-Robust-MAIL.

</details>


### [15] [CREMD: Crowd-Sourced Emotional Multimodal Dogs Dataset](https://arxiv.org/abs/2602.15349)
*Jinho Baek,Houwei Cao,Kate Blackwell*

Main category: cs.CV

TL;DR: 该研究创建了CREMD数据集，探索不同呈现模式（上下文、音频、视频）和标注者特征（养狗经验、性别、专业背景）如何影响狗情绪识别，发现视觉上下文显著提升标注一致性，音频增强标注者信心，但非养狗者和男性标注者表现出更高一致性。


<details>
  <summary>Details</summary>
Motivation: 狗情绪识别对于改善人-动物互动、兽医护理和自动化监测系统至关重要，但由于情感评估的主观性和缺乏标准化方法，准确识别狗情绪具有挑战性。需要研究不同信息呈现方式和标注者特征如何影响情绪识别可靠性。

Method: 创建CREMD数据集，包含923个视频片段，以三种模式呈现：无上下文/音频、有上下文无音频、有上下文和音频。收集来自不同背景参与者（狗主人、专业人士、不同人口统计特征）的标注，分析影响情绪识别可靠性的因素。

Result: 1) 添加视觉上下文显著提高标注一致性，音频影响因设计限制（缺少无上下文有音频条件，音频质量有限）而不确定；2) 非养狗者和男性标注者比养狗者和女性标注者表现出更高一致性，专业人士一致性更高符合预期；3) 音频显著增强标注者对特定情绪（特别是愤怒和恐惧）识别的信心。

Conclusion: 狗情绪识别受呈现模式和标注者特征影响，视觉上下文是关键因素，音频增强标注信心但需进一步研究。标注者特征（如养狗经验、性别）对一致性有意外影响，专业人士表现更好。这些发现对改进狗情绪识别系统和数据集设计有重要意义。

Abstract: Dog emotion recognition plays a crucial role in enhancing human-animal interactions, veterinary care, and the development of automated systems for monitoring canine well-being. However, accurately interpreting dog emotions is challenging due to the subjective nature of emotional assessments and the absence of standardized ground truth methods. We present the CREMD (Crowd-sourced Emotional Multimodal Dogs Dataset), a comprehensive dataset exploring how different presentation modes (e.g., context, audio, video) and annotator characteristics (e.g., dog ownership, gender, professional experience) influence the perception and labeling of dog emotions. The dataset consists of 923 video clips presented in three distinct modes: without context or audio, with context but no audio, and with both context and audio. We analyze annotations from diverse participants, including dog owners, professionals, and individuals with varying demographic backgrounds and experience levels, to identify factors that influence reliable dog emotion recognition. Our findings reveal several key insights: (1) while adding visual context significantly improved annotation agreement, our findings regarding audio cues are inconclusive due to design limitations (specifically, the absence of a no-context-with-audio condition and limited clean audio availability); (2) contrary to expectations, non-owners and male annotators showed higher agreement levels than dog owners and female annotators, respectively, while professionals showed higher agreement levels, aligned with our initial hypothesis; and (3) the presence of audio substantially increased annotators' confidence in identifying specific emotions, particularly anger and fear.

</details>


### [16] [DAV-GSWT: Diffusion-Active-View Sampling for Data-Efficient Gaussian Splatting Wang Tiles](https://arxiv.org/abs/2602.15355)
*Rong Fu,Jiekai Wu,Haiyun Wei,Yee Tan Jia,Wenxin Zhang,Yang Li,Xiaowen Ma,Wangyu Wu,Simon Fong*

Main category: cs.CV

TL;DR: DAV-GSWT：利用扩散先验和主动视角采样，从少量输入观测合成高质量高斯溅射Wang Tiles的数据高效框架


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯溅射方法虽然能实现逼真神经渲染，但生成大规模场景时仍依赖密集采样的示例重建，数据需求量大

Method: 结合分层不确定性量化机制与生成扩散模型，自主识别最具信息量的视角，同时幻觉缺失的结构细节以确保瓦片无缝过渡

Result: 实验表明该系统显著减少所需数据量，同时保持大规模虚拟环境所需的视觉完整性和交互性能

Conclusion: DAV-GSWT为数据高效合成高质量高斯溅射Wang Tiles提供了有效解决方案，推动了大规模虚拟环境构建的实用化

Abstract: The emergence of 3D Gaussian Splatting has fundamentally redefined the capabilities of photorealistic neural rendering by enabling high-throughput synthesis of complex environments. While procedural methods like Wang Tiles have recently been integrated to facilitate the generation of expansive landscapes, these systems typically remain constrained by a reliance on densely sampled exemplar reconstructions. We present DAV-GSWT, a data-efficient framework that leverages diffusion priors and active view sampling to synthesize high-fidelity Gaussian Splatting Wang Tiles from minimal input observations. By integrating a hierarchical uncertainty quantification mechanism with generative diffusion models, our approach autonomously identifies the most informative viewpoints while hallucinating missing structural details to ensure seamless tile transitions. Experimental results indicate that our system significantly reduces the required data volume while maintaining the visual integrity and interactive performance necessary for large-scale virtual environments.

</details>


### [17] [GMAIL: Generative Modality Alignment for generated Image Learning](https://arxiv.org/abs/2602.15368)
*Shentong Mo,Sukmin Yun*

Main category: cs.CV

TL;DR: 提出GMAIL框架，将生成图像视为与真实图像不同的模态，通过多模态学习方法在潜在空间对齐两种模态，从而有效利用生成图像提升视觉语言任务性能


<details>
  <summary>Details</summary>
Motivation: 生成模型能合成高度逼真的图像，为训练机器学习模型提供丰富数据源。但直接将生成图像当作真实图像使用会导致模态差异问题，甚至引起模式崩溃。需要一种能区分对待生成图像和真实图像的方法

Method: 提出GMAIL框架：1) 将生成图像视为独立模态；2) 使用跨模态对齐损失在生成图像上微调模型；3) 用对齐后的模型进一步训练各种视觉语言模型；4) 在潜在空间而非像素空间对齐两种模态

Result: 框架显著提升了图像描述、零样本图像检索、零样本图像分类和长描述检索等任务的性能。展示了生成数据的正向缩放趋势，并在大型多模态模型LLaVA的描述性能上取得显著提升

Conclusion: 通过将生成图像视为独立模态并进行跨模态对齐，GMAIL框架能有效利用生成模型的优势，提升视觉语言任务的性能，且易于与各种视觉语言模型集成

Abstract: Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined GMAIL, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.

</details>


### [18] [Bridging Day and Night: Target-Class Hallucination Suppression in Unpaired Image Translation](https://arxiv.org/abs/2602.15383)
*Shuwei Li,Lei Tan,Robby T. Tan*

Main category: cs.CV

TL;DR: 提出一种新的无配对图像翻译框架，通过双头判别器和类特定原型检测并抑制目标类别特征的幻觉，在日转夜翻译中显著提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 日转夜无配对图像翻译对下游任务很重要，但由于外观差异大且缺乏像素级监督而具有挑战性。现有方法常产生语义幻觉，错误合成交通标志、车辆等人造光效，严重影响下游性能。

Method: 提出双头判别器进行语义分割以检测背景区域的幻觉内容；引入类特定原型作为语义锚点，通过聚合标注目标域对象特征构建；基于薛定谔桥翻译模型进行迭代优化，将检测到的幻觉特征在特征空间中推离类原型。

Result: 在BDD100K数据集上，日转夜域适应任务中mAP提升15.5%，对易产生幻觉的类别如交通灯提升31.7%，在定性和定量评估中均优于现有方法。

Conclusion: 通过检测和抑制目标类别特征的幻觉，提出的框架能有效提升无配对图像翻译的质量和下游任务性能，特别是在易产生语义幻觉的场景中表现优异。

Abstract: Day-to-night unpaired image translation is important to downstream tasks but remains challenging due to large appearance shifts and the lack of direct pixel-level supervision. Existing methods often introduce semantic hallucinations, where objects from target classes such as traffic signs and vehicles, as well as man-made light effects, are incorrectly synthesized. These hallucinations significantly degrade downstream performance. We propose a novel framework that detects and suppresses hallucinations of target-class features during unpaired translation. To detect hallucination, we design a dual-head discriminator that additionally performs semantic segmentation to identify hallucinated content in background regions. To suppress these hallucinations, we introduce class-specific prototypes, constructed by aggregating features of annotated target-domain objects, which act as semantic anchors for each class. Built upon a Schrodinger Bridge-based translation model, our framework performs iterative refinement, where detected hallucination features are explicitly pushed away from class prototypes in feature space, thus preserving object semantics across the translation trajectory.Experiments show that our method outperforms existing approaches both qualitatively and quantitatively. On the BDD100K dataset, it improves mAP by 15.5% for day-to-night domain adaptation, with a notable 31.7% gain for classes such as traffic lights that are prone to hallucinations.

</details>


### [19] [Efficient Generative Modeling beyond Memoryless Diffusion via Adjoint Schrödinger Bridge Matching](https://arxiv.org/abs/2602.15396)
*Jeongwoo Shin,Jinhwan Sul,Joonseok Lee,Jaewong Choi,Jaemoo Choi*

Main category: cs.CV

TL;DR: 提出Adjoint Schrödinger Bridge Matching (ASBM)框架，通过两阶段方法学习最优轨迹，相比传统扩散模型产生更直的采样路径，在图像生成中实现更高保真度和更少采样步数。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型由于前向过程无信息且无记忆，导致轨迹高度弯曲和噪声评分目标，需要更高效的采样路径。

Method: 两阶段方法：1) 将Schrödinger Bridge前向动态视为耦合构建问题，通过数据到能量的采样视角学习；2) 使用简单匹配损失学习后向生成动态，由诱导的最优耦合监督。

Result: ASBM在非无记忆机制下产生显著更直、更高效的采样路径，在高维数据上具有更好的稳定性和效率，图像生成实验显示保真度提高且采样步数减少。

Conclusion: ASBM通过恢复高维最优轨迹，为生成建模提供了更高效的框架，并能蒸馏到单步生成器，展示了其最优轨迹的有效性。

Abstract: Diffusion models often yield highly curved trajectories and noisy score targets due to an uninformative, memoryless forward process that induces independent data-noise coupling. We propose Adjoint Schrödinger Bridge Matching (ASBM), a generative modeling framework that recovers optimal trajectories in high dimensions via two stages. First, we view the Schrödinger Bridge (SB) forward dynamic as a coupling construction problem and learn it through a data-to-energy sampling perspective that transports data to an energy-defined prior. Then, we learn the backward generative dynamic with a simple matching loss supervised by the induced optimal coupling. By operating in a non-memoryless regime, ASBM produces significantly straighter and more efficient sampling paths. Compared to prior works, ASBM scales to high-dimensional data with notably improved stability and efficiency. Extensive experiments on image generation show that ASBM improves fidelity with fewer sampling steps. We further showcase the effectiveness of our optimal trajectory via distillation to a one-step generator.

</details>


### [20] [Emergent Morphing Attack Detection in Open Multi-modal Large Language Models](https://arxiv.org/abs/2602.15461)
*Marija Ivanovska,Vitomir Štruc*

Main category: cs.CV

TL;DR: 首次系统评估开源多模态大语言模型在零样本条件下的单图像人脸融合攻击检测能力，发现LLaVA1.6-Mistral-7B超越特定任务基线23%以上，表明多模态预训练能隐式编码融合伪影的细粒度面部不一致性。


<details>
  <summary>Details</summary>
Motivation: 人脸融合攻击威胁生物特征验证，但现有检测系统需要特定任务训练且泛化能力差。开源多模态大语言模型展现出强大的视觉-语言推理能力，但在生物特征取证领域的潜力尚未充分探索。

Method: 首次对开源MLLMs进行系统性的零样本单图像MAD评估，使用公开可得的权重和标准化、可复现的协议。评估涵盖多种融合技术，无需微调或领域适应。

Result: 许多MLLMs在没有微调的情况下展现出非平凡的判别能力，LLaVA1.6-Mistral-7B达到最先进性能，在等错误率上超越高度竞争的特定任务MAD基线至少23%。

Conclusion: 多模态预训练能隐式编码指示融合伪影的细粒度面部不一致性，实现零样本取证敏感性。开源MLLMs可作为生物特征安全和取证图像分析的复现性、可解释性和竞争性基础，为开发最先进MAD系统提供新机会。

Abstract: Face morphing attacks threaten biometric verification, yet most morphing attack detection (MAD) systems require task-specific training and generalize poorly to unseen attack types. Meanwhile, open-source multimodal large language models (MLLMs) have demonstrated strong visual-linguistic reasoning, but their potential in biometric forensics remains underexplored. In this paper, we present the first systematic zero-shot evaluation of open-source MLLMs for single-image MAD, using publicly available weights and a standardized, reproducible protocol. Across diverse morphing techniques, many MLLMs show non-trivial discriminative ability without any fine-tuning or domain adaptation, and LLaVA1.6-Mistral-7B achieves state-of-the-art performance, surpassing highly competitive task-specific MAD baselines by at least 23% in terms of equal error rate (EER). The results indicate that multimodal pretraining can implicitly encode fine-grained facial inconsistencies indicative of morphing artifacts, enabling zero-shot forensic sensitivity. Our findings position open-source MLLMs as reproducible, interpretable, and competitive foundations for biometric security and forensic image analysis. This emergent capability also highlights new opportunities to develop state-of-the-art MAD systems through targeted fine-tuning or lightweight adaptation, further improving accuracy and efficiency while preserving interpretability. To support future research, all code and evaluation protocols will be released upon publication.

</details>


### [21] [RPT-SR: Regional Prior attention Transformer for infrared image Super-Resolution](https://arxiv.org/abs/2602.15490)
*Youngwan Jin,Incheol Park,Yagiz Nalcakan,Hyeongjin Ju,Sanghyeop Yeo,Shiho Kim*

Main category: cs.CV

TL;DR: 提出RPT-SR模型，利用区域先验注意力Transformer解决固定视角红外图像超分辨率问题，通过双令牌框架融合场景布局先验和局部内容


<details>
  <summary>Details</summary>
Motivation: 现有通用超分辨率模型（特别是Vision Transformers）在固定视角的红外成像场景（如监控、自动驾驶）中存在效率问题，未能充分利用场景中固有的强空间先验，导致冗余学习和次优性能

Method: 提出RPT-SR架构，核心是双令牌框架：1) 可学习的区域先验令牌，作为场景全局结构的持久记忆；2) 局部令牌，捕捉当前输入的帧特定内容。通过注意力机制让先验动态调制局部重建过程

Result: 在覆盖长波(LWIR)和短波(SWIR)光谱的多样化数据集上建立了新的最先进性能，验证了方法的广泛适用性和多功能性

Conclusion: RPT-SR通过显式编码场景布局信息到注意力机制中，有效解决了固定视角红外图像超分辨率问题，相比通用模型能更好地利用空间先验，提高效率和性能

Abstract: General-purpose super-resolution models, particularly Vision Transformers, have achieved remarkable success but exhibit fundamental inefficiencies in common infrared imaging scenarios like surveillance and autonomous driving, which operate from fixed or nearly-static viewpoints. These models fail to exploit the strong, persistent spatial priors inherent in such scenes, leading to redundant learning and suboptimal performance. To address this, we propose the Regional Prior attention Transformer for infrared image Super-Resolution (RPT-SR), a novel architecture that explicitly encodes scene layout information into the attention mechanism. Our core contribution is a dual-token framework that fuses (1) learnable, regional prior tokens, which act as a persistent memory for the scene's global structure, with (2) local tokens that capture the frame-specific content of the current input. By utilizing these tokens into an attention, our model allows the priors to dynamically modulate the local reconstruction process. Extensive experiments validate our approach. While most prior works focus on a single infrared band, we demonstrate the broad applicability and versatility of RPT-SR by establishing new state-of-the-art performance across diverse datasets covering both Long-Wave (LWIR) and Short-Wave (SWIR) spectra

</details>


### [22] [LEADER: Lightweight End-to-End Attention-Gated Dual Autoencoder for Robust Minutiae Extraction](https://arxiv.org/abs/2602.15493)
*Raffaele Cappelli,Matteo Ferrara*

Main category: cs.CV

TL;DR: LEADER是一个轻量级端到端注意力门控双自编码器，直接从原始指纹图像提取细节点描述符（位置、方向、类型），无需单独预处理和后处理，在NIST SD27数据集上F1分数比专业潜在指纹提取器高34%。


<details>
  <summary>Details</summary>
Motivation: 指纹识别中的细节点提取正转向深度学习，但真正消除单独预处理和后处理的端到端方法仍然稀缺。现有方法通常需要多个独立步骤，限制了效率和泛化能力。

Method: 提出LEADER架构：1) 集成非极大值抑制和角度解码实现完全端到端推理；2) 使用新颖的"城堡-护城河-城墙"真值编码；3) 双自编码器结构通过注意力门控机制连接；4) 仅需0.9M参数。

Result: 在NIST SD27数据集上F1分数比专业潜在指纹提取器高34%；在挑战性基准测试中平均排名2.07，47%的样本排名第一（是第二名的两倍以上）；GPU推理15ms，CPU推理322ms，计算效率优于领先商业软件。

Conclusion: LEADER实现了真正端到端的细节点提取，在精度和计算效率方面达到最先进水平，并展示了强大的跨域泛化能力。模型学习到的内部表示与指纹领域特征一致，代码和预训练权重已公开。

Abstract: Minutiae extraction, a fundamental stage in fingerprint recognition, is increasingly shifting toward deep learning. However, truly end-to-end methods that eliminate separate preprocessing and postprocessing steps remain scarce. This paper introduces LEADER (Lightweight End-to-end Attention-gated Dual autoencodER), a neural network that maps raw fingerprint images to minutiae descriptors, including location, direction, and type. The proposed architecture integrates non-maximum suppression and angular decoding to enable complete end-to-end inference using only 0.9M parameters. It employs a novel "Castle-Moat-Rampart" ground-truth encoding and a dual-autoencoder structure, interconnected through an attention-gating mechanism. Experimental evaluations demonstrate state-of-the-art accuracy on plain fingerprints and robust cross-domain generalization to latent impressions. Specifically, LEADER attains a 34% higher F1-score on the NIST SD27 dataset compared to specialized latent minutiae extractors. Sample-level analysis on this challenging benchmark reveals an average rank of 2.07 among all compared methods, with LEADER securing the first-place position in 47% of the samples-more than doubling the frequency of the second-best extractor. The internal representations learned by the model align with established fingerprint domain features, such as segmentation masks, orientation fields, frequency maps, and skeletons. Inference requires 15ms on GPU and 322ms on CPU, outperforming leading commercial software in computational efficiency. The source code and pre-trained weights are publicly released to facilitate reproducibility.

</details>


### [23] [Semantic-Guided 3D Gaussian Splatting for Transient Object Removal](https://arxiv.org/abs/2602.15516)
*Aditi Prabakaran,Priyesh Shukla*

Main category: cs.CV

TL;DR: 提出基于语义过滤的框架，利用视觉语言模型实现类别感知的瞬态物体去除，解决3D高斯泼溅重建中的鬼影问题


<details>
  <summary>Details</summary>
Motivation: 多视角捕获中的瞬态物体（如行人、车辆）会在3D高斯泼溅重建中产生鬼影伪影。现有方法要么依赖场景分解导致内存成本高，要么基于运动启发式方法容易受到视差模糊的影响

Method: 使用视觉语言模型（CLIP）进行语义过滤：计算渲染视图与干扰物文本提示之间的相似度得分，在训练迭代中为每个高斯累积得分，超过校准阈值的高斯进行不透明度正则化和周期性剪枝

Result: 在RobustNeRF基准测试中，相比原始3DGS在四个序列上重建质量持续提升，同时保持最小内存开销和实时渲染性能。阈值校准和基线比较验证了语义引导在可预测干扰物类别场景中的实用性

Conclusion: 语义分类通过独立于运动模式识别物体类别，解决了视差模糊问题，为具有可预测干扰物类别的场景提供了一种实用的瞬态去除策略

Abstract: Transient objects in casual multi-view captures cause ghosting artifacts in 3D Gaussian Splatting (3DGS) reconstruction. Existing solutions relied on scene decomposition at significant memory cost or on motion-based heuristics that were vulnerable to parallax ambiguity. A semantic filtering framework was proposed for category-aware transient removal using vision-language models. CLIP similarity scores between rendered views and distractor text prompts were accumulated per-Gaussian across training iterations. Gaussians exceeding a calibrated threshold underwent opacity regularization and periodic pruning. Unlike motion-based approaches, semantic classification resolved parallax ambiguity by identifying object categories independently of motion patterns. Experiments on the RobustNeRF benchmark demonstrated consistent improvement in reconstruction quality over vanilla 3DGS across four sequences, while maintaining minimal memory overhead and real-time rendering performance. Threshold calibration and comparisons with baselines validated semantic guidance as a practical strategy for transient removal in scenarios with predictable distractor categories.

</details>


### [24] [Advanced Acceptance Score: A Holistic Measure for Biometric Quantification](https://arxiv.org/abs/2602.15535)
*Aman Verma,Seshan Srirangarajan,Sumantra Dutta Roy*

Main category: cs.CV

TL;DR: 提出一个全面的手势生物特征质量评估框架，通过排名偏差、相关性奖励和身份特征解耦等要素，构建高级接受分数作为整体评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有生物特征容量估计方法依赖错误率，但错误率不能反映分数质量的好坏。需要开发能够评估手势生物特征分数质量的综合方法。

Method: 首先确定输出分数的排名顺序和相关性作为评估基础，考虑排名偏差以及两个奖励：(1)高排名手势获得更高分数，(2)低排名手势获得更低分数。同时补偿输出分数与真实分数趋势的对应性，并将手势身份特征的解耦作为折扣因子。整合这些要素并适当加权，构建高级接受分数作为整体评估指标。

Result: 在三个数据集上对五个SOTA模型进行深入实验，结果显示使用该指标选择的最优分数比现有其他指标更合适。提出的指标与现有指标存在相关性，进一步验证了其可靠性。

Conclusion: 提出了一个全面的评估框架来量化手势生物特征分数的质量，通过整合多个评估维度构建了高级接受分数，实验证明该指标比现有方法更有效且可靠。

Abstract: Quantifying biometric characteristics within hand gestures involve derivation of fitness scores from a gesture and identity aware feature space. However, evaluating the quality of these scores remains an open question. Existing biometric capacity estimation literature relies upon error rates. But these rates do not indicate goodness of scores. Thus, in this manuscript we present an exhaustive set of evaluation measures. We firstly identify ranking order and relevance of output scores as the primary basis for evaluation. In particular, we consider both rank deviation as well as rewards for: (i) higher scores of high ranked gestures and (ii) lower scores of low ranked gestures. We also compensate for correspondence between trends of output and ground truth scores. Finally, we account for disentanglement between identity features of gestures as a discounting factor. Integrating these elements with adequate weighting, we formulate advanced acceptance score as a holistic evaluation measure. To assess effectivity of the proposed we perform in-depth experimentation over three datasets with five state-of-the-art (SOTA) models. Results show that the optimal score selected with our measure is more appropriate than existing other measures. Also, our proposed measure depicts correlation with existing measures. This further validates its reliability. We have made our \href{https://github.com/AmanVerma2307/MeasureSuite}{code} public.

</details>


### [25] [Dynamic Training-Free Fusion of Subject and Style LoRAs](https://arxiv.org/abs/2602.15539)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CV

TL;DR: 提出动态无训练LoRA融合框架，通过特征级选择和度量引导的潜在调整，在扩散过程中动态融合主题和风格LoRA权重，实现连贯的主题-风格合成。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA融合方法多采用静态统计启发式方法，偏离了LoRA学习自适应特征调整的初衷，且忽略了采样输入的随机性，需要更动态的融合机制。

Method: 1) 前向传播时，在LoRA应用层动态计算基础模型原始特征与主题/风格LoRA特征间的KL散度，自适应选择融合权重；2) 反向去噪阶段，基于CLIP和DINO等客观度量的梯度修正动态调整生成轨迹；3) 在整个扩散时间线上集成这两种互补机制。

Result: 在多样化的主题-风格组合实验中，该方法在定性和定量评估上均优于最先进的LoRA融合方法，无需任何重新训练即可实现连贯的主题-风格合成。

Conclusion: 通过特征级选择和度量引导的潜在调整的动态融合框架，能够有效解决现有LoRA融合方法的局限性，实现更高质量的主题-风格合成。

Abstract: Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.

</details>


### [26] [Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2602.15556)
*Guangtao Lyu,Qi Liu,Chenghao Xu,Jiexi Yan,Muli Yang,Xueting Li,Fen Fang,Cheng Deng*

Main category: cs.CV

TL;DR: 提出PADE方法，通过增强LVLMs内部正注意力动态来减少幻觉，无需额外训练，在多个模型和基准测试中提升视觉基础并减少错误输出。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs存在幻觉问题，输出与视觉输入或用户指令不一致。现有免训练方法（如对比解码、辅助专家模型）计算开销大且可能引入干扰，静态内部信号增强方法易受注意力下沉现象影响。

Method: 提出正注意力动态增强(PADE)：1) 构建PAD图识别语义核心视觉区域；2) 应用每头中位数绝对偏差缩放自适应控制干预强度；3) 利用系统令牌补偿保持对复杂用户指令的注意力并支持长期输出一致性。

Result: 在多个LVLMs和基准测试上的实验表明，PADE能改善视觉基础并减少幻觉，验证了利用内部注意力动态进行可靠多模态推理的有效性。

Conclusion: PADE是一种有效的免训练注意力干预方法，通过增强LVLMs内部正注意力动态来提升模型可靠性和减少幻觉，为多模态推理提供了新思路。

Abstract: LVLMs have achieved strong multimodal reasoning capabilities but remain prone to hallucinations, producing outputs inconsistent with visual inputs or user instructions. Existing training-free methods, including contrastive decoding and auxiliary expert models, which incur several times more computational overhead and may introduce potential interference, as well as static internal signal enhancement, are often vulnerable to the attention sink phenomenon. We find that internal Positive Attention Dynamics (PAD) in LVLMs naturally reveal semantically core visual regions under the distortions of attention sinks. Based on this, we propose Positive Attention Dynamics Enhancement (PADE), a training-free attention intervention that constructs a PAD map to identify semantically core visual regions, applies per-head Median Absolute Deviation Scaling to adaptively control the intervention strength, and leverages System-Token Compensation to maintain attention to complex user instructions and support long-term output consistency. Experiments on multiple LVLMs and benchmarks show that PADE improves visual grounding and reduces hallucinations, validating the effectiveness of leveraging internal attention dynamics for reliable multimodal reasoning.

</details>


### [27] [Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning](https://arxiv.org/abs/2602.15579)
*Amal Lahchim,Lambros Athanasiou*

Main category: cs.CV

TL;DR: 提出全自动OCT血管分割与分类管道，结合图像预处理、导丝伪影去除、坐标变换、聚类和特征提取，使用机器学习分类器实现高精度血管边界检测


<details>
  <summary>Details</summary>
Motivation: 冠状动脉OCT成像虽然能提供高分辨率血管解剖图像，但面临噪声、成像伪影和复杂组织结构等挑战，需要自动化解决方案来准确分析血管结构

Method: 集成图像预处理、导丝伪影去除、极坐标到笛卡尔坐标变换、无监督K-means聚类和局部特征提取，使用逻辑回归和支持向量机进行像素级血管分类

Result: 实验结果显示优异性能，精确率、召回率和F1分数最高达1.00，总体分类准确率达到99.68%，计算复杂度低且需要最少人工标注

Conclusion: 该方法为自动化OCT图像分析提供了可靠高效的解决方案，具有临床应用潜力，可用于临床决策支持和实时医学图像处理

Abstract: Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification in OCT images using machine learning techniques. The proposed method integrates image preprocessing, guidewire artifact removal, polar-to-Cartesian transformation, unsupervised K-means clustering, and local feature extraction. These features are used to train Logistic Regression and Support Vector Machine classifiers for pixel-wise vessel classification. Experimental results demonstrate excellent performance, achieving precision, recall, and F1-score values up to 1.00 and overall classification accuracy of 99.68%. The proposed approach provides accurate vessel boundary detection while maintaining low computational complexity and requiring minimal manual annotation. This method offers a reliable and efficient solution for automated OCT image analysis and has potential applications in clinical decision support and real-time medical image processing.

</details>


### [28] [An Industrial Dataset for Scene Acquisitions and Functional Schematics Alignment](https://arxiv.org/abs/2602.15584)
*Flavien Armangeon,Thibaud Ehret,Enric Meinhardt-Llopis,Rafael Grompone von Gioi,Guillaume Thibault,Marc Petit,Gabriele Facciolo*

Main category: cs.CV

TL;DR: IRIS-v2数据集：首个包含图像、点云、CAD模型、P&ID等完整工业场景数据的公开数据集，用于解决工业设施图纸与现实场景对齐的难题


<details>
  <summary>Details</summary>
Motivation: 老旧工业设施缺乏原生数字模型，现有手动对齐方法（图像+LiDAR）无法规模化，图纸与现实不一致且缺乏公开工业数据集，使得该问题既具挑战性又研究不足

Method: 提出IRIS-v2综合数据集，包含图像、点云、2D标注框和分割掩码、CAD模型、3D管道布线信息、P&ID图；通过分割和图匹配相结合的方法进行对齐实验

Result: 创建了首个全面的工业场景数据集，支持进一步研究；通过案例研究表明该方法能减少对齐任务所需时间

Conclusion: IRIS-v2数据集填补了工业数字孪生领域的数据空白，为功能原理图与2D/3D场景采集对齐提供了研究基础，有望推动该领域发展

Abstract: Aligning functional schematics with 2D and 3D scene acquisitions is crucial for building digital twins, especially for old industrial facilities that lack native digital models. Current manual alignment using images and LiDAR data does not scale due to tediousness and complexity of industrial sites. Inconsistencies between schematics and reality, and the scarcity of public industrial datasets, make the problem both challenging and underexplored. This paper introduces IRIS-v2, a comprehensive dataset to support further research. It includes images, point clouds, 2D annotated boxes and segmentation masks, a CAD model, 3D pipe routing information, and the P&ID (Piping and Instrumentation Diagram). The alignment is experimented on a practical case study, aiming at reducing the time required for this task by combining segmentation and graph matching.

</details>


### [29] [Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation](https://arxiv.org/abs/2602.15650)
*Marco Salmè,Federico Siciliano,Fabrizio Silvestri,Paolo Soda,Rosa Sicilia,Valerio Guarrasi*

Main category: cs.CV

TL;DR: CEMRAG框架通过将视觉表征分解为可解释的临床概念，并与多模态检索增强生成结合，统一提升放射学报告生成的解释性和事实准确性，挑战了传统认为解释性与性能之间存在权衡的观点。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型的放射学报告生成存在解释性不足和幻觉问题，临床采用受限。现有研究通常将解释性和准确性视为独立目标，缺乏统一解决方案。

Method: 提出概念增强多模态检索增强生成框架，将视觉表征分解为可解释的临床概念，并与多模态检索增强生成集成，通过丰富的上下文提示改进放射学报告生成。

Result: 在MIMIC-CXR和IU X-Ray数据集上，跨多种VLM架构、训练机制和检索配置的实验显示，CEMRAG在临床准确性指标和标准NLP指标上均优于传统RAG和仅概念基线方法。

Conclusion: 透明视觉概念可以增强而非损害医学VLM的诊断准确性，模块化设计为临床可信赖的AI辅助放射学提供了原则性路径，挑战了解释性与性能之间的传统权衡假设。

Abstract: Radiology Report Generation (RRG) through Vision-Language Models (VLMs) promises to reduce documentation burden, improve reporting consistency, and accelerate clinical workflows. However, their clinical adoption remains limited by the lack of interpretability and the tendency to hallucinate findings misaligned with imaging evidence. Existing research typically treats interpretability and accuracy as separate objectives, with concept-based explainability techniques focusing primarily on transparency, while Retrieval-Augmented Generation (RAG) methods targeting factual grounding through external retrieval. We present Concept-Enhanced Multimodal RAG (CEMRAG), a unified framework that decomposes visual representations into interpretable clinical concepts and integrates them with multimodal RAG. This approach exploits enriched contextual prompts for RRG, improving both interpretability and factual accuracy. Experiments on MIMIC-CXR and IU X-Ray across multiple VLM architectures, training regimes, and retrieval configurations demonstrate consistent improvements over both conventional RAG and concept-only baselines on clinical accuracy metrics and standard NLP measures. These results challenge the assumed trade-off between interpretability and performance, showing that transparent visual concepts can enhance rather than compromise diagnostic accuracy in medical VLMs. Our modular design decomposes interpretability into visual transparency and structured language model conditioning, providing a principled pathway toward clinically trustworthy AI-assisted radiology.

</details>


### [30] [A Novel Public Dataset for Strawberry (Fragaria x ananassa) Ripeness Detection and Comparative Evaluation of YOLO-Based Models](https://arxiv.org/abs/2602.15656)
*Mustafa Yurdakul,Zeynep Sena Bastug,Ali Emre Gok,Sakir Taşdemir*

Main category: cs.CV

TL;DR: 提出一个新的公开草莓成熟度数据集，包含566张图像和1201个标注对象，在土耳其两个不同温室中采集。使用YOLO系列模型进行测试，YOLOv8s在mAP@50上表现最佳（86.09%），为智慧农业应用建立基准。


<details>
  <summary>Details</summary>
Motivation: 草莓成熟度判断对生产者和消费者都至关重要，但传统视觉评估方法主观且误差大。现有研究中缺乏公开可用的综合数据集，导致难以进行有效比较。

Method: 创建包含566张图像和1201个标注对象的公开草莓成熟度数据集，在土耳其两个不同温室的不同光照和环境条件下采集。使用YOLOv8、YOLOv9和YOLO11系列模型进行对比测试，评估精度、召回率和mAP@50等指标。

Result: YOLOv9c模型获得最高精度90.94%，YOLO11s模型获得最高召回率83.74%。在综合性能指标mAP@50上，YOLOv8s表现最佳，达到86.09%。结果显示中小型模型在此类数据集上表现更平衡高效。

Conclusion: 提出的公开数据集填补了草莓成熟度检测领域的空白，为智慧农业应用提供了重要基准。中小型YOLO模型在此类数据集上表现良好，为实际应用提供了实用参考。

Abstract: The strawberry (Fragaria x ananassa), known worldwide for its economic value and nutritional richness, is a widely cultivated fruit. Determining the correct ripeness level during the harvest period is crucial for both preventing losses for producers and ensuring consumers receive a quality product. However, traditional methods, i.e., visual assessments alone, can be subjective and have a high margin of error. Therefore, computer-assisted systems are needed. However, the scarcity of comprehensive datasets accessible to everyone in the literature makes it difficult to compare studies in this field. In this study, a new and publicly available strawberry ripeness dataset, consisting of 566 images and 1,201 labeled objects, prepared under variable light and environmental conditions in two different greenhouses in Turkey, is presented to the literature. Comparative tests conducted on the data set using YOLOv8, YOLOv9, and YOLO11-based models showed that the highest precision value was 90.94% in the YOLOv9c model, while the highest recall value was 83.74% in the YOLO11s model. In terms of the general performance criterion mAP@50, YOLOv8s was the best performing model with a success rate of 86.09%. The results show that small and medium-sized models work more balanced and efficiently on this type of dataset, while also establishing a fundamental reference point for smart agriculture applications.

</details>


### [31] [Bayesian Optimization for Design Parameters of 3D Image Data Analysis](https://arxiv.org/abs/2602.15660)
*David Exler,Joaquin Eduardo Urrutia Gómez,Martin Krüger,Maike Schliephake,John Jbeily,Mario Vitacolonna,Rüdiger Rudolf,Markus Reischl*

Main category: cs.CV

TL;DR: 提出3D数据分析优化流程，通过两阶段贝叶斯优化自动选择分割模型、优化参数和分类器设计，减少手动调参负担


<details>
  <summary>Details</summary>
Motivation: 3D生物医学图像分析中，手动选择合适模型和调参是主要瓶颈，需要自动化流程来简化分割和分类任务的设计与参数化

Method: 两阶段贝叶斯优化：第一阶段选择分割模型并优化后处理参数，使用领域适应的合成基准数据集和自定义分割质量指标；第二阶段优化分类器设计选择，包括编码器、分类头架构、先验知识整合和预训练策略，并包含辅助类别标注工作流

Result: 在四个案例研究中，该流程能够高效识别针对个体数据集的有效模型和参数配置

Conclusion: 3D数据分析优化流程为生物医学图像分析提供了一种系统化的自动化方法，显著减少了手动调参和标注的工作量

Abstract: Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical. Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice. Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameterization of segmentation and classification using two Bayesian Optimization stages. First, the pipeline selects a segmentation model and optimizes postprocessing parameters using a domain-adapted syntactic benchmark dataset. To ensure a concise evaluation of segmentation performance, we introduce a segmentation quality metric that serves as the objective function. Second, the pipeline optimizes design choices of a classifier, such as encoder and classifier head architectures, incorporation of prior knowledge, and pretraining strategies. To reduce manual annotation effort, this stage includes an assisted class-annotation workflow that extracts predicted instances from the segmentation results and sequentially presents them to the operator, eliminating the need for manual tracking. In four case studies, the 3D data Analysis Optimization Pipeline efficiently identifies effective model and parameter configurations for individual datasets.

</details>


### [32] [Criteria-first, semantics-later: reproducible structure discovery in image-based sciences](https://arxiv.org/abs/2602.15712)
*Jan Bumberger*

Main category: cs.CV

TL;DR: 提出"标准优先、语义后置"的图像分析新范式，将结构发现与语义标注分离，以应对科学发现中的标签漂移和跨域可比性问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于语义标签的图像分析范式在开放科学发现、跨传感器/站点比较、长期监测等场景中失效，因为领域本体和标签集会随时间、文化和生态变化而漂移。

Method: 引入统一框架，将标准定义的无语义结构提取与下游语义映射分离，结构发现基于明确的优化标准而非领域本体，语义作为从发现结构到领域本体的显式映射。

Result: 该框架为图像科学提供领域通用的可重复分析支架，支持多元解释和显式交叉映射，无需重写上游提取过程，已在跨领域证据中得到验证。

Conclusion: "标准优先"范式将结构产品作为FAIR、AI就绪的数字对象，支持长期监测和数字孪生，推动超越分类准确度的验证方法发展。

Abstract: Across the natural and life sciences, images have become a primary measurement modality, yet the dominant analytic paradigm remains semantics-first. Structure is recovered by predicting or enforcing domain-specific labels. This paradigm fails systematically under the conditions that make image-based science most valuable, including open-ended scientific discovery, cross-sensor and cross-site comparability, and long-term monitoring in which domain ontologies and associated label sets drift culturally, institutionally, and ecologically. A deductive inversion is proposed in the form of criteria-first and semantics-later. A unified framework for criteria-first structure discovery is introduced. It separates criterion-defined, semantics-free structure extraction from downstream semantic mapping into domain ontologies or vocabularies and provides a domain-general scaffold for reproducible analysis across image-based sciences. Reproducible science requires that the first analytic layer perform criterion-driven, semantics-free structure discovery, yielding stable partitions, structural fields, or hierarchies defined by explicit optimality criteria rather than local domain ontologies. Semantics is not discarded; it is relocated downstream as an explicit mapping from the discovered structural product to a domain ontology or vocabulary, enabling plural interpretations and explicit crosswalks without rewriting upstream extraction. Grounded in cybernetics, observation-as-distinction, and information theory's separation of information from meaning, the argument is supported by cross-domain evidence showing that criteria-first components recur whenever labels do not scale. Finally, consequences are outlined for validation beyond class accuracy and for treating structural products as FAIR, AI-ready digital objects for long-term monitoring and digital twins.

</details>


### [33] [ToaSt: Token Channel Selection and Structured Pruning for Efficient ViT](https://arxiv.org/abs/2602.15720)
*Hyunchan Moon,Cheonjun Park,Steven L. Waslander*

Main category: cs.CV

TL;DR: ToaSt是一个解耦的ViT压缩框架，通过耦合头结构化剪枝和Token通道选择分别处理注意力模块和FFN，在保持精度的同时显著减少计算量。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers虽然性能优异但计算成本过高，现有结构化剪枝和token压缩方法存在训练时间长和全局传播优化问题，需要更高效的压缩方案。

Method: 提出ToaSt解耦框架：对多头自注意力模块采用耦合头结构化剪枝，利用注意力特性增强鲁棒性；对FFN（占60%以上FLOPs）引入Token通道选择，避免全局传播问题。

Result: 在9个模型（DeiT、ViT-MAE、Swin Transformer等）上评估，ToaSt在精度和效率间取得最优权衡。ViT-MAE-Huge上达到88.52%精度（+1.64%）同时减少39.4% FLOPs，下游任务迁移效果良好。

Conclusion: ToaSt通过解耦策略为不同ViT组件设计专门压缩方法，有效解决了现有压缩技术的局限性，实现了高效且准确的ViT部署方案。

Abstract: Vision Transformers (ViTs) have achieved remarkable success across various vision tasks, yet their deployment is often hindered by prohibitive computational costs. While structured weight pruning and token compression have emerged as promising solutions, they suffer from prolonged retraining times and global propagation that creates optimization challenges, respectively. We propose ToaSt, a decoupled framework applying specialized strategies to distinct ViT components. We apply coupled head-wise structured pruning to Multi-Head Self-Attention modules, leveraging attention operation characteristics to enhance robustness. For Feed-Forward Networks (over 60\% of FLOPs), we introduce Token Channel Selection (TCS) that enhances compression ratios while avoiding global propagation issues. Our analysis reveals TCS effectively filters redundant noise during selection. Extensive evaluations across nine diverse models, including DeiT, ViT-MAE, and Swin Transformer, demonstrate that ToaSt achieves superior trade-offs between accuracy and efficiency, consistently outperforming existing baselines. On ViT-MAE-Huge, ToaSt achieves 88.52\% accuracy (+1.64 \%) with 39.4\% FLOPs reduction. ToaSt transfers effectively to downstream tasks, cccccachieving 52.2 versus 51.9 mAP on COCO object detection. Code and models will be released upon acceptance.

</details>


### [34] [Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation](https://arxiv.org/abs/2602.15724)
*Shutian Gu,Chengkai Huang,Ruoyu Wang,Lina Yao*

Main category: cs.CV

TL;DR: 提出检索增强框架提升基于LLM的视觉语言导航效率，通过指令级轨迹检索和候选方向剪枝减少重复推理


<details>
  <summary>Details</summary>
Motivation: 基于提示的LLM导航存在效率问题：需要重复解释指令，并在每一步推理嘈杂冗长的导航候选。需要不修改LLM本身就能提升效率和稳定性的方法。

Method: 提出两级检索增强框架：1) 指令级嵌入检索器选择语义相似的成功轨迹作为上下文示例；2) 模仿学习的候选检索器在LLM推理前剪枝无关导航方向。两个模块轻量、模块化，独立于LLM训练。

Result: 在Room-to-Room基准测试中，在已见和未见环境上都一致提升了成功率、Oracle成功率和SPL。消融研究表明指令级示例检索和候选剪枝对全局指导和逐步决策效率有互补效益。

Conclusion: 检索增强决策支持是增强基于LLM的视觉语言导航的有效且可扩展策略，无需修改或微调底层语言模型。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning capability. However, prompt-based LLM navigation often suffers from inefficient decision-making, as the model must repeatedly interpret instructions from scratch and reason over noisy and verbose navigable candidates at each step. In this paper, we propose a retrieval-augmented framework to improve the efficiency and stability of LLM-based VLN without modifying or fine-tuning the underlying language model. Our approach introduces retrieval at two complementary levels. At the episode level, an instruction-level embedding retriever selects semantically similar successful navigation trajectories as in-context exemplars, providing task-specific priors for instruction grounding. At the step level, an imitation-learned candidate retriever prunes irrelevant navigable directions before LLM inference, reducing action ambiguity and prompt complexity. Both retrieval modules are lightweight, modular, and trained independently of the LLM. We evaluate our method on the Room-to-Room (R2R) benchmark. Experimental results demonstrate consistent improvements in Success Rate, Oracle Success Rate, and SPL on both seen and unseen environments. Ablation studies further show that instruction-level exemplar retrieval and candidate pruning contribute complementary benefits to global guidance and step-wise decision efficiency. These results indicate that retrieval-augmented decision support is an effective and scalable strategy for enhancing LLM-based vision-and-language navigation.

</details>


### [35] [Spanning the Visual Analogy Space with a Weight Basis of LoRAs](https://arxiv.org/abs/2602.15727)
*Hila Manor,Rinon Gal,Haggai Maron,Tomer Michaeli,Gal Chechik*

Main category: cs.CV

TL;DR: LoRWeB：通过动态组合学习到的LoRA基模块来实现视觉类比学习，提升未见视觉变换的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有方法使用单一LoRA模块来捕捉视觉变换，但固定模块限制了泛化能力。受限于LoRA在受限领域中形成可插值语义空间的启发，需要更灵活的动态组合方法

Method: 提出LoRWeB方法：1）学习一组LoRA基模块来覆盖不同的视觉变换空间；2）轻量级编码器根据输入类比对动态选择和加权这些基模块

Result: 综合评估显示该方法达到最先进性能，显著提升对未见视觉变换的泛化能力

Conclusion: LoRA基分解是灵活视觉操控的有前景方向，动态组合学习到的变换基元能有效解决视觉类比学习中的泛化限制

Abstract: Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\{\mathbf{a}$, $\mathbf{a}'$, $\mathbf{b}\}$, the goal is to generate $\mathbf{b}'$ such that $\mathbf{a} : \mathbf{a}' :: \mathbf{b} : \mathbf{b}'$. Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities. Inspired by recent work showing that LoRAs in constrained domains span meaningful, interpolatable semantic spaces, we propose LoRWeB, a novel approach that specializes the model for each analogy task at inference time through dynamic composition of learned transformation primitives, informally, choosing a point in a "space of LoRAs". We introduce two key components: (1) a learnable basis of LoRA modules, to span the space of different visual transformations, and (2) a lightweight encoder that dynamically selects and weighs these basis LoRAs based on the input analogy pair. Comprehensive evaluations demonstrate our approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations. Our findings suggest that LoRA basis decompositions are a promising direction for flexible visual manipulation. Code and data are in https://research.nvidia.com/labs/par/lorweb

</details>


### [36] [Language and Geometry Grounded Sparse Voxel Representations for Holistic Scene Understanding](https://arxiv.org/abs/2602.15734)
*Guile Wu,David Huang,Bingbing Liu,Dongfeng Bai*

Main category: cs.CV

TL;DR: 提出了一种利用语言和几何基础稀疏体素表示的统一框架，协同建模3D场景的外观、语义和几何，在整体场景理解和重建方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D开放词汇场景理解方法主要关注从2D基础模型蒸馏语言特征到3D特征场，但忽视了场景外观、语义和几何之间的协同作用，导致场景理解偏离几何结构并与重建过程脱节。

Method: 使用3D稀疏体素作为基本单元，构建包含外观场、密度场、特征场和置信场的统一表示框架。通过特征调制模块促进各场之间的协同，从2D基础模型蒸馏语言特征，并通过深度相关正则化和模式一致性正则化从几何基础模型蒸馏几何知识。

Result: 广泛的实验表明，该方法在整体场景理解和重建方面相比最先进方法取得了优越的整体性能。

Conclusion: 提出了一种统一框架，能够协同建模3D场景的外观、语义和几何，解决了现有方法中场景理解与几何结构脱节的问题，在场景理解和重建任务中表现出色。

Abstract: Existing 3D open-vocabulary scene understanding methods mostly emphasize distilling language features from 2D foundation models into 3D feature fields, but largely overlook the synergy among scene appearance, semantics, and geometry. As a result, scene understanding often deviates from the underlying geometric structure of scenes and becomes decoupled from the reconstruction process. In this work, we propose a novel approach that leverages language and geometry grounded sparse voxel representations to comprehensively model appearance, semantics, and geometry within a unified framework. Specifically, we use 3D sparse voxels as primitives and employ an appearance field, a density field, a feature field, and a confidence field to holistically represent a 3D scene. To promote synergy among the appearance, density, and feature fields, we construct a feature modulation module and distill language features from a 2D foundation model into our 3D scene model. In addition, we integrate geometric distillation into feature field distillation to transfer geometric knowledge from a geometry foundation model to our 3D scene representations via depth correlation regularization and pattern consistency regularization. These components work together to synergistically model the appearance, semantics, and geometry of the 3D scene within a unified framework. Extensive experiments demonstrate that our approach achieves superior overall performance compared with state-of-the-art methods in holistic scene understanding and reconstruction.

</details>


### [37] [RaCo: Ranking and Covariance for Practical Learned Keypoints](https://arxiv.org/abs/2602.15755)
*Abhiram Shenoi,Philipp Lindenberger,Paul-Edouard Sarlin,Marc Pollefeys*

Main category: cs.CV

TL;DR: RaCo是一种轻量级神经网络，通过可重复关键点检测器、可微分排序器和协方差估计器三个组件，仅使用透视图像裁剪训练，无需共视图像对，就能学习适用于多种3D视觉任务的鲁棒关键点。


<details>
  <summary>Details</summary>
Motivation: 现有关键点检测方法通常需要共视图像对进行训练，且在处理大平面旋转时鲁棒性不足。RaCo旨在开发一种无需共视图像对、具有强旋转鲁棒性的轻量级关键点检测方法，适用于多种3D视觉任务。

Method: RaCo包含三个核心组件：1）可重复关键点检测器；2）可微分排序器，用于在有限关键点数量下最大化匹配；3）协方差估计器，用于量化度量尺度下的空间不确定性。仅使用透视图像裁剪训练，无需共视图像对，通过大量数据增强实现旋转鲁棒性，避免使用计算昂贵的等变网络架构。

Result: 在多个挑战性数据集上评估，RaCo在关键点可重复性和两视图匹配方面达到最先进性能，特别是在大平面旋转情况下表现突出。能够独立估计关键点排序和度量协方差，无需额外标签，检测出可解释且可重复的兴趣点。

Conclusion: RaCo提供了一种有效且简单的策略，仅通过透视图像裁剪训练，无需共视图像对，就能学习鲁棒且通用的关键点。该方法在旋转鲁棒性方面表现出色，为3D计算机视觉任务提供了实用的关键点检测解决方案。

Abstract: This paper introduces RaCo, a lightweight neural network designed to learn robust and versatile keypoints suitable for a variety of 3D computer vision tasks. The model integrates three key components: the repeatable keypoint detector, a differentiable ranker to maximize matches with a limited number of keypoints, and a covariance estimator to quantify spatial uncertainty in metric scale. Trained on perspective image crops only, RaCo operates without the need for covisible image pairs. It achieves strong rotational robustness through extensive data augmentation, even without the use of computationally expensive equivariant network architectures. The method is evaluated on several challenging datasets, where it demonstrates state-of-the-art performance in keypoint repeatability and two-view matching, particularly under large in-plane rotations. Ultimately, RaCo provides an effective and simple strategy to independently estimate keypoint ranking and metric covariance without additional labels, detecting interpretable and repeatable interest points. The code is available at https://github.com/cvg/RaCo.

</details>


### [38] [Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models](https://arxiv.org/abs/2602.15772)
*Sen Ye,Mengde Xu,Shuyang Gu,Di He,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: R3框架通过"生成-理解-再生成"的多步过程解决多模态模型中生成与理解能力的权衡问题


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型面临一个关键挑战：提升生成能力往往以牺牲理解为代价，反之亦然。研究发现生成与理解之间可能存在冲突，导致模型内部形成竞争动态

Method: 提出Reason-Reflect-Refine (R3)框架，将单步生成任务重构为"生成-理解-再生成"的多步过程，在生成过程中显式利用模型的理解能力

Result: 成功缓解了优化困境，实现了更强的生成结果和与生成过程相关的理解能力提升

Conclusion: R3框架为设计下一代统一多模态模型提供了有价值的见解，代码已开源

Abstract: Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of "generate-understand-regenerate". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma, achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models. Code is available at https://github.com/sen-ye/R3.

</details>


### [39] [NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy](https://arxiv.org/abs/2602.15775)
*Laura Salort-Benejam,Antonio Agudo*

Main category: cs.CV

TL;DR: NeRFscopy：一种用于内窥镜视频的自监督神经渲染管道，可实现可变形组织的3D重建和新视角合成


<details>
  <summary>Details</summary>
Motivation: 内窥镜在医学成像中至关重要，但现有方法面临组织可变形、单目相机、光照变化、遮挡和未知相机轨迹等挑战。开发鲁棒的动态3D重建管道可以增强可视化、提高诊断准确性、辅助治疗规划和指导手术。

Method: 提出NeRFscopy自监督管道，包含具有规范辐射场和时间相关变形场的可变形模型，使用SE(3)变换参数化。通过引入复杂项有效利用彩色图像，无需任何模板或预训练模型，仅从数据中学习3D隐式模型。

Result: NeRFscopy在新视角合成方面取得了准确结果，在各种具有挑战性的内窥镜场景中优于竞争方法。

Conclusion: NeRFscopy为内窥镜视频中可变形组织的3D重建和新视角合成提供了一种有效的自监督解决方案，能够克服传统方法面临的挑战。

Abstract: Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. However, challenges arise due to the deformable nature of the tissues, the use of monocular cameras, illumination changes, occlusions and unknown camera trajectories. Inspired by neural rendering, we introduce NeRFscopy, a self-supervised pipeline for novel view synthesis and 3D reconstruction of deformable endoscopic tissues from a monocular video. NeRFscopy includes a deformable model with a canonical radiance field and a time-dependent deformation field parameterized by SE(3) transformations. In addition, the color images are efficiently exploited by introducing sophisticated terms to learn a 3D implicit model without assuming any template or pre-trained model, solely from data. NeRFscopy achieves accurate results in terms of novel view synthesis, outperforming competing methods across various challenging endoscopy scenes.

</details>


### [40] [Meteorological data and Sky Images meets Neural Models for Photovoltaic Power Forecasting](https://arxiv.org/abs/2602.15782)
*Ines Montoya-Espinagosa,Antonio Agudo*

Main category: cs.CV

TL;DR: 该研究提出了一种结合天空图像、光伏历史数据和气象数据的多模态混合方法，用于短期和长期光伏预测，特别关注提高斜坡事件预测准确性和多云条件下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源特别是太阳能的使用增加，光伏发电的变异性带来了挑战。需要改进光伏预测方法以应对光伏能源生产的波动性，支持电网更高效运行和太阳能变异性管理。

Method: 采用混合多模态方法，结合天空图像、光伏历史数据和气象数据。使用深度神经网络模型进行临近预报和预报，整合单个和多个气象变量以及太阳位置分析。

Result: 结果表明，包含气象数据（特别是地表长波辐射、向下辐射以及风与太阳位置的组合）显著改善了当前预测，尤其是在多云天的临近预报和预报任务中。

Conclusion: 该研究强调了整合多样化数据源对于提高太阳能预测模型可靠性和可解释性的重要性，为电网运营和太阳能变异性管理提供了更有效的预测工具。

Abstract: Due to the rise in the use of renewable energies as an alternative to traditional ones, and especially solar energy, there is increasing interest in studying how to address photovoltaic forecasting in the face of the challenge of variability in photovoltaic energy production, using different methodologies. This work develops a hybrid approach for short and long-term forecasting based on two studies with the same purpose. A multimodal approach that combines images of the sky and photovoltaic energy history with meteorological data is proposed. The main goal is to improve the accuracy of ramp event prediction, increase the robustness of forecasts in cloudy conditions, and extend capabilities beyond nowcasting, to support more efficient operation of the power grid and better management of solar variability. Deep neural models are used for both nowcasting and forecasting solutions, incorporating individual and multiple meteorological variables, as well as an analytical solar position. The results demonstrate that the inclusion of meteorological data, particularly the surface long-wave, radiation downwards, and the combination of wind and solar position, significantly improves current predictions in both nowcasting and forecasting tasks, especially on cloudy days. This study highlights the importance of integrating diverse data sources to improve the reliability and interpretability of solar energy prediction models.

</details>


### [41] [Context-aware Skin Cancer Epithelial Cell Classification with Scalable Graph Transformers](https://arxiv.org/abs/2602.15783)
*Lucas Sancéré,Noémie Moreau,Katarzyna Bozek*

Main category: cs.CV

TL;DR: 提出使用可扩展的图变换器对全切片细胞图进行分类，在皮肤鳞状细胞癌的肿瘤与健康上皮细胞分类任务中，图变换器方法优于基于图像的方法。


<details>
  <summary>Details</summary>
Motivation: 全切片图像包含丰富的医学诊断信息，但现有基于卷积神经网络和视觉变换器的深度学习方法依赖于基于补丁的表示，丢失了重要的组织级上下文信息。特别是在皮肤鳞状细胞癌中，肿瘤与健康上皮细胞形态相似，难以通过图像方法区分。

Method: 使用可扩展的图变换器（SGFormer和DIFFormer）对全切片细胞图进行分类。首先在单个WSI上比较图像和图方法，然后扩展到多个患者的多张WSI。为处理计算约束，从每张图像提取四个2560×2560像素补丁并转换为图。评估了多种节点特征配置。

Result: 在单个WSI的3折交叉验证中，SGFormer和DIFFormer分别达到85.2±1.5%和85.1±2.5%的平衡准确率，而最佳图像方法为81.2±3.0%。在多WSI设置中，DIFFormer达到83.6±1.9%，而最先进的图像模型CellViT256为78.1±0.5%。最具信息性的表示结合了形态学、纹理特征以及非上皮细胞的细胞类别。

Conclusion: 图变换器方法在皮肤鳞状细胞癌的细胞分类任务中优于图像方法，证明了细胞图表示在保留组织级上下文方面的优势，特别是结合形态学、纹理特征和周围细胞环境信息时效果最佳。

Abstract: Whole-slide images (WSIs) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. To automate their analysis, numerous deep learning methods based on convolutional neural networks and Vision Transformers have been developed and have achieved strong performance in segmentation and classification tasks. However, due to the large size and complex cellular organization of WSIs, these models rely on patch-based representations, losing vital tissue-level context. We propose using scalable Graph Transformers on a full-WSI cell graph for classification. We evaluate this methodology on a challenging task: the classification of healthy versus tumor epithelial cells in cutaneous squamous cell carcinoma (cSCC), where both cell types exhibit very similar morphologies and are therefore difficult to differentiate for image-based approaches. We first compared image-based and graph-based methods on a single WSI. Graph Transformer models SGFormer and DIFFormer achieved balanced accuracies of $85.2 \pm 1.5$ ($\pm$ standard error) and $85.1 \pm 2.5$ in 3-fold cross-validation, respectively, whereas the best image-based method reached $81.2 \pm 3.0$. By evaluating several node feature configurations, we found that the most informative representation combined morphological and texture features as well as the cell classes of non-epithelial cells, highlighting the importance of the surrounding cellular context. We then extended our work to train on several WSIs from several patients. To address the computational constraints of image-based models, we extracted four $2560 \times 2560$ pixel patches from each image and converted them into graphs. In this setting, DIFFormer achieved a balanced accuracy of $83.6 \pm 1.9$ (3-fold cross-validation), while the state-of-the-art image-based model CellViT256 reached $78.1 \pm 0.5$.

</details>


### [42] [Task-Agnostic Continual Learning for Chest Radiograph Classification](https://arxiv.org/abs/2602.15811)
*Muthu Subash Kavitha,Anas Zafar,Amgad Muneer,Jia Wu*

Main category: cs.CV

TL;DR: CARL-XRay：一种用于胸部X光分类的持续学习方法，通过适配器路由策略实现无需重训练历史数据的模型更新，支持任务未知推理。


<details>
  <summary>Details</summary>
Motivation: 临床部署胸部X光分类器需要能够随着新数据集出现而更新的模型，但传统方法需要重新训练所有历史数据或导致性能下降。现有方法缺乏针对胸部X光分类的任务增量持续学习研究，特别是在任务标识符在推理时不可用的情况下。

Method: 提出CARL-XRay方法：1）保持固定的高容量主干网络；2）增量分配轻量级任务特定适配器和分类器头；3）潜在任务选择器基于任务适应特征操作，利用当前和历史上下文（通过紧凑原型和特征级经验回放）；4）避免原始图像存储，支持稳定任务识别和适应。

Result: 在大规模公共胸部X光数据集上：1）在任务未知部署中优于联合训练，路由准确率75.0% vs. 62.5%；2）在真实任务标识符的oracle设置下AUROC为0.74，任务未知推理下为0.75；3）使用显著更少的可训练参数；4）保持稳健的性能保留和可靠的任务感知推理。

Conclusion: CARL-XRay为临床持续部署提供了实用的替代方案，避免了联合训练和重复完全重训练的需求，支持模型在任务未知情况下稳定更新和部署。

Abstract: Clinical deployment of chest radiograph classifiers requires models that can be updated as new datasets become available without retraining on previously ob- served data or degrading validated performance. We study, for the first time, a task-incremental continual learning setting for chest radiograph classification, in which heterogeneous chest X-ray datasets arrive sequentially and task identifiers are unavailable at inference. We propose a continual adapter-based routing learning strategy for Chest X-rays (CARL-XRay) that maintains a fixed high-capacity backbone and incrementally allocates lightweight task-specific adapters and classifier heads. A latent task selector operates on task-adapted features and leverages both current and historical context preserved through compact prototypes and feature-level experience replay. This design supports stable task identification and adaptation across sequential updates while avoiding raw-image storage. Experiments on large-scale public chest radiograph datasets demonstrate robust performance retention and reliable task-aware inference under continual dataset ingestion. CARL-XRay outperforms joint training under task-unknown deployment, achieving higher routing accuracy (75.0\% vs.\ 62.5\%), while maintaining competitive diagnostic performance with AUROC of 0.74 in the oracle setting with ground-truth task identity and 0.75 under task-unknown inference, using significantly fewer trainable parameters. Finally, the proposed framework provides a practical alternative to joint training and repeated full retraining in continual clinical deployment.

</details>


### [43] [VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation](https://arxiv.org/abs/2602.15819)
*Hui Ren,Yuval Alaluf,Omer Bar Tal,Alexander Schwing,Antonio Torralba,Yael Vinker*

Main category: cs.CV

TL;DR: 提出一种数据高效的序列草图生成方法，通过微调文本到视频扩散模型，利用LLM进行语义规划和笔画排序，视频扩散模型作为渲染器生成高质量的时序草图绘制过程。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型将草图视为静态图像，忽略了绘制过程中的时序结构，而草图绘制本质上是顺序过程，笔画按有意义顺序绘制以探索和精炼想法。

Method: 将草图表示为短视频，笔画在空白画布上逐步绘制，采用两阶段微调策略：第一阶段使用合成形状组合学习笔画排序，第二阶段仅用7个人工绘制的草图过程学习视觉外观。

Result: 尽管使用极少量人工草图数据，方法能生成高质量的序列草图，紧密遵循文本指定的顺序，同时展现丰富的视觉细节，并支持笔刷风格控制和自回归草图生成。

Conclusion: 结合LLM的语义规划和视频扩散模型的渲染能力，实现了数据高效的序列草图生成，为交互式协作绘图提供了灵活可控的解决方案。

Abstract: Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. We present a data-efficient approach for sequential sketch generation that adapts pretrained text-to-video diffusion models to generate sketching processes. Our key insight is that large language models and video diffusion models offer complementary strengths for this task: LLMs provide semantic planning and stroke ordering, while video diffusion models serve as strong renderers that produce high-quality, temporally coherent visuals. We leverage this by representing sketches as short videos in which strokes are progressively drawn on a blank canvas, guided by text-specified ordering instructions. We introduce a two-stage fine-tuning strategy that decouples the learning of stroke ordering from the learning of sketch appearance. Stroke ordering is learned using synthetic shape compositions with controlled temporal structure, while visual appearance is distilled from as few as seven manually authored sketching processes that capture both global drawing order and the continuous formation of individual strokes. Despite the extremely limited amount of human-drawn sketch data, our method generates high-quality sequential sketches that closely follow text-specified orderings while exhibiting rich visual detail. We further demonstrate the flexibility of our approach through extensions such as brush style conditioning and autoregressive sketch generation, enabling additional controllability and interactive, collaborative drawing.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [44] [EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research](https://arxiv.org/abs/2602.15034)
*Houping Yue,Zixiang Di,Mei Jiang,Bingdong Li,Hao Hao,Yu Song,Bo Jiang,Aimin Zhou*

Main category: cs.CL

TL;DR: EduResearchBench是首个专门评估教育学术写作能力的平台，通过分层原子任务分解框架将研究流程分解为6个模块24个原子任务，提供细粒度诊断评估，并基于课程学习策略训练出EduWrite模型，在30B参数下超越72B通用模型。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在社会科学AI应用中面临评估挑战，现有基准测试主要关注单次、整体性生成，缺乏对复杂学术研究流程的细粒度评估，无法反映真实学术写作需求。

Method: 提出分层原子任务分解(HATD)框架，将端到端研究流程分解为6个专业研究模块和24个原子任务；采用课程学习策略从基础技能逐步过渡到复杂方法论推理；基于55K原始学术样本构建11K高质量指令对训练EduWrite模型。

Result: EduWrite(30B参数)在多个核心指标上显著超越更大的通用模型(72B)，证明在垂直领域中，数据质量密度和分层训练课程比参数规模更具决定性。

Conclusion: EduResearchBench填补了学术写作评估的空白，通过细粒度诊断评估和课程学习策略，展示了在专业领域中，专业化训练策略比单纯扩大模型规模更有效，为AI4SS提供了新的评估范式。

Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic generation and thus lack the fine-grained assessments required to reflect complex academic research workflows. To fill this gap, we introduce EduResearchBench, the first comprehensive evaluation platform dedicated to educational academic writing. EduResearchBench is built upon our Hierarchical Atomic Task Decomposition (HATD) framework, which decomposes an end-to-end research workflow into six specialized research modules (e.g., Quantitative Analysis, Qualitative Research, and Policy Research) spanning 24 fine-grained atomic tasks. This taxonomy enables an automated evaluation pipeline that mitigates a key limitation of holistic scoring, where aggregate scores often obscure specific capability bottlenecks, and instead provides fine-grained, diagnostic feedback on concrete deficiencies. Moreover, recognizing the high cognitive load inherent in scholarly writing, we propose a curriculum learning strategy that progressively builds competence from foundational skills to complex methodological reasoning and argumentation. Leveraging 55K raw academic samples, we curate 11K high-quality instruction pairs to train EduWrite, a specialized educational scholarly writing model. Experiments show that EduWrite (30B) substantially outperforms larger general-purpose models (72B) on multiple core metrics, demonstrating that in vertical domains, data quality density and hierarchically staged training curricula are more decisive than parameter scale.

</details>


### [45] [Indic-TunedLens: Interpreting Multilingual Models in Indian Languages](https://arxiv.org/abs/2602.15038)
*Mihir Panchal,Deeksha Varshney,Mamta,Asif Ekbal*

Main category: cs.CL

TL;DR: Indic-TunedLens：针对印度语言的可解释性框架，通过学习共享仿射变换来调整隐藏状态，比标准Logit Lens能更准确地解码多语言模型表示。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在印度等语言多样化地区部署增多，但现有可解释性工具主要针对英语。研究发现LLM通常在英语中心表示空间中运行，跨语言可解释性成为迫切需求。

Method: 提出Indic-TunedLens框架，为每种目标语言学习共享仿射变换，调整隐藏状态以对齐目标输出分布，实现更忠实的模型表示解码。

Result: 在10种印度语言的MMLU基准测试中，Indic-TunedLens显著优于现有最先进可解释性方法，特别是在形态丰富、资源匮乏的语言上表现突出。

Conclusion: 该框架为多语言变换器的分层语义编码提供了重要见解，有助于理解LLM在非英语语言中的内部表示机制。

Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability framework specifically for Indian languages that learns shared affine transformations. Unlike the standard Logit Lens, which directly decodes intermediate activations, Indic-TunedLens adjusts hidden states for each target language, aligning them with the target output distributions to enable more faithful decoding of model representations. We evaluate our framework on 10 Indian languages using the MMLU benchmark and find that it significantly improves over SOTA interpretability methods, especially for morphologically rich, low resource languages. Our results provide crucial insights into the layer-wise semantic encoding of multilingual transformers. Our model is available at https://huggingface.co/spaces/AnonymousAccountACL/IndicTunedLens. Our code is available at https://github.com/AnonymousAccountACL/IndicTunedLens.

</details>


### [46] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: 提出CGRA DeBERTa模型，通过概念引导的残差域增强Transformer框架，显著提升伊斯兰圣训文本的问答准确率，达到97.85 EM分数，超越BERT和DeBERTa。


<details>
  <summary>Details</summary>
Motivation: 伊斯兰经典文本的问答面临领域特定语义、长上下文依赖和概念敏感推理的挑战，需要专门针对神学领域优化的解决方案。

Method: 基于定制DeBERTa Transformer骨干，结合轻量级LoRA适配和残差概念感知门控机制，利用包含12个核心术语的伊斯兰概念词典融入神学先验知识。

Result: 在42,591个QA对的数据集上，CGRA DeBERTa获得97.85 EM分数，显著超越BERT（75.87）和DeBERTa（89.77），仅增加约8%推理开销。

Conclusion: 该研究提出了高效、可解释且准确的圣训问答系统，能够为教育材料提供必要的神学细微差别，同时保持计算效率。

Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.

</details>


### [47] [AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking](https://arxiv.org/abs/2602.15190)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: 提出一个结合检索增强生成和反向图像搜索的第三名系统，用于事实核查任务，每次核查仅需0.013美元，易于复现和调整。


<details>
  <summary>Details</summary>
Motivation: 构建一个简单但性能竞争的事实核查系统，结合文本和图像检索能力，同时保持低成本和高可复现性。

Method: 系统包含三个解耦模块：基于相似性搜索的文本检索模块、基于API访问的反向图像搜索模块、以及使用GPT5.1的生成模块。

Result: 在AVerImaTeC共享任务中获得第三名，每次事实核查平均成本仅0.013美元，性能具有竞争力。

Conclusion: 该系统提供了一个易于复现和调整的起点，适合进一步实验，作者已公开代码、提示、向量存储和成本分析。

Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year's retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers competitive performance with a single multimodal LLM call per fact-check at just $0.013 on average using GPT5.1 via OpenAI Batch API. Our system is also easy to reproduce and tweak, consisting of only three decoupled modules - a textual retrieval module based on similarity search, an image retrieval module based on API-accessed RIS, and a generation module using GPT5.1 - which is why we suggest it as an accesible starting point for further experimentation. We publish its code and prompts, as well as our vector stores and insights into the scheme's running costs and directions for further improvement.

</details>


### [48] [OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction](https://arxiv.org/abs/2602.15197)
*Skyler Hallinan,Thejas Venkatesh,Xiang Ren,Sai Praneeth Karimireddy,Ashwin Paranjape,Yuhao Zhang,Jack Hessel*

Main category: cs.CL

TL;DR: 论文提出了OpaqueToolsBench基准测试，用于评估LLM在工具不透明环境下的表现，并提出了ToolObserver框架通过迭代观察执行反馈来改进工具文档，显著提升了性能并减少了token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试假设工具简单且文档完善，但现实世界中的工具（如通用"搜索"API）往往不透明，缺乏明确的最佳实践或失败模式。需要研究LLM代理能否通过交互和改进文档来提升在不透明工具环境中的性能。

Method: 创建了OpaqueToolsBench基准测试，包含三个任务导向环境：通用函数调用、交互式国际象棋对弈和长轨迹代理搜索。提出了ToolObserver框架，通过迭代观察工具调用轨迹的执行反馈来改进工具文档。

Result: 在OpaqueToolsBench上的结果显示，现有自动文档生成方法在不透明工具环境下昂贵且不可靠。ToolObserver在所有数据集上都优于现有方法，在测试时工具探索设置中效率更高，总token消耗比最佳基线少3.5-7.5倍。

Conclusion: LLM代理可以通过迭代观察执行反馈来改进不透明工具的文档，从而显著提升性能。ToolObserver框架为处理现实世界中不透明工具提供了一种有效且高效的解决方案。

Abstract: Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general "search" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5x fewer total tokens than the best baseline.

</details>


### [49] [Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement](https://arxiv.org/abs/2602.15312)
*Stephan Ludwig,Peter J. Danaher,Xiaohao Yang,Yu-Ting Lin,Ehsan Abedin,Dhruv Grewal,Lan Du*

Main category: cs.CL

TL;DR: LX模型通过微调大语言模型，从消费者文本中准确提取16种消费相关情绪和4个评价构念，在多项任务上超越GPT-4等现有模型，为营销研究提供了新的方法论基础。


<details>
  <summary>Details</summary>
Motivation: 准确从非结构化文本中测量消费者情绪和评价是营销研究和实践的核心挑战，现有模型在这方面存在局限，需要更精准的消费者感知测量方法。

Method: 开发了Linguistic eXtractor (LX)模型，通过微调大语言模型，在消费者自述文本及其自我报告的16种消费情绪和4个评价构念（信任、承诺、推荐、情感）标签上进行训练。

Result: LX在开放式调查回复中达到81%的宏观F1准确率，在第三方标注的亚马逊和Yelp评论中准确率超过95%，均优于GPT-4 Turbo、RoBERTa和DeepSeek等领先模型。应用分析显示评论表达的情绪能预测产品评分，进而影响购买行为。

Conclusion: LX为消费者感知测量建立了新的方法论基础，证明大语言模型能有效推进营销研究和实践，情绪语调提供了超越星级评分的有效信号，并提供了免费的无代码网络应用支持实际使用。

Abstract: Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.

</details>


### [50] [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)
*Zihao Tang,Xin Yu,Ziyu Xiao,Zengxuan Wen,Zelin Li,Jiaxi Zhou,Hualei Wang,Haohua Wang,Haizhen Huang,Weiwei Deng,Feng Sun,Qi Zhang*

Main category: cs.CL

TL;DR: Mnemis是一个新颖的AI记忆框架，结合了基于相似性的System-1检索和需要全局推理的System-2机制，通过图结构组织记忆，在长期记忆基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（RAG和Graph-RAG）主要通过相似性机制检索记忆，这种System-1风格的检索在处理需要全局推理或全面覆盖相关信息的场景时存在困难。

Method: Mnemis将记忆组织为基础图（用于相似性检索）和层次图（支持自上而下的语义层次遍历），结合System-1相似性搜索和System-2全局选择机制。

Result: 在长期记忆基准测试中达到最先进性能：在LoCoMo上得分93.9，在LongMemEval-S上得分91.6（使用GPT-4.1-mini）。

Conclusion: 通过结合两种检索路径的互补优势，Mnemis能够检索既语义相关又结构相关的记忆项，有效解决了传统相似性检索在全局推理场景中的局限性。

Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.

</details>


### [51] [NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.15353)
*Rong Fu,Yang Li,Zeyu Zhang,Jiekai Wu,Yaohua Liu,Shuaishuai Cao,Yangchen Zeng,Yuhang Zhang,Xiaojing Du,Chuang Zhao,Kangning Cui,Simon Fong*

Main category: cs.CL

TL;DR: NeuroSymActive是一个结合神经符号推理与主动探索的框架，用于知识图谱问答，在保持高准确率的同时减少昂贵的图查询和模型调用。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型和神经推理系统在处理需要精确、结构化多跳推理的知识密集型查询时仍面临挑战。知识图谱提供了事实基础，但将图结构与神经模型结合存在困难：简单嵌入图事实到提示中效率低且脆弱，而纯符号或搜索密集的方法检索成本高且缺乏基于梯度的优化。

Method: NeuroSymActive是一个模块化框架，结合了可微分的神经符号推理层与主动、价值引导的探索控制器。该方法将软统一风格的符号模块与神经路径评估器以及蒙特卡洛风格的探索策略相结合，优先扩展高价值路径。

Result: 在标准KGQA基准测试中的实证结果表明，NeuroSymActive在保持强答案准确率的同时，相比常见的检索增强基线方法，减少了昂贵的图查询和模型调用次数。

Conclusion: NeuroSymActive通过神经符号推理与主动探索的有效结合，为知识图谱问答提供了一种高效且准确的解决方案，平衡了符号推理的精确性与神经模型的灵活性。

Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.

</details>


### [52] [Far Out: Evaluating Language Models on Slang in Australian and Indian English](https://arxiv.org/abs/2602.15373)
*Deniz Kaya Dilsiz,Dipankar Srirag,Aditya Joshi*

Main category: cs.CL

TL;DR: 该研究评估了语言模型对印度英语和澳大利亚英语中俚语的识别能力，发现模型在判别任务上表现优于生成任务，且对真实网络数据比合成数据更敏感，印度英语任务表现优于澳大利亚英语。


<details>
  <summary>Details</summary>
Motivation: 语言模型在处理非标准语言变体时存在系统性性能差距，但对特定变体俚语的理解能力在多种语言中尚未得到充分探索，特别是在印度英语和澳大利亚英语这样的英语变体中。

Method: 构建了两个互补数据集：Web数据集包含377个来自Urban Dictionary的网络俚语用例，Gen数据集包含1,492个合成生成的俚语使用场景。评估了7个最先进的语言模型在三个任务上的表现：目标词预测(TWP)、引导目标词预测(TWP*)和目标词选择(TWS)。

Result: 主要发现：(1) TWS任务平均表现优于TWP和TWP*，准确率从0.03提升到0.49；(2) 模型在Web数据集上表现优于Gen数据集，相似度得分分别提高0.03和0.05；(3) 印度英语任务在所有模型和数据集上平均表现优于澳大利亚英语，TWS任务差异最大，准确率从0.44提升到0.54。

Conclusion: 研究揭示了语言模型在生成和判别能力之间的基本不对称性，特别是在处理变体特定的俚语表达时，即使是在英语这样技术丰富的语言中也是如此。

Abstract: Language models exhibit systematic performance gaps when processing text in non-standard language varieties, yet their ability to comprehend variety-specific slang remains underexplored for several languages. We present a comprehensive evaluation of slang awareness in Indian English (en-IN) and Australian English (en-AU) across seven state-of-the-art language models. We construct two complementary datasets: \textsc{web}, containing 377 web-sourced usage examples from Urban Dictionary, and \textsc{gen}, featuring 1,492 synthetically generated usages of these slang terms, across diverse scenarios. We assess language models on three tasks: target word prediction (TWP), guided target word prediction (TWP$^*$) and target word selection (TWS). Our results reveal four key findings: (1) Higher average model performance TWS versus TWP and TWP$^*$, with average accuracy score increasing from 0.03 to 0.49 respectively (2) Stronger average model performance on \textsc{web} versus \textsc{gen} datasets, with average similarity score increasing by 0.03 and 0.05 across TWP and TWP$^*$ tasks respectively (3) en-IN tasks outperform en-AU when averaged across all models and datasets, with TWS demonstrating the largest disparity, increasing average accuracy from 0.44 to 0.54. These findings underscore fundamental asymmetries between generative and discriminative competencies for variety-specific language, particularly in the context of slang expressions despite being in a technologically rich language such as English.

</details>


### [53] [Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework](https://arxiv.org/abs/2602.15377)
*Mengze Hong,Chen Jason Zhang,Zichang Guo,Hanlin Gu,Di Jiang,Li Qing*

Main category: cs.CL

TL;DR: 提出Task-Oriented Flowcharts (TOFs)框架，实现无需人工干预的端到端客服自动化，通过流程图抽象服务对话知识，支持本地部署小模型解决数据稀缺和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 现有客服自动化方法要么依赖模块化系统设计需要大量代理编排，要么使用过于简化的指令模式，导致指导有限且泛化能力差。需要一种编排自由的端到端自动化框架。

Method: 1) 定义TOFs组件和评估指标；2) 提出成本高效的流程图构建算法，从服务对话中抽象程序性知识；3) 强调小语言模型本地部署，提出基于流程图的去中心化蒸馏方法，缓解模型训练中的数据稀缺和隐私问题。

Result: 在多种服务任务上的广泛实验验证了方法的有效性，相比强基线方法和市场产品，在定量和应用性能上均表现优越。发布了基于Web的系统演示和案例研究。

Conclusion: TOFs框架能够实现编排自由的端到端客服自动化，通过流程图知识抽象和去中心化蒸馏解决实际部署中的数据隐私问题，为未来服务自动化提供了简化创建途径。

Abstract: Customer service automation has seen growing demand within digital transformation. Existing approaches either rely on modular system designs with extensive agent orchestration or employ over-simplified instruction schemas, providing limited guidance and poor generalizability. This paper introduces an orchestration-free framework using Task-Oriented Flowcharts (TOFs) to enable end-to-end automation without manual intervention. We first define the components and evaluation metrics for TOFs, then formalize a cost-efficient flowchart construction algorithm to abstract procedural knowledge from service dialogues. We emphasize local deployment of small language models and propose decentralized distillation with flowcharts to mitigate data scarcity and privacy issues in model training. Extensive experiments validate the effectiveness in various service tasks, with superior quantitative and application performance compared to strong baselines and market products. By releasing a web-based system demonstration with case studies, we aim to promote streamlined creation of future service automation.

</details>


### [54] [Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language](https://arxiv.org/abs/2602.15378)
*Prathamesh Devadiga,Paras Chopra*

Main category: cs.CL

TL;DR: 研究探索大语言模型能否通过结构化提示而非微调，在训练数据中几乎不存在的语言（以图鲁语为例）上实现基本对话能力。通过结合语法文档、负约束、罗马化标准化和质量控制的合成数据生成，显著降低了词汇污染并提高了语法准确性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索大语言模型是否能在训练数据中几乎不存在的语言上实现对话能力。以图鲁语（Dravidian语系，200多万使用者但数字存在极少）为案例，研究不通过微调，仅通过结构化提示能否激发基本对话能力。

Method: 方法包括：1）结合明确的语法文档；2）使用负约束抑制相关语言的高概率词汇；3）罗马化标准化；4）通过自我游戏生成质量控制的合成数据。在三个LLM（Gemini 2.0 Flash、GPT-4o、Llama 3.1 70B）上评估，并由母语者验证。

Result: 结果：词汇污染从80%降低到5%，语法准确率达到85%。负约束带来12-18个百分点的稳定提升，语法文档的效果因模型架构而异（8-22个百分点）。

Conclusion: 结论表明，即使对于训练数据中几乎不存在的语言，通过精心设计的结构化提示（特别是负约束和语法文档），大语言模型也能实现基本的对话能力，为低资源语言支持提供了有前景的途径。

Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than fine-tuning an LLM, we examine whether structured prompts alone can elicit basic conversational ability under controlled prompting. We systematically tackle various challenges posed by absence of training data for Tulu by combining explicit grammar documentation, negative constraints to suppress high-probability tokens from related languages, romanization standardization, and quality-controlled synthetic data generation via self-play. Evaluated on a manually curated held-out set across three LLMs (Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B) and validated by native speakers, our approach reduces vocabulary contamination from 80% to 5% while achieving 85% grammatical accuracy. Cross-model analysis reveals that negative constraints provide consistent improvements (12--18 percentage points), while grammar documentation effects vary by model architecture (8--22 points).

</details>


### [55] [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)
*Xiaoze Liu,Ruowang Zhang,Weichen Yu,Siheng Xiong,Liu He,Feijie Wu,Hoin Jung,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.CL

TL;DR: Vision Wormhole框架利用视觉语言模型的视觉接口实现模型无关的无文本通信，通过通用视觉编解码器将异构推理轨迹映射到共享连续潜在空间，显著降低多智能体系统通信开销


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的多智能体系统依赖离散文本通信，存在运行时开销大和信息量化损失问题，而现有潜在状态传输方法要么假设同构架构，要么依赖特定配对学习，限制了在异构模型间的可扩展性和模块化

Method: 提出Vision Wormhole框架，引入通用视觉编解码器将异构推理轨迹映射到共享连续潜在空间，采用中心辐射拓扑结构将成对对齐复杂度从O(N²)降至O(N)，使用无标签师生蒸馏目标对齐高速视觉通道与文本推理模式

Result: 在异构模型家族（如Qwen-VL、Gemma）上的广泛实验表明，Vision Wormhole在控制比较中减少了端到端运行时间，同时保持了与标准文本基多智能体系统相当的推理保真度

Conclusion: Vision Wormhole通过将视觉语言模型的视觉接口重新定位为通用通信端口，实现了模型无关的高效无文本通信，为异构多智能体系统提供了可扩展的解决方案

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a high-bandwidth alternative, existing approaches either assume homogeneous sender-receiver architectures or rely on pair-specific learned translators, limiting scalability and modularity across diverse model families with disjoint manifolds. In this work, we propose the Vision Wormhole, a novel framework that repurposes the visual interface of Vision-Language Models (VLMs) to enable model-agnostic, text-free communication. By introducing a Universal Visual Codec, we map heterogeneous reasoning traces into a shared continuous latent space and inject them directly into the receiver's visual pathway, effectively treating the vision encoder as a universal port for inter-agent telepathy. Our framework adopts a hub-and-spoke topology to reduce pairwise alignment complexity from O(N^2) to O(N) and leverages a label-free, teacher-student distillation objective to align the high-speed visual channel with the robust reasoning patterns of the text pathway. Extensive experiments across heterogeneous model families (e.g., Qwen-VL, Gemma) demonstrate that the Vision Wormhole reduces end-to-end wall-clock time in controlled comparisons while maintaining reasoning fidelity comparable to standard text-based MAS. Code is available at https://github.com/xz-liu/heterogeneous-latent-mas

</details>


### [56] [Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs](https://arxiv.org/abs/2602.15436)
*Joonatan Laato,Veera Schroderus,Jenna Kanerva,Jenni Kauppi,Virpi Lummaa,Filip Ginter*

Main category: cs.CL

TL;DR: 使用大语言模型对芬兰二战难民访谈中的35万个休闲活动和组织名称进行自动分类，构建结构化数据集用于社会整合研究


<details>
  <summary>Details</summary>
Motivation: 数字化历史档案包含大量日常生活信息，但直接提取的文本信息难以直接用于历史学家和社会学家的定量研究。芬兰二战难民访谈中提取的35万个活动和组织名称数量过多，无法直接分析。

Method: 开发包含活动类型、社交性、规律性和体力需求四个维度的分类框架；标注黄金标准数据集用于评估；测试大语言模型能否应用该分类框架；使用多轮投票方法提高分类准确性。

Result: 开放权重的大语言模型通过简单投票方法能够接近专家判断水平；成功将分类方法应用于35万个实体，为下游社会整合研究提供了结构化资源。

Conclusion: 大语言模型能够有效处理大规模历史档案中的复杂分类任务，为定量历史和社会学研究提供了可行的技术方案。

Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a quantitative manner. We address this problem in a large collection of Finnish World War II Karelian evacuee family interviews. Prior work extracted more than 350K mentions of leisure time activities and organizational memberships from these interviews, yielding 71K unique activity and organization names -- far too many to analyze directly.
  We develop a categorization framework that captures key aspects of participation (the kind of activity/organization, how social it typically is, how regularly it happens, and how physically demanding it is). We annotate a gold-standard set to allow for a reliable evaluation, and then test whether large language models can apply the same schema at scale. Using a simple voting approach across multiple model runs, we find that an open-weight LLM can closely match expert judgments. Finally, we apply the method to label the 350K entities, producing a structured resource for downstream studies of social integration and related outcomes.

</details>


### [57] [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)
*Chansung Park,Juyong Jiang,Fan Wang,Sayak Paul,Jiasi Shen,Jing Tang,Jianguo Li*

Main category: cs.CL

TL;DR: TAROT提出了一种测试驱动和能力自适应的课程强化微调方法，通过构建四层测试套件和根据模型能力自适应选择课程策略，显著提升了代码生成的功能正确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调方法忽视了测试用例的异质难度和粒度，导致奖励信号分布不均和训练中的梯度偏差，限制了LLMs在算法复杂代码生成方面的深度推理能力。

Method: TAROT为每个问题构建四层测试套件（基础、中级、复杂、边缘），将课程进展与原始奖励分数解耦，基于模型能力进行条件评估，并从课程策略组合中进行原则性选择。

Result: 实验表明，代码生成中RFT的最佳课程与模型固有能力密切相关：能力较弱的模型在易到难课程中获益更大，而能力较强的模型在难到易课程中表现更优。

Conclusion: TAROT提供了一种可重复的方法，能够根据模型能力自适应调整课程设计，从而持续提升生成代码的功能正确性和鲁棒性，为社区研究提供了开源代码和数据。

Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.

</details>


### [58] [In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](https://arxiv.org/abs/2602.15456)
*Mohammad Aflah Khan,Mahsa Amani,Soumi Das,Bishwamittra Ghosh,Qinyuan Wu,Krishna P. Gummadi,Manish Gupta,Abhilasha Ravichander*

Main category: cs.CL

TL;DR: 研究发现当前LLM代理在呈现信息时存在系统性来源偏好，会优先选择某些特定来源的信息，这种偏好会影响信息推荐结果。


<details>
  <summary>Details</summary>
Motivation: LLM代理越来越多地作为在线平台的信息接口，它们过滤、排序和综合信息。虽然之前的研究关注LLM生成信息中的偏见，但较少关注LLM选择和呈现信息时的影响因素。本研究假设当信息被归因于特定来源时，当前LLM会表现出系统性的潜在来源偏好。

Method: 通过对6个模型提供商的12个LLM进行受控实验，涵盖合成和现实世界任务。研究评估了模型在信息呈现时的来源偏好，包括偏好对上下文框架的敏感性、与内容影响力的比较，以及提示指令能否消除这些偏好。

Result: 研究发现多个模型表现出强烈且可预测的来源偏好。这些偏好对上下文框架敏感，可能超过内容本身的影响力，并且即使明确提示也无法避免。这些偏好有助于解释先前研究中观察到的新闻推荐左倾偏斜现象。

Conclusion: 研究结果呼吁深入调查这些偏好的起源，并建立机制为用户提供透明度，让用户能够控制LLM驱动代理的偏见。这强调了需要更好地理解和管理LLM在信息选择和呈现中的系统性偏好。

Abstract: Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the information users receive, by drawing users' attention to particular instances of retrieved information at the expense of others. While much prior work has focused on biases in the information LLMs themselves generate, less attention has been paid to the factors that influence what information LLMs select and present to users. We hypothesize that when information is attributed to specific sources (e.g., particular publishers, journals, or platforms), current LLMs exhibit systematic latent source preferences- that is, they prioritize information from some sources over others. Through controlled experiments on twelve LLMs from six model providers, spanning both synthetic and real-world tasks, we find that several models consistently exhibit strong and predictable source preferences. These preferences are sensitive to contextual framing, can outweigh the influence of content itself, and persist despite explicit prompting to avoid them. They also help explain phenomena such as the observed left-leaning skew in news recommendations in prior work. Our findings advocate for deeper investigation into the origins of these preferences, as well as for mechanisms that provide users with transparency and control over the biases guiding LLM-powered agents.

</details>


### [59] [Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit](https://arxiv.org/abs/2602.15504)
*Aswathy Velutharambath,Amelie Wührl*

Main category: cs.CL

TL;DR: 本文提出"期望检测"任务，构建RedHOTExpect语料库（4.5K Reddit帖子），使用LLM银标注分析医疗场景中患者的治疗期望表达模式


<details>
  <summary>Details</summary>
Motivation: 患者对治疗的期望对治疗效果有重要影响。虽然临床环境已有研究，但在线患者平台（如医疗subreddit）可能包含患者不愿在其他地方分享的期望信息。目前尚无研究分析在线用户讨论的期望类型和表达方式，且NLP领域尚未研究期望检测任务

Method: 1. 提出期望检测任务；2. 构建RedHOTExpect语料库（4.5K Reddit帖子）；3. 使用大语言模型进行银标注；4. 手动验证标注质量（准确率约78%）；5. 分析期望的语言模式，探索患者期望内容和原因

Result: 1. 乐观和积极框架在身体或治疗相关疾病帖子中比心理健康语境更明显；2. 数据集中患者主要讨论益处而非负面结果；3. 银标注准确率约78%；4. 识别了医疗期望的特定语言模式

Conclusion: 在线患者平台是研究治疗期望的宝贵数据源，期望检测是NLP中重要的新任务。RedHOTExpect语料库为医疗领域的期望分析提供了资源，有助于意见挖掘和产品设计等应用

Abstract: Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from https://www.ims.uni-stuttgart.de/data/RedHOTExpect

</details>


### [60] [LuxMT Technical Report](https://arxiv.org/abs/2602.15506)
*Nils Rehlinger*

Main category: cs.CL

TL;DR: LuxMT是基于Gemma 3 27B的卢森堡语到法语/英语机器翻译系统，使用LuxAlign平行语料和议会记录训练，通过LuxEmbedder过滤低质量数据，在多个语言对上表现优于基线


<details>
  <summary>Details</summary>
Motivation: 解决卢森堡语（LB）到法语（FR）和英语（EN）的机器翻译问题，填补该语言对的资源空白，并探索使用LuxEmbedder作为质量评估指标的潜力

Method: 基于Gemma 3 27B模型微调，使用LuxAlign平行语料（多语言卢森堡新闻文章）和议会记录（通过谷歌翻译增强）作为训练数据，采用LuxEmbedder（卢森堡语句子嵌入）过滤低等价性片段对

Result: LuxMT在LB-FR和LB-EN翻译上相比Gemma 3基线有显著改进，甚至在未训练的LB-DE翻译上也表现良好；LuxEmbedder作为质量评估指标与其他基于参考的指标有强相关性

Conclusion: LuxMT系统在卢森堡语翻译任务上表现优秀，LuxEmbedder有潜力作为质量评估指标，但需要进一步研究验证其效用，建议谨慎使用

Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN, and LB-FR using human-translated data from Luci, a tourist magazine about Luxembourg. Training data stems from LuxAlign, a parallel corpus of multilingual Luxembourgish news articles, and LB parliamentary transcripts augmented with Google Translate. We filter the data using LuxEmbedder, LB sentence embeddings, to remove low-equivalence segment-pairs. Overall, LuxMT's results suggest strong improvements over the Gemma 3 baseline, even for translating LB to German (DE), despite the training data not containing any DE. We also explore LuxEmbedder's potential to be used as a quality estimation metric and find strong correlations with other reference-based metrics. However, we call for further research to fully assess the metric's utility and advise using it with caution.

</details>


### [61] [Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination](https://arxiv.org/abs/2602.15509)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: Fine-Refine是一个细粒度精炼框架，通过将对话响应分解为原子单元、验证每个单元的事实性、评估流畅度，并迭代修正错误，显著提升LLM对话系统的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在对话系统中存在幻觉问题，会产生事实错误的响应误导用户并破坏系统信任。现有精炼方法通常在响应层面操作，忽略了单个响应可能包含多个可验证或不可验证的事实单元。

Method: 提出Fine-Refine框架：1) 将响应分解为原子单元；2) 使用外部知识验证每个单元的事实性；3) 通过困惑度评估流畅度；4) 迭代修正细粒度错误。

Result: 在HybriDialogue和OpendialKG数据集上的实验表明，Fine-Refine显著提升了事实性，对话事实分数最高提升7.63分，仅在对话质量上有小幅权衡。

Conclusion: Fine-Refine通过细粒度的响应分解和验证机制，有效解决了LLM对话系统的幻觉问题，在保持对话质量的同时大幅提升事实准确性。

Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for dialogue systems typically operate at the response level, overlooking the fact that a single response may contain multiple verifiable or unverifiable facts. To address this gap, we propose Fine-Refine, a fine-grained refinement framework that decomposes responses into atomic units, verifies each unit using external knowledge, assesses fluency via perplexity, and iteratively corrects granular errors. We evaluate factuality across the HybriDialogue and OpendialKG datasets in terms of factual accuracy (fact score) and coverage (Not Enough Information Proportion), and experiments show that Fine-Refine substantially improves factuality, achieving up to a 7.63-point gain in dialogue fact score, with a small trade-off in dialogue quality.

</details>


### [62] [DependencyAI: Detecting AI Generated Text through Dependency Parsing](https://arxiv.org/abs/2602.15514)
*Sara Ahmed,Tracy Hammond*

Main category: cs.CL

TL;DR: DependencyAI：一种基于语言依存关系标签的简单可解释AI文本检测方法，在单语、多生成器和多语言场景中表现优异


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型日益普及，需要可靠的方法来检测AI生成的文本以降低潜在风险。现有方法可能过于复杂或缺乏可解释性。

Method: 仅使用语言依存关系标签来检测AI生成文本。通过分析特征重要性来揭示区分AI生成和人类写作的句法结构。

Result: 在单语、多生成器和多语言设置中均取得有竞争力的性能。发现某些模型在未见领域存在系统性过预测，表明生成器特定的写作风格可能影响跨领域泛化。

Conclusion: 依存关系本身为AI生成文本检测提供了稳健信号，DependencyAI成为基于语言学、可解释且非神经网络的强基线方法。

Abstract: As large language models (LLMs) become increasingly prevalent, reliable methods for detecting AI-generated text are critical for mitigating potential risks. We introduce DependencyAI, a simple and interpretable approach for detecting AI-generated text using only the labels of linguistic dependency relations. Our method achieves competitive performance across monolingual, multi-generator, and multilingual settings. To increase interpretability, we analyze feature importance to reveal syntactic structures that distinguish AI-generated from human-written text. We also observe a systematic overprediction of certain models on unseen domains, suggesting that generator-specific writing styles may affect cross-domain generalization. Overall, our results demonstrate that dependency relations alone provide a robust signal for AI-generated text detection, establishing DependencyAI as a strong linguistically grounded, interpretable, and non-neural network baseline.

</details>


### [63] [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)
*Ziyu Zhao,Tong Zhu,Zhi Zhang,Tiantian Fan,Jinluan Yang,Kun Kuang,Zhongyu Wei,Fei Wu,Yu Cheng*

Main category: cs.CL

TL;DR: 本文提出ExpertWeaver，一种基于GLU激活模式的训练免费框架，用于将预训练稠密模型转换为稀疏MoE架构，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 训练高质量MoE从头开始成本极高，现有稠密转MoE方法破坏了稠密模型的固有激活模式，导致专家构建不理想。GLU机制为稠密转MoE提供了自然蓝图。

Method: 基于GLU的细粒度神经激活模式揭示粗粒度结构，发现固有MoE架构由一致激活的通用神经元和动态激活的专业神经元组成。提出ExpertWeaver训练免费框架，根据激活模式划分神经元，构建共享专家和专业路由专家，采用层自适应配置。

Result: 实验表明，ExpertWeaver作为训练免费动态结构剪枝技术和作为高质量MoE初始化的降循环策略，均显著优于现有方法。

Conclusion: GLU激活模式揭示了稠密模型中的固有MoE架构，ExpertWeaver利用这一发现实现了高效的稠密转MoE转换，为构建高质量稀疏模型提供了有效途径。

Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.

</details>


### [64] [ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling](https://arxiv.org/abs/2602.15537)
*Nicol Visser,Simon Malan,Danel Slabbert,Herman Kamper*

Main category: cs.CL

TL;DR: ZeroSyl是一种无需训练的简单方法，可直接从冻结的WavLM模型中提取音节边界和嵌入，用于纯语音语言模型训练，在多项基准测试中优于现有音节标记化方法。


<details>
  <summary>Details</summary>
Motivation: 纯语音语言模型直接从原始音频学习语言面临挑战：自监督语音编码器的离散标记会产生过长的序列，而现有的音节提取方法（如Sylber和SyllableLM）需要复杂多阶段训练流程。

Method: 使用冻结WavLM模型的中间层特征的L2范数来检测音节边界，对得到的片段进行平均池化，使用K-means离散化，然后用这些标记训练语言模型。

Result: ZeroSyl在音节分割性能上具有竞争力，在词汇、句法和叙事基准测试中优于先前的音节标记化方法。扩展实验表明，虽然更细粒度的单元对词汇任务有益，但发现的音节单元在句法建模方面表现出更好的扩展行为。

Conclusion: ZeroSyl提供了一种简单有效的训练免费方法，直接从预训练语音模型中提取音节单元，为纯语音语言模型提供了更好的标记化方案，在保持性能的同时简化了流程。

Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.

</details>


### [65] [Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite](https://arxiv.org/abs/2602.15540)
*Tim Fischer,Chris Biemann*

Main category: cs.CL

TL;DR: Perspectives是一个交互式文档分析工具，通过人机协作的聚类流程帮助数字人文学者探索和组织大型非结构化文档集合


<details>
  <summary>Details</summary>
Motivation: 数字人文学者需要处理大量非结构化文档，传统方法难以有效探索和组织这些数据，需要更灵活、交互式的工具来支持分析工作

Method: 采用灵活的面向方面的文档聚类流程，结合人在回路优化能力。通过文档重写提示和基于指令的嵌入定义分析视角，并提供聚类细化和嵌入模型微调工具

Result: 开发了Perspectives工具，展示了典型工作流程，帮助研究者通过交互式文档地图发现主题、情感或其他相关类别，为后续深入分析准备数据

Conclusion: Perspectives为数字人文学者提供了强大的交互式探索工具，通过人机协作的聚类方法有效支持大规模文档集合的分析和组织

Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.

</details>


### [66] [jina-embeddings-v5-text: Task-Targeted Embedding Distillation](https://arxiv.org/abs/2602.15547)
*Mohammad Kalim Akram,Saba Sturua,Nastia Havriushenko,Quentin Herreros,Michael Günther,Maximilian Werk,Han Xiao*

Main category: cs.CL

TL;DR: 提出结合模型蒸馏与任务特定对比损失的新训练方法，生成紧凑高性能的文本嵌入模型，在小型模型上超越纯对比或蒸馏方法


<details>
  <summary>Details</summary>
Motivation: 现有通用文本嵌入模型通常使用单阶段或多阶段的对比损失训练，但这种方法在训练小型模型时效果有限。需要开发更有效的训练方法来生成紧凑且高性能的嵌入模型。

Method: 提出新颖的训练方案，将模型蒸馏技术与任务特定的对比损失相结合。通过这种混合方法训练出两个紧凑模型：jina-embeddings-v5-text-small 和 jina-embeddings-v5-text-nano。

Result: 生成的模型在相似尺寸模型中达到或超越最先进水平，支持长达32k tokens的多语言长文本，嵌入表示在截断和二进制量化下保持鲁棒性。

Conclusion: 结合蒸馏与对比损失的训练方法比纯对比或纯蒸馏方法更有效，特别适合训练小型嵌入模型。公开模型权重以促进嵌入模型开发的进一步进展。

Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.

</details>


### [67] [Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL](https://arxiv.org/abs/2602.15564)
*Yihan Wang,Peiyu Liu,Runyu Chen,Wei Xu*

Main category: cs.CL

TL;DR: 本文提出SquRL强化学习框架，通过动态构建工作流来提升Text-to-SQL系统的适应性和性能，特别是在复杂和分布外查询上表现显著优于静态工作流方法。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL系统依赖单一的静态工作流，难以适应真实场景中的分布外和长尾情况。用户需要通过大量实验选择合适方法，系统缺乏自适应构建工作流的能力。

Method: 提出SquRL强化学习框架，增强LLM在自适应工作流构建中的推理能力。设计基于规则的奖励函数，引入动态演员掩码以鼓励广泛探索，并使用伪奖励提高训练效率。

Result: 在广泛使用的Text-to-SQL基准测试中，动态工作流构建方法始终优于最佳静态工作流方法，在复杂查询和分布外查询上表现尤为突出。

Conclusion: 动态策略通过利用候选工作流的异质性，能够持续超越最佳静态工作流，SquRL框架为Text-to-SQL系统提供了有效的自适应工作流构建方案。

Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL

</details>


### [68] [Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations](https://arxiv.org/abs/2602.15578)
*Chaithra Nerella,Chiranjeevi Yarra*

Main category: cs.CL

TL;DR: 提出一个症状导向的抑郁症严重程度评估框架，通过症状引导的交叉注意力机制将PHQ-8问卷项目与情感感知的语音表征对齐，实现症状级别的分析。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症预测方法通常将抑郁症视为二元标签或总体严重程度评分，缺乏对具体症状的建模，限制了临床筛查中症状级别分析的能力。

Method: 使用症状引导的交叉注意力机制，将PHQ-8问卷项目与情感感知的语音表征对齐；引入可学习的症状特定参数，自适应控制注意力分布的锐度；在EDAIC临床数据集上验证。

Result: 在EDAIC数据集上表现优于先前工作；注意力分析显示，对包含多个抑郁症状线索的话语分配了更高注意力，证明了方法的可解释性。

Conclusion: 症状引导和情感感知建模对于基于语音的抑郁症筛查具有重要意义，提出的框架能够提供症状级别的分析，增强临床相关性。

Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.

</details>


### [69] [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620)
*Shiqi Liu,Zeyu He,Guojian Zhan,Letian Tao,Zhilong Zheng,Jiang Wu,Yinuo Wang,Yang Guan,Kehua Sheng,Bo Zhang,Keqiang Li,Jingliang Duan,Shengbo Eben Li*

Main category: cs.CL

TL;DR: STAPO通过识别并屏蔽仅占0.01%的"虚假令牌"来解决RL微调中的性能崩溃问题，在数学推理基准上平均提升7.13%


<details>
  <summary>Details</summary>
Motivation: 现有RL微调方法依赖启发式技术（如熵正则化和重加权）来保持稳定性，但在实践中经常出现后期性能崩溃，导致推理质量下降和训练不稳定。研究发现训练不稳定性主要由极少数的"虚假令牌"驱动。

Method: 提出Spurious-Token-Aware Policy Optimization (STAPO)：1）识别虚假令牌（约占0.01%），这些令牌对推理结果贡献很小但继承了完整的序列级奖励；2）选择性屏蔽这些令牌的梯度更新；3）在有效令牌上重新归一化损失。

Result: 在六个数学推理基准上使用Qwen 1.7B、8B和14B基础模型，STAPO始终表现出优越的熵稳定性，相比GRPO、20-Entropy和JustRL平均性能提升7.13%。

Conclusion: STAPO通过针对性地处理虚假令牌，有效解决了RL微调中的训练不稳定问题，显著提升了大型语言模型的推理性能。

Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\%, which we term \emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\% over GRPO, 20-Entropy and JustRL.

</details>


### [70] [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)
*Ahmed Khaled Khamis,Hesham Ali*

Main category: cs.CL

TL;DR: 研究者创建了首个公开的埃及阿拉伯语TTS数据集NileTTS，包含38小时转录语音，并开发了基于LLM的合成数据生成流程，通过微调XTTS v2模型提升了埃及阿拉伯语语音合成质量。


<details>
  <summary>Details</summary>
Motivation: 尽管神经TTS技术有进展，但埃及阿拉伯语作为最广泛理解的阿拉伯语方言，资源严重不足，大多数资源集中在现代标准阿拉伯语和海湾方言上，需要填补这一空白。

Method: 1) 创建NileTTS数据集：38小时转录语音，来自两个说话者，涵盖医疗、销售和日常对话等领域；2) 使用新颖的合成流程：LLM生成埃及阿拉伯语内容，音频合成工具转换为自然语音，自动转录和说话人分割，人工质量验证；3) 在XTTS v2多语言TTS模型上微调。

Result: 1) 发布了首个公开的埃及阿拉伯语TTS数据集；2) 建立了可复现的方言TTS合成数据生成流程；3) 提供了开源微调模型；4) 与在其他阿拉伯方言上训练的基线模型相比，性能有所提升。

Conclusion: 该研究填补了埃及阿拉伯语TTS资源的空白，提供了数据集、合成流程和开源模型，将推动埃及阿拉伯语语音合成研究的发展。

Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.

</details>


### [71] [Revisiting Northrop Frye's Four Myths Theory with Large Language Models](https://arxiv.org/abs/2602.15678)
*Edirlei Soares de Lima,Marco A. Casanova,Antonio L. Furtado*

Main category: cs.CL

TL;DR: 本文提出一个基于诺斯罗普·弗莱四叙事体裁的字符功能框架，结合荣格原型理论，通过LLM验证了16种体裁特定角色，为计算叙事学提供新方法。


<details>
  <summary>Details</summary>
Motivation: 现有计算叙事研究主要关注叙事模式而非字符功能，需要开发一个能补充模式分析的字符功能框架，以更好地理解弗莱四体裁中角色如何差异化呈现。

Method: 结合荣格原型理论推导四个通用字符功能（主角、导师、反派、同伴），再细化为16种体裁特定角色。使用6个先进LLM对40部叙事作品进行验证，包含正负样本评估。

Result: LLM平均平衡准确率达82.5%，模型间一致性高（Fleiss' κ=0.600）。体裁表现差异明显（72.7%-89.9%），角色识别率差异大（52.5%-99.2%），反映了真实的叙事特性。

Conclusion: 字符导向方法展示了LLM支持的计算叙事学潜力，为未来叙事生成方法和交互式讲故事应用奠定基础，验证了框架捕捉系统结构模式的能力。

Abstract: Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $κ$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.

</details>


### [72] [A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models](https://arxiv.org/abs/2602.15689)
*Meirav Segal,Noa Linder,Omer Antverg,Gil Gekker,Tomer Fichman,Omri Bodenheimer,Edan Maor,Omer Nevo*

Main category: cs.CL

TL;DR: 提出基于内容的网络安全拒绝框架，通过明确权衡攻击风险与防御效益，而非依赖意图或主题分类，来解决现有拒绝系统的不一致性和过度限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于主题禁令或攻击分类的拒绝系统存在不一致决策、过度限制合法防御者、以及对混淆或请求分割行为脆弱的问题。需要更有效的方法来平衡网络安全任务的双重用途特性。

Method: 引入基于内容的网络安全拒绝政策框架，通过五个维度评估请求：攻击行动贡献、攻击风险、技术复杂性、防御效益、合法用户预期频率，这些维度基于请求的技术实质而非陈述意图。

Result: 该内容导向方法解决了当前前沿模型行为的不一致性，并允许组织构建可调、风险感知的拒绝政策。

Conclusion: 有效的网络安全拒绝需要明确建模攻击风险与防御效益之间的权衡，基于内容的技术框架比基于意图或分类的方法更有效和一致。

Abstract: Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused taxonomies. As a result, they can yield inconsistent decisions, over-restrict legitimate defenders, and behave brittlely under obfuscation or request segmentation. We argue that effective refusal requires explicitly modeling the trade-off between offensive risk and defensive benefit, rather than relying solely on intent or offensive classification. In this paper, we introduce a content-based framework for designing and auditing cyber refusal policies that makes offense-defense tradeoffs explicit. The framework characterizes requests along five dimensions: Offensive Action Contribution, Offensive Risk, Technical Complexity, Defensive Benefit, and Expected Frequency for Legitimate Users, grounded in the technical substance of the request rather than stated intent. We demonstrate that this content-grounded approach resolves inconsistencies in current frontier model behavior and allows organizations to construct tunable, risk-aware refusal policies.

</details>


### [73] [Rethinking Metrics for Lexical Semantic Change Detection](https://arxiv.org/abs/2602.15716)
*Roksana Goworek,Haim Dubossarsky*

Main category: cs.CL

TL;DR: 论文提出了两种新的词汇语义变化检测指标AMD和SAMD，相比传统APD和PRT方法，在不同语言、编码器和表示空间中表现更稳健。


<details>
  <summary>Details</summary>
Motivation: 当前词汇语义变化检测主要依赖APD和余弦距离等少数指标，这些方法可能不是最优选择，需要探索更稳健的语义变化度量方法。

Method: 提出了两种新指标：平均最小距离（AMD）和对称平均最小距离（SAMD），通过跨时间段的词汇使用局部对应关系来量化语义变化。

Result: 在多语言、多种编码器和表示空间的实验中，AMD在降维和非专门编码器下表现更稳健，SAMD在专门编码器上表现优异。

Conclusion: 词汇语义变化检测应考虑APD和PRT之外的替代指标，AMD为基于上下文嵌入的分析提供了稳健的选择。

Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.

</details>


### [74] [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)
*Omri Feldman,Amar Venugopal,Jann Spiess,Amir Feder*

Main category: cs.CL

TL;DR: 提出一个端到端管道，用于生成和因果估计潜在文本干预，通过稀疏自编码器进行假设生成和引导，结合协变量残差化解决文本作为治疗时的估计偏差问题。


<details>
  <summary>Details</summary>
Motivation: 理解文本对下游结果的因果效应是许多应用的核心任务，但现有方法在生成和评估受控文本变化方面存在不足，特别是文本固有的治疗与协变量信息混淆问题导致估计偏差。

Method: 1. 使用稀疏自编码器（SAEs）进行假设生成和引导；2. 提出基于协变量残差化的解决方案来处理文本中治疗与协变量信息的混淆；3. 构建端到端管道，解决文本作为治疗实验中的计算和统计挑战。

Result: 实证结果表明，该管道能有效诱导目标特征的变化，并显著减轻估计误差，为文本作为治疗场景下的因果效应估计提供了稳健基础。

Conclusion: 提出的端到端管道通过结合稀疏自编码器和协变量残差化方法，解决了文本因果效应估计中的关键挑战，为文本干预研究提供了可靠的工具。

Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.

</details>


### [75] [Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753)
*Chahan Vidal-Gorène,Bastien Kindt,Florian Cafiero*

Main category: cs.CL

TL;DR: LLMs在少样本和零样本设置下，对四种低资源语言（古希腊语、古典亚美尼亚语、古格鲁吉亚语、叙利亚语）的词形还原和词性标注任务表现出竞争力，可作为无数据时的有效标注辅助工具。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在自然语言处理任务（如词形还原和词性标注）中持续面临挑战，需要探索大语言模型在这些任务中的能力，特别是在少样本和零样本设置下。

Method: 使用包含对齐训练数据和领域外测试数据的新基准，评估GPT-4变体和Mistral等大语言模型在四种历史语言（古希腊语、古典亚美尼亚语、古格鲁吉亚语、叙利亚语）上的表现，并与任务特定的RNN基线模型PIE进行比较。

Result: 即使不进行微调，LLMs在少样本设置下对大多数语言在词性标注和词形还原任务上达到竞争性或更优的性能。对于具有复杂形态和非拉丁文字的语言仍存在挑战，但LLMs可作为无数据时启动语言标注任务的有效辅助工具。

Conclusion: 大语言模型是低资源语言标注任务的可行选择，特别是在数据稀缺的情况下，可作为有效的标注辅助工具，尽管在复杂形态和非拉丁文字语言上仍需改进。

Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.

</details>


### [76] [Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos](https://arxiv.org/abs/2602.15757)
*Laura De Grazia,Danae Sánchez Villegas,Desmond Elliott,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 提出了FineMuSe数据集，这是一个西班牙语多模态性别歧视检测数据集，包含二元和细粒度标注，并评估了LLMs在检测细微性别歧视方面的表现。


<details>
  <summary>Details</summary>
Motivation: 在线性别歧视表现形式多样，现有自动化工具多限于二元分类，难以检测更细微、上下文敏感的性别歧视表达。

Method: 1) 创建FineMuSe多模态数据集（西班牙语），包含二元和细粒度标注；2) 设计分层分类法，涵盖性别歧视形式、非性别歧视内容以及讽刺幽默等修辞手法；3) 评估多种LLMs在二元和细粒度性别歧视检测上的表现。

Result: 多模态LLMs在识别细微性别歧视方面表现与人类标注者相当，但在处理通过视觉线索传达的并发性别歧视类型时存在困难。

Conclusion: 多模态LLMs在性别歧视检测方面具有潜力，特别是在识别细微表达方面，但在处理视觉线索中的并发性别歧视类型时需要改进。

Abstract: Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.

</details>


### [77] [ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758)
*Manav Nitin Kapadnis,Lawanya Baghel,Atharva Naik,Carolyn Rosé*

Main category: cs.CL

TL;DR: 提出了ChartEditBench基准测试，用于评估多模态大语言模型在增量式、视觉基础的图表编辑任务中的表现，包含5000个难度可控的修改链，并提出了结合执行保真度、像素级视觉相似度和逻辑代码验证的评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在单轮图表生成任务上表现良好，但在支持真实世界探索性数据分析方面的能力尚未充分探索。实际应用中，用户通过多轮交互迭代优化可视化图表，这需要维持共同基础、跟踪先前编辑并适应不断变化的偏好。

Method: 1. 引入ChartEditBench基准测试，包含5000个难度可控的修改链和人工验证子集；2. 提出稳健的评估框架，整合执行保真度检查、像素级视觉相似度和逻辑代码验证，以缓解LLM-as-a-Judge指标的局限性；3. 在最先进的多模态大语言模型上进行实验。

Result: 实验显示，在多轮设置中，由于错误累积和共享上下文崩溃，模型性能显著下降。模型在样式编辑上表现良好，但在以数据为中心的转换上经常出现执行失败。

Conclusion: ChartEditBench为基于基础的、意图感知的多模态编程建立了一个具有挑战性的测试平台，揭示了当前多模态大语言模型在支持真实世界探索性数据分析方面的局限性。

Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.

</details>


### [78] [ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution](https://arxiv.org/abs/2602.15769)
*Yahia Alqurnawi,Preetom Biswas,Anmol Rao,Tejas Anvekar,Chitta Baral,Vivek Gupta*

Main category: cs.CL

TL;DR: 多模态大语言模型在结构化数据（如表格）问答中表现尚可，但在证据溯源方面表现很差，特别是对JSON格式，溯源准确率接近随机猜测。


<details>
  <summary>Details</summary>
Motivation: 研究多模态大语言模型在结构化数据（表格、JSON、图像等）问答中的证据溯源能力，因为用户不仅需要正确答案，还需要知道答案的来源依据。

Method: 评估多个多模态大语言模型在不同表格格式（Markdown、JSON、图像）和提示策略下的表现，特别关注模型定位支持答案的具体行和列的能力。

Result: 问答准确率中等，但证据溯源准确率低得多，特别是对JSON输入接近随机水平；模型在引用行方面比列更可靠；对文本格式比对图像格式更困难；不同模型家族存在显著差异。

Conclusion: 当前多模态大语言模型在提供细粒度、可信的结构化数据溯源方面不可靠，这限制了它们在需要透明度和可追溯性的应用中的使用。

Abstract: Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In this work, we study structured data attribution/citation, which is the ability of the models to point to the specific rows and columns that support an answer. We evaluate several mLLMs across different table formats and prompting strategies. Our results show a clear gap between question answering and evidence attribution. Although question answering accuracy remains moderate, attribution accuracy is much lower, near random for JSON inputs, across all models. We also find that models are more reliable at citing rows than columns, and struggle more with textual formats than images. Finally, we observe notable differences across model families. Overall, our findings show that current mLLMs are unreliable at providing fine-grained, trustworthy attribution for structured data, which limits their usage in applications requiring transparency and traceability.

</details>


### [79] [*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778)
*Quentin Lemesle,Léane Jourdan,Daisy Munson,Pierre Alain,Jonathan Chevelu,Arnaud Delhay,Damien Lolive*

Main category: cs.CL

TL;DR: 提出*-PLUIE方法，基于ParaPLUIE的困惑度评估框架，通过任务特定提示变体提升与人类判断的关联性，同时保持低计算成本


<details>
  <summary>Details</summary>
Motivation: 当前LLM-as-a-judge方法虽然有效，但计算成本高且需要后处理，需要更高效、低成本的文本质量评估方法

Method: 在ParaPLUIE（基于困惑度的LLM评判指标）基础上，引入任务特定提示变体*-PLUIE，通过个性化提示提升评估效果

Result: 个性化*-PLUIE与人类评分有更强的相关性，同时保持了低计算成本的优势

Conclusion: *-PLUIE提供了一种高效、低成本且与人类判断更一致的自动文本质量评估方法，解决了现有LLM评判方法的计算成本问题

Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.

</details>


### [80] [Avey-B](https://arxiv.org/abs/2602.15814)
*Devang Acharya,Mohammad Hammoud*

Main category: cs.CL

TL;DR: 本文提出了一种基于Avey架构的编码器改进方案，通过架构创新在保持紧凑性的同时，在多项NLP任务上超越了Transformer编码器，且在处理长上下文时具有更好的扩展效率。


<details>
  <summary>Details</summary>
Motivation: 工业NLP应用通常受限于计算和内存预算，需要紧凑的预训练双向编码器。虽然基于自注意力的BERT架构提供了高质量的双向上下文建模能力，但最近出现的Avey架构作为一种自回归、无注意力的替代方案，自然支持编码器适配。本文旨在将Avey重新设计为编码器架构，以提供更高效的替代方案。

Method: 将Avey重新设计为编码器架构，提出了多项创新：1）解耦的静态和动态参数化；2）面向稳定性的归一化；3）神经压缩技术。这些改进使模型能够更高效地处理双向上下文信息。

Result: 改进后的Avey编码器在标准标记分类和信息检索基准测试中，持续优于四种广泛使用的基于Transformer的编码器，同时在处理长上下文时展现出更好的扩展效率。

Conclusion: 重新设计的Avey编码器架构为工业NLP应用提供了一个有前景的紧凑编码器替代方案，在保持高性能的同时，在处理长序列时具有更好的计算效率。

Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [81] [Attention-gated U-Net model for semantic segmentation of brain tumors and feature extraction for survival prognosis](https://arxiv.org/abs/2602.15067)
*Rut Pate,Snehal Rajput,Mehul S. Raval,Rupal A. Kapdi,Mohendra Roy*

Main category: cs.AI

TL;DR: 该研究提出了一种基于注意力门控循环残差U-Net的三平面（2.5D）模型，用于改进脑肿瘤分割，并在BraTS2021验证集上取得了0.900的Dice相似性分数，同时使用人工神经网络进行生存天数预测。


<details>
  <summary>Details</summary>
Motivation: 胶质瘤作为最常见的原发性脑肿瘤，其侵袭性、预后和组织学特征差异很大，复杂的长时间手术干预使治疗具有挑战性，需要更精确的肿瘤分割来辅助治疗规划。

Method: 提出注意力门控循环残差U-Net（R2U-Net）三平面（2.5D）模型，整合残差、循环和三平面架构，增强特征表示和分割精度，同时保持计算效率。使用人工神经网络将三平面网络提取的64个特征降维至28个进行生存天数预测。

Result: 在BraTS2021验证集上，全肿瘤分割的Dice相似性分数达到0.900，性能与领先模型相当。生存天数预测在测试集上准确率为45.71%，均方误差为108,318.128，斯皮尔曼等级相关系数为0.338。

Conclusion: 提出的三平面模型在脑肿瘤分割方面表现出色，有望改善治疗规划，同时通过特征提取和降维方法为生存预测提供了可行方案。

Abstract: Gliomas, among the most common primary brain tumors, vary widely in aggressiveness, prognosis, and histology, making treatment challenging due to complex and time-intensive surgical interventions. This study presents an Attention-Gated Recurrent Residual U-Net (R2U-Net) based Triplanar (2.5D) model for improved brain tumor segmentation. The proposed model enhances feature representation and segmentation accuracy by integrating residual, recurrent, and triplanar architectures while maintaining computational efficiency, potentially aiding in better treatment planning. The proposed method achieves a Dice Similarity Score (DSC) of 0.900 for Whole Tumor (WT) segmentation on the BraTS2021 validation set, demonstrating performance comparable to leading models. Additionally, the triplanar network extracts 64 features per planar model for survival days prediction, which are reduced to 28 using an Artificial Neural Network (ANN). This approach achieves an accuracy of 45.71%, a Mean Squared Error (MSE) of 108,318.128, and a Spearman Rank Correlation Coefficient (SRC) of 0.338 on the test dataset.

</details>


### [82] [ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112)
*Aniketh Garikaparthi,Manasi Patwardhan,Arman Cohan*

Main category: cs.AI

TL;DR: ResearchGym是一个评估AI智能体端到端研究能力的基准测试和执行环境，基于5篇顶会论文构建了39个子任务，发现前沿AI智能体存在能力-可靠性差距，偶尔能达到SOTA但表现不稳定。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估AI智能体进行完整研究流程（提出假设、运行实验、超越人类基线）的基准环境，需要量化智能体在真实研究任务中的表现和局限性。

Method: 选取ICML、ICLR、ACL的5篇口头报告和焦点论文，保留数据集、评估框架和基线实现，但隐藏原论文方法，构建5个容器化任务环境共39个子任务。评估GPT-5等智能体在这些环境中提出假设、运行实验、超越基线的能力。

Result: GPT-5智能体仅在15次评估中的1次（6.7%）超越基线，平均只完成26.5%子任务。发现了耐心不足、资源管理差、对弱假设过度自信、并行实验协调困难、上下文长度限制等长期失败模式。但在单次运行中成功超越了一个ICML 2025焦点任务的解决方案。

Conclusion: 前沿AI智能体偶尔能达到SOTA研究性能，但存在显著的能力-可靠性差距。ResearchGym为系统评估自主智能体的闭环研究能力提供了基础设施，揭示了当前智能体在长期研究任务中的系统性局限性。

Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.

</details>


### [83] [Protecting Language Models Against Unauthorized Distillation through Trace Rewriting](https://arxiv.org/abs/2602.15143)
*Xinhang Ma,William Yeoh,Ning Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该论文研究如何通过修改教师模型的推理轨迹来防止未经授权的知识蒸馏，同时保持答案正确性，实现了反蒸馏和API水印两种保护目标。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏被广泛用于将大模型能力迁移到更小的学生模型，但未经授权的蒸馏利用会不公平地利用前沿模型开发的大量投入和成本，因此需要保护措施。

Method: 提出了多种动态重写教师模型推理输出的方法：包括基于LLM的重写能力和基于梯度的技术，在保持答案正确性和语义连贯性的同时修改推理轨迹。

Result: 简单的基于指令的重写方法实现了强大的反蒸馏效果，同时保持甚至提升了教师模型性能；重写方法还实现了高度可靠的水印检测，几乎没有误报。

Conclusion: 通过重写教师模型的推理输出可以有效防止未经授权的知识蒸馏，同时实现反蒸馏和API水印双重保护，为LLM知识产权保护提供了实用解决方案。

Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.

</details>


### [84] [Panini: Continual Learning in Token Space via Structured Memory](https://arxiv.org/abs/2602.15156)
*Shreyas Rajesh,Pavan Holur,Mehmet Yigit Turali,Chenda Duan,Vwani Roychowdhury*

Main category: cs.AI

TL;DR: Panini提出了一种基于生成语义工作空间（GSW）的非参数持续学习框架，将文档表示为实体和事件感知的问答对网络，实现高效推理和记忆整合。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成（RAG）方法存在计算效率低（重复处理相同文档）和检索不相关内容导致生成不可靠的问题，需要更高效、可靠的持续学习框架。

Method: 提出Panini框架，将文档表示为生成语义工作空间（GSW）——一个实体和事件感知的问答对网络，支持LLM通过推理链在网络上进行基于推理的推断，实现持续更新的外部语义记忆状态。

Result: 在六个QA基准测试中，Panini平均性能最高，比其他基线高5%-7%，同时使用2-30倍更少的答案上下文token，支持完全开源管道，并在精心设计的不可回答查询上减少不可支持的答案。

Conclusion: 在写入时高效准确地结构化经验（如GSW框架所实现）在读取时既能提高效率又能增强可靠性，为持续学习提供了有前景的方向。

Abstract: Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same documents); moreover, chunk retrieval can inject irrelevant context that increases unsupported generation. We propose a human-like non-parametric continual learning framework, where the base model remains fixed, and learning occurs by integrating each new experience into an external semantic memory state that accumulates and consolidates itself continually. We present Panini, which realizes this by representing documents as Generative Semantic Workspaces (GSW) -- an entity- and event-aware network of question-answer (QA) pairs, sufficient for an LLM to reconstruct the experienced situations and mine latent knowledge via reasoning-grounded inference chains on the network. Given a query, Panini only traverses the continually-updated GSW (not the verbatim documents or chunks), and retrieves the most likely inference chains. Across six QA benchmarks, Panini achieves the highest average performance, 5%-7% higher than other competitive baselines, while using 2-30x fewer answer-context tokens, supports fully open-source pipelines, and reduces unsupported answers on curated unanswerable queries. The results show that efficient and accurate structuring of experiences at write time -- as achieved by the GSW framework -- yields both efficiency and reliability gains at read time. Code is available at https://github.com/roychowdhuryresearch/gsw-memory.

</details>


### [85] [da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems](https://arxiv.org/abs/2602.15158)
*Gabriel Rocha*

Main category: cs.AI

TL;DR: 本文提出了一种基于da Costian-Tarskianism的本体异质性新方法，使用扩展后果系统和扩展开发图来关联本体。


<details>
  <summary>Details</summary>
Motivation: 解决本体异质性问题，借鉴Carnapian-Goguenism思想，为不同本体系统之间的互操作提供理论基础。

Method: 基于后果系统理论，引入扩展后果系统（添加本体公理），定义扩展开发图结构，通过扩展后果系统的态射以及纤维化和分裂等操作关联本体。

Result: 建立了da Costian-Tarskianism框架，提供了处理本体异质性的形式化工具，包括扩展后果系统和扩展开发图的概念定义。

Conclusion: 该方法为应用本体论领域提供了新的理论框架，指出了未来研究方向，特别是在本体集成和互操作方面的应用潜力。

Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and Lücke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.

</details>


### [86] [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)
*Luise Ge,Yongyan Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该研究比较了20个前沿和开源大语言模型在风险决策中的表现，发现LLM可分为推理模型和对话模型两类，前者更理性，后者更接近人类但理性程度较低，数学推理训练是关键区分因素。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在决策支持和智能体工作流中的广泛应用，但对其在不确定性下的决策机制理解有限。研究旨在比较LLM在风险选择中的表现，特别是在不同前景表示方式（显式vs经验式）和决策理由（解释）两个维度上的差异。

Method: 研究设计了两个维度：前景表示方式（显式描述vs经验历史）和决策理由（解释）。对20个前沿和开源LLM进行测试，同时进行匹配的人类受试者实验作为参考点，并以期望收益最大化的理性智能体模型作为另一个参考。

Result: 发现LLM可分为两类：推理模型（RMs）倾向于理性行为，对前景顺序、得失框架和解释不敏感，在显式和经验式前景下表现相似；对话模型（CMs）理性程度显著较低，更接近人类，对前景顺序、框架和解释敏感，且存在较大的描述-历史差距。开源LLM的配对比较表明，数学推理训练是区分RMs和CMs的关键因素。

Conclusion: LLM在风险决策中存在明显的分类差异，推理模型更接近理性智能体，而对话模型更接近人类决策模式。数学推理训练是塑造LLM理性决策能力的重要因素，这对LLM在决策支持系统中的设计和应用具有重要启示。

Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.

</details>


### [87] [Secure and Energy-Efficient Wireless Agentic AI Networks](https://arxiv.org/abs/2602.15212)
*Yuanyan Song,Kezhi Wang,Xinmian Xu*

Main category: cs.AI

TL;DR: 提出安全无线智能体AI网络，通过智能体选择和友好干扰确保推理任务QoS和隐私保护，设计两种资源分配方案ASC和LAW来最小化能耗


<details>
  <summary>Details</summary>
Motivation: 为用户推理任务提供服务质量保障的同时，保护私有知识和推理结果的机密性，并延长AI智能体的服务时间

Method: 构建包含一个监督AI智能体和多个其他AI智能体的网络，监督智能体动态分配参与协作推理的智能体，未选中的智能体作为友好干扰器。提出ASC方案（基于ADMM、SDR和SCA的迭代优化）和LAW方案（基于LLM优化器的智能体工作流）

Result: 相比基准方案，提出的解决方案能将网络能耗降低高达59.1%，并在基于Qwen的实际智能体AI系统中验证了在各种公共基准测试中达到满意的推理准确率

Conclusion: 提出的安全无线智能体AI网络和资源分配方案能有效保障推理任务的QoS和隐私安全，显著降低能耗，并在实际系统中验证了可行性

Abstract: In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. To extend the service duration of AI agents, an energy minimization problem is formulated that jointly optimizes AI agent selection, base station (BS) beamforming, and AI agent transmission power, subject to latency and reasoning accuracy constraints. To address the formulated problem, we propose two resource allocation schemes, ASC and LAW, which first decompose it into three sub-problems. Specifically, ASC optimizes each sub-problem iteratively using the proposed alternating direction method of multipliers (ADMM)-based algorithm, semi-definite relaxation (SDR), and successive convex approximation (SCA), while LAW tackles each sub-problem using the proposed large language model (LLM) optimizer within an agentic workflow. The experimental results show that the proposed solutions can reduce network energy consumption by up to 59.1% compared to other benchmark schemes. Furthermore, the proposed schemes are validated using a practical agentic AI system based on Qwen, demonstrating satisfactory reasoning accuracy across various public benchmarks.

</details>


### [88] [Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models](https://arxiv.org/abs/2602.15248)
*Pavel Koptev,Vishnu Kumar,Konstantin Malkov,George Shapiro,Yury Vikhanov*

Main category: cs.AI

TL;DR: 提出AI机器学习框架预测发票稀释风险，补充传统确定性算法，使用实时动态信用限额替代传统不可撤销支付承诺


<details>
  <summary>Details</summary>
Motivation: 发票或支付稀释（批准金额与实际收款之间的差距）是供应链金融中非信用风险和利润损失的重要来源。传统依赖买方不可撤销支付承诺的方法会阻碍供应链金融的采用，特别是对于次级投资级买方。

Method: 提出AI机器学习框架，使用实时动态信用限额方法，基于九个关键交易字段的广泛生产数据集，预测每个买方-供应商对的发票稀释风险，补充传统确定性算法。

Result: 论文评估了AI机器学习框架如何补充确定性算法来预测发票稀释，但摘要中未提供具体实验结果数据。

Conclusion: 数据驱动的AI方法可以替代或补充传统的不可撤销支付承诺，更有效地管理供应链金融中的发票稀释风险，特别是对于次级投资级买方。

Abstract: Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.

</details>


### [89] [Enhancing Diversity and Feasibility: Joint Population Synthesis from Multi-source Data Using Generative Models](https://arxiv.org/abs/2602.15270)
*Farbod Abbasi,Zachary Patterson,Bilal Farooq*

Main category: cs.AI

TL;DR: 提出基于WGAN-GP的多源数据联合生成方法，通过逆梯度惩罚正则化提升合成人口的多样性和可行性，优于传统序列方法


<details>
  <summary>Details</summary>
Motivation: 现有合成人口生成方法存在两个主要问题：1）依赖单一数据集或采用序列化数据融合生成过程，无法捕捉特征间的复杂交互；2）难以处理采样零值（有效但未观测到的属性组合）和结构零值（因逻辑约束不可行的组合），导致生成数据多样性不足且可行性差

Method: 提出基于Wasserstein生成对抗网络（WGAN）与梯度惩罚的多源数据联合学习框架，在生成器损失函数中引入逆梯度惩罚正则化项，同时整合多源数据集进行合成人口生成

Result: 联合方法优于序列基线方法：召回率提升7%，精确率提升15%；正则化项进一步改善多样性和可行性，召回率再提升10%，精确率提升1%；相似性分布评估中，联合方法得分为88.1，优于序列方法的84.6

Conclusion: 该多源生成方法能显著提升合成人口的多样性和可行性，作为基于智能体模型的关键输入，有望大幅提高ABM的准确性和可靠性

Abstract: Generating realistic synthetic populations is essential for agent-based models (ABM) in transportation and urban planning. Current methods face two major limitations. First, many rely on a single dataset or follow a sequential data fusion and generation process, which means they fail to capture the complex interplay between features. Second, these approaches struggle with sampling zeros (valid but unobserved attribute combinations) and structural zeros (infeasible combinations due to logical constraints), which reduce the diversity and feasibility of the generated data. This study proposes a novel method to simultaneously integrate and synthesize multi-source datasets using a Wasserstein Generative Adversarial Network (WGAN) with gradient penalty. This joint learning method improves both the diversity and feasibility of synthetic data by defining a regularization term (inverse gradient penalty) for the generator loss function. For the evaluation, we implement a unified evaluation metric for similarity, and place special emphasis on measuring diversity and feasibility through recall, precision, and the F1 score. Results show that the proposed joint approach outperforms the sequential baseline, with recall increasing by 7\% and precision by 15\%. Additionally, the regularization term further improves diversity and feasibility, reflected in a 10\% increase in recall and 1\% in precision. We assess similarity distributions using a five-metric score. The joint approach performs better overall, and reaches a score of 88.1 compared to 84.6 for the sequential method. Since synthetic populations serve as a key input for ABM, this multi-source generative approach has the potential to significantly enhance the accuracy and reliability of ABM.

</details>


### [90] [When Remembering and Planning are Worth it: Navigating under Change](https://arxiv.org/abs/2602.15274)
*Omid Madani,J. Brian Burns,Reza Eghbali,Thomas L. Dean*

Main category: cs.AI

TL;DR: 研究不同记忆类型如何帮助智能体在动态不确定环境中进行空间导航，发现结合多种策略的架构能有效处理探索和路径规划任务，使用非平稳概率学习更新记忆并构建动态地图的智能体比简单智能体更高效。


<details>
  <summary>Details</summary>
Motivation: 研究在动态变化、感知受限的不确定环境中，如何通过不同类型的记忆机制来提升空间导航效率。环境具有非平稳性（障碍物和食物位置每日变化）、感知不确定性（位置信息有限且不精确）等挑战，需要快速学习且鲁棒的导航策略。

Method: 研究了从简单到复杂的多种策略，包括不同记忆使用和学习方式。重点分析了一种能够整合多种策略的架构，该架构使用非平稳概率学习技术持续更新情景记忆，并基于这些记忆构建动态地图（不完美地图，受限于智能体经验且包含噪声），进行实时路径规划。

Result: 当任务难度（如目标距离）增加时，使用非平稳概率学习更新记忆并构建动态地图的智能体比简单（最小记忆）智能体显著更高效，前提是定位和环境变化带来的不确定性不过大。这种架构能有效处理探索（食物位置未知）和路径规划（记忆中的可能食物位置）等不同性质的子任务。

Conclusion: 在动态不确定环境中，需要能够整合多种策略的架构来处理不同类型的导航子任务。通过非平稳概率学习持续更新记忆并构建动态地图的方法，在任务难度较高且不确定性可控的情况下，能显著提升导航效率。

Abstract: We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.

</details>


### [91] [EAA: Automating materials characterization with vision language model agents](https://arxiv.org/abs/2602.15294)
*Ming Du,Yanqi Luo,Srutarshi Banerjee,Michael Wojcik,Jelena Popovic,Mathew J. Cherukara*

Main category: cs.AI

TL;DR: EAA是一个基于视觉语言模型的代理系统，用于自动化复杂的实验显微镜工作流程，通过多模态推理和工具增强实现自主实验操作。


<details>
  <summary>Details</summary>
Motivation: 传统实验显微镜工作流程复杂且需要专业知识，EAA旨在通过自动化降低操作负担、提高光束线效率，并降低用户专业知识门槛。

Method: 采用灵活的任务管理器架构，集成多模态推理、工具增强动作和可选长期记忆，支持从完全代理驱动到逻辑定义的工作流程，并提供双向兼容的MCP工具生态系统。

Result: 在先进光子源的成像光束线上成功演示了自动区域板聚焦、自然语言描述的特征搜索和交互式数据采集，展示了系统在实际实验环境中的有效性。

Conclusion: 视觉能力代理系统能够显著提高光束线效率、减轻操作负担，并为用户降低专业知识门槛，为实验自动化提供了有前景的解决方案。

Abstract: We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous procedures and interactive user-guided measurements. Built on a flexible task-manager architecture, the system enables workflows ranging from fully agent-driven automation to logic-defined routines that embed localized LLM queries. EAA further provides a modern tool ecosystem with two-way compatibility for Model Context Protocol (MCP), allowing instrument-control tools to be consumed or served across applications. We demonstrate EAA at an imaging beamline at the Advanced Photon Source, including automated zone plate focusing, natural language-described feature search, and interactive data acquisition. These results illustrate how vision-capable agents can enhance beamline efficiency, reduce operational burden, and lower the expertise barrier for users.

</details>


### [92] [X-MAP: eXplainable Misclassification Analysis and Profiling for Spam and Phishing Detection](https://arxiv.org/abs/2602.15298)
*Qi Zhang,Dian Chen,Lance M. Kaplan,Audun Jøsang,Dong Hyun Jeong,Feng Chen,Jin-Hee Cho*

Main category: cs.AI

TL;DR: X-MAP是一个可解释的误分类分析和剖析框架，通过主题级语义模式揭示模型失败原因，结合SHAP特征归因和非负矩阵分解构建可解释主题轮廓，用于改进垃圾邮件和钓鱼检测。


<details>
  <summary>Details</summary>
Motivation: 垃圾邮件和钓鱼检测中的误分类危害很大：假阴性使用户面临攻击风险，假阳性降低用户信任。现有基于不确定性的检测器虽然可以标记潜在错误，但可能被欺骗且可解释性有限。

Method: X-MAP结合SHAP特征归因和非负矩阵分解，为可靠分类的垃圾邮件/钓鱼邮件和合法邮件构建可解释的主题轮廓，然后使用Jensen-Shannon散度测量每条消息与这些轮廓的偏差。

Result: 实验显示误分类消息的偏差至少是正确分类消息的两倍。作为检测器，X-MAP达到0.98 AUROC，在95% TRR时将误拒率降至0.089。作为修复层时，能恢复高达97%的误拒正确预测。

Conclusion: X-MAP通过揭示主题级语义模式，有效提高了垃圾邮件和钓鱼检测的性能和可解释性，既能作为独立检测器，也能作为现有检测器的修复层。

Abstract: Misclassifications in spam and phishing detection are very harmful, as false negatives expose users to attacks while false positives degrade trust. Existing uncertainty-based detectors can flag potential errors, but possibly be deceived and offer limited interpretability. This paper presents X-MAP, an eXplainable Misclassification Analysis and Profilling framework that reveals topic-level semantic patterns behind model failures. X-MAP combines SHAP-based feature attributions with non-negative matrix factorization to build interpretable topic profiles for reliably classified spam/phishing and legitimate messages, and measures each message's deviation from these profiles using Jensen-Shannon divergence. Experiments on SMS and phishing datasets show that misclassified messages exhibit at least two times larger divergence than correctly classified ones. As a detector, X-MAP achieves up to 0.98 AUROC and lowers the false-rejection rate at 95% TRR to 0.089 on positive predictions. When used as a repair layer on base detectors, it recovers up to 97% of falsely rejected correct predictions with moderate leakage. These results demonstrate X-MAP's effectiveness and interpretability for improving spam and phishing detection.

</details>


### [93] [AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents](https://arxiv.org/abs/2602.15325)
*Zhixing Zhang,Jesen Zhang,Hao Liu,Qinhan Lv,Jing Yang,Kaitong Cai,Keze Wang*

Main category: cs.AI

TL;DR: 该论文提出了一个农业科学代理框架，通过结合大语言模型与农业数据执行环境，实现代码驱动的农业推理分析。


<details>
  <summary>Details</summary>
Motivation: 现有农业基础模型虽然能处理大规模时空数据，但缺乏语言推理和交互能力；而大语言模型擅长文本处理，却无法直接处理高维异构农业数据。需要桥接这一鸿沟。

Method: 构建AgriWorld执行环境提供统一工具（地理空间查询、遥感时序分析、作物生长模拟等），设计Agro-Reflective多轮LLM代理，通过执行-观察-精炼循环迭代编写代码进行分析。

Result: 在AgroBench基准测试中，该方法在查询、预测、异常检测和反事实分析等任务上优于纯文本和直接工具使用基线，验证了执行驱动反思对可靠农业推理的有效性。

Conclusion: 提出的代理框架成功结合了LLM的语言能力与农业数据执行环境，通过代码驱动的反思循环实现了可靠的农业科学推理。

Abstract: Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual "what-if" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.

</details>


### [94] [World-Model-Augmented Web Agents with Action Correction](https://arxiv.org/abs/2602.15384)
*Zhouzhou Shen,Xueyu Hu,Xiyun Li,Tianqing Fang,Juncheng Li,Shengyu Zhang*

Main category: cs.AI

TL;DR: WAC是一个集成模型协作、结果模拟和反馈驱动动作优化的Web智能体，通过多智能体协作和两阶段推理链提升任务执行的安全性和成功率。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的Web智能体在预测环境变化方面存在局限，缺乏对执行风险的全面认知，容易过早执行危险动作导致任务失败。需要解决智能体推理能力不足和风险意识薄弱的问题。

Method: 1. 多智能体协作：动作模型咨询作为Web环境专家的世界模型获取策略指导，然后基于环境状态转换的先验知识生成可执行动作。2. 两阶段推理链：世界模型模拟动作结果，法官模型审查结果并在必要时触发动作修正反馈。

Result: 在VisualWebArena上获得1.8%的绝对提升，在Online-Mind2Web上获得1.3%的绝对提升，显著提高了任务执行成功率。

Conclusion: WAC通过模型协作和反馈驱动的动作优化，有效解决了现有Web智能体的推理局限和风险意识问题，实现了更安全、更可靠的自动化Web任务执行。

Abstract: Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of execution risks, prematurely performing risky actions that cause losses and lead to task failure. To address these challenges, we propose WAC, a web agent that integrates model collaboration, consequence simulation, and feedback-driven action refinement. To overcome the cognitive isolation of individual models, we introduce a multi-agent collaboration process that enables an action model to consult a world model as a web-environment expert for strategic guidance; the action model then grounds these suggestions into executable actions, leveraging prior knowledge of environmental state transition dynamics to enhance candidate action proposal. To achieve risk-aware resilient task execution, we introduce a two-stage deduction chain. A world model, specialized in environmental state transitions, simulates action outcomes, which a judge model then scrutinizes to trigger action corrective feedback when necessary. Experiments show that WAC achieves absolute gains of 1.8% on VisualWebArena and 1.3% on Online-Mind2Web.

</details>


### [95] [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)
*Ankit Sharma,Nachiket Tapas,Jyotiprakash Patra*

Main category: cs.AI

TL;DR: 论文提出了一种自适应弃权系统，通过基于上下文信号动态调整安全阈值，结合五路并行检测器和分层级联机制，在保证安全性的同时减少误报和延迟。


<details>
  <summary>Details</summary>
Motivation: LLM在生产环境中面临安全性与实用性的根本权衡：严格过滤会阻止良性查询，宽松控制则可能生成不安全内容。传统基于静态规则或固定置信度阈值的护栏通常缺乏上下文敏感性且计算成本高，导致高延迟和用户体验下降。

Method: 引入自适应弃权系统，基于实时上下文信号（如领域和用户历史）动态调整安全阈值。采用多维度检测架构，包含五个并行检测器，通过分层级联机制结合以优化速度和精度。级联设计通过逐步过滤查询减少不必要的计算。

Result: 在混合和特定领域工作负载上的广泛评估显示，误报显著减少，特别是在医疗建议和创意写作等敏感领域。系统在严格操作模式下保持高安全精度和接近完美的召回率。与非级联模型和外部护栏系统相比，实现了显著的延迟改进。

Conclusion: 上下文感知的弃权框架有效平衡了安全性和实用性，同时保持性能，为可靠的LLM部署提供了可扩展的解决方案。

Abstract: Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.

</details>


### [96] [Common Belief Revisited](https://arxiv.org/abs/2602.15403)
*Thomas Ågotnes*

Main category: cs.AI

TL;DR: 本文研究了在KD45个体信念下共同信念的逻辑特性，发现共同信念不仅失去5属性，还获得shift-reflexivity属性，最终给出了共同信念的完整逻辑刻画。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为共同信念是KD4，但本文发现当个体信念是KD45时，共同信念会失去5属性，获得shift-reflexivity属性。这引发了一个开放性问题：KD4加上shift-reflexivity公理是否足以完整刻画共同信念？

Method: 通过逻辑分析研究共同信念在KD45个体信念下的特性，考察KD4加上shift-reflexivity公理的完备性，并发现需要额外公理来完整刻画共同信念。

Result: 研究发现：1) KD4加上shift-reflexivity不足以完整刻画共同信念；2) 需要额外公理；3) 该公理依赖于智能体数量；4) 最终给出了共同信念的完整逻辑刻画。

Conclusion: 本文解决了共同信念逻辑的开放性问题，给出了在KD45个体信念下共同信念的完整逻辑刻画，发现其不仅包含shift-reflexivity属性，还需要依赖于智能体数量的额外公理。

Abstract: Contrary to common belief, common belief is not KD4.
  If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(Cφ\rightarrow φ)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:
  is KD4 extended with this axiom a complete characterisation of common belief in the KD45 case? If not, what \emph{is} the logic of common belief? In this paper we show that the answer to the first question is ``no'': there is one additional axiom, and, furthermore, it relies on the number of agents. We show that the result is a complete characterisation of common belief, settling the open problem.

</details>


### [97] [GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway](https://arxiv.org/abs/2602.15531)
*Javier Irigoyen,Roberto Daza,Aythami Morales,Julian Fierrez,Francisco Jurado,Alvaro Ortigosa,Ruben Tolosana*

Main category: cs.AI

TL;DR: EduEVAL-DB是一个基于教师角色的数据集，用于评估和训练自动教学评估器和AI导师，包含854个解释，对应ScienceQA基准的139个问题，涵盖K-12科学、语言和社会科学领域。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门用于评估和训练自动教学评估器和AI导师的数据集，特别是在教学解释质量评估方面。需要建立一个标准化的评估框架来确保AI教育工具的教学质量。

Method: 1. 基于ScienceQA基准构建数据集，包含139个问题和854个解释；2. 设计6种LLM模拟的教师角色（基于实际教学实践中的教学风格和缺陷）；3. 提出包含五个维度的教学风险评估标准：事实正确性、解释深度和完整性、焦点和相关性、学生水平适当性、意识形态偏见；4. 通过半自动流程和专家教师评审进行二元风险标注；5. 进行初步验证实验，比较Gemini 2.5 Pro和Llama 3.1 8B模型，并测试在EduEVAL-DB上监督微调对教学风险检测的效果。

Result: 创建了EduEVAL-DB数据集，包含854个标注了教学风险的解释。初步实验表明，该数据集适用于评估教学风险检测模型，并支持在消费级硬件上部署的轻量级模型通过监督微调来改进教学风险检测能力。

Conclusion: EduEVAL-DB为自动教学评估器和AI导师的评估和训练提供了一个有价值的基准数据集，提出的教学风险评估框架有助于确保AI教育工具的教学质量，支持在资源受限环境下部署有效的教学风险检测模型。

Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.

</details>


### [98] [Quantifying construct validity in large language model evaluations](https://arxiv.org/abs/2602.15532)
*Ryan Othniel Kearns*

Main category: cs.AI

TL;DR: 该论文提出结构化能力模型，首次从大量LLM基准测试结果中提取可解释且可泛化的能力，解决了现有方法在构造效度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前LLM社区将基准测试结果等同于模型通用能力，但基准测试存在测试集污染、标注错误等问题，影响构造效度。现有方法（潜在因子模型和缩放定律）都无法有效分离模型规模与真实能力。

Method: 提出结构化能力模型，结合缩放定律和潜在因子模型的优势：模型规模影响能力（如缩放定律），能力影响观测结果并考虑测量误差（如潜在因子模型）。在OpenLLM Leaderboard的大规模结果样本上拟合该模型及其两种替代方法。

Result: 结构化能力模型在简约拟合指标上优于潜在因子模型，在分布外基准预测上优于缩放定律。该模型能更好地解释和预测LLM评估中的构造效度。

Conclusion: 结构化能力模型通过适当分离模型规模与能力，提供了更好的解释和预测能力，是量化LLM评估构造效度的有效方法。

Abstract: The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance.
  Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks.
  This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.

</details>


### [99] [RUVA: Personalized Transparent On-Device Graph Reasoning](https://arxiv.org/abs/2602.15553)
*Gabriele Conte,Alessio Mattiace,Gianni Carmosino,Potito Aghilar,Giovanni Servedio,Francesco Musicco,Vito Walter Anelli,Tommaso Di Noia,Francesco Maria Donini*

Main category: cs.AI

TL;DR: Ruva提出首个"透明盒"架构，将个人AI从向量匹配转向知识图谱推理，实现用户可检查AI知识并精确删除特定事实，保障"被遗忘权"。


<details>
  <summary>Details</summary>
Motivation: 当前个人AI主要采用"黑盒"检索增强生成，存在缺乏问责性、无法检查错误原因、无法精确删除概念、隐私保护不足等问题。用户需要能够检查和编辑AI记忆的透明系统。

Method: Ruva采用"透明盒"架构，将个人AI建立在个人知识图谱基础上，从向量匹配转向图谱推理，支持人类在环记忆管理，允许用户检查和精确删除特定事实。

Result: Ruva实现了用户可检查AI知识的能力，支持精确的事实删除，解决了向量数据库中概念删除不精确的问题，确保了"被遗忘权"的真正实现。

Conclusion: Ruva通过知识图谱架构将AI记忆管理从黑盒转变为透明盒，让用户成为自己生活的编辑者，实现了真正的隐私保护和记忆控制权。

Abstract: The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the "Right to be Forgotten." Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.

</details>


### [100] [How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580)
*Hongxuan Wu,Yukun Zhang,Xueqing Zhou*

Main category: cs.AI

TL;DR: 该研究使用部分信息分解(PID)分析多模态Transformer，发现视觉信息在早期层达到峰值后衰减，语言信息在后期层主导预测(约82%)，跨模态协同作用始终低于2%，揭示了"模态转导"模式。


<details>
  <summary>Details</summary>
Motivation: 研究多模态Transformer在回答视觉问题时，预测是由视觉证据、语言推理还是真正的跨模态计算驱动，以及这种结构如何在不同层间演化。旨在理解视觉如何转化为语言信息。

Method: 提出PID Flow框架：结合降维、归一化流高斯化和闭式高斯PID估计，将每个Transformer层的预测信息分解为冗余、视觉独特、语言独特和协同四个部分。应用于LLaVA-1.5-7B和LLaVA-1.6-7B模型，并进行注意力敲除实验验证因果关系。

Result: 发现一致的"模态转导"模式：视觉独特信息早期达到峰值后衰减，语言独特信息在后期层激增(占最终预测约82%)，跨模态协同作用始终低于2%。模型变体间高度稳定(层间相关性>0.96)，但任务依赖性很强。注意力敲除实验证实了因果关系。

Conclusion: 研究提供了信息论和因果关系的解释，说明在多模态Transformer中视觉如何转化为语言信息，并为识别模态特定信息丢失的架构瓶颈提供了定量指导。

Abstract: When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\% of the final prediction, and cross-modal synergy remains below 2\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.

</details>


### [101] [On inferring cumulative constraints](https://arxiv.org/abs/2602.15635)
*Konstantin Sidorov*

Main category: cs.AI

TL;DR: 提出一种预处理方法，通过推断额外的累积约束来捕获多资源交互，提升调度问题的搜索性能


<details>
  <summary>Details</summary>
Motivation: 传统约束规划中累积约束的传播通常单独进行，忽略了多资源间的交互作用，导致在某些基准测试上性能严重下降

Method: 将累积约束解释为占用向量的线性不等式，通过：(1)发现覆盖集（不能并行运行的任务集），(2)通过提升技术加强覆盖不等式，(3)将生成的约束注入调度问题实例

Result: 在标准RCPSP和RCPSP/max测试集上，推断的约束改善了搜索性能并收紧目标界限，发现了25个新的下界和5个新的最优解，其中8个下界直接来自推断的约束

Conclusion: 该方法能有效捕获多资源交互，在有利实例上显著提升性能，在不利实例上性能下降很小，为调度问题提供了有效的预处理技术

Abstract: Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.

</details>


### [102] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: CARE Drive框架用于评估自动驾驶中视觉语言模型是否基于人类相关理由进行决策，而非事后合理化，通过上下文扰动测量模型对安全、社会压力等理由的敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶模型评估主要关注结果性能（如安全性、轨迹精度），但无法判断模型决策是否真正基于人类相关理由，可能导致在安全关键领域产生虚假信心。

Method: 提出CARE Drive框架：1)提示校准确保稳定输出；2)系统化上下文扰动，测量模型决策对人类理由（安全边际、社会压力、效率约束）的敏感性，比较基准模型和理由增强模型在受控上下文变化下的决策。

Result: 明确的人类理由显著影响模型决策，改善与专家推荐行为的一致性；但对不同理由的响应性存在差异，表明模型对不同类型理由的敏感性不均。

Conclusion: 无需修改模型参数即可系统评估基础模型中的理由响应性，为评估自动驾驶中视觉语言模型是否进行真正基于理由的决策提供了实证方法。

Abstract: Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.

</details>


### [103] [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)
*Xiachong Feng,Liang Zhao,Weihong Zhong,Yichong Huang,Yuxuan Gu,Lingpeng Kong,Xiaocheng Feng,Bing Qin*

Main category: cs.AI

TL;DR: PERSONA：无需训练的LLM人格控制框架，通过激活空间中的向量操作实现细粒度人格调控，性能接近监督微调水平


<details>
  <summary>Details</summary>
Motivation: 当前LLM人格控制方法依赖静态提示或昂贵的微调，无法捕捉人类特质的动态性和组合性，需要更灵活高效的解决方案

Method: 提出三阶段框架：1) Persona-Base通过对比激活分析提取正交人格向量；2) Persona-Algebra通过向量算术（标量乘法调节强度、加法组合、减法抑制）实现精确控制；3) Persona-Flow在推理时动态组合向量实现上下文感知适应

Result: 在PersonalityBench上平均得分9.60，接近监督微调上限9.61；在Persona-Evolve动态人格适应基准上，跨不同模型家族达到91%胜率

Conclusion: LLM人格特质在数学上是可处理的，表现为可提取、近似正交的激活空间方向，为可解释且高效的行为控制开辟了新方向

Abstract: Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.

</details>


### [104] [Recursive Concept Evolution for Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.15725)
*Sarim Chaudhry*

Main category: cs.AI

TL;DR: RCE框架让预训练语言模型在推理时动态修改内部表示几何，通过生成低秩概念子空间来构建新抽象，显著提升组合推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过扩展token级搜索来改进推理，但保持模型的潜在表示空间固定。当所需抽象未编码在该空间中时，性能会崩溃。需要让模型能在推理时修改内部表示几何。

Method: 提出递归概念演化(RCE)框架：检测到表示不足时生成动态低秩概念子空间，通过最小描述长度准则选择，协同时合并，通过约束优化进行整合以保持稳定性。

Result: 在Mistral-7B上集成RCE，在组合推理基准测试中：ARC-AGI-2提升12-18点，GPQA和BBH提升8-14点，MATH和HLE上深度诱导误差持续减少。

Conclusion: RCE使预训练语言模型能够在推理时构建新抽象而非仅重组现有抽象，显著提升组合推理能力，为解决复杂推理任务中的表示不足问题提供了新途径。

Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.

</details>


### [105] [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776)
*Yiqin Yang,Xu Yang,Yuhua Jiang,Ni Mu,Hao Hu,Runpeng Xie,Ziyou Zhang,Siyuan Li,Yuan-Hua Ni,Qianchuan Zhao,Bo Xu*

Main category: cs.AI

TL;DR: GlobeDiff：一种基于扩散模型的多模态全局状态推断算法，用于解决多智能体系统中的部分可观测性问题


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中的部分可观测性是协调与决策的关键障碍。现有方法如信念状态估计和智能体间通信存在局限：信念方法过度依赖历史经验而未能充分利用全局信息，通信方法缺乏有效利用辅助信息的鲁棒模型。

Method: 提出Global State Diffusion Algorithm (GlobeDiff)，将状态推断过程建模为多模态扩散过程。通过局部观测推断全局状态，克服状态估计中的模糊性，同时实现高保真度的全局状态推断。

Result: 理论证明了GlobeDiff在单模态和多模态分布下的估计误差有界。大量实验结果表明，GlobeDiff实现了优越性能，能够准确推断全局状态。

Conclusion: GlobeDiff通过多模态扩散过程有效解决了多智能体系统中的部分可观测性问题，为全局状态推断提供了新的解决方案，在理论和实验上都表现出色。

Abstract: In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.

</details>


### [106] [This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785)
*Jessica Hullman,David Broska,Huaman Sun,Aaron Shaw*

Main category: cs.AI

TL;DR: 论文分析了使用大语言模型作为合成参与者在社会科学实验中的有效性，对比了启发式方法和统计校准两种策略，并讨论了它们在不同研究阶段的应用条件。


<details>
  <summary>Details</summary>
Motivation: 当前越来越多的研究使用LLMs作为合成参与者来生成低成本、即时的响应，但缺乏关于何时这种模拟能够有效推断人类行为的指导。需要明确在什么条件下LLM模拟能支持有效的因果效应估计。

Method: 论文对比了两种策略：1）启发式方法：通过提示工程、模型微调等修复策略来减少LLM引入的不准确性，使模拟和观察的人类行为可互换；2）统计校准：结合辅助人类数据和统计调整来考虑观察与模拟响应之间的差异。

Result: 启发式方法适用于探索性研究但缺乏正式统计保证；统计校准在明确假设下能保持有效性，并以比仅依赖人类参与者的实验更低的成本提供更精确的因果效应估计。两种方法的潜力都取决于LLMs对相关人群的近似程度。

Conclusion: 研究者不应仅仅关注用LLMs替代人类参与者，而应考虑被忽视的机会。需要根据研究目的（探索性vs验证性）选择合适的方法，并明确各自的假设条件，同时认识到LLMs对目标人群的近似程度是关键限制因素。

Abstract: A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.

</details>


### [107] [Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings](https://arxiv.org/abs/2602.15791)
*Suhyung Jang,Ghang Lee,Jaekun Lee,Hyunjun Lee*

Main category: cs.AI

TL;DR: 本研究提出使用LLM嵌入作为编码方法，替代传统的one-hot编码，以更好地捕捉建筑对象子类型之间的语义关系，在BIM分类任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统编码方法（如one-hot）无法有效传达建筑对象子类型之间的细微语义关系，限制了AI在AECO行业中对复杂建筑语义的理解能力。

Method: 使用大型语言模型（如OpenAI GPT和Meta LLaMA）的嵌入作为编码，包括原始高维嵌入和通过Matryoshka表示模型生成的压缩嵌入，用于训练GraphSAGE模型分类42个建筑对象子类型。

Result: LLM编码在五个高层住宅BIM模型的分类任务中优于传统one-hot基线，其中llama-3（压缩）嵌入的加权平均F1分数达到0.8766，而one-hot编码为0.8475。

Conclusion: LLM编码方法能够增强AI对复杂领域特定建筑语义的理解能力，随着LLM和降维技术的发展，该方法在AECO行业的语义细化任务中具有广泛应用潜力。

Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.

</details>


### [108] [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816)
*Xiaoran Liu,Istvan David*

Main category: cs.AI

TL;DR: 本章介绍基于仿真的合成数据生成，用于解决AI训练中数据不足的问题，并提出了数字孪生AI仿真解决方案的参考框架。


<details>
  <summary>Details</summary>
Motivation: 数据量不足和质量问题是现代符号AI采用的主要障碍，因此对合成数据生成技术的需求很高。仿真提供了一种系统化的方法来生成多样化的合成数据。

Method: 本章介绍了基于仿真的合成数据生成的关键概念、优势和挑战，并提出了一个参考框架来描述、设计和分析基于数字孪生的AI仿真解决方案。

Result: 提供了系统化的仿真方法来生成合成数据，并建立了数字孪生AI仿真解决方案的参考框架。

Conclusion: 仿真为AI训练提供了有效的合成数据生成方法，数字孪生框架为设计和分析AI仿真解决方案提供了系统化的参考。

Abstract: As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [109] [Near-Optimal Sample Complexity for Online Constrained MDPs](https://arxiv.org/abs/2602.15076)
*Chang Liu,Yunfan Li,Lin F. Yang*

Main category: cs.LG

TL;DR: 提出一种基于模型的原对偶算法，用于在线学习约束马尔可夫决策过程，在允许小违规和零违规两种设置下，分别达到与无约束MDP相同的样本复杂度下界。


<details>
  <summary>Details</summary>
Motivation: 强化学习在自动驾驶、机器人等现实应用中面临安全挑战，现有CMDP方法存在安全违规严重或样本复杂度高的问题，需要开发更高效的在线安全RL算法。

Method: 提出基于模型的原对偶算法，结合在线RL和约束优化技术，平衡遗憾和约束违规。针对两种可行性设置：允许小违规的松弛可行性和零违规的严格可行性。

Result: 对于松弛可行性：算法以任意高概率返回ε最优策略且违规有界，需要Õ(SAH³/ε²)学习回合，匹配无约束MDP下界。对于严格可行性：算法以任意高概率返回ε最优策略且零违规，需要Õ(SAH⁵/ε²ζ²)学习回合，匹配生成模型下界。

Conclusion: 在线学习CMDP与使用生成模型学习同样容易，当允许小违规时，其难度不高于学习无约束MDP，为安全RL提供了高效的在线算法框架。

Abstract: Safety is a fundamental challenge in reinforcement learning (RL), particularly in real-world applications such as autonomous driving, robotics, and healthcare. To address this, Constrained Markov Decision Processes (CMDPs) are commonly used to enforce safety constraints while optimizing performance. However, existing methods often suffer from significant safety violations or require a high sample complexity to generate near-optimal policies. We address two settings: relaxed feasibility, where small violations are allowed, and strict feasibility, where no violation is allowed. We propose a model-based primal-dual algorithm that balances regret and bounded constraint violations, drawing on techniques from online RL and constrained optimization. For relaxed feasibility, we prove that our algorithm returns an $\varepsilon$-optimal policy with $\varepsilon$-bounded violation with arbitrarily high probability, requiring $\tilde{O}\left(\frac{SAH^3}{\varepsilon^2}\right)$ learning episodes, matching the lower bound for unconstrained MDPs. For strict feasibility, we prove that our algorithm returns an $\varepsilon$-optimal policy with zero violation with arbitrarily high probability, requiring $\tilde{O}\left(\frac{SAH^5}{\varepsilon^2ζ^2}\right)$ learning episodes, where $ζ$ is the problem-dependent Slater constant characterizing the size of the feasible region. This result matches the lower bound for learning CMDPs with access to a generative model.
  Our results demonstrate that learning CMDPs in an online setting is as easy as learning with a generative model and is no more challenging than learning unconstrained MDPs when small violations are allowed.

</details>


### [110] [Hybrid Feature Learning with Time Series Embeddings for Equipment Anomaly Prediction](https://arxiv.org/abs/2602.15089)
*Takato Yasuno*

Main category: cs.LG

TL;DR: 提出一种混合方法，结合Granite TinyTimeMixer的时间序列嵌入和基于领域知识的统计特征，用于HVAC设备异常预测，在64台设备上实现高精度异常检测。


<details>
  <summary>Details</summary>
Motivation: 在设备预测性维护中，纯深度学习方法在真实世界数据上往往无法达到足够精度，需要结合领域知识来提高异常检测的准确性。

Method: 采用混合方法：1) 使用LoRA微调的Granite TinyTimeMixer编码器提取64维时间序列嵌入；2) 基于领域知识提取28维统计特征（趋势、波动性、回撤等指标）；3) 使用LightGBM梯度提升分类器进行学习。

Result: 在64台设备、51,564个样本的实验中，30天、60天、90天预测时段的精度达到91-95%，ROC-AUC为0.995，误报率≤1.1%，检测率88-94%，满足生产就绪性能。

Conclusion: 通过结合深度学习的表示学习能力和统计特征工程的互补优势，可以实现实用的异常检测系统，为预测性维护应用提供有效解决方案。

Abstract: In predictive maintenance of equipment, deep learning-based time series anomaly detection has garnered significant attention; however, pure deep learning approaches often fail to achieve sufficient accuracy on real-world data. This study proposes a hybrid approach that integrates 64-dimensional time series embeddings from Granite TinyTimeMixer with 28-dimensional statistical features based on domain knowledge for HVAC equipment anomaly prediction tasks. Specifically, we combine time series embeddings extracted from a Granite TinyTimeMixer encoder fine-tuned with LoRA (Low-Rank Adaptation) and 28 types of statistical features including trend, volatility, and drawdown indicators, which are then learned using a LightGBM gradient boosting classifier. In experiments using 64 equipment units and 51,564 samples, we achieved Precision of 91--95\% and ROC-AUC of 0.995 for anomaly prediction at 30-day, 60-day, and 90-day horizons. Furthermore, we achieved production-ready performance with a false positive rate of 1.1\% or less and a detection rate of 88--94\%, demonstrating the effectiveness of the system for predictive maintenance applications. This work demonstrates that practical anomaly detection systems can be realized by leveraging the complementary strengths between deep learning's representation learning capabilities and statistical feature engineering.

</details>


### [111] [PolyNODE: Variable-dimension Neural ODEs on M-polyfolds](https://arxiv.org/abs/2602.15128)
*Per Åhag,Alexander Friedrich,Fredrik Ohlsson,Viktor Vigren Näslund*

Main category: cs.LG

TL;DR: PolyNODEs：首个可变维度的流模型，将神经常微分方程扩展到M-多流形，解决了传统NODE模型维度固定的限制


<details>
  <summary>Details</summary>
Motivation: 传统神经常微分方程（NODEs）基于流形上的向量场和动力学系统，但所有现有NODE模型都受限于固定维度，无法处理可变维度的几何深度学习任务

Method: 将NODEs扩展到M-多流形（可同时容纳不同维度和可微概念的空间），引入PolyNODEs模型，构建具有维度瓶颈的M-多流形，并基于参数化向量场实现PolyNODE自编码器

Result: 实验证明PolyNODE模型能够在这些空间中训练解决重构任务，并能提取输入的潜在表示用于下游分类任务

Conclusion: PolyNODEs是几何深度学习中首个可变维度的流模型，成功扩展了NODEs的能力边界，为处理可变维度数据提供了新方法

Abstract: Neural ordinary differential equations (NODEs) are geometric deep learning models based on dynamical systems and flows generated by vector fields on manifolds. Despite numerous successful applications, particularly within the flow matching paradigm, all existing NODE models are fundamentally constrained to fixed-dimensional dynamics by the intrinsic nature of the manifold's dimension. In this paper, we extend NODEs to M-polyfolds (spaces that can simultaneously accommodate varying dimensions and a notion of differentiability) and introduce PolyNODEs, the first variable-dimensional flow-based model in geometric deep learning. As an example application, we construct explicit M-polyfolds featuring dimensional bottlenecks and PolyNODE autoencoders based on parametrised vector fields that traverse these bottlenecks. We demonstrate experimentally that our PolyNODE models can be trained to solve reconstruction tasks in these spaces, and that latent representations of the input can be extracted and used to solve downstream classification tasks. The code used in our experiments is publicly available at https://github.com/turbotage/PolyNODE .

</details>


### [112] [Refine Now, Query Fast: A Decoupled Refinement Paradigm for Implicit Neural Fields](https://arxiv.org/abs/2602.15155)
*Tianyu Xiong,Skylar Wurster,Han-Wei Shen*

Main category: cs.LG

TL;DR: DRR范式通过解耦深度精炼网络与快速推理路径，解决了INR中的保真度-速度困境，实现了高保真度且27倍加速的推理性能。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INR）作为3D科学模拟的代理模型面临保真度-速度困境：深度MLP推理成本高，而高效的嵌入模型表达能力不足。

Method: 提出解耦表示精炼（DRR）架构范式：利用深度精炼网络和非参数变换，在一次性离线过程中将丰富表示编码到紧凑高效的嵌入结构中，将慢速高容量神经网络与快速推理路径解耦。

Result: 在多个集成模拟数据集上的实验表明，DRR-Net实现了最先进的保真度，推理速度比高保真度基线快27倍，并与最快模型保持竞争力。

Conclusion: DRR范式为构建强大实用的神经场代理模型提供了有效策略，在速度和质量之间实现了最小妥协，可广泛应用于INR相关应用。

Abstract: Implicit Neural Representations (INRs) have emerged as promising surrogates for large 3D scientific simulations due to their ability to continuously model spatial and conditional fields, yet they face a critical fidelity-speed dilemma: deep MLPs suffer from high inference cost, while efficient embedding-based models lack sufficient expressiveness. To resolve this, we propose the Decoupled Representation Refinement (DRR) architectural paradigm. DRR leverages a deep refiner network, alongside non-parametric transformations, in a one-time offline process to encode rich representations into a compact and efficient embedding structure. This approach decouples slow neural networks with high representational capacity from the fast inference path. We introduce DRR-Net, a simple network that validates this paradigm, and a novel data augmentation strategy, Variational Pairs (VP) for improving INRs under complex tasks like high-dimensional surrogate modeling. Experiments on several ensemble simulation datasets demonstrate that our approach achieves state-of-the-art fidelity, while being up to 27$\times$ faster at inference than high-fidelity baselines and remaining competitive with the fastest models. The DRR paradigm offers an effective strategy for building powerful and practical neural field surrogates and \rev{INRs in broader applications}, with a minimal compromise between speed and quality.

</details>


### [113] [Learning Representations from Incomplete EHR Data with Dual-Masked Autoencoding](https://arxiv.org/abs/2602.15159)
*Xiao Xiang,David Restrepo,Hyewon Jeong,Yugang Jia,Leo Anthony Celi*

Main category: cs.LG

TL;DR: AID-MAE：一种双掩码自编码器，直接从电子病历不完整时间序列中学习，通过内在缺失掩码和增强掩码处理缺失值，在多个临床任务上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 电子病历时间序列学习面临不规则采样、异质性缺失和观测稀疏性的挑战。现有自监督方法要么先插补再学习，要么通过专用输入信号表示缺失，要么仅优化插补任务，限制了学习支持临床下游任务表示的能力。

Method: 提出增强-内在双掩码自编码器（AID-MAE），直接从不完整时间序列学习：1）使用内在缺失掩码表示自然缺失值；2）使用增强掩码隐藏部分观测值进行重建训练；3）仅处理未掩码的token子集。

Result: 在两个数据集上的多个临床任务中，AID-MAE持续优于强基线方法（包括XGBoost和DuETT）。学习到的嵌入在表示空间中自然分层患者队列。

Conclusion: AID-MAE通过双掩码策略有效处理电子病历时间序列的缺失问题，学习到支持临床下游任务的表示，并在多个任务上表现优异。

Abstract: Learning from electronic health records (EHRs) time series is challenging due to irregular sam- pling, heterogeneous missingness, and the resulting sparsity of observations. Prior self-supervised meth- ods either impute before learning, represent missingness through a dedicated input signal, or optimize solely for imputation, reducing their capacity to efficiently learn representations that support clinical downstream tasks. We propose the Augmented-Intrinsic Dual-Masked Autoencoder (AID-MAE), which learns directly from incomplete time series by applying an intrinsic missing mask to represent naturally missing values and an augmented mask that hides a subset of observed values for reconstruction during training. AID-MAE processes only the unmasked subset of tokens and consistently outperforms strong baselines, including XGBoost and DuETT, across multiple clinical tasks on two datasets. In addition, the learned embeddings naturally stratify patient cohorts in the representation space.

</details>


### [114] [Seeing to Generalize: How Visual Data Corrects Binding Shortcuts](https://arxiv.org/abs/2602.15183)
*Nicolas Buzeta,Felipe del Rio,Cristian Hinostroza,Denis Parra,Hans Lobel,Rodrigo Toro Icarte*

Main category: cs.LG

TL;DR: 视觉语言模型在纯文本任务上能超越其底层语言模型，特别是在长上下文信息检索中。研究发现视觉训练改变了模型的内部绑定策略，使其采用更鲁棒的符号绑定机制，从而提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究观察到视觉语言模型在纯文本任务上能超越其底层语言模型的反常现象，特别是在长上下文信息检索中。这引发了对跨模态训练如何影响单模态任务性能的研究兴趣。

Method: 构建受控的合成检索任务，比较仅文本训练的transformer和后续在图像标记化版本上训练的模型。使用机制可解释性分析内部绑定策略的变化，并研究不同训练机制、视觉编码器和初始化条件下的绑定策略变化。

Result: 仅文本训练的模型在分布内表现完美但泛化失败，而图像训练使文本任务的分布外性能翻倍。视觉训练通过空间平移不变性破坏位置捷径，迫使模型采用更鲁棒的符号绑定机制，这种机制在重新引入纯文本示例后仍能保持。

Conclusion: 跨模态训练可以增强推理和泛化能力，即使对于单模态任务也是如此。视觉训练改变了模型的内部表示策略，使其从依赖位置捷径转向更鲁棒的符号绑定机制，这解释了VLM在纯文本任务上超越LLM的现象。

Abstract: Vision Language Models (VLMs) are designed to extend Large Language Models (LLMs) with visual capabilities, yet in this work we observe a surprising phenomenon: VLMs can outperform their underlying LLMs on purely text-only tasks, particularly in long-context information retrieval. To investigate this effect, we build a controlled synthetic retrieval task and find that a transformer trained only on text achieves perfect in-distribution accuracy but fails to generalize out of distribution, while subsequent training on an image-tokenized version of the same task nearly doubles text-only OOD performance. Mechanistic interpretability reveals that visual training changes the model's internal binding strategy: text-only training encourages positional shortcuts, whereas image-based training disrupts them through spatial translation invariance, forcing the model to adopt a more robust symbolic binding mechanism that persists even after text-only examples are reintroduced. We further characterize how binding strategies vary across training regimes, visual encoders, and initializations, and show that analogous shifts occur during pretrained LLM-to-VLM transitions. Our findings suggest that cross-modal training can enhance reasoning and generalization even for tasks grounded in a single modality.

</details>


### [115] [Learning Data-Efficient and Generalizable Neural Operators via Fundamental Physics Knowledge](https://arxiv.org/abs/2602.15184)
*Siying Ma,Mehrdad M. Zadeh,Mauricio Soroco,Wuyang Chen,Jiguo Cao,Vijay Ganesh*

Main category: cs.LG

TL;DR: 提出多物理训练框架，通过联合学习原始PDE及其简化基本形式，提升神经算子的数据效率、预测精度和分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子方法主要关注从目标PDE学习模拟，但忽略了这些方程背后更基本的物理原理。受数值求解器能与不同PDE设置兼容的启发，需要开发能更好利用基础物理知识的方法。

Method: 提出多物理训练框架，同时从原始PDE及其简化基本形式中联合学习。该方法与架构无关，通过显式融入基础物理知识来增强神经算子的泛化能力。

Result: 在广泛的1D/2D/3D PDE问题上，该方法在归一化均方根误差(nRMSE)方面表现出一致的改进，显著提升了数据效率、预测精度和分布外泛化能力，特别是在物理参数偏移和合成到真实转移场景中。

Conclusion: 显式融入基础物理知识能显著增强神经算子的泛化能力，多物理训练框架为科学机器学习提供了更有效的方法。

Abstract: Recent advances in scientific machine learning (SciML) have enabled neural operators (NOs) to serve as powerful surrogates for modeling the dynamic evolution of physical systems governed by partial differential equations (PDEs). While existing approaches focus primarily on learning simulations from the target PDE, they often overlook more fundamental physical principles underlying these equations. Inspired by how numerical solvers are compatible with simulations of different settings of PDEs, we propose a multiphysics training framework that jointly learns from both the original PDEs and their simplified basic forms. Our framework enhances data efficiency, reduces predictive errors, and improves out-of-distribution (OOD) generalization, particularly in scenarios involving shifts of physical parameters and synthetic-to-real transfer. Our method is architecture-agnostic and demonstrates consistent improvements in normalized root mean square error (nRMSE) across a wide range of 1D/2D/3D PDE problems. Through extensive experiments, we show that explicit incorporation of fundamental physics knowledge significantly strengthens the generalization ability of neural operators. We will release models and codes at https://sites.google.com/view/sciml-fundemental-pde.

</details>


### [116] [COMPOT: Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers Compression](https://arxiv.org/abs/2602.15200)
*Denis Makhov,Dmitriy Shopkhoev,Magauiya Zhussip,Ammar Ali,Baher Mohammad,Stamatios Lefkimmiatis*

Main category: cs.LG

TL;DR: COMPOT是一种无需训练、基于校准的Transformer模型压缩框架，使用正交字典和Procrustes更新实现稀疏权重分解，优于传统低秩和稀疏方法。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型压缩方法存在局限性：截断SVD强制共享单一子空间会损害精度，而稀疏字典学习方法需要迭代优化，计算效率低。需要一种更灵活、高效的无训练压缩框架。

Method: COMPOT使用小规模校准数据集估计稀疏权重分解，采用正交字典实现封闭形式的Procrustes字典更新和单步稀疏编码。引入一次性动态分配策略，根据层敏感性自适应调整压缩率。

Result: 在多种架构和任务上的实验表明，COMPOT在质量-压缩权衡方面始终优于强基线方法，且与后训练量化完全兼容，可实现极端压缩。

Conclusion: COMPOT提供了一种高效、无需训练的Transformer压缩解决方案，通过正交字典和自适应压缩分配实现了优越的压缩性能，代码已开源。

Abstract: Post-training compression of Transformer models commonly relies on truncated singular value decomposition (SVD). However, enforcing a single shared subspace can degrade accuracy even at moderate compression. Sparse dictionary learning provides a more flexible union-of-subspaces representation, but existing approaches often suffer from iterative dictionary and coefficient updates. We propose COMPOT (Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers), a training-free compression framework that uses a small calibration dataset to estimate a sparse weight factorization. COMPOT employs orthogonal dictionaries that enable closed-form Procrustes updates for the dictionary and analytical single-step sparse coding for the coefficients, eliminating iterative optimization. To handle heterogeneous layer sensitivity under a global compression budget, COMPOT further introduces a one-shot dynamic allocation strategy that adaptively redistributes layer-wise compression rates. Extensive experiments across diverse architectures and tasks show that COMPOT consistently delivers a superior quality-compression trade-off over strong low-rank and sparse baselines, while remaining fully compatible with post-training quantization for extreme compression. Code is available $\href{https://github.com/mts-ai/COMPOT}{here}$.

</details>


### [117] [MAVRL: Learning Reward Functions from Multiple Feedback Types with Amortized Variational Inference](https://arxiv.org/abs/2602.15206)
*Raphaël Baur,Yannick Metz,Maria Gkoulta,Mennatallah El-Assady,Giorgia Ramponi,Thomas Kleine Buening*

Main category: cs.LG

TL;DR: 提出一种贝叶斯推理框架，通过变分推断联合学习来自多种异质反馈类型（演示、比较、评分、停止）的奖励函数，避免手动损失平衡，提高策略鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前奖励学习通常依赖单一反馈类型或手动加权组合多种反馈，缺乏有效方法联合学习来自异质反馈类型（如演示、比较、评分、停止）的奖励函数，这些反馈提供不同性质的信号。

Method: 将多反馈类型奖励学习建模为共享潜在奖励函数的贝叶斯推理，每种反馈通过显式似然函数贡献信息。提出可扩展的摊销变分推断方法，学习共享奖励编码器和反馈特定似然解码器，通过优化单一证据下界进行训练。

Result: 在离散和连续控制基准测试中，联合推断的奖励后验优于单类型基线，利用跨反馈类型的互补信息，产生的策略对环境扰动更鲁棒。推断的奖励不确定性提供可解释信号用于分析模型置信度和跨反馈类型一致性。

Conclusion: 提出的贝叶斯推理框架能够有效联合学习来自多种异质反馈类型的奖励函数，避免手动损失平衡，提高学习效果和策略鲁棒性，同时提供不确定性估计增强可解释性。

Abstract: Reward learning typically relies on a single feedback type or combines multiple feedback types using manually weighted loss terms. Currently, it remains unclear how to jointly learn reward functions from heterogeneous feedback types such as demonstrations, comparisons, ratings, and stops that provide qualitatively different signals. We address this challenge by formulating reward learning from multiple feedback types as Bayesian inference over a shared latent reward function, where each feedback type contributes information through an explicit likelihood. We introduce a scalable amortized variational inference approach that learns a shared reward encoder and feedback-specific likelihood decoders and is trained by optimizing a single evidence lower bound. Our approach avoids reducing feedback to a common intermediate representation and eliminates the need for manual loss balancing. Across discrete and continuous-control benchmarks, we show that jointly inferred reward posteriors outperform single-type baselines, exploit complementary information across feedback types, and yield policies that are more robust to environment perturbations. The inferred reward uncertainty further provides interpretable signals for analyzing model confidence and consistency across feedback types.

</details>


### [118] [ÜberWeb: Insights from Multilingual Curation for a 20-Trillion-Token Dataset](https://arxiv.org/abs/2602.15210)
*DatologyAI,:,Aldo Gael Carranza,Kaleigh Mentzer,Ricardo Pio Monti,Alex Fang,Alvin Deng,Amro Abbas,Anshuman Suri,Brett Larsen,Cody Blakeney,Darren Teh,David Schwab,Diego Kiner,Fan Pan,Haakon Mongstad,Jack Urbanek,Jason Lee,Jason Telanoff,Josh Wills,Luke Merrick,Parth Doshi,Paul Burstein,Pratyush Maini,Spandan Das,Tony Jiang,Vineeth Dorna,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 研究发现多语言性能下降主要源于数据质量问题而非模型容量限制，通过针对性的语言数据优化可以显著提升多语言训练效率


<details>
  <summary>Details</summary>
Motivation: 现代基础模型需要多语言能力，但多语言训练面临数据分布不均和性能干扰（"多语言诅咒"）的挑战，需要探索更高效的多语言训练方法

Method: 在13种语言上进行多语言数据优化研究，通过双语对照实验验证数据质量改进的效果，并将发现扩展到大规模通用训练混合中，使用仅占总量8%的优化多语言数据

Result: 优化英语数据可提升12/13种非英语语言性能，优化非英语数据也能提升英语性能；使用3B和8B参数模型在1T token随机子集上训练，比现有基准少4-10倍FLOPs达到竞争性多语言准确率；20T token语料库用于训练400B/A13B模型也表现出色

Conclusion: 针对性的语言数据优化能够缓解多语言干扰，实现计算高效的多语言扩展，为多语言模型训练建立了新的帕累托前沿

Abstract: Multilinguality is a core capability for modern foundation models, yet training high-quality multilingual models remains challenging due to uneven data availability across languages. A further challenge is the performance interference that can arise from joint multilingual training, commonly referred to as the "curse of multilinguality". We study multilingual data curation across thirteen languages and find that many reported regressions are not inherent to multilingual scaling but instead stem from correctable deficiencies in data quality and composition rather than fundamental capacity limits. In controlled bilingual experiments, improving data quality for any single language benefits others: curating English improves non-English performance in 12 of 13 languages, while curating non-English yields reciprocal improvements in English. Bespoke per-language curation produces substantially larger within-language improvements. Extending these findings to large-scale general-purpose training mixtures, we show that curated multilingual allocations comprising under 8% of total tokens remain remarkably effective. We operationalize this approach within an effort that produced a 20T-token pretraining corpus derived entirely from public sources. Models with 3B and 8B parameters trained on a 1T-token random subset achieve competitive multilingual accuracy with 4-10x fewer training FLOPs than strong public baselines, establishing a new Pareto frontier in multilingual performance versus compute. Moreover, these benefits extend to frontier model scale: the 20T-token corpus served as part of the pretraining dataset for Trinity Large (400B/A13B), which exhibits strong multilingual performance relative to its training FLOPs. These results show that targeted, per-language data curation mitigates multilingual interference and enables compute-efficient multilingual scaling.

</details>


### [119] [Automatically Finding Reward Model Biases](https://arxiv.org/abs/2602.15222)
*Atticus Wang,Iván Arcuschin,Arthur Conmy*

Main category: cs.LG

TL;DR: 提出自动发现奖励模型偏见的框架，使用LLM迭代生成和精炼候选偏见，能发现已知和新颖偏见，并验证进化迭代优于最佳N搜索


<details>
  <summary>Details</summary>
Motivation: 奖励模型在LLM后训练中至关重要，但现有研究表明它们会奖励虚假或不良属性（如长度、格式、幻觉和奉承），需要自动发现这些偏见的方法

Method: 使用LLM迭代提出和精炼候选偏见，通过进化迭代方法（优于平面最佳N搜索）自动发现奖励模型在自然语言中的偏见

Result: 方法能恢复已知偏见并发现新偏见：例如发现Skywork-V2-8B奖励模型经常错误地偏好带有冗余空格和幻觉内容的回答；进化迭代优于最佳N搜索；通过合成注入偏见验证了管道的召回率

Conclusion: 该工作为通过自动可解释性方法改进奖励模型的研究做出了贡献，展示了自动发现奖励模型偏见的可行性

Abstract: Reward models are central to large language model (LLM) post-training. However, past work has shown that they can reward spurious or undesirable attributes such as length, format, hallucinations, and sycophancy. In this work, we introduce and study the research problem of automatically finding reward model biases in natural language. We offer a simple approach of using an LLM to iteratively propose and refine candidate biases. Our method can recover known biases and surface novel ones: for example, we found that Skywork-V2-8B, a leading open-weight reward model, often mistakenly favors responses with redundant spacing and responses with hallucinated content. In addition, we show evidence that evolutionary iteration outperforms flat best-of-N search, and we validate the recall of our pipeline using synthetically injected biases. We hope our work contributes to further research on improving RMs through automated interpretability methods.

</details>


### [120] [tensorFM: Low-Rank Approximations of Cross-Order Feature Interactions](https://arxiv.org/abs/2602.15229)
*Alessio Mazzetto,Mohammad Mahdi Khalili,Laura Fee Nern,Michael Viderman,Alex Shtoff,Krzysztof Dembczyński*

Main category: cs.LG

TL;DR: tensorFM：一种用于表格分类数据预测的新模型，通过低秩张量近似高效捕获属性间的高阶交互，在保持低延迟的同时达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 表格分类数据（如点击率预测、社会科学）中的预测问题需要有效建模多个分类属性间的交互。现有方法可能无法高效捕获高阶交互或计算成本过高。

Method: 提出tensorFM模型，通过低秩张量近似来表示属性间交互的强度，该方法推广了场加权分解机（field-weighted factorization machines），能高效捕获高阶交互。

Result: tensorFM在实证中表现出与最先进方法相竞争的性能，同时具有低延迟特性，特别适合在线广告等时间敏感应用。

Conclusion: tensorFM是一种高效且有效的模型，能很好地处理表格分类数据中的预测问题，在性能和延迟之间取得了良好平衡。

Abstract: We address prediction problems on tabular categorical data, where each instance is defined by multiple categorical attributes, each taking values from a finite set. These attributes are often referred to as fields, and their categorical values as features. Such problems frequently arise in practical applications, including click-through rate prediction and social sciences. We introduce and analyze {tensorFM}, a new model that efficiently captures high-order interactions between attributes via a low-rank tensor approximation representing the strength of these interactions. Our model generalizes field-weighted factorization machines. Empirically, tensorFM demonstrates competitive performance with state-of-the-art methods. Additionally, its low latency makes it well-suited for time-sensitive applications, such as online advertising.

</details>


### [121] [BindCLIP: A Unified Contrastive-Generative Representation Learning Framework for Virtual Screening](https://arxiv.org/abs/2602.15236)
*Anjie Qiao,Zhen Wang,Yaliang Li,Jiahua Rao,Yuedong Yang*

Main category: cs.LG

TL;DR: BindCLIP通过结合对比学习和生成式姿态监督，改进虚拟筛选中的口袋-配体表示学习，提升对真实结合相互作用的敏感性


<details>
  <summary>Details</summary>
Motivation: 现有CLIP风格模型（如DrugCLIP）在虚拟筛选中存在两个问题：1）对精细结合相互作用不敏感；2）依赖训练数据中的捷径相关性，限制了按真实结合兼容性排序配体的能力

Method: 提出BindCLIP统一框架，结合CLIP风格对比学习和口袋条件扩散姿态生成目标，通过姿态级监督直接塑造检索嵌入空间朝向相互作用相关特征。引入硬负样本增强和配体-配体锚定正则化器防止表示坍塌

Result: 在两个公共基准测试中表现优于强基线，在具有挑战性的分布外虚拟筛选中取得显著提升，在FEP+基准上改进配体类似物排序

Conclusion: 将生成式姿态级监督与对比学习相结合，能产生更具相互作用感知的嵌入表示，在现实筛选场景中改善泛化能力，使虚拟筛选更接近实际应用

Abstract: Virtual screening aims to efficiently identify active ligands from massive chemical libraries for a given target pocket. Recent CLIP-style models such as DrugCLIP enable scalable virtual screening by embedding pockets and ligands into a shared space. However, our analyses indicate that such representations can be insensitive to fine-grained binding interactions and may rely on shortcut correlations in training data, limiting their ability to rank ligands by true binding compatibility. To address these issues, we propose BindCLIP, a unified contrastive-generative representation learning framework for virtual screening. BindCLIP jointly trains pocket and ligand encoders using CLIP-style contrastive learning together with a pocket-conditioned diffusion objective for binding pose generation, so that pose-level supervision directly shapes the retrieval embedding space toward interaction-relevant features. To further mitigate shortcut reliance, we introduce hard-negative augmentation and a ligand-ligand anchoring regularizer that prevents representation collapse. Experiments on two public benchmarks demonstrate consistent improvements over strong baselines. BindCLIP achieves substantial gains on challenging out-of-distribution virtual screening and improves ligand-analogue ranking on the FEP+ benchmark. Together, these results indicate that integrating generative, pose-level supervision with contrastive learning yields more interaction-aware embeddings and improves generalization in realistic screening settings, bringing virtual screening closer to real-world applicability.

</details>


### [122] [Closing the Distribution Gap in Adversarial Training for LLMs](https://arxiv.org/abs/2602.15238)
*Chengzhi Hu,Jonas Dornbusch,David Lüdke,Stephan Günnemann,Leo Schwinn*

Main category: cs.LG

TL;DR: 提出分布对抗训练(DAT)，利用扩散LLM近似真实数据分布，生成多样高似然样本，显著提升对抗鲁棒性


<details>
  <summary>Details</summary>
Motivation: 当前对抗训练方法虽然取得进展，但模型仍容易受到简单攻击（如改写时态或翻译），这是因为现有方法只最小化训练集上的对抗损失，未能充分覆盖数据分布

Method: 提出分布对抗训练(DAT)：1) 利用扩散LLM近似提示和响应的真实联合分布；2) 生成多样高似然样本解决泛化失败问题；3) 结合扩散模型提供的数据分布优化与连续对抗训练

Result: DAT相比之前方法实现了显著更高的对抗鲁棒性

Conclusion: 通过近似真实数据分布并生成多样样本，DAT能够有效解决当前对抗训练的数据覆盖不足问题，显著提升LLM的对抗鲁棒性

Abstract: Adversarial training for LLMs is one of the most promising methods to reliably improve robustness against adversaries. However, despite significant progress, models remain vulnerable to simple in-distribution exploits, such as rewriting prompts in the past tense or translating them into other languages. We argue that this persistent fragility stems from a fundamental limitation in current adversarial training algorithms: they minimize adversarial loss on their training set but inadequately cover the data distribution, resulting in vulnerability to seemingly simple attacks. To bridge this gap, we propose Distributional Adversarial Training, DAT. We leverage Diffusion LLMs to approximate the true joint distribution of prompts and responses, enabling generation of diverse, high-likelihood samples that address generalization failures. By combining optimization over the data distribution provided by the diffusion model with continuous adversarial training, DAT achieves substantially higher adversarial robustness than previous methods.

</details>


### [123] [Size Transferability of Graph Transformers with Convolutional Positional Encodings](https://arxiv.org/abs/2602.15239)
*Javier Porras-Valenzuela,Zhiyang Wang,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 图Transformer通过GNN位置编码继承可迁移性，能在小图上训练后泛化到大图，理论证明与流形神经网络相关，实验验证其可扩展性与GNN相当。


<details>
  <summary>Details</summary>
Motivation: 研究图Transformer（GTs）的理论基础，特别是它们如何通过GNN位置编码融入图结构信息，并探索GTs的可迁移性保证，为大规模图上的高效训练提供理论指导。

Method: 通过流形极限模型分析图序列，建立GTs与流形神经网络的理论联系；利用GNN在流形收敛下的可迁移性结果，证明GTs继承其位置编码的可迁移性；在标准图基准和实际场景（地形最短路径估计）中进行实验验证。

Result: 理论证明GTs具有可迁移性保证，能在小图上训练后泛化到大图；实验表明GTs表现出与GNN相当的可扩展行为；在实际应用中，可迁移GTs能高效处理地形最短路径估计问题。

Conclusion: GTs通过GNN位置编码继承可迁移性，为理解GTs提供了新视角，并为大规模图上的高效训练提供了实用方向，证明了GTs在实际应用中的可扩展潜力。

Abstract: Transformers have achieved remarkable success across domains, motivating the rise of Graph Transformers (GTs) as attention-based architectures for graph-structured data. A key design choice in GTs is the use of Graph Neural Network (GNN)-based positional encodings to incorporate structural information. In this work, we study GTs through the lens of manifold limit models for graph sequences and establish a theoretical connection between GTs with GNN positional encodings and Manifold Neural Networks (MNNs). Building on transferability results for GNNs under manifold convergence, we show that GTs inherit transferability guarantees from their positional encodings. In particular, GTs trained on small graphs provably generalize to larger graphs under mild assumptions. We complement our theory with extensive experiments on standard graph benchmarks, demonstrating that GTs exhibit scalable behavior on par with GNNs. To further show the efficiency in a real-world scenario, we implement GTs for shortest path distance estimation over terrains to better illustrate the efficiency of the transferable GTs. Our results provide new insights into the understanding of GTs and suggest practical directions for efficient training of GTs in large-scale settings.

</details>


### [124] [Scaling Laws for Masked-Reconstruction Transformers on Single-Cell Transcriptomics](https://arxiv.org/abs/2602.15253)
*Ihor Kendiukhov*

Main category: cs.LG

TL;DR: 首次系统研究单细胞RNA测序数据上掩码重建Transformer的缩放规律，发现在数据丰富时存在类似NLP的幂律缩放，数据稀缺时缩放效应可忽略。


<details>
  <summary>Details</summary>
Motivation: 虽然神经缩放规律在语言和视觉Transformer中已被广泛记录，但在单细胞基因组学中仍未被充分探索。本研究旨在填补这一空白，探索单细胞转录组学中是否存在类似的缩放规律。

Method: 使用CELLxGENE Census的表达谱构建两个实验体系：数据丰富体系（512个高变异基因，20万个细胞）和数据有限体系（1024个基因，1万个细胞）。在跨越三个数量级的七个模型规模（533到3.4×10^8参数）上，将参数化缩放规律拟合到验证均方误差。

Result: 数据丰富体系显示出清晰的幂律缩放，不可约损失下限c≈1.44；数据有限体系缩放效应可忽略，表明当数据稀缺时模型容量不是限制因素。数据丰富体系的渐近下限转换为信息论单位后，估计每个掩码基因位置约2.30比特熵。

Conclusion: 当有足够数据时，单细胞转录组学中确实会出现类似于自然语言处理的缩放规律，数据与参数的比例是缩放行为的关键决定因素。这对单细胞基础模型的设计有重要启示。

Abstract: Neural scaling laws -- power-law relationships between loss, model size, and data -- have been extensively documented for language and vision transformers, yet their existence in single-cell genomics remains largely unexplored. We present the first systematic study of scaling behaviour for masked-reconstruction transformers trained on single-cell RNA sequencing (scRNA-seq) data. Using expression profiles from the CELLxGENE Census, we construct two experimental regimes: a data-rich regime (512 highly variable genes, 200,000 cells) and a data-limited regime (1,024 genes, 10,000 cells). Across seven model sizes spanning three orders of magnitude in parameter count (533 to 3.4 x 10^8 parameters), we fit the parametric scaling law to validation mean squared error (MSE). The data-rich regime exhibits clear power-law scaling with an irreducible loss floor of c ~ 1.44, while the data-limited regime shows negligible scaling, indicating that model capacity is not the binding constraint when data are scarce. These results establish that scaling laws analogous to those observed in natural language processing do emerge in single-cell transcriptomics when sufficient data are available, and they identify the data-to-parameter ratio as a critical determinant of scaling behaviour. A preliminary conversion of the data-rich asymptotic floor to information-theoretic units yields an estimate of approximately 2.30 bits of entropy per masked gene position. We discuss implications for the design of single-cell foundation models and outline the additional measurements needed to refine this entropy estimate.

</details>


### [125] [Fast and Effective On-policy Distillation from Reasoning Prefixes](https://arxiv.org/abs/2602.15260)
*Dongxu Zhang,Zhichao Yang,Sepehr Janghorbani,Jun Han,Andrew Ressler,Qian Qian,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.LG

TL;DR: 提出一种名为"on-policy prefix distillation"的方法，通过仅对学生模型生成输出的前缀应用蒸馏目标并提前终止采样，大幅降低训练成本，同时保持与完整on-policy蒸馏相当的性能。


<details>
  <summary>Details</summary>
Motivation: On-policy蒸馏（OPD）虽然能比off-policy蒸馏获得更好的泛化性能，但需要在训练过程中实时采样学生策略，训练成本高昂，特别是对于长响应任务。研究发现训练信号通常集中在输出的前缀部分，即使短的前缀也能显著帮助学生产生正确答案。

Method: 提出on-policy前缀蒸馏方法：仅对学生生成输出的前缀应用蒸馏目标，并在蒸馏过程中提前终止每个采样。这种方法减少了需要处理的序列长度，从而大幅降低训练计算成本。

Result: 在AI-for-Math和跨领域基准测试套件上的实验表明，on-policy前缀蒸馏能够匹配完整OPD的性能，同时将训练FLOP降低2x-47x。

Conclusion: on-policy前缀蒸馏是一种简单而有效的OPD改进方法，通过专注于输出前缀的蒸馏，在保持性能的同时显著降低了训练成本，为高效的知识蒸馏提供了新思路。

Abstract: On-policy distillation (OPD), which samples trajectories from the student model and supervises them with a teacher at the token level, avoids relying solely on verifiable terminal rewards and can yield better generalization than off-policy distillation. However, OPD requires expensive on-the-fly sampling of the student policy during training, which substantially increases training cost, especially for long responses. Our initial analysis shows that, during OPD, training signals are often concentrated in the prefix of each output, and that even a short teacher-generated prefix can significantly help the student produce the correct answer. Motivated by these observations, we propose a simple yet effective modification of OPD: we apply the distillation objective only to prefixes of student-generated outputs and terminate each sampling early during distillation. Experiments on a suite of AI-for-Math and out-of-domain benchmarks show that on-policy prefix distillation matches the performance of full OPD while reducing training FLOP by 2x-47x.

</details>


### [126] [Complex-Valued Unitary Representations as Classification Heads for Improved Uncertainty Quantification in Deep Neural Networks](https://arxiv.org/abs/2602.15283)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.LG

TL;DR: 量子启发的分类头架构通过复数希尔伯特空间中的酉变换改善神经网络校准，在CIFAR-10上ECE降低2.4倍，但Born规则测量反而恶化校准。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络预测准确率高但校准性差，置信度不能可靠反映正确概率。需要改善神经网络校准性能。

Method: 提出量子启发的分类头架构：将骨干网络特征投影到复数希尔伯特空间，通过Cayley映射参数化的酉变换演化特征。采用混合实验设计，比较轻量级可互换头部。

Result: 酉幅度头在CIFAR-10上ECE为0.0146，比标准softmax头(0.0355)改善2.4倍，比温度缩放(0.0510)改善3.5倍。Born规则测量反而恶化校准(ECE 0.0819)。在CIFAR-10H上波函数头获得最低KL散度(0.336)。

Conclusion: 复数表示能更好捕捉人类感知模糊性，但Born规则测量不适合校准任务。酉动力学通过特征空间几何改善校准，对安全关键应用有实际意义。

Abstract: Modern deep neural networks achieve high predictive accuracy but remain poorly calibrated: their confidence scores do not reliably reflect the true probability of correctness. We propose a quantum-inspired classification head architecture that projects backbone features into a complex-valued Hilbert space and evolves them under a learned unitary transformation parameterised via the Cayley map. Through a controlled hybrid experimental design - training a single shared backbone and comparing lightweight interchangeable heads - we isolate the effect of complex-valued unitary representations on calibration. Our ablation study on CIFAR-10 reveals that the unitary magnitude head (complex features evolved under a Cayley unitary, read out via magnitude and softmax) achieves an Expected Calibration Error (ECE) of 0.0146, representing a 2.4x improvement over a standard softmax head (0.0355) and a 3.5x improvement over temperature scaling (0.0510). Surprisingly, replacing the softmax readout with a Born rule measurement layer - the quantum-mechanically motivated approach - degrades calibration to an ECE of 0.0819. On the CIFAR-10H human-uncertainty benchmark, the wave function head achieves the lowest KL-divergence (0.336) to human soft labels among all compared methods, indicating that complex-valued representations better capture the structure of human perceptual ambiguity. We provide theoretical analysis connecting norm-preserving unitary dynamics to calibration through feature-space geometry, report negative results on out-of-distribution detection and sentiment analysis to delineate the method's scope, and discuss practical implications for safety-critical applications. Code is publicly available.

</details>


### [127] [The Information Geometry of Softmax: Probing and Steering](https://arxiv.org/abs/2602.15293)
*Kiho Park,Todd Nief,Yo Joong Choe,Victor Veitch*

Main category: cs.LG

TL;DR: 论文探讨AI系统如何将语义结构编码到表示空间的几何结构中，提出信息几何是表示空间的自然几何，并开发了"双重引导"方法用于概念操控。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是理解AI系统如何将语义结构编码到表示空间的几何结构中。核心观察是：表示空间的自然几何应该反映模型如何使用这些表示来产生行为。特别关注定义softmax分布的表示情况。

Method: 论文提出信息几何是表示空间的自然几何，并开发了"双重引导"方法。该方法使用线性探针来稳健地引导表示以展现特定概念。理论证明双重引导能最优地修改目标概念，同时最小化对非目标概念的改变。

Result: 经验研究发现，双重引导增强了概念操控的可控性和稳定性。该方法在语义编码和线性表示假设方面表现出优越性能。

Conclusion: 信息几何为理解AI表示空间的语义结构提供了合适的几何框架，双重引导方法为概念操控提供了有效工具，增强了AI系统的可解释性和可控性。

Abstract: This paper concerns the question of how AI systems encode semantic structure into the geometric structure of their representation spaces. The motivating observation of this paper is that the natural geometry of these representation spaces should reflect the way models use representations to produce behavior. We focus on the important special case of representations that define softmax distributions. In this case, we argue that the natural geometry is information geometry. Our focus is on the role of information geometry on semantic encoding and the linear representation hypothesis. As an illustrative application, we develop "dual steering", a method for robustly steering representations to exhibit a particular concept using linear probes. We prove that dual steering optimally modifies the target concept while minimizing changes to off-target concepts. Empirically, we find that dual steering enhances the controllability and stability of concept manipulation.

</details>


### [128] [Hybrid Federated and Split Learning for Privacy Preserving Clinical Prediction and Treatment Optimization](https://arxiv.org/abs/2602.15304)
*Farzana Akter,Rakib Hossain,Deb Kanna Roy Toushi,Mahmood Menon Khan,Sultana Amin,Lisan Al Amin*

Main category: cs.LG

TL;DR: 提出结合联邦学习(FL)和分割学习(SL)的混合隐私保护框架，用于医疗决策支持，无需共享原始数据，在预测性能、隐私泄露和通信开销之间提供可调节的平衡。


<details>
  <summary>Details</summary>
Motivation: 临床决策支持系统常受治理和隐私规则限制，无法跨机构共享患者级数据，需要一种既能保护隐私又能实现有效协作的解决方案。

Method: 提出混合FL-SL框架：客户端保留特征提取主干，服务器托管预测头，通过成员推理审计隐私泄露，并研究基于激活裁剪和高斯噪声的轻量级防御机制。

Result: 混合FL-SL变体在三个公共临床数据集上表现出与独立FL或SL相当的预测性能和决策优先排序能力，同时提供可调节的隐私-效用权衡，能减少审计泄露风险。

Conclusion: 混合FL-SL为医疗决策支持提供了一个实用的设计空间，可以在效用、泄露风险和部署成本之间进行明确平衡，是隐私保护协作的有效解决方案。

Abstract: Collaborative clinical decision support is often constrained by governance and privacy rules that prevent pooling patient-level records across institutions. We present a hybrid privacy-preserving framework that combines Federated Learning (FL) and Split Learning (SL) to support decision-oriented healthcare modeling without raw-data sharing. The approach keeps feature-extraction trunks on clients while hosting prediction heads on a coordinating server, enabling shared representation learning and exposing an explicit collaboration boundary where privacy controls can be applied. Rather than assuming distributed training is inherently private, we audit leakage empirically using membership inference on cut-layer representations and study lightweight defenses based on activation clipping and additive Gaussian noise. We evaluate across three public clinical datasets under non-IID client partitions using a unified pipeline and assess performance jointly along four deployment-relevant axes: factual predictive utility, uplift-based ranking under capacity constraints, audited privacy leakage, and communication overhead. Results show that hybrid FL-SL variants achieve competitive predictive performance and decision-facing prioritization behavior relative to standalone FL or SL, while providing a tunable privacy-utility trade-off that can reduce audited leakage without requiring raw-data sharing. Overall, the work positions hybrid FL-SL as a practical design space for privacy-preserving healthcare decision support where utility, leakage risk, and deployment cost must be balanced explicitly.

</details>


### [129] [On Surprising Effectiveness of Masking Updates in Adaptive Optimizers](https://arxiv.org/abs/2602.15322)
*Taejong Joo,Wenhan Xia,Cheolmin Kim,Ming Zhang,Eugene Ie*

Main category: cs.LG

TL;DR: 提出Magma优化器，通过随机掩码参数更新和动量梯度对齐，在LLM预训练中超越现有自适应优化器，显著降低困惑度


<details>
  <summary>Details</summary>
Motivation: 挑战当前LLM训练依赖复杂自适应优化器的现状，发现随机掩码参数更新能有效提升性能，这启发了新优化器的设计

Method: 提出Momentum-aligned gradient masking (Magma)，结合随机掩码参数更新和动量梯度对齐机制，作为现有自适应优化器的简单替代方案

Result: 在LLM预训练实验中，Magma相比Adam和Muon等优化器有显著提升，1B模型困惑度分别降低19%和9%，计算开销可忽略

Conclusion: Magma是一种简单有效的优化器，通过随机掩码诱导的几何正则化机制，为LLM训练提供了优于现有自适应优化器的解决方案

Abstract: Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners. We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment. Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\% and 9\% compared to Adam and Muon, respectively.

</details>


### [130] [Prescriptive Scaling Reveals the Evolution of Language Model Capabilities](https://arxiv.org/abs/2602.15327)
*Hanlin Zhang,Jikai Jin,Vasilis Syrgkanis,Sham Kakade*

Main category: cs.LG

TL;DR: 该论文提出了一个通过平滑分位数回归估计模型能力边界的方法，用于预测给定预训练计算预算下的下游任务性能，并验证了该方法的时间稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型的部署需求增加，实践者需要能够根据预训练计算预算预测下游任务准确性的缩放定律，并了解这种映射关系随着时间演变的稳定性。

Method: 使用大规模观测评估（5k观测数据和2k新采样数据），通过具有单调饱和sigmoid参数化的平滑分位数回归来估计能力边界（即基准分数的高条件分位数作为预训练FLOPs对数的函数）。验证了时间可靠性，并在早期模型上拟合，在后期模型上评估。

Result: 在大多数任务中，估计的能力边界基本稳定，但数学推理任务表现出随时间持续提升的边界。方法还扩展到分析任务依赖的饱和度和探测数学推理任务中的污染相关偏移。开发了高效算法，用约20%的评估预算恢复接近完整的数据前沿。

Conclusion: 该工作发布了最新的模型性能评估数据集Proteus 2k，并提供了一个实用方法学，用于将计算预算转化为可靠的性能预期，并监测能力边界随时间的变化。

Abstract: For deploying foundation models, practitioners increasingly need prescriptive scaling laws: given a pre training compute budget, what downstream accuracy is attainable with contemporary post training practice, and how stable is that mapping as the field evolves? Using large scale observational evaluations with 5k observational and 2k newly sampled data on model performance, we estimate capability boundaries, high conditional quantiles of benchmark scores as a function of log pre training FLOPs, via smoothed quantile regression with a monotone, saturating sigmoid parameterization. We validate the temporal reliability by fitting on earlier model generations and evaluating on later releases. Across various tasks, the estimated boundaries are mostly stable, with the exception of math reasoning that exhibits a consistently advancing boundary over time. We then extend our approach to analyze task dependent saturation and to probe contamination related shifts on math reasoning tasks. Finally, we introduce an efficient algorithm that recovers near full data frontiers using roughly 20% of evaluation budget. Together, our work releases the Proteus 2k, the latest model performance evaluation dataset, and introduces a practical methodology for translating compute budgets into reliable performance expectations and for monitoring when capability boundaries shift across time.

</details>


### [131] [A Scalable Curiosity-Driven Game-Theoretic Framework for Long-Tail Multi-Label Learning in Data Mining](https://arxiv.org/abs/2602.15330)
*Jing Yang,Keze Wang*

Main category: cs.LG

TL;DR: 提出CD-GTMLL框架，将长尾多标签分类重构为多玩家博弈，通过好奇心驱动机制自适应增强尾部标签学习，无需手动平衡或调参。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据挖掘中，多标签分类面临长尾分布挑战：少数头部标签主导，大量尾部标签稀少。现有重采样和重加权方法会破坏标签间依赖关系或需要脆弱的超参数调优，尤其在标签空间扩展到数万个标签时问题更严重。

Method: 提出好奇心驱动的博弈论多标签学习(CD-GTMLL)：将长尾多标签分类重构为多玩家博弈，每个子预测器专门处理标签空间的划分，通过合作最大化全局准确率，同时基于尾部标签稀有性和玩家间分歧追求内在好奇心奖励。该机制自适应地向代表性不足的尾部标签注入学习信号，无需手动平衡或调参。

Result: 在7个基准测试（包括超过30,000个标签的极端多标签分类数据集）上的广泛实验表明，CD-GTMLL始终优于最先进方法，在Wiki10-31K上P@3指标提升高达+1.6%。消融研究进一步证实了博弈论合作和好奇心驱动探索对稳健尾部性能的贡献。

Conclusion: 通过整合博弈论和好奇心机制，CD-GTMLL不仅提高了资源受限环境中的模型效率，还为电子商务和医疗等行业的不平衡数据场景中更自适应学习铺平了道路。

Abstract: The long-tail distribution, where a few head labels dominate while rare tail labels abound, poses a persistent challenge for large-scale Multi-Label Classification (MLC) in real-world data mining applications. Existing resampling and reweighting strategies often disrupt inter-label dependencies or require brittle hyperparameter tuning, especially as the label space expands to tens of thousands of labels. To address this issue, we propose Curiosity-Driven Game-Theoretic Multi-Label Learning (CD-GTMLL), a scalable cooperative framework that recasts long-tail MLC as a multi-player game - each sub-predictor ("player") specializes in a partition of the label space, collaborating to maximize global accuracy while pursuing intrinsic curiosity rewards based on tail label rarity and inter-player disagreement. This mechanism adaptively injects learning signals into under-represented tail labels without manual balancing or tuning. We further provide a theoretical analysis showing that our CD-GTMLL converges to a tail-aware equilibrium and formally links the optimization dynamics to improvements in the Rare-F1 metric. Extensive experiments across 7 benchmarks, including extreme multi-label classification datasets with 30,000+ labels, demonstrate that CD-GTMLL consistently surpasses state-of-the-art methods, with gains up to +1.6% P@3 on Wiki10-31K. Ablation studies further confirm the contributions of both game-theoretic cooperation and curiosity-driven exploration to robust tail performance. By integrating game theory with curiosity mechanisms, CD-GTMLL not only enhances model efficiency in resource-constrained environments but also paves the way for more adaptive learning in imbalanced data scenarios across industries like e-commerce and healthcare.

</details>


### [132] [Directional Reasoning Trajectory Change (DRTC): Identifying Critical Trace Segments in Reasoning Models](https://arxiv.org/abs/2602.15332)
*Waldemar Chang*

Main category: cs.LG

TL;DR: DRTC是一个因果解释框架，用于分析语言模型的长程推理过程，通过检测关键决策点并干预信息流来识别哪些上下文片段真正引导了推理方向。


<details>
  <summary>Details</summary>
Motivation: 现有解释方法通常只标记与答案相关的token或文本片段，但很少揭示模型在哪里做出关键推理转折、哪些早期上下文因果触发了这些转折，或者标记的文本是否真正引导了推理过程。

Method: DRTC通过不确定性和分布偏移信号检测关键决策点，然后应用接收端干预，在保持实际rollout的同时阻断选定早期片段的信息流。通过测量干预是否改变模型对数概率轨迹的方向，产生带符号的片段归因分数，并计算原始logits上的转向角曲率变化作为补充诊断。

Result: 方向性影响在四个推理模型中高度集中（|DRTC|共享的基尼系数0.50-0.58，前5%质量0.23-0.28），学习到的关键片段比随机匹配片段产生更强的干预幅度。在500个MATH问题上的扩展研究中，学习片段显著优于随机匹配片段（中位数差异=0.409，355/500为正，符号检验p=2.3e-21）。

Conclusion: DRTC提供了一个因果基础、轨迹层面的视角，揭示了在策略动态下特定上下文元素如何引导推理过程。

Abstract: Understanding how language models carry out long-horizon reasoning remains an open challenge. Existing interpretability methods often highlight tokens or spans correlated with an answer, but they rarely reveal where the model makes consequential reasoning turns, which earlier context causally triggers those turns, or whether the highlighted text actually steers the reasoning process. We introduce Directional Reasoning Trajectory Change (DRTC), a process-causal framework for interpreting long-form reasoning from a single on-policy rollout. DRTC detects pivot decision points using uncertainty and distribution-shift signals, then applies receiver-side interventions that preserve the realized rollout without resampling the continuation while blocking information flow from selected earlier chunks only at a pivot. It measures whether each intervention redirects the direction of the model's log-probability trajectory relative to the realized rollout direction, producing a signed per-chunk attribution score. We also compute turning-angle curvature changes on raw logits as a complementary diagnostic and introduce curvature signatures to summarize shared intervention-response geometry. Empirically, directional influence is sharply concentrated across four reasoning models (per-example |DRTC| shares yield Gini 0.50 to 0.58 and top-5 percent mass 0.23 to 0.28), and learned pivots induce stronger intervention magnitudes than matched random spans. In a scaling study on 500 MATH problems with R1-Distill-Qwen-1.5B, learned spans outperform matched random spans (median delta = 0.409, 355 of 500 positive; sign test p = 2.3e-21). Overall, DRTC provides a causally grounded, trajectory-level view of how specific context elements steer reasoning under on-policy dynamics.

</details>


### [133] [FedPSA: Modeling Behavioral Staleness in Asynchronous Federated Learning](https://arxiv.org/abs/2602.15337)
*Chaoyi Lu*

Main category: cs.LG

TL;DR: FedPSA：基于参数敏感度的异步联邦学习框架，通过细粒度评估模型过时程度和动态调整过时信息容忍度，提升异步联邦学习性能


<details>
  <summary>Details</summary>
Motivation: 异步联邦学习（AFL）虽然能加速训练，但异步过程引入的过时性（staleness）会降低性能。现有方法仅使用轮次差异作为过时性度量，这种粗粒度方法缺乏对模型本身的观察，限制了异步方法的性能上限。

Method: 提出FedPSA框架：1）利用参数敏感度（parameter sensitivity）来更细粒度地衡量模型过时程度；2）建立动态动量队列（dynamic momentum queue）实时评估当前训练阶段；3）动态调整对过时信息的容忍度。

Result: 在多个数据集上的实验表明，FedPSA相比基线方法提升高达6.37%，相比当前最优方法提升1.93%，表现出优越性能。

Conclusion: FedPSA通过引入参数敏感度和动态动量队列，实现了对异步联邦学习中过时性的更细粒度评估和动态调整，显著提升了异步联邦学习的性能。

Abstract: Asynchronous Federated Learning (AFL) has emerged as a significant research area in recent years. By not waiting for slower clients and executing the training process concurrently, it achieves faster training speed compared to traditional federated learning. However, due to the staleness introduced by the asynchronous process, its performance may degrade in some scenarios. Existing methods often use the round difference between the current model and the global model as the sole measure of staleness, which is coarse-grained and lacks observation of the model itself, thereby limiting the performance ceiling of asynchronous methods. In this paper, we propose FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning), a more fine-grained AFL framework that leverages parameter sensitivity to measure model obsolescence and establishes a dynamic momentum queue to assess the current training phase in real time, thereby adjusting the tolerance for outdated information dynamically. Extensive experiments on multiple datasets and comparisons with various methods demonstrate the superior performance of FedPSA, achieving up to 6.37\% improvement over baseline methods and 1.93\% over the current state-of-the-art method.

</details>


### [134] [Discovering Implicit Large Language Model Alignment Objectives](https://arxiv.org/abs/2602.15338)
*Edward Chen,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.LG

TL;DR: Obj-Disco框架自动将LLM对齐奖励信号分解为可解释的自然语言目标，揭示对齐过程中的隐式目标，提高AI开发的透明度和安全性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM对齐方法依赖复杂奖励信号，这些信号往往掩盖了具体被激励的行为，导致错位和奖励攻击风险。现有解释方法要么依赖预定义标准可能遗漏未知问题，要么无法全面识别与模型行为因果相关的目标。

Method: 提出Obj-Disco框架，使用迭代贪婪算法分析训练检查点间的行为变化，识别并验证最能解释剩余奖励信号的候选目标，将对齐奖励信号分解为稀疏、加权的可解释自然语言目标组合。

Result: 在不同任务、模型大小和对齐算法上的广泛评估显示框架具有鲁棒性。实验表明框架能持续捕获超过90%的奖励行为，人类评估进一步证实了这一发现。案例研究显示Obj-Disco能成功识别与预期行为同时出现的潜在错位激励。

Conclusion: Obj-Disco为揭示LLM对齐中的隐式目标提供了关键工具，为实现更透明、更安全的AI开发铺平了道路。

Abstract: Large language model (LLM) alignment relies on complex reward signals that often obscure the specific behaviors being incentivized, creating critical risks of misalignment and reward hacking. Existing interpretation methods typically rely on pre-defined rubrics, risking the omission of "unknown unknowns", or fail to identify objectives that comprehensively cover and are causal to the model behavior. To address these limitations, we introduce Obj-Disco, a framework that automatically decomposes an alignment reward signal into a sparse, weighted combination of human-interpretable natural language objectives. Our approach utilizes an iterative greedy algorithm to analyze behavioral changes across training checkpoints, identifying and validating candidate objectives that best explain the residual reward signal. Extensive evaluations across diverse tasks, model sizes, and alignment algorithms demonstrate the framework's robustness. Experiments with popular open-source reward models show that the framework consistently captures > 90% of reward behavior, a finding further corroborated by human evaluation. Additionally, a case study on alignment with an open-source reward model reveals that Obj-Disco can successfully identify latent misaligned incentives that emerge alongside intended behaviors. Our work provides a crucial tool for uncovering the implicit objectives in LLM alignment, paving the way for more transparent and safer AI development.

</details>


### [135] [ER-MIA: Black-Box Adversarial Memory Injection Attacks on Long-Term Memory-Augmented Large Language Models](https://arxiv.org/abs/2602.15344)
*Mitchell Piehl,Zhaohan Xi,Zuobin Xiong,Pan He,Muchao Ye*

Main category: cs.LG

TL;DR: 本文首次系统研究了针对长时记忆增强LLM中基于相似性检索机制的黑盒对抗性记忆注入攻击，提出了ER-MIA框架，揭示了相似性检索作为系统级漏洞的安全风险。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地配备长时记忆系统以克服有限上下文窗口，但研究发现记忆系统提供了额外的攻击面，使LLM变得更加脆弱。目前缺乏对针对相似性检索机制的黑盒对抗性记忆注入攻击的系统研究。

Method: 提出ER-MIA统一框架，形式化了两种现实攻击场景：基于内容的攻击和问题目标攻击。该框架包含可组合的攻击原语和集成攻击方法，在最小攻击者假设下实现高成功率。

Result: 在多个LLM和长时记忆系统上的广泛实验表明，基于相似性的检索构成了一个根本性的系统级漏洞，这种安全风险在不同记忆设计和应用场景中持续存在。

Conclusion: 相似性检索机制是长时记忆增强LLM中的基本安全漏洞，ER-MIA框架成功暴露了这一脆弱性，揭示了跨系统和应用场景的持久安全风险。

Abstract: Large language models (LLMs) are increasingly augmented with long-term memory systems to overcome finite context windows and enable persistent reasoning across interactions. However, recent research finds that LLMs become more vulnerable because memory provides extra attack surfaces. In this paper, we present the first systematic study of black-box adversarial memory injection attacks that target the similarity-based retrieval mechanism in long-term memory-augmented LLMs. We introduce ER-MIA, a unified framework that exposes this vulnerability and formalizes two realistic attack settings: content-based attacks and question-targeted attacks. In these settings, ER-MIA includes an arsenal of composable attack primitives and ensemble attacks that achieve high success rates under minimal attacker assumptions. Extensive experiments across multiple LLMs and long-term memory systems demonstrate that similarity-based retrieval constitutes a fundamental and system-level vulnerability, revealing security risks that persist across memory designs and application scenarios.

</details>


### [136] [CDRL: A Reinforcement Learning Framework Inspired by Cerebellar Circuits and Dendritic Computational Strategies](https://arxiv.org/abs/2602.15367)
*Sibo Zhang,Rui Jing,Liangfu Lv,Jian Zhang,Yunliang Zang*

Main category: cs.LG

TL;DR: 提出受小脑结构启发的强化学习架构，通过大规模扩展、稀疏连接、稀疏激活和树突级调制，在噪声高维任务中提升样本效率、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习在高维序列决策任务中表现出色，但存在样本效率低、对噪声敏感、部分可观测下泛化能力弱等问题。现有方法主要通过优化策略解决这些问题，而架构先验在塑造表示学习和决策动态方面的作用较少被探索。

Method: 受小脑结构原理启发，提出生物启发的强化学习架构，包含大规模扩展、稀疏连接、稀疏激活和树突级调制等特征。

Result: 在噪声高维强化学习基准测试中，小脑架构和树突调制相比传统设计能一致提升样本效率、鲁棒性和泛化能力。架构参数敏感性分析表明小脑启发的结构能在有限模型参数下提供优化性能。

Conclusion: 小脑结构先验可作为强化学习的有效归纳偏置，为架构设计提供有价值的生物学启示。

Abstract: Reinforcement learning (RL) has achieved notable performance in high-dimensional sequential decision-making tasks, yet remains limited by low sample efficiency, sensitivity to noise, and weak generalization under partial observability. Most existing approaches address these issues primarily through optimization strategies, while the role of architectural priors in shaping representation learning and decision dynamics is less explored. Inspired by structural principles of the cerebellum, we propose a biologically grounded RL architecture that incorporate large expansion, sparse connectivity, sparse activation, and dendritic-level modulation. Experiments on noisy, high-dimensional RL benchmarks show that both the cerebellar architecture and dendritic modulation consistently improve sample efficiency, robustness, and generalization compared to conventional designs. Sensitivity analysis of architectural parameters suggests that cerebellum-inspired structures can offer optimized performance for RL with constrained model parameters. Overall, our work underscores the value of cerebellar structural priors as effective inductive biases for RL.

</details>


### [137] [Fractional-Order Federated Learning](https://arxiv.org/abs/2602.15380)
*Mohammad Partohaghighi,Roummel Marcia,YangQuan Chen*

Main category: cs.LG

TL;DR: 提出FOFedAvg算法，将分数阶梯度下降引入联邦学习，通过记忆感知更新提升通信效率和收敛速度，在非IID数据上表现优异


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能保护隐私，但存在收敛慢、通信成本高、非IID数据等问题，需要更鲁棒高效的优化算法

Method: 提出FOFedAvg算法，结合分数阶随机梯度下降（FOSGD），引入记忆感知的分数阶更新，捕捉长期关系和历史信息

Result: 在多个基准数据集上，FOFedAvg在非IID划分下与现有算法竞争并经常超越，在测试性能和收敛速度上表现优异

Conclusion: 分数阶记忆感知更新能显著提升联邦学习的鲁棒性和有效性，为异构数据分布式训练提供实用路径

Abstract: Federated learning (FL) allows remote clients to train a global model collaboratively while protecting client privacy. Despite its privacy-preserving benefits, FL has significant drawbacks, including slow convergence, high communication cost, and non-independent-and-identically-distributed (non-IID) data. In this work, we present a novel FedAvg variation called Fractional-Order Federated Averaging (FOFedAvg), which incorporates Fractional-Order Stochastic Gradient Descent (FOSGD) to capture long-range relationships and deeper historical information. By introducing memory-aware fractional-order updates, FOFedAvg improves communication efficiency and accelerates convergence while mitigating instability caused by heterogeneous, non-IID client data. We compare FOFedAvg against a broad set of established federated optimization algorithms on benchmark datasets including MNIST, FEMNIST, CIFAR-10, CIFAR-100, EMNIST, the Cleveland heart disease dataset, Sent140, PneumoniaMNIST, and Edge-IIoTset. Across a range of non-IID partitioning schemes, FOFedAvg is competitive with, and often outperforms, these baselines in terms of test performance and convergence speed. On the theoretical side, we prove that FOFedAvg converges to a stationary point under standard smoothness and bounded-variance assumptions for fractional order $0<α\le 1$. Together, these results show that fractional-order, memory-aware updates can substantially improve the robustness and effectiveness of federated learning, offering a practical path toward distributed training on heterogeneous data.

</details>


### [138] [Doubly Stochastic Mean-Shift Clustering](https://arxiv.org/abs/2602.15393)
*Tom Trigano,Yann Sepulcre,Itshak Lapidot*

Main category: cs.LG

TL;DR: DSMS通过引入随机带宽机制改进Mean-Shift算法，解决传统方法对带宽超参数敏感的问题，在数据稀疏场景下防止过分割


<details>
  <summary>Details</summary>
Motivation: 传统Mean-Shift算法对带宽超参数非常敏感，特别是在数据稀缺的情况下，固定尺度的密度估计会导致分割碎片化和虚假模式的出现

Method: 提出双重随机Mean-Shift（DSMS），不仅在轨迹更新中引入随机性，还在核带宽本身引入随机性。每次迭代从连续均匀分布中抽取数据样本和半径，实现对密度景观的更好探索

Result: 在合成高斯混合数据上的比较实验显示，DSMS显著优于标准和随机Mean-Shift基线，表现出卓越的稳定性，在稀疏聚类场景中防止过分割，且没有其他性能下降

Conclusion: 随机带宽策略作为隐式正则化机制，DSMS通过双重随机性改进了Mean-Shift算法，在数据稀缺情况下提供了更好的聚类性能

Abstract: Standard Mean-Shift algorithms are notoriously sensitive to the bandwidth hyperparameter, particularly in data-scarce regimes where fixed-scale density estimation leads to fragmentation and spurious modes. In this paper, we propose Doubly Stochastic Mean-Shift (DSMS), a novel extension that introduces randomness not only in the trajectory updates but also in the kernel bandwidth itself. By drawing both the data samples and the radius from a continuous uniform distribution at each iteration, DSMS effectively performs a better exploration of the density landscape. We show that this randomized bandwidth policy acts as an implicit regularization mechanism, and provide convergence theoretical results. Comparative experiments on synthetic Gaussian mixtures reveal that DSMS significantly outperforms standard and stochastic Mean-Shift baselines, exhibiting remarkable stability and preventing over-segmentation in sparse clustering scenarios without other performance degradation.

</details>


### [139] [Joint Enhancement and Classification using Coupled Diffusion Models of Signals and Logits](https://arxiv.org/abs/2602.15405)
*Gilad Nurko,Roi Benita,Yehoshua Dissen,Tomohiro Nakatani,Marc Delcroix,Shoko Araki,Joseph Keshet*

Main category: cs.LG

TL;DR: 提出一个联合增强框架，通过两个相互作用的扩散模型同时处理输入信号和分类器输出，提升噪声环境下的分类鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法将信号增强和分类作为分离的串行阶段，无法利用分类器输出的语义信息来指导去噪过程，限制了在噪声环境下的分类性能。

Method: 提出一个领域无关的框架，集成两个相互作用的扩散模型：一个处理输入信号，另一个处理分类器输出logits。通过三种策略建模输入和logit的联合分布，实现相互指导，无需重新训练或微调分类器。

Result: 在图像分类和自动语音识别任务上评估，该方法超越了传统的串行增强基线，在多种噪声条件下提供了更鲁棒和灵活的分类准确性提升。

Conclusion: 通过联合增强框架实现信号增强和分类的协同优化，利用语义信息指导去噪过程，显著提高了噪声环境下的分类鲁棒性。

Abstract: Robust classification in noisy environments remains a fundamental challenge in machine learning. Standard approaches typically treat signal enhancement and classification as separate, sequential stages: first enhancing the signal and then applying a classifier. This approach fails to leverage the semantic information in the classifier's output during denoising. In this work, we propose a general, domain-agnostic framework that integrates two interacting diffusion models: one operating on the input signal and the other on the classifier's output logits, without requiring any retraining or fine-tuning of the classifier. This coupled formulation enables mutual guidance, where the enhancing signal refines the class estimation and, conversely, the evolving class logits guide the signal reconstruction towards discriminative regions of the manifold. We introduce three strategies to effectively model the joint distribution of the input and the logit. We evaluated our joint enhancement method for image classification and automatic speech recognition. The proposed framework surpasses traditional sequential enhancement baselines, delivering robust and flexible improvements in classification accuracy under diverse noise conditions.

</details>


### [140] [Fairness over Equality: Correcting Social Incentives in Asymmetric Sequential Social Dilemmas](https://arxiv.org/abs/2602.15407)
*Alper Demir,Hüseyin Aydın,Kale-ab Abebe Tessera,David Abel,Stefano V. Albrecht*

Main category: cs.LG

TL;DR: 本文针对非对称情境下的顺序社会困境问题，提出了一种改进的公平性定义和局部化社会反馈方法，以促进合作策略的更快涌现。


<details>
  <summary>Details</summary>
Motivation: 现有顺序社会困境研究大多假设智能体面临相同的激励，并需要持续访问全局信息来评估公平性。然而，现实世界中智能体往往存在自然差异（非对称性），现有基于公平性的方法在这种非对称条件下难以适应，因为它们强制原始平等反而错误地激励了背叛行为。

Method: 提出了三个关键改进：1）重新定义公平性，考虑智能体的奖励范围；2）引入基于智能体的加权机制，更好地处理固有的非对称性；3）将社会反馈局部化，使方法在部分可观测性下有效，无需全局信息共享。

Result: 实验结果表明，在非对称情境下，相比现有方法，本文方法能够更快地促进合作策略的涌现，同时不牺牲可扩展性或实用性。

Conclusion: 通过重新定义公平性、引入加权机制和局部化社会反馈，本文提出的方法能够有效应对非对称顺序社会困境，促进合作行为的形成，为多智能体强化学习在现实复杂环境中的应用提供了更实用的解决方案。

Abstract: Sequential Social Dilemmas (SSDs) provide a key framework for studying how cooperation emerges when individual incentives conflict with collective welfare. In Multi-Agent Reinforcement Learning, these problems are often addressed by incorporating intrinsic drives that encourage prosocial or fair behavior. However, most existing methods assume that agents face identical incentives in the dilemma and require continuous access to global information about other agents to assess fairness. In this work, we introduce asymmetric variants of well-known SSD environments and examine how natural differences between agents influence cooperation dynamics. Our findings reveal that existing fairness-based methods struggle to adapt under asymmetric conditions by enforcing raw equality that wrongfully incentivize defection. To address this, we propose three modifications: (i) redefining fairness by accounting for agents' reward ranges, (ii) introducing an agent-based weighting mechanism to better handle inherent asymmetries, and (iii) localizing social feedback to make the methods effective under partial observability without requiring global information sharing. Experimental results show that in asymmetric scenarios, our method fosters faster emergence of cooperative policies compared to existing approaches, without sacrificing scalability or practicality.

</details>


### [141] [Logit Distance Bounds Representational Similarity](https://arxiv.org/abs/2602.15438)
*Beatrix M. B. Nielsen,Emanuele Marconato,Luigi Gresele,Andrea Dittadi,Simon Buchholz*

Main category: cs.LG

TL;DR: 研究显示，对于判别模型，当两个模型的logit距离接近时，其内部表示具有线性相似性保证，而KL散度接近则不能保证这种线性表示相似性。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明，当两个模型的条件分布完全相同时，它们的内部表示在线性变换下是等价的。但实际中模型分布只是接近而非相等，需要研究这种近似情况下是否仍能保持线性表示相似性。

Method: 基于logit差异定义分布距离，证明该距离的接近性能够保证线性表示相似性。定义基于模型可识别性类的表示差异度量，证明其受logit距离限制。同时分析KL散度与logit距离的关系。

Result: logit距离接近确实能保证线性表示相似性，而KL散度接近不能提供有意义的控制。在蒸馏实验中，基于logit距离的蒸馏方法能产生更高线性表示相似性的学生模型，并更好地保留教师模型的可线性恢复概念。

Conclusion: logit距离是比KL散度更有效的度量，能保证模型间的线性表示相似性。基于logit距离的蒸馏方法能更好地保留教师模型的表示特性，而传统KL蒸馏可能匹配预测但无法保持线性表示属性。

Abstract: For a broad family of discriminative models that includes autoregressive language models, identifiability results imply that if two models induce the same conditional distributions, then their internal representations agree up to an invertible linear transformation. We ask whether an analogous conclusion holds approximately when the distributions are close instead of equal. Building on the observation of Nielsen et al. (2025) that closeness in KL divergence need not imply high linear representational similarity, we study a distributional distance based on logit differences and show that closeness in this distance does yield linear similarity guarantees. Specifically, we define a representational dissimilarity measure based on the models' identifiability class and prove that it is bounded by the logit distance. We further show that, when model probabilities are bounded away from zero, KL divergence upper-bounds logit distance; yet the resulting bound fails to provide nontrivial control in practice. As a consequence, KL-based distillation can match a teacher's predictions while failing to preserve linear representational properties, such as linear-probe recoverability of human-interpretable concepts. In distillation experiments on synthetic and image datasets, logit-distance distillation yields students with higher linear representational similarity and better preservation of the teacher's linearly recoverable concepts.

</details>


### [142] [Benchmarking IoT Time-Series AD with Event-Level Augmentations](https://arxiv.org/abs/2602.15457)
*Dmitry Zhevnenko,Ilya Makarov,Aleksandr Kovalenko,Fedor Meshchaninov,Anton Kozhukhov,Vladislav Travnikov,Makar Ippolitov,Kirill Yashunin,Iurii Katser*

Main category: cs.LG

TL;DR: 本文提出一个针对物联网时间序列异常检测的评估协议，包含统一的事件级数据增强来模拟真实扰动，并在多个数据集上评估14个模型，发现没有通用最优模型，不同模型在不同场景下表现各异。


<details>
  <summary>Details</summary>
Motivation: 当前异常检测研究过于关注点级结果和经过处理的基础数据集，缺乏对实际应用中模型选择的实用价值。需要建立能模拟真实世界扰动（如传感器故障、漂移、噪声等）的评估协议，以更好地评估模型在实际安全关键物联网系统中的可靠性和及时性。

Method: 引入统一的评估协议：1）事件级数据增强模拟真实扰动（校准传感器丢失、线性和对数漂移、加性噪声、窗口偏移）；2）传感器级探测通过掩码作为缺失零值处理，配合每通道影响估计支持根因分析；3）在5个公共数据集和2个工业数据集上评估14个代表性模型，使用统一的数据分割和事件聚合方法。

Result: 没有通用最优模型：图结构模型在传感器丢失和长事件场景下转移性最好；密度/流模型在清洁稳定工厂表现良好但对单调漂移脆弱；谱CNN在周期性强的场景领先；重构自编码器在基本传感器筛选后变得有竞争力；预测/混合动态模型在故障破坏时间依赖时有效但对窗口敏感。协议还揭示了设计选择的影响。

Conclusion: 实际物联网异常检测需要基于事件级评估和真实扰动模拟的协议。模型选择应针对具体场景：图模型适合传感器故障场景，谱CNN适合周期性系统，重构自编码器在传感器筛选后有效。设计选择（如密度模型类型、图结构固定与否）对鲁棒性有显著影响。

Abstract: Anomaly detection (AD) for safety-critical IoT time series should be judged at the event level: reliability and earliness under realistic perturbations. Yet many studies still emphasize point-level results on curated base datasets, limiting value for model selection in practice. We introduce an evaluation protocol with unified event-level augmentations that simulate real-world issues: calibrated sensor dropout, linear and log drift, additive noise, and window shifts. We also perform sensor-level probing via mask-as-missing zeroing with per-channel influence estimation to support root-cause analysis. We evaluate 14 representative models on five public anomaly datasets (SWaT, WADI, SMD, SKAB, TEP) and two industrial datasets (steam turbine, nuclear turbogenerator) using unified splits and event aggregation. There is no universal winner: graph-structured models transfer best under dropout and long events (e.g., on SWaT under additive noise F1 drops 0.804->0.677 for a graph autoencoder, 0.759->0.680 for a graph-attention variant, and 0.762->0.756 for a hybrid graph attention model); density/flow models work well on clean stationary plants but can be fragile to monotone drift; spectral CNNs lead when periodicity is strong; reconstruction autoencoders become competitive after basic sensor vetting; predictive/hybrid dynamics help when faults break temporal dependencies but remain window-sensitive. The protocol also informs design choices: on SWaT under log drift, replacing normalizing flows with Gaussian density reduces high-stress F1 from ~0.75 to ~0.57, and fixing a learned DAG gives a small clean-set gain (~0.5-1.0 points) but increases drift sensitivity by ~8x.

</details>


### [143] [On the Out-of-Distribution Generalization of Reasoning in Multimodal LLMs for Simple Visual Planning Tasks](https://arxiv.org/abs/2602.15460)
*Yannic Neuhaus,Nicolas Flammarion,Matthias Hein,Francesco Croce*

Main category: cs.LG

TL;DR: 该研究评估了思维链（CoT）方法在简单规划任务上的泛化能力，发现CoT能提升分布内泛化，但分布外泛化有限，多文本格式的推理轨迹效果最佳，纯文本模型优于图像输入模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型和大视觉语言模型中的推理能力有所提升，但推理模型的泛化能力仍定义不清且理解不足。本研究旨在严格评估思维链方法在简单规划任务上的泛化表现。

Method: 采用基于网格的导航任务，模型接收地图并输出从起点到终点的移动序列以避开障碍。通过不同输入表示（视觉和文本）和CoT推理策略微调模型变体，系统评估其在分布内和分布外测试条件下的表现。

Result: 实验表明：1）CoT推理能提升所有表示形式的分布内泛化；2）控制与分布内数据的简单匹配后，分布外泛化（如更大地图）在多数情况下仍非常有限；3）结合多种文本格式的推理轨迹能获得最佳（且非平凡的）分布外泛化；4）纯文本模型始终优于基于图像输入的模型，包括最近提出的潜在空间推理方法。

Conclusion: 思维链方法在简单规划任务中能有效提升分布内泛化，但分布外泛化能力有限。多文本格式的推理策略表现出最佳分布外泛化，而纯文本表示优于视觉表示，这对未来推理模型的设计具有重要启示。

Abstract: Integrating reasoning in large language models and large vision-language models has recently led to significant improvement of their capabilities. However, the generalization of reasoning models is still vaguely defined and poorly understood. In this work, we present an evaluation framework to rigorously examine how well chain-of-thought (CoT) approaches generalize on a simple planning task. Specifically, we consider a grid-based navigation task in which a model is provided with a map and must output a sequence of moves that guides a player from a start position to a goal while avoiding obstacles. The versatility of the task and its data allows us to fine-tune model variants using different input representations (visual and textual) and CoT reasoning strategies, and systematically evaluate them under both in-distribution (ID) and out-of-distribution (OOD) test conditions. Our experiments show that, while CoT reasoning improves in-distribution generalization across all representations, out-of-distribution generalization (e.g., to larger maps) remains very limited in most cases when controlling for trivial matches with the ID data. Surprisingly, we find that reasoning traces which combine multiple text formats yield the best (and non-trivial) OOD generalization. Finally, purely text-based models consistently outperform those utilizing image-based inputs, including a recently proposed approach relying on latent space reasoning.

</details>


### [144] [POP: Prior-fitted Optimizer Policies](https://arxiv.org/abs/2602.15473)
*Jan Kobiolka,Christian Frey,Gresa Shala,Arlind Kadra,Erind Bedalli,Josif Grabocka*

Main category: cs.LG

TL;DR: POP是一种元学习优化器，通过从包含凸和非凸目标的先验分布中学习，预测基于优化轨迹上下文信息的坐标步长，在47个优化函数基准测试中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的优化器对超参数选择高度敏感，在高度非凸设置中性能依赖于精心调整的学习率、动量和梯度累积。需要一种更鲁棒、无需任务特定调优的优化方法。

Method: 提出POP（先验拟合优化器策略），这是一种元学习优化器，从包含凸和非凸目标的合成优化问题先验分布中学习，预测基于优化轨迹上下文信息的坐标步长。

Result: 在包含47个不同复杂度优化函数的基准测试中，POP在相同预算约束下一致优于一阶梯度方法、非凸优化方法（如进化策略）、贝叶斯优化和最近的元学习竞争对手。

Conclusion: POP展示了强大的泛化能力，无需任务特定调优，为优化问题提供了一种更鲁棒和高效的解决方案。

Abstract: Optimization refers to the task of finding extrema of an objective function. Classical gradient-based optimizers are highly sensitive to hyperparameter choices. In highly non-convex settings their performance relies on carefully tuned learning rates, momentum, and gradient accumulation. To address these limitations, we introduce POP (Prior-fitted Optimizer Policies), a meta-learned optimizer that predicts coordinate-wise step sizes conditioned on the contextual information provided in the optimization trajectory. Our model is learned on millions of synthetic optimization problems sampled from a novel prior spanning both convex and non-convex objectives. We evaluate POP on an established benchmark including 47 optimization functions of various complexity, where it consistently outperforms first-order gradient-based methods, non-convex optimization approaches (e.g., evolutionary strategies), Bayesian optimization, and a recent meta-learned competitor under matched budget constraints. Our evaluation demonstrates strong generalization capabilities without task-specific tuning.

</details>


### [145] [Evaluating Federated Learning for Cross-Country Mood Inference from Smartphone Sensing Data](https://arxiv.org/abs/2602.15478)
*Sharmad Kalpande,Saurabh Shirke,Haroon R. Lone*

Main category: cs.LG

TL;DR: FedFAP：一种用于跨国家智能手机情绪推断的特征感知个性化联邦学习框架，在保护隐私的同时处理不同地区的异构传感数据，性能优于集中式方法和现有基线。


<details>
  <summary>Details</summary>
Motivation: 传统情绪评估依赖不频繁的回顾性报告，无法捕捉情绪的连续性。基于智能手机的移动感知虽然能被动推断情绪，但在大规模部署时面临隐私限制、传感可用性不均和行为模式差异等挑战。

Method: 提出FedFAP框架，在跨国家联邦学习设置中处理异构传感模态。每个国家作为独立客户端保留本地数据，通过特征感知个性化方法适应不同地区的行为模式差异。

Result: 在跨地理和文化多样化人群的评估中，FedFAP达到AUROC 0.744，优于集中式方法和现有个性化联邦基线。

Conclusion: FedFAP展示了基于人口感知的个性化和隐私保护学习如何实现可扩展的情绪感知移动感知技术，为情绪感知系统设计提供了重要见解。

Abstract: Mood instability is a key behavioral indicator of mental health, yet traditional assessments rely on infrequent and retrospective reports that fail to capture its continuous nature. Smartphone-based mobile sensing enables passive, in-the-wild mood inference from everyday behaviors; however, deploying such systems at scale remains challenging due to privacy constraints, uneven sensing availability, and substantial variability in behavioral patterns.
  In this work, we study mood inference using smartphone sensing data in a cross-country federated learning setting, where each country participates as an independent client while retaining local data. We introduce FedFAP, a feature-aware personalized federated framework designed to accommodate heterogeneous sensing modalities across regions. Evaluations across geographically and culturally diverse populations show that FedFAP achieves an AUROC of 0.744, outperforming both centralized approaches and existing personalized federated baselines. Beyond inference, our results offer design insights for mood-aware systems, demonstrating how population-aware personalization and privacy-preserving learning can enable scalable and mood-aware mobile sensing technologies.

</details>


### [146] [LLM-as-Judge on a Budget](https://arxiv.org/abs/2602.15481)
*Aadirupa Saha,Aniket Wagde,Branislav Kveton*

Main category: cs.LG

TL;DR: 提出一种基于多臂老虎机和集中不等式的方差自适应方法，用于在固定计算预算下优化LLM评估中的查询分配，以最小化评分估计误差。


<details>
  <summary>Details</summary>
Motivation: 在LLM评估中，由于LLM判断具有随机性，通常需要对每个提示-响应对进行多次查询以获得准确的均值评分。给定固定计算预算B，如何跨K个对最优分配查询以最小化估计误差成为一个关键挑战。

Method: 基于多臂老虎机理论和集中不等式，提出方差自适应方法，根据估计的评分方差动态分配查询，将资源集中在不确定性最高的地方。

Result: 该方法在最坏情况下实现了$\tilde{O}\left(\sqrt{\frac{\sum_{i=1}^K σ_i^2}{B}}\right)$的评分估计误差，其中$σ_i^2$是第i个对的未知评分方差。在Summarize-From-Feedback和HelpSteer2数据集上的实验表明，该方法显著优于均匀分配，在相同预算下减少了最坏情况估计误差。

Conclusion: 该工作为高效LLM评估建立了理论基础，对AI安全、模型对齐和大规模自动评估具有实际意义。

Abstract: LLM-as-a-judge has emerged as a cornerstone technique for evaluating large language models by leveraging LLM reasoning to score prompt-response pairs. Since LLM judgments are stochastic, practitioners commonly query each pair multiple times to estimate mean scores accurately. This raises a critical challenge: given a fixed computational budget $B$, how to optimally allocate queries across $K$ prompt-response pairs to minimize estimation error? %
We present a principled variance-adaptive approach leveraging multi-armed bandit theory and concentration inequalities. Our method dynamically allocates queries based on estimated score variances, concentrating resources where uncertainty is highest. Further, our algorithm is shown to achieve a worst-case score-estimation error of $\tilde{O}\left(\sqrt{\frac{\sum_{i=1}^K σ_i^2}{B}}\right)$, $σ_i^2$ being the unknown score variance for pair $i \in [K]$ with near-optimal budget allocation. %
Experiments on \emph{Summarize-From-Feedback} and \emph{HelpSteer2} demonstrate that our method significantly outperforms uniform allocation, reducing worst-case estimation error while maintaining identical budgets. Our work establishes a theoretical foundation for efficient LLM evaluation with practical implications for AI safety, model alignment, and automated assessment at scale.

</details>


### [147] [ExLipBaB: Exact Lipschitz Constant Computation for Piecewise Linear Neural Networks](https://arxiv.org/abs/2602.15499)
*Tom A. Splittgerber*

Main category: cs.LG

TL;DR: 本文提出了一种名为LipBaB的算法扩展，用于精确计算任意分段线性神经网络在p-范数下的Lipschitz常数，支持ReLU、LeakyReLU、GroupSort、MinMax、FullSort和MaxPool等多种激活函数。


<details>
  <summary>Details</summary>
Motivation: 神经网络Lipschitz常数在鲁棒性保证、正则化和可逆网络构建中具有重要作用。现有精确计算方法仅限于ReLU激活网络，而ReLU在Lipschitz约束网络中具有严重缺陷。需要一种能处理更广泛分段线性激活函数的精确计算方法。

Method: 提出LipBaB算法的泛化版本，能够计算任意分段线性神经网络在p-范数下的精确Lipschitz常数。该方法支持传统激活函数（ReLU、LeakyReLU）以及近年来受关注的GroupSort、MinMax、FullSort等激活函数，还包括MaxPool等其他分段线性函数。

Result: 该方法能够为包含多种分段线性激活函数的神经网络提供精确Lipschitz常数计算，突破了现有方法仅限于ReLU网络的限制，为小模型在敏感数据上的鲁棒性保证和新方法的基准测试提供了精确计算工具。

Conclusion: 通过扩展LipBaB算法，实现了对任意分段线性神经网络Lipschitz常数的精确计算，填补了现有精确计算方法仅支持ReLU网络的空白，为Lipschitz约束网络的研究和应用提供了更强大的分析工具。

Abstract: It has been shown that a neural network's Lipschitz constant can be leveraged to derive robustness guarantees, to improve generalizability via regularization or even to construct invertible networks. Therefore, a number of methods varying in the tightness of their bounds and their computational cost have been developed to approximate the Lipschitz constant for different classes of networks. However, comparatively little research exists on methods for exact computation, which has been shown to be NP-hard. Nonetheless, there are applications where one might readily accept the computational cost of an exact method. These applications could include the benchmarking of new methods or the computation of robustness guarantees for small models on sensitive data. Unfortunately, existing exact algorithms restrict themselves to only ReLU-activated networks, which are known to come with severe downsides in the context of Lipschitz-constrained networks. We therefore propose a generalization of the LipBaB algorithm to compute exact Lipschitz constants for arbitrary piecewise linear neural networks and $p$-norms. With our method, networks may contain traditional activations like ReLU or LeakyReLU, activations like GroupSort or the related MinMax and FullSort, which have been of increasing interest in the context of Lipschitz constrained networks, or even other piecewise linear functions like MaxPool.

</details>


### [148] [Approximation Theory for Lipschitz Continuous Transformers](https://arxiv.org/abs/2602.15503)
*Takashi Furuya,Davide Murari,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: 提出一种梯度下降型上下文Transformer，通过构造保证Lipschitz连续性，在Lipschitz约束函数空间中实现通用逼近，为稳健Transformer架构提供理论基础


<details>
  <summary>Details</summary>
Motivation: Transformer在安全敏感场景中需要稳定性和鲁棒性，约束Lipschitz常数是保证这些特性的原则性方法，但目前缺乏对显式保持Lipschitz连续性的架构的逼近理论保证

Method: 引入梯度下降型上下文Transformer，将MLP和注意力块实现为负梯度流的显式欧拉步，确保固有稳定性而不牺牲表达能力；采用测度论形式化，将Transformer解释为概率测度上的算子

Result: 证明了该类Transformer在Lipschitz约束函数空间中的通用逼近定理，分析结果独立于token数量，为稳健的Lipschitz连续Transformer架构设计提供了严格理论基础

Conclusion: 通过构造保证Lipschitz连续性的梯度下降型Transformer填补了理论空白，为安全敏感应用中的稳健Transformer部署提供了原则性框架

Abstract: Stability and robustness are critical for deploying Transformers in safety-sensitive settings. A principled way to enforce such behavior is to constrain the model's Lipschitz constant. However, approximation-theoretic guarantees for architectures that explicitly preserve Lipschitz continuity have yet to be established. In this work, we bridge this gap by introducing a class of gradient-descent-type in-context Transformers that are Lipschitz-continuous by construction. We realize both MLP and attention blocks as explicit Euler steps of negative gradient flows, ensuring inherent stability without sacrificing expressivity. We prove a universal approximation theorem for this class within a Lipschitz-constrained function space. Crucially, our analysis adopts a measure-theoretic formalism, interpreting Transformers as operators on probability measures, to yield approximation guarantees independent of token count. These results provide a rigorous theoretical foundation for the design of robust, Lipschitz continuous Transformer architectures.

</details>


### [149] [On the Geometric Coherence of Global Aggregation in Federated GNN](https://arxiv.org/abs/2602.15510)
*Chethana Prasad Kabgere,Shylaja SS*

Main category: cs.LG

TL;DR: 提出GGRS框架，解决联邦图神经网络中因客户端图结构异质性导致全局聚合时关系变换几何特性破坏的问题


<details>
  <summary>Details</summary>
Motivation: 在跨域联邦图神经网络中，客户端图具有异构的结构和传播特性。标准的聚合机制应用于这些异构更新时，虽然全局模型可能在数值上收敛，但会表现出退化的关系行为。作者发现全局聚合存在几何失效模式：GNN参数虽然以向量形式数值表示，但编码了关系变换，聚合来自不兼容传播机制的更新会在变换空间中引入破坏性干扰，导致全局消息传递失去一致性，而这种退化不一定反映在传统指标如损失或准确率中。

Method: 提出GGRS（全局几何参考结构），这是一个服务器端框架，基于几何可容许性标准在聚合前调节客户端更新。GGRS保持关系变换的方向一致性，维护可容许传播子空间的多样性，并稳定对邻域交互的敏感性，同时不访问客户端数据或图拓扑。

Result: 在异构的GNN原生数据集和Amazon Co-purchase数据集上的实验表明，GGRS在训练轮次中保持了全局消息传递的一致性，突出了在联邦图学习中几何感知调节的必要性。

Conclusion: 联邦图神经网络中的全局聚合需要考虑关系变换的几何特性，GGRS框架通过几何可容许性标准有效调节客户端更新，保持消息传递的一致性，为联邦图学习提供了几何感知的调节方法。

Abstract: Federated Learning (FL) enables distributed training across multiple clients without centralized data sharing, while Graph Neural Networks (GNNs) model relational data through message passing. In federated GNN settings, client graphs often exhibit heterogeneous structural and propagation characteristics. When standard aggregation mechanisms are applied to such heterogeneous updates, the global model may converge numerically while exhibiting degraded relational behavior.Our work identifies a geometric failure mode of global aggregation in Cross- Domain Federated GNNs. Although GNN parameters are numerically represented as vectors, they encode relational transformations that govern the direction, strength, and sensitivity of information flow across graph neighborhoods. Aggregating updates originating from incompatible propagation regimes can therefore introduce destructive interference in this transformation space.This leads to loss of coherence in global message passing. Importantly, this degradation is not necessarily reflected in conventional metrics such as loss or accuracy.To address this issue, we propose GGRS (Global Geometric Reference Structure), a server-side framework that regulates client updates prior to aggregation based on geometric admissibility criteria. GGRS preserves directional consistency of relational transformations as well as maintains diversity of admissible propagation subspaces. It also stabilizes sensitivity to neighborhood interactions, without accessing client data or graph topology. Experiments on heterogeneous GNN-native, Amazon Co-purchase datasets demonstrate that GGRS preserves global message-passing coherence across training rounds by highlighting the necessity of geometry-aware regulation in federated graph learning.

</details>


### [150] [The Obfuscation Atlas: Mapping Where Honesty Emerges in RLVR with Deception Probes](https://arxiv.org/abs/2602.15515)
*Mohammad Taufeeque,Stefan Heimersheim,Adam Gleave,Chris Cundy*

Main category: cs.LG

TL;DR: 论文研究在对抗白盒欺骗检测器训练中出现的两种混淆策略：混淆激活和混淆策略，并在真实编码环境中验证了这些现象。


<details>
  <summary>Details</summary>
Motivation: 对抗白盒欺骗检测器的训练可能导致模型学会混淆其欺骗行为以逃避检测。先前研究仅在人工环境中研究混淆现象，本研究旨在在真实编码环境中验证混淆现象的出现。

Method: 构建真实的编码环境，其中通过硬编码测试用例自然发生奖励黑客行为。引入对抗欺骗检测器训练可能结果的分类法，并通过实验验证两种混淆策略的出现。

Result: 在真实编码环境中观察到了混淆现象。混淆激活源于强化学习中的表示漂移，而混淆策略则由探测器惩罚激励产生。足够的KL正则化和探测器惩罚可以产生诚实策略。

Conclusion: 白盒欺骗检测器可以作为易受奖励黑客攻击任务的可行训练信号，但需要足够高的KL正则化和探测器惩罚来确保诚实行为。

Abstract: Training against white-box deception detectors has been proposed as a way to make AI systems honest. However, such training risks models learning to obfuscate their deception to evade the detector. Prior work has studied obfuscation only in artificial settings where models were directly rewarded for harmful output. We construct a realistic coding environment where reward hacking via hardcoding test cases naturally occurs, and show that obfuscation emerges in this setting. We introduce a taxonomy of possible outcomes when training against a deception detector. The model either remains honest, or becomes deceptive via two possible obfuscation strategies. (i) Obfuscated activations: the model outputs deceptive text while modifying its internal representations to no longer trigger the detector. (ii) Obfuscated policy: the model outputs deceptive text that evades the detector, typically by including a justification for the reward hack. Empirically, obfuscated activations arise from representation drift during RL, with or without a detector penalty. The probe penalty only incentivizes obfuscated policies; we theoretically show this is expected for policy gradient methods. Sufficiently high KL regularization and detector penalty can yield honest policies, establishing white-box deception detectors as viable training signals for tasks prone to reward hacking.

</details>


### [151] [CEPAE: Conditional Entropy-Penalized Autoencoders for Time Series Counterfactuals](https://arxiv.org/abs/2602.15546)
*Tomàs Garriga,Gerard Sanz,Eduard Serrahima de Cambra,Axel Brando*

Main category: cs.LG

TL;DR: 提出CEPAE方法，通过熵惩罚损失在潜在空间鼓励解耦表示，用于时间序列反事实推理，在合成和真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在金融、医疗、营销等领域，准确进行时间序列反事实推理对于决策制定至关重要，能够理解事件或干预对时间序列结果的影响。本文受工业应用驱动，针对受市场事件影响的时间序列数据开发反事实推理方法。

Method: 基于结构因果模型框架和溯因-行动-预测程序，首先将变分自编码器和对抗自编码器方法适配到时间序列设置。然后提出条件熵惩罚自编码器(CEPAE)，通过在潜在空间使用熵惩罚损失来鼓励解耦的数据表示。

Result: 在合成、半合成和真实世界数据集上进行理论和实验验证，表明CEPAE在评估指标上通常优于其他方法。

Conclusion: CEPAE是一种有效的自编码器方法，适用于时间序列反事实推理，能够处理市场事件影响的时间序列数据，在多种数据集上表现出优越性能。

Abstract: The ability to accurately perform counterfactual inference on time series is crucial for decision-making in fields like finance, healthcare, and marketing, as it allows us to understand the impact of events or treatments on outcomes over time. In this paper, we introduce a new counterfactual inference approach tailored to time series data impacted by market events, which is motivated by an industrial application. Utilizing the abduction-action-prediction procedure and the Structural Causal Model framework, we first adapt methods based on variational autoencoders and adversarial autoencoders, both previously used in counterfactual literature although not in time series settings. Then, we present the Conditional Entropy-Penalized Autoencoder (CEPAE), a novel autoencoder-based approach for counterfactual inference, which employs an entropy penalization loss over the latent space to encourage disentangled data representations. We validate our approach both theoretically and experimentally on synthetic, semi-synthetic, and real-world datasets, showing that CEPAE generally outperforms the other approaches in the evaluated metrics.

</details>


### [152] [1-Bit Wonder: Improving QAT Performance in the Low-Bit Regime through K-Means Quantization](https://arxiv.org/abs/2602.15563)
*Sohir Maskey,Constantin Eichenberg,Johannes Messner,Douglas Orr*

Main category: cs.LG

TL;DR: 本文通过实证研究发现，在低比特量化中，k-means权重量化优于整数格式，且在固定推理内存预算下，1比特权重量化在生成式下游任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 量化感知训练(QAT)能显著减少LLMs内存占用，但实践中量化格式和比特宽度的选择存在挑战。量化设计空间未被充分探索，量化与下游性能的权衡关系不明确，现有评估多依赖困惑度指标。

Method: 进行低比特量化感知训练的实证研究，比较k-means权重量化与整数格式，在标准硬件上实现高效量化，并在固定推理内存预算下评估不同量化配置。

Result: k-means权重量化优于整数格式，可在标准硬件高效实现；在固定推理内存预算下，1比特权重量化在生成式下游任务中表现最佳。

Conclusion: k-means量化是有效的低比特量化方法，1比特权重量化在内存受限的生成任务中具有最佳性能，为实际部署提供了指导。

Abstract: Quantization-aware training (QAT) is an effective method to drastically reduce the memory footprint of LLMs while keeping performance degradation at an acceptable level. However, the optimal choice of quantization format and bit-width presents a challenge in practice. The full design space of quantization is not fully explored in the context of QAT, and the precise trade-off between quantization and downstream performance is poorly understood, as comparisons often rely solely on perplexity-based evaluations. In this work, we address these shortcomings with an empirical study of QAT in the low-bit regime. We show that k-means based weight quantization outperforms integer formats and can be implemented efficiently on standard hardware. Furthermore, we find that, under a fixed inference memory budget, the best performance on generative downstream tasks is achieved with $1$-bit quantized weights.

</details>


### [153] [Accelerated Predictive Coding Networks via Direct Kolen-Pollack Feedback Alignment](https://arxiv.org/abs/2602.15571)
*Davide Casnici,Martin Lefebvre,Justin Dauwels,Charlotte Frenkel*

Main category: cs.LG

TL;DR: 本文提出DKP-PC算法，通过引入可学习的反馈连接直接传输误差信号，解决了传统预测编码中误差传播延迟和指数衰减问题，将时间复杂度从O(L)降至O(1)，实现了更高效的并行学习。


<details>
  <summary>Details</summary>
Motivation: 传统预测编码算法虽然依赖局部更新实现并行学习，但存在两个关键限制：误差信号需要通过多个推理步骤从输出层传播到早期层，且反馈信号在传播过程中呈指数衰减，导致早期层更新消失。

Method: 提出直接Kolen-Pollack预测编码（DKP-PC），结合直接反馈对齐和直接Kolen-Pollack算法，引入从输出层到所有隐藏层的可学习反馈连接，建立误差传输的直接通路。

Result: DKP-PC将误差传播的时间复杂度从O(L)降低到O(1)，消除了深度依赖的延迟。实验结果显示其性能至少与传统PC相当，甚至更优，同时具有更低的延迟和更好的计算性能。

Conclusion: DKP-PC同时解决了反馈延迟和指数衰减问题，提供了更高效、可扩展的预测编码变体，同时保持了更新局部性，为定制硬件高效实现提供了潜力。

Abstract: Predictive coding (PC) is a biologically inspired algorithm for training neural networks that relies only on local updates, allowing parallel learning across layers. However, practical implementations face two key limitations: error signals must still propagate from the output to early layers through multiple inference-phase steps, and feedback decays exponentially during this process, leading to vanishing updates in early layers. We propose direct Kolen-Pollack predictive coding (DKP-PC), which simultaneously addresses both feedback delay and exponential decay, yielding a more efficient and scalable variant of PC while preserving update locality. Leveraging direct feedback alignment and direct Kolen-Pollack algorithms, DKP-PC introduces learnable feedback connections from the output layer to all hidden layers, establishing a direct pathway for error transmission. This yields an algorithm that reduces the theoretical error propagation time complexity from O(L), with L being the network depth, to O(1), removing depth-dependent delay in error signals. Moreover, empirical results demonstrate that DKP-PC achieves performance at least comparable to, and often exceeding, that of standard PC, while offering improved latency and computational performance, supporting its potential for custom hardware-efficient implementations.

</details>


### [154] [Neural Network-Based Parameter Estimation of a Labour Market Agent-Based Model](https://arxiv.org/abs/2602.15572)
*M Lopes Alves,Joel Dyer,Doyne Farmer,Michael Wooldridge,Anisoara Calinescu*

Main category: cs.LG

TL;DR: 该研究评估了一种基于神经网络的模拟推断框架，用于大规模基于代理模型的参数估计，并在劳动力市场ABM上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 基于代理模型（ABM）作为决策支持工具面临参数估计的挑战，特别是在大规模ABM中，由于计算限制难以探索参数空间。

Method: 使用最先进的基于模拟推断（SBI）框架，结合神经网络进行参数估计。将框架应用于基于工作转换网络的劳动力市场ABM，使用合成数据集和真实美国劳动力市场数据，并比较传统统计度量与神经网络学习摘要统计量的效果。

Result: 神经网络方法能够在不同数据集规模下恢复原始参数，评估后验分布，并且相比传统贝叶斯方法提高了效率。

Conclusion: 基于神经网络的SBI框架为大规模ABM的参数估计提供了有效的解决方案，克服了传统方法的计算限制。

Abstract: Agent-based modelling (ABM) is a widespread approach to simulate complex systems. Advancements in computational processing and storage have facilitated the adoption of ABMs across many fields; however, ABMs face challenges that limit their use as decision-support tools. A significant issue is parameter estimation in large-scale ABMs, particularly due to computational constraints on exploring the parameter space. This study evaluates a state-of-the-art simulation-based inference (SBI) framework that uses neural networks (NN) for parameter estimation. This framework is applied to an established labour market ABM based on job transition networks. The ABM is initiated with synthetic datasets and the real U.S. labour market. Next, we compare the effectiveness of summary statistics derived from a list of statistical measures with that learned by an embedded NN. The results demonstrate that the NN-based approach recovers the original parameters when evaluating posterior distributions across various dataset scales and improves efficiency compared to traditional Bayesian methods.

</details>


### [155] [Uniform error bounds for quantized dynamical models](https://arxiv.org/abs/2602.15586)
*Abdelkader Metakalard,Fabien Lauer,Kevin Colin,Marion Gilson*

Main category: cs.LG

TL;DR: 论文为从依赖数据序列学习动态模型的准确性提供统计保证，开发了适用于量化模型和不完美优化算法的统一误差界，通过块分解和间隔点策略获得两种边界族。


<details>
  <summary>Details</summary>
Motivation: 在系统识别（特别是混合系统识别）的实际应用中，通常使用量化模型和不完美的优化算法，但缺乏对这些方法准确性的统计保证。需要建立能够反映硬件约束的统计复杂度度量。

Method: 开发了两种边界族：1）通过块分解获得慢速率边界；2）通过新颖的间隔点策略获得快速率、方差自适应的边界。边界规模与编码模型所需的比特数成正比。

Result: 获得了可应用于量化模型和不完美优化算法的统一误差界，这些边界能够将硬件约束转化为可解释的统计复杂度，为动态模型学习提供统计保证。

Conclusion: 该研究为从依赖数据学习动态模型提供了理论保证，特别是针对实际应用中的量化模型和优化算法，通过将硬件约束与统计复杂度联系起来，增强了系统识别方法的可靠性。

Abstract: This paper provides statistical guarantees on the accuracy of dynamical models learned from dependent data sequences. Specifically, we develop uniform error bounds that apply to quantized models and imperfect optimization algorithms commonly used in practical contexts for system identification, and in particular hybrid system identification. Two families of bounds are obtained: slow-rate bounds via a block decomposition and fast-rate, variance-adaptive, bounds via a novel spaced-point strategy. The bounds scale with the number of bits required to encode the model and thus translate hardware constraints into interpretable statistical complexities.

</details>


### [156] [GLM-5: from Vibe Coding to Agentic Engineering](https://arxiv.org/abs/2602.15763)
*GLM-5 Team,:,Aohan Zeng,Xin Lv,Zhenyu Hou,Zhengxiao Du,Qinkai Zheng,Bin Chen,Da Yin,Chendi Ge,Chengxing Xie,Cunxiang Wang,Gengzheng Pan,Hao Zeng,Haoke Zhang,Haoran Wang,Huilong Chen,Jiajie Zhang,Jian Jiao,Jiaqi Guo,Jingsen Wang,Jingzhao Du,Jinzhu Wu,Kedong Wang,Lei Li,Lin Fan,Lucen Zhong,Mingdao Liu,Mingming Zhao,Pengfan Du,Qian Dong,Rui Lu,Shuang-Li,Shulin Cao,Song Liu,Ting Jiang,Xiaodong Chen,Xiaohan Zhang,Xuancheng Huang,Xuezhen Dong,Yabo Xu,Yao Wei,Yifan An,Yilin Niu,Yitong Zhu,Yuanhao Wen,Yukuo Cen,Yushi Bai,Zhongpei Qiao,Zihan Wang,Zikang Wang,Zilin Zhu,Ziqiang Liu,Zixuan Li,Bojie Wang,Bosi Wen,Can Huang,Changpeng Cai,Chao Yu,Chen Li,Chen Li,Chenghua Huang,Chengwei Hu,Chenhui Zhang,Chenzheng Zhu,Congfeng Yin,Daoyan Lin,Dayong Yang,Di Wang,Ding Ai,Erle Zhu,Fangzhou Yi,Feiyu Chen,Guohong Wen,Hailong Sun,Haisha Zhao,Haiyi Hu,Hanchen Zhang,Hanrui Liu,Hanyu Zhang,Hao Peng,Hao Tai,Haobo Zhang,He Liu,Hongwei Wang,Hongxi Yan,Hongyu Ge,Huan Liu,Huan Liu,Huanpeng Chu,Jia'ni Zhao,Jiachen Wang,Jiajing Zhao,Jiamin Ren,Jiapeng Wang,Jiaxin Zhang,Jiayi Gui,Jiayue Zhao,Jijie Li,Jing An,Jing Li,Jingwei Yuan,Jinhua Du,Jinxin Liu,Junkai Zhi,Junwen Duan,Kaiyue Zhou,Kangjian Wei,Ke Wang,Keyun Luo,Laiqiang Zhang,Leigang Sha,Liang Xu,Lindong Wu,Lintao Ding,Lu Chen,Minghao Li,Nianyi Lin,Pan Ta,Qiang Zou,Rongjun Song,Ruiqi Yang,Shangqing Tu,Shangtong Yang,Shaoxiang Wu,Shengyan Zhang,Shijie Li,Shuang Li,Shuyi Fan,Wei Qin,Wei Tian,Weining Zhang,Wenbo Yu,Wenjie Liang,Xiang Kuang,Xiangmeng Cheng,Xiangyang Li,Xiaoquan Yan,Xiaowei Hu,Xiaoying Ling,Xing Fan,Xingye Xia,Xinyuan Zhang,Xinze Zhang,Xirui Pan,Xunkai Zhang,Yandong Wu,Yanfu Li,Yidong Wang,Yifan Zhu,Yijun Tan,Yilin Zhou,Yiming Pan,Ying Zhang,Yinpei Su,Yipeng Geng,Yipeng Geng,Yong Yan,Yonglin Tan,Yuean Bi,Yuhan Shen,Yuhao Yang,Yujiang Li,Yunan Liu,Yunqing Wang,Yuntao Li,Yurong Wu,Yutao Zhang,Yuxi Duan,Yuxuan Zhang,Zezhen Liu,Zhengtao Jiang,Zhenhe Yan,Zheyu Zhang,Zhixiang Wei,Zhuo Chen,Zhuoer Feng,Zijun Yao,Ziwei Chai,Ziyuan Wang,Zuzhou Zhang,Bin Xu,Minlie Huang,Hongning Wang,Juanzi Li,Yuxiao Dong,Jie Tang*

Main category: cs.LG

TL;DR: GLM-5是一个下一代基础模型，旨在从氛围编码转向代理工程，通过DSA降低训练和推理成本，采用异步强化学习提高后训练效率，在开放基准测试中达到最先进水平，在真实世界编码任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在推动从"氛围编码"范式向"代理工程"范式的转变，解决现有模型在训练成本、推理效率、长上下文保持以及复杂长期交互学习方面的挑战。

Method: 1. 采用DSA技术显著降低训练和推理成本，同时保持长上下文保真度；2. 实现新的异步强化学习基础设施，通过解耦生成和训练提高后训练效率；3. 提出新颖的异步代理RL算法，提高强化学习质量，使模型能更有效地从复杂长期交互中学习。

Result: GLM-5在主要开放基准测试中达到最先进性能，在真实世界编码任务中展现出前所未有的能力，超越了先前基线在处理端到端软件工程挑战方面的表现。

Conclusion: GLM-5通过创新的架构设计、高效的训练方法和先进的强化学习技术，成功实现了从氛围编码到代理工程的范式转变，为复杂软件工程任务提供了强大的基础模型解决方案。

Abstract: We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.

</details>


### [157] [A unified theory of feature learning in RNNs and DNNs](https://arxiv.org/abs/2602.15593)
*Jan P. Bauer,Kirsten Fischer,Moritz Helias,Agostina Palmigiano*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的平均场理论，通过表示核来描述RNN和DNN在特征学习（μP）机制下的差异，揭示了权重共享如何导致RNN在时序任务中产生相关表示和归纳偏置。


<details>
  <summary>Details</summary>
Motivation: RNN和DNN在结构上仅相差权重共享（通过时间展开可见），但功能特性却显著不同。本文旨在理解这种结构相似性与功能差异之间的关系，探究权重共享如何影响网络的功能特性。

Method: 开发了一个统一的平均场理论，使用表示核来描述完全训练的网络在特征学习（μP）机制下的行为。该理论将训练过程视为对序列和模式的贝叶斯推断，直接揭示RNN权重共享的功能含义。

Result: 在DNN典型任务中，发现了一个相变：当学习信号克服权重随机性产生的噪声时，RNN和DNN行为相同；超过该阈值后，只有RNN能在时间步之间发展出相关表示。对于时序任务，RNN的权重共享还诱导了归纳偏置，通过插值无监督时间步来帮助泛化。

Conclusion: 该理论提供了一种将架构结构连接到功能偏置的方法，揭示了RNN权重共享如何导致其在时序任务中的独特功能特性，包括跨时间步的相关表示和更好的泛化能力。

Abstract: Recurrent and deep neural networks (RNNs/DNNs) are cornerstone architectures in machine learning. Remarkably, RNNs differ from DNNs only by weight sharing, as can be shown through unrolling in time. How does this structural similarity fit with the distinct functional properties these networks exhibit? To address this question, we here develop a unified mean-field theory for RNNs and DNNs in terms of representational kernels, describing fully trained networks in the feature learning ($μ$P) regime. This theory casts training as Bayesian inference over sequences and patterns, directly revealing the functional implications induced by the RNNs' weight sharing. In DNN-typical tasks, we identify a phase transition when the learning signal overcomes the noise due to randomness in the weights: below this threshold, RNNs and DNNs behave identically; above it, only RNNs develop correlated representations across timesteps. For sequential tasks, the RNNs' weight sharing furthermore induces an inductive bias that aids generalization by interpolating unsupervised time steps. Overall, our theory offers a way to connect architectural structure to functional biases.

</details>


### [158] [Multi-Objective Coverage via Constraint Active Search](https://arxiv.org/abs/2602.15595)
*Zakaria Shams Siam,Xuefeng Liu,Chong Liu*

Main category: cs.LG

TL;DR: 提出多目标覆盖（MOC）问题，旨在找到能广泛覆盖多目标空间的小规模代表性样本集，并开发了MOC-CAS算法来解决该问题，在蛋白质靶点数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 在药物发现和材料设计等关键应用中，需要快速评估样本集以加速科学发现过程。现有方法要么关注样本空间覆盖，要么专注于帕累托前沿的多目标优化，无法直接解决多目标覆盖问题。

Method: 提出MOC-CAS算法，使用基于置信上界的采集函数，在高斯过程后验预测指导下选择乐观样本。开发平滑松弛的可行性测试和近似优化器以实现高效优化。

Result: 在SARS-CoV-2和癌症的大规模蛋白质靶点数据集上，与竞争基线相比，MOC-CAS在基于SMILES特征的五种目标评估中取得了优越性能。

Conclusion: MOC问题对于加速科学发现至关重要，提出的MOC-CAS算法能有效解决该问题，在真实世界应用中表现出色。

Abstract: In this paper, we formulate the new multi-objective coverage (MOC) problem where our goal is to identify a small set of representative samples whose predicted outcomes broadly cover the feasible multi-objective space. This problem is of great importance in many critical real-world applications, e.g., drug discovery and materials design, as this representative set can be evaluated much faster than the whole feasible set, thus significantly accelerating the scientific discovery process. Existing works cannot be directly applied as they either focus on sample space coverage or multi-objective optimization that targets the Pareto front. However, chemically diverse samples often yield identical objective profiles, and safety constraints are usually defined on the objectives. To solve this MOC problem, we propose a novel search algorithm, MOC-CAS, which employs an upper confidence bound-based acquisition function to select optimistic samples guided by Gaussian process posterior predictions. For enabling efficient optimization, we develop a smoothed relaxation of the hard feasibility test and derive an approximate optimizer. Compared to the competitive baselines, we show that our MOC-CAS empirically achieves superior performances across large-scale protein-target datasets for SARS-CoV-2 and cancer, each assessed on five objectives derived from SMILES-based features.

</details>


### [159] [Certified Per-Instance Unlearning Using Individual Sensitivity Bounds](https://arxiv.org/abs/2602.15602)
*Hanna Benarroch,Jamal Atif,Olivier Cappé*

Main category: cs.LG

TL;DR: 提出一种基于自适应逐实例噪声校准的认证机器遗忘方法，相比传统差分隐私的保守噪声注入，能显著减少性能损失


<details>
  <summary>Details</summary>
Motivation: 传统基于差分隐私的认证机器遗忘方法采用最坏情况敏感度校准噪声，导致性能显著下降，限制了实际应用。需要一种更精细的噪声校准方法，根据每个数据点对学习解的个体贡献来调整噪声

Method: 采用自适应逐实例噪声校准方法，基于逐实例差分隐私定义个体数据点敏感度。针对通过Langevin动力学训练的岭回归，推导高概率的逐实例敏感度边界，实现认证遗忘同时显著减少噪声注入

Result: 理论分析表明该方法能实现认证遗忘且噪声注入大幅减少。在线性设置实验中验证了理论发现，并在深度学习设置中提供了进一步实证证据

Conclusion: 基于逐实例噪声校准的认证机器遗忘方法相比传统差分隐私方法更实用，能在保证形式化遗忘保证的同时显著减少性能损失，为实际应用提供了有前景的解决方案

Abstract: Certified machine unlearning can be achieved via noise injection leading to differential privacy guarantees, where noise is calibrated to worst-case sensitivity. Such conservative calibration often results in performance degradation, limiting practical applicability. In this work, we investigate an alternative approach based on adaptive per-instance noise calibration tailored to the individual contribution of each data point to the learned solution. This raises the following challenge: how can one establish formal unlearning guarantees when the mechanism depends on the specific point to be removed? To define individual data point sensitivities in noisy gradient dynamics, we consider the use of per-instance differential privacy. For ridge regression trained via Langevin dynamics, we derive high-probability per-instance sensitivity bounds, yielding certified unlearning with substantially less noise injection. We corroborate our theoretical findings through experiments in linear settings and provide further empirical evidence on the relevance of the approach in deep learning settings.

</details>


### [160] [Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design](https://arxiv.org/abs/2602.15648)
*Jens U. Kreber,Christian Weißenfels,Joerg Stueckler*

Main category: cs.LG

TL;DR: 提出基于扩散模型的新逆设计方法，将离散设计空间松弛为连续网格表示，通过可微分模拟和引导扩散生成满足目标性能的多样化材料设计。


<details>
  <summary>Details</summary>
Motivation: 逆设计问题在工程和材料科学中常见，但面临两大挑战：1）多个设计参数可能产生相同或相似的输出值，需要多模态概率方法获得多样化解决方案；2）设计空间结构复杂，离散参数或约束限制了基于梯度的优化方法直接应用。

Method: 1）将原始设计空间松弛为连续网格表示，使梯度可通过前向模拟中的隐式微分计算；2）在松弛参数空间上训练扩散模型作为合理设计的先验；3）在推理时使用通过可微分模拟传播的目标函数梯度进行引导扩散采样；4）通过反向投影将样本映射回原始参数空间。

Result: 在复合材料设计问题上验证，前向过程建模为线性FEM问题。方法能够在2D和3D设置中为中高目标体积模量找到相对误差在1%以内的多样化设计。同时通过多目标损失函数成功最小化生成样本的材料密度。

Conclusion: 提出的基于扩散模型的逆设计方法有效解决了离散约束设计空间中的多样化解决方案生成问题，通过松弛表示、可微分模拟和引导扩散实现了高性能材料设计的自动化生成。

Abstract: Inverse design problems are common in engineering and materials science. The forward direction, i.e., computing output quantities from design parameters, typically requires running a numerical simulation, such as a FEM, as an intermediate step, which is an optimization problem by itself. In many scenarios, several design parameters can lead to the same or similar output values. For such cases, multi-modal probabilistic approaches are advantageous to obtain diverse solutions. A major difficulty in inverse design stems from the structure of the design space, since discrete parameters or further constraints disallow the direct use of gradient-based optimization. To tackle this problem, we propose a novel inverse design method based on diffusion models. Our approach relaxes the original design space into a continuous grid representation, where gradients can be computed by implicit differentiation in the forward simulation. A diffusion model is trained on this relaxed parameter space in order to serve as a prior for plausible relaxed designs. Parameters are sampled by guided diffusion using gradients that are propagated from an objective function specified at inference time through the differentiable simulation. A design sample is obtained by backprojection into the original parameter space. We develop our approach for a composite material design problem where the forward process is modeled as a linear FEM problem. We evaluate the performance of our approach in finding designs that match a specified bulk modulus. We demonstrate that our method can propose diverse designs within 1% relative error margin from medium to high target bulk moduli in 2D and 3D settings. We also demonstrate that the material density of generated samples can be minimized simultaneously by using a multi-objective loss function.

</details>


### [161] [Symbolic recovery of PDEs from measurement data](https://arxiv.org/abs/2602.15603)
*Erion Morina,Philipp Scholl,Martin Holler*

Main category: cs.LG

TL;DR: 该论文提出使用基于有理函数的神经网络架构进行偏微分方程模型的符号表示，证明了在无噪声完整测量条件下可唯一重建最简单的物理定律，并通过ParFam架构进行了实证验证。


<details>
  <summary>Details</summary>
Motivation: 偏微分方程模型在自然科学中描述复杂关系很强大，但传统方法通常难以获得符号表达式，阻碍了可解释性。需要专门的方法从间接噪声测量中重建可解释的物理定律。

Method: 采用基于有理函数的神经网络架构进行物理定律的符号表示，利用有理函数的逼近能力和算术运算的灵活性。通过可识别性理论分析，证明在无噪声完整测量下能唯一重建最简单的物理定律。

Result: 理论证明：在无噪声完整测量极限下，符号网络能唯一重建PDE模型中最简单的物理定律；重建的定律保持在符号网络架构内表达；L1正则化促进可解释性和稀疏性；提供了符号网络的规律性结果。

Conclusion: 基于有理函数的符号神经网络能够从测量数据中重建可解释的物理定律，理论可识别性结果得到ParFam架构的实证支持，为物理定律的符号重建提供了实用方法。

Abstract: Models based on partial differential equations (PDEs) are powerful for describing a wide range of complex relationships in the natural sciences. Accurately identifying the PDE model, which represents the underlying physical law, is essential for a proper understanding of the problem. This reconstruction typically relies on indirect and noisy measurements of the system's state and, without specifically tailored methods, rarely yields symbolic expressions, thereby hindering interpretability. In this work, we address this issue by considering existing neural network architectures based on rational functions for the symbolic representation of physical laws. These networks leverage the approximation power of rational functions while also benefiting from their flexibility in representing arithmetic operations. Our main contribution is an identifiability result, showing that, in the limit of noiseless, complete measurements, such symbolic networks can uniquely reconstruct the simplest physical law within the PDE model. Specifically, reconstructed laws remain expressible within the symbolic network architecture, with regularization-minimizing parameterizations promoting interpretability and sparsity in case of $L^1$-regularization. In addition, we provide regularity results for symbolic networks. Empirical validation using the ParFam architecture supports these theoretical findings, providing evidence for the practical reconstructibility of physical laws.

</details>


### [162] [DNN-Enabled Multi-User Beamforming for Throughput Maximization under Adjustable Fairness](https://arxiv.org/abs/2602.15617)
*Kaifeng Lu,Markus Rupp,Stefan Schwarz*

Main category: cs.LG

TL;DR: 提出基于无线变压器架构的优化无监督学习方法，通过拉格朗日乘子自动更新机制，在保证规定公平性的同时最大化总速率，实现帕累托前沿上的可控权衡。


<details>
  <summary>Details</summary>
Motivation: 无线通信中的用户公平性保障是一个基本挑战，平衡公平性与总速率之间的权衡会导致非凸、多目标优化问题，其复杂度随网络规模增长而增加。

Method: 提出基于无线变压器架构的优化无监督学习方法，从信道状态信息特征中学习。通过拉格朗日乘子将总速率和公平性目标结合，并通过双上升算法自动更新乘子，实现可控的公平性约束同时最大化总速率。

Result: 该方法能够在规定的公平性要求下灵活管理权衡优化，有效实现了两个冲突目标之间帕累托前沿上的轨迹。

Conclusion: 所提出的方法为在规定的公平性约束下管理权衡优化提供了一个灵活的解决方案，有效缓解了公平性与总速率之间的冲突。

Abstract: Ensuring user fairness in wireless communications is a fundamental challenge, as balancing the trade-off between fairness and sum rate leads to a non-convex, multi-objective optimization whose complexity grows with network scale. To alleviate this conflict, we propose an optimization-based unsupervised learning approach based on the wireless transformer (WiT) architecture that learns from channel state information (CSI) features. We reformulate the trade-off by combining the sum rate and fairness objectives through a Lagrangian multiplier, which is updated automatically via a dual-ascent algorithm. This mechanism allows for a controllable fairness constraint while simultaneously maximizing the sum rate, effectively realizing a trace on the Pareto front between two conflicting objectives. Our findings show that the proposed approach offers a flexible solution for managing the trade-off optimization under prescribed fairness.

</details>


### [163] [Beyond ReLU: Bifurcation, Oversmoothing, and Topological Priors](https://arxiv.org/abs/2602.15634)
*Erkan Turan,Gaspard Abel,Maysam Behmanesh,Emery Pierson,Maks Ovsjanikov*

Main category: cs.LG

TL;DR: 论文从分岔理论视角重新定义GNN过平滑问题，提出通过替换激活函数打破同质稳定状态，理论预测并实验验证了新模式的出现和抗过平滑能力。


<details>
  <summary>Details</summary>
Motivation: 深度图神经网络存在过平滑问题，节点特征收敛到同质、无信息状态。现有研究缺乏对这一现象的理论理解，需要从动力学系统角度重新审视过平滑的本质。

Method: 采用分岔理论框架，将过平滑重新定义为收敛到稳定"同质固定点"。通过李雅普诺夫-施密特约化，理论证明用特定函数类替换单调激活函数可诱导分岔，破坏同质状态的稳定性，产生稳定的非同质模式。

Result: 理论预测了新模式振幅的非平凡标度律，实验定量验证了该预测。推导出闭式分岔感知初始化方法，在真实基准实验中展示了实用价值。

Conclusion: 从分岔理论视角为GNN过平滑问题提供了新的理论框架，通过激活函数替换有效打破同质稳定状态，理论预测与实验一致，为深度GNN设计提供了新思路。

Abstract: Graph Neural Networks (GNNs) learn node representations through iterative network-based message-passing. While powerful, deep GNNs suffer from oversmoothing, where node features converge to a homogeneous, non-informative state. We re-frame this problem of representational collapse from a \emph{bifurcation theory} perspective, characterizing oversmoothing as convergence to a stable ``homogeneous fixed point.'' Our central contribution is the theoretical discovery that this undesired stability can be broken by replacing standard monotone activations (e.g., ReLU) with a class of functions. Using Lyapunov-Schmidt reduction, we analytically prove that this substitution induces a bifurcation that destabilizes the homogeneous state and creates a new pair of stable, non-homogeneous \emph{patterns} that provably resist oversmoothing. Our theory predicts a precise, nontrivial scaling law for the amplitude of these emergent patterns, which we quantitatively validate in experiments. Finally, we demonstrate the practical utility of our theory by deriving a closed-form, bifurcation-aware initialization and showing its utility in real benchmark experiments.

</details>


### [164] [The Stationarity Bias: Stratified Stress-Testing for Time-Series Imputation in Regulated Dynamical Systems](https://arxiv.org/abs/2602.15637)
*Amirreza Dolatpour Fathkouhi,Alireza Namazi,Heman Shakeri*

Main category: cs.LG

TL;DR: 论文揭示时间序列插补基准存在"平稳性偏差"问题，提出分层压力测试方法，在血糖监测数据上验证了线性方法在平稳区间有效但在关键瞬态表现差，而深度学习模型能保持形态完整性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列插补基准使用均匀随机掩码和形状无关的评估指标（如MSE、RMSE），在具有主导吸引子的系统中（如稳态生理、工业运行、网络流量）会产生系统性"平稳性偏差"——简单方法看似优越，因为基准主要采样容易的低熵平稳区间。

Method: 提出"分层压力测试"方法，将评估划分为平稳和瞬态两种机制；使用连续血糖监测数据作为测试平台，利用其精确的机制识别能力；从临床试验中推导经验缺失分布并应用于完整训练数据。

Result: 发现：(1)线性插值在平稳区间达到最优重建；(2)在关键瞬态期间，线性方法的形态保真度显著下降，出现"RMSE幻象"；(3)深度学习模型在瞬态期间能保持点准确性和形态完整性。

Conclusion: 该框架适用于任何常规平稳性主导关键瞬态的受调节系统，强调需要机制条件模型选择，深度学习模型对于安全关键的下游任务至关重要。

Abstract: Time-series imputation benchmarks employ uniform random masking and shape-agnostic metrics (MSE, RMSE), implicitly weighting evaluation by regime prevalence. In systems with a dominant attractor -- homeostatic physiology, nominal industrial operation, stable network traffic -- this creates a systematic \emph{Stationarity Bias}: simple methods appear superior because the benchmark predominantly samples the easy, low-entropy regime where they trivially succeed. We formalize this bias and propose a \emph{Stratified Stress-Test} that partitions evaluation into Stationary and Transient regimes. Using Continuous Glucose Monitoring (CGM) as a testbed -- chosen for its rigorous ground-truth forcing functions (meals, insulin) that enable precise regime identification -- we establish three findings with broad implications:(i)~Stationary Efficiency: Linear interpolation achieves state-of-the-art reconstruction during stable intervals, confirming that complex architectures are computationally wasteful in low-entropy regimes.(ii)~Transient Fidelity: During critical transients (post-prandial peaks, hypoglycemic events), linear methods exhibit drastically degraded morphological fidelity (DTW), disproportionate to their RMSE -- a phenomenon we term the \emph{RMSE Mirage}, where low pointwise error masks the destruction of signal shape.(iii)~Regime-Conditional Model Selection: Deep learning models preserve both pointwise accuracy and morphological integrity during transients, making them essential for safety-critical downstream tasks. We further derive empirical missingness distributions from clinical trials and impose them on complete training data, preventing models from exploiting unrealistically clean observations and encouraging robustness under real-world missingness. This framework generalizes to any regulated system where routine stationarity dominates critical transients.

</details>


### [165] [Continuous-Time Piecewise-Linear Recurrent Neural Networks](https://arxiv.org/abs/2602.15649)
*Alena Brändle,Lukas Eisenmann,Florian Götz,Daniel Durstewitz*

Main category: cs.LG

TL;DR: 提出连续时间分段线性循环神经网络(cPLRNN)，解决传统离散时间PLRNN与物理生物过程连续时间特性不匹配的问题，同时保持数学可分析性


<details>
  <summary>Details</summary>
Motivation: 现有PLRNN都是离散时间模型，与大多数物理生物过程的连续时间本质不符，且难以处理不规则时间间隔数据。神经ODE虽能解决连续时间问题，但在动态系统重建性能和可分析性上不如PLRNN

Method: 开发连续时间PLRNN(cPLRNN)理论，提出新的训练和模拟算法，通过利用分段线性结构绕过数值积分，并展示如何半解析地确定平衡点、极限环等重要拓扑对象

Result: 在动态系统重建基准测试中，cPLRNN既优于离散时间PLRNN，也优于神经ODE，包括具有硬阈值不连续性的系统

Conclusion: cPLRNN结合了连续时间建模的优势和PLRNN的数学可分析性，为科学和医学领域提供了既准确又可解释的动态系统重建工具

Abstract: In dynamical systems reconstruction (DSR) we aim to recover the dynamical system (DS) underlying observed time series. Specifically, we aim to learn a generative surrogate model which approximates the underlying, data-generating DS, and recreates its long-term properties (`climate statistics'). In scientific and medical areas, in particular, these models need to be mechanistically tractable -- through their mathematical analysis we would like to obtain insight into the recovered system's workings. Piecewise-linear (PL), ReLU-based RNNs (PLRNNs) have a strong track-record in this regard, representing SOTA DSR models while allowing mathematical insight by virtue of their PL design. However, all current PLRNN variants are discrete-time maps. This is in disaccord with the assumed continuous-time nature of most physical and biological processes, and makes it hard to accommodate data arriving at irregular temporal intervals. Neural ODEs are one solution, but they do not reach the DSR performance of PLRNNs and often lack their tractability. Here we develop theory for continuous-time PLRNNs (cPLRNNs): We present a novel algorithm for training and simulating such models, bypassing numerical integration by efficiently exploiting their PL structure. We further demonstrate how important topological objects like equilibria or limit cycles can be determined semi-analytically in trained models. We compare cPLRNNs to both their discrete-time cousins as well as Neural ODEs on DSR benchmarks, including systems with discontinuities which come with hard thresholds.

</details>


### [166] [Relative Geometry of Neural Forecasters: Linking Accuracy and Alignment in Learned Latent Geometry](https://arxiv.org/abs/2602.15676)
*Deniz Kucukahmetler,Maximilian Jean Hemmann,Julian Mosig von Aehrenfeld,Maximilian Amthor,Christian Deubel,Nico Scherf,Diaaeldin Taha*

Main category: cs.LG

TL;DR: 论文通过引入锚点相对嵌入方法，研究不同神经网络在预测复杂动力系统时内部表示的对齐性，发现模型家族间存在可复现的结构模式。


<details>
  <summary>Details</summary>
Motivation: 神经网络能准确预测复杂动力系统，但其内部如何表示潜在几何结构仍不清楚。需要理解不同模型家族如何内部化并表示动力结构。

Method: 引入基于锚点的几何无关相对嵌入方法，消除潜在空间中的旋转和缩放歧义。在七个典型动力系统（从周期性到混沌）上应用此框架，分析多层感知机、循环网络、变换器和回声状态网络等模型。

Result: 发现可复现的家族级结构：多层感知机与MLPs对齐，循环网络与RNNs对齐，而变换器和回声状态网络虽然预测能力强但对齐性较弱。对齐性通常与预测准确性相关，但高准确性可与低对齐性共存。

Conclusion: 相对几何为比较不同模型家族如何内部化并表示动力结构提供了简单、可复现的基础框架，揭示了模型内部表示的系统性模式。

Abstract: Neural networks can accurately forecast complex dynamical systems, yet how they internally represent underlying latent geometry remains poorly understood. We study neural forecasters through the lens of representational alignment, introducing anchor-based, geometry-agnostic relative embeddings that remove rotational and scaling ambiguities in latent spaces. Applying this framework across seven canonical dynamical systems - ranging from periodic to chaotic - we reveal reproducible family-level structure: multilayer perceptrons align with other MLPs, recurrent networks with RNNs, while transformers and echo-state networks achieve strong forecasts despite weaker alignment. Alignment generally correlates with forecasting accuracy, yet high accuracy can coexist with low alignment. Relative geometry thus provides a simple, reproducible foundation for comparing how model families internalize and represent dynamical structure.

</details>


### [167] [CAMEL: An ECG Language Model for Forecasting Cardiac Events](https://arxiv.org/abs/2602.15677)
*Neelay Velingker,Alaia Solko-Breslin,Mayank Keoliya,Seewon Choi,Jiayi Xin,Anika Marathe,Alireza Oraii,Rajat Deo,Sameed Khatana,Rajeev Alur,Mayur Naik,Eric Wong*

Main category: cs.LG

TL;DR: CAMEL是首个能够进行心电图长期信号推理和未来心脏事件预测的心电图语言模型，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前的心电图语言模型虽然能进行分类和报告生成，但无法预测未来心脏事件，而这对早期干预规划具有重要临床价值。

Method: 提出专门的心电图编码器实现心电图与文本的跨模态理解，采用LoRA适应和课程学习管道训练，包括分类、指标计算和多轮对话推理。

Result: 在6个任务9个数据集上展示强大的零样本性能，在ECGBench上获得+7.0%绝对平均增益，在ECGForecastBench上比全监督模型高+12.4%，比零样本ELMs高+21.1%。

Conclusion: CAMEL是首个具备心电图长期信号推理和预测能力的心电图语言模型，在分布内和分布外都达到或超越现有方法，为心脏事件预测提供了新框架。

Abstract: Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address this gap, we propose CAMEL, the first ELM that is capable of inference over longer signal durations which enables its forecasting capability. Our key insight is a specialized ECG encoder which enables cross-understanding of ECG signals with text. We train CAMEL using established LLM training procedures, combining LoRA adaptation with a curriculum learning pipeline. Our curriculum includes ECG classification, metrics calculations, and multi-turn conversations to elicit reasoning. CAMEL demonstrates strong zero-shot performance across 6 tasks and 9 datasets, including ECGForecastBench, a new benchmark that we introduce for forecasting arrhythmias. CAMEL is on par with or surpasses ELMs and fully supervised baselines both in- and out-of-distribution, achieving SOTA results on ECGBench (+7.0% absolute average gain) as well as ECGForecastBench (+12.4% over fully supervised models and +21.1% over zero-shot ELMs).

</details>


### [168] [Controlled oscillation modeling using port-Hamiltonian neural networks](https://arxiv.org/abs/2602.15704)
*Maximino Linares,Guillaume Doras,Thomas Hélie*

Main category: cs.LG

TL;DR: 本文提出在端口哈密顿神经网络中使用二阶离散梯度方法学习动力系统，相比传统龙格-库塔方法表现更优，并在三个不同动态行为的系统中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 纯数据驱动方法学习动力系统难以捕捉守恒定律，现有端口哈密顿神经网络方法虽基于功率平衡原理，但通常不考虑功率保持离散化，且依赖龙格-库塔数值方法。

Method: 在端口哈密顿神经网络学习动力系统时嵌入二阶离散梯度方法，该方法能保持功率守恒特性，并在三个不同动态行为的系统中进行验证：二次能量存储的谐振子、非二次哈密顿的Duffing振子、以及具有非线性耗散的自持振子。

Result: 实验表明，二阶离散梯度方法在性能上优于同阶龙格-库塔方法。同时比较了两种理论上等价的端口哈密顿系统表述，并分析了训练中正则化端口哈密顿神经网络雅可比矩阵的影响。

Conclusion: 在端口哈密顿神经网络中采用离散梯度方法能更好地保持系统的物理守恒特性，提高学习精度和泛化能力，为动力系统建模提供了更有效的数值离散化方案。

Abstract: Learning dynamical systems through purely data-driven methods is challenging as they do not learn the underlying conservation laws that enable them to correctly generalize. Existing port-Hamiltonian neural network methods have recently been successfully applied for modeling mechanical systems. However, even though these methods are designed on power-balance principles, they usually do not consider power-preserving discretizations and often rely on Runge-Kutta numerical methods. In this work, we propose to use a second-order discrete gradient method embedded in the learning of dynamical systems with port-Hamiltonian neural networks. Numerical results are provided for three systems deliberately selected to span different ranges of dynamical behavior under control: a baseline harmonic oscillator with quadratic energy storage; a Duffing oscillator, with a non-quadratic Hamiltonian offering amplitude-dependent effects; and a self-sustained oscillator, which can stabilize in a controlled limit cycle through the incorporation of a nonlinear dissipation. We show how the use of this discrete gradient method outperforms the performance of a Runge-Kutta method of the same order. Experiments are also carried out to compare two theoretically equivalent port-Hamiltonian systems formulations and to analyze the impact of regularizing the Jacobian of port-Hamiltonian neural networks during training.

</details>


### [169] [Random Wavelet Features for Graph Kernel Machines](https://arxiv.org/abs/2602.15711)
*Valentin de Bassompierre,Jean-Charles Delvenne,Laurent Jacques*

Main category: cs.LG

TL;DR: 该论文提出了一种基于随机特征方法的随机谱节点嵌入技术，用于高效近似图核，在保持结构信息的同时实现可扩展的图表示学习。


<details>
  <summary>Details</summary>
Motivation: 图核提供了定义节点相似度的原则性方法，但直接计算在大规模网络上往往不可行。需要设计能够有效近似图核的可扩展节点嵌入方法。

Method: 受欧几里得空间中核近似的随机特征方法启发，提出了随机谱节点嵌入技术，通过随机谱构造来估计特定图核的低秩近似。

Result: 理论和实证结果表明，该方法比现有方法实现了更准确的核近似，特别是在谱局部化核方面表现更优。

Conclusion: 随机谱构造为可扩展且原则性的图表示学习提供了有效方法，能够高效近似图核并保持结构信息。

Abstract: Node embeddings map graph vertices into low-dimensional Euclidean spaces while preserving structural information. They are central to tasks such as node classification, link prediction, and signal reconstruction. A key goal is to design node embeddings whose dot products capture meaningful notions of node similarity induced by the graph. Graph kernels offer a principled way to define such similarities, but their direct computation is often prohibitive for large networks. Inspired by random feature methods for kernel approximation in Euclidean spaces, we introduce randomized spectral node embeddings whose dot products estimate a low-rank approximation of any specific graph kernel. We provide theoretical and empirical results showing that our embeddings achieve more accurate kernel approximations than existing methods, particularly for spectrally localized kernels. These results demonstrate the effectiveness of randomized spectral constructions for scalable and principled graph representation learning.

</details>


### [170] [MRC-GAT: A Meta-Relational Copula-Based Graph Attention Network for Interpretable Multimodal Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2602.15740)
*Fatemeh Khalvandi,Saadat Izadi,Abdolah Chalechale*

Main category: cs.LG

TL;DR: 提出MRC-GAT模型用于阿尔茨海默病分类，通过copula相似性对齐、关系注意力和节点融合实现多模态特征整合，在TADPOLE和NACC数据集上分别达到96.87%和92.31%的准确率。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病需要早期精确诊断，现有图基方法依赖固定结构设计，限制了灵活性和对异质患者数据的泛化能力。

Method: 提出Meta-Relational Copula-Based Graph Attention Network (MRC-GAT)，整合copula相似性对齐、关系注意力和节点融合作为元学习核心组件，将风险因素、认知测试分数和MRI等多模态特征在共同统计空间对齐后通过多关系注意力机制结合。

Result: 在TADPOLE和NACC数据集上分别达到96.87%和92.31%的准确率，优于现有诊断模型，并在疾病诊断各阶段提供可解释性。

Conclusion: MRC-GAT模型通过灵活的图结构设计和多模态特征整合，在阿尔茨海默病分类中表现出优越性能、鲁棒性和可解释性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative condition necessitating early and precise diagnosis to provide prompt clinical management. Given the paramount importance of early diagnosis, recent studies have increasingly focused on computer-aided diagnostic models to enhance precision and reliability. However, most graph-based approaches still rely on fixed structural designs, which restrict their flexibility and limit generalization across heterogeneous patient data. To overcome these limitations, the Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) is proposed as an efficient multimodal model for AD classification tasks. The proposed architecture, copula-based similarity alignment, relational attention, and node fusion are integrated as the core components of episodic meta-learning, such that the multimodal features, including risk factors (RF), Cognitive test scores, and MRI attributes, are first aligned via a copula-based transformation in a common statistical space and then combined by a multi-relational attention mechanism. According to evaluations performed on the TADPOLE and NACC datasets, the MRC-GAT model achieved accuracies of 96.87% and 92.31%, respectively, demonstrating state-of-the-art performance compared to existing diagnostic models. Finally, the proposed model confirms the robustness and applicability of the proposed method by providing interpretability at various stages of disease diagnosis.

</details>


### [171] [UrbanVerse: Learning Urban Region Representation Across Cities and Tasks](https://arxiv.org/abs/2602.15750)
*Fengze Sun,Egemen Tanin,Shanika Karunasekera,Zuqing Li,Flora D. Salim,Jianzhong Qi*

Main category: cs.LG

TL;DR: UrbanVerse：一个用于跨城市表示学习和跨任务分析的城市基础模型，通过图结构随机游走和条件扩散模块实现泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有城市区域表示学习方法在跨城市和跨任务泛化能力上有限，需要构建一个类似基础模型的城市分析框架

Method: 1) 将区域建模为图节点，通过随机游走形成"区域序列"来捕捉局部和邻域结构特征；2) 提出HCondDiffCT模块，将区域条件先验知识和任务条件语义集成到扩散过程中，联合建模多个下游预测任务

Result: 在真实世界数据集上，UrbanVerse在跨城市设置的六个任务中持续优于最先进方法，预测准确率提升高达35.89%

Conclusion: UrbanVerse成功实现了跨城市表示学习和跨任务分析，为城市分析提供了一个基础模型框架，其HCondDiffCT模块也可增强现有模型的性能

Abstract: Recent advances in urban region representation learning have enabled a wide range of applications in urban analytics, yet existing methods remain limited in their capabilities to generalize across cities and analytic tasks. We aim to generalize urban representation learning beyond city- and task-specific settings, towards a foundation-style model for urban analytics. To this end, we propose UrbanVerse, a model for cross-city urban representation learning and cross-task urban analytics. For cross-city generalization, UrbanVerse focuses on features local to the target regions and structural features of the nearby regions rather than the entire city. We model regions as nodes on a graph, which enables a random walk-based procedure to form "sequences of regions" that reflect both local and neighborhood structural features for urban region representation learning. For cross-task generalization, we propose a cross-task learning module named HCondDiffCT. This module integrates region-conditioned prior knowledge and task-conditioned semantics into the diffusion process to jointly model multiple downstream urban prediction tasks. HCondDiffCT is generic. It can also be integrated with existing urban representation learning models to enhance their downstream task effectiveness. Experiments on real-world datasets show that UrbanVerse consistently outperforms state-of-the-art methods across six tasks under cross-city settings, achieving up to 35.89% improvements in prediction accuracy.

</details>


### [172] [Beyond Match Maximization and Fairness: Retention-Optimized Two-Sided Matching](https://arxiv.org/abs/2602.15752)
*Ren Kishimoto,Rikiya Takehi,Koichi Tanaka,Masahiro Nomura,Riku Togashi,Yoji Tomita,Yuta Saito*

Main category: cs.LG

TL;DR: 提出MRet算法，通过动态学习个性化留存曲线来最大化双边匹配平台的用户留存率，而非传统方法只关注匹配数量或公平性。


<details>
  <summary>Details</summary>
Motivation: 传统双边匹配平台（如在线约会、招聘）通常以最大化匹配数量为目标，但这会导致用户匹配分布不均：部分用户获得过多匹配，而许多用户获得极少匹配最终流失。虽然公平性目标可以缓解此问题，但公平性本身并非平台的终极目标，用户不会仅仅因为曝光均等就奖励平台。在实际中，用户留存往往是平台的最终目标，单纯依赖公平性无法有效优化留存。

Method: 提出MRet（Matching for Retention）动态学习排序算法。该方法通过学习每个用户的个性化留存曲线（基于用户资料和交互历史），动态调整推荐策略。MRet联合考虑推荐接收方和被推荐方的留存收益，将有限的匹配机会分配到最能提升整体留存的地方。

Result: 在合成数据集和来自主要在线约会平台的真实数据集上的实证评估表明，MRet实现了更高的用户留存率，因为传统方法只优化匹配数量或公平性，而非留存。

Conclusion: MRet算法通过直接优化用户留存而非匹配数量或公平性，为双边匹配平台提供了一种更有效的用户保留策略，解决了传统方法导致的用户流失问题。

Abstract: On two-sided matching platforms such as online dating and recruiting, recommendation algorithms often aim to maximize the total number of matches. However, this objective creates an imbalance, where some users receive far too many matches while many others receive very few and eventually abandon the platform. Retaining users is crucial for many platforms, such as those that depend heavily on subscriptions. Some may use fairness objectives to solve the problem of match maximization. However, fairness in itself is not the ultimate objective for many platforms, as users do not suddenly reward the platform simply because exposure is equalized. In practice, where user retention is often the ultimate goal, casually relying on fairness will leave the optimization of retention up to luck.
  In this work, instead of maximizing matches or axiomatically defining fairness, we formally define the new problem setting of maximizing user retention in two-sided matching platforms. To this end, we introduce a dynamic learning-to-rank (LTR) algorithm called Matching for Retention (MRet). Unlike conventional algorithms for two-sided matching, our approach models user retention by learning personalized retention curves from each user's profile and interaction history. Based on these curves, MRet dynamically adapts recommendations by jointly considering the retention gains of both the user receiving recommendations and those who are being recommended, so that limited matching opportunities can be allocated where they most improve overall retention. Naturally but importantly, empirical evaluations on synthetic and real-world datasets from a major online dating platform show that MRet achieves higher user retention, since conventional methods optimize matches or fairness rather than retention.

</details>


### [173] [The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety](https://arxiv.org/abs/2602.15799)
*Max Springer,Chung Peng Lee,Blossom Metevier,Jane Castleman,Bohdan Turbal,Hayoung Jung,Zeyu Shen,Aleksandra Korolova*

Main category: cs.LG

TL;DR: 微调对齐的语言模型即使在良性任务上也会不可预测地破坏安全防护，这是由于对齐几何的低维子空间具有尖锐曲率，导致梯度下降的二阶加速效应将优化轨迹推入安全敏感区域。


<details>
  <summary>Details</summary>
Motivation: 当前的安全微调方法存在结构性盲点：即使训练数据无害且开发者无恶意意图，微调对齐模型仍会破坏安全护栏。主流解释认为微调更新在高维参数空间中应与安全关键方向正交，但这种正交性在梯度下降动态下是结构不稳定的。

Method: 通过新颖的几何分析，证明对齐集中在具有尖锐曲率的低维子空间中，创建了梯度下降无法检测或防御的脆弱结构。提出"对齐不稳定性条件"——三个几何特性共同满足时会导致安全退化。建立了四次方缩放定律：对齐损失随训练时间的四次方增长。

Result: 揭示了安全退化的根本机制：初始微调更新可能避开对齐子空间，但微调损失的曲率产生二阶加速，系统性地将轨迹引导到对齐敏感区域。对齐脆弱性不是可修补的错误，而是曲流形上梯度下降的内在几何特性。

Conclusion: 当前安全范式存在结构性盲点，主流安全微调方法只解决了基本动态问题的初始快照。需要开发曲率感知方法，推动对齐安全分析从反应式红队测试转向预测性诊断，以支持开放权重模型部署。

Abstract: Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical directions in high-dimensional parameter space, offers false reassurance: we show this orthogonality is structurally unstable and collapses under the dynamics of gradient descent. We then resolve this through a novel geometric analysis, proving that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure that first-order methods cannot detect or defend. While initial fine-tuning updates may indeed avoid these subspaces, the curvature of the fine-tuning loss generates second-order acceleration that systematically steers trajectories into alignment-sensitive regions. We formalize this mechanism through the Alignment Instability Condition, three geometric properties that, when jointly satisfied, lead to safety degradation. Our main result establishes a quartic scaling law: alignment loss grows with the fourth power of training time, governed by the sharpness of alignment geometry and the strength of curvature coupling between the fine-tuning task and safety-critical parameters. These results expose a structural blind spot in the current safety paradigm. The dominant approaches to safe fine-tuning address only the initial snapshot of a fundamentally dynamic problem. Alignment fragility is not a bug to be patched; it is an intrinsic geometric property of gradient descent on curved manifolds. Our results motivate the development of curvature-aware methods, and we hope will further enable a shift in alignment safety analysis from reactive red-teaming to predictive diagnostics for open-weight model deployment.

</details>


### [174] [Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning](https://arxiv.org/abs/2602.15817)
*Oswin So,Eric Yang Yu,Songyuan Zhang,Matthew Cleaveland,Mitchell Black,Chuchu Fan*

Main category: cs.LG

TL;DR: 提出可行性引导探索(FGE)方法，解决强化学习在可达性问题中的不匹配问题，同时识别可行初始条件子集并学习安全策略


<details>
  <summary>Details</summary>
Motivation: 传统强化学习优化期望回报与可达性问题最大化安全状态集之间存在根本性不匹配，导致策略在低概率但安全的状态上表现不佳

Method: 提出可行性引导探索(FGE)，同时识别存在安全策略的可行初始条件子集，并学习在该初始条件集上解决可达性问题的策略

Result: 在MuJoCo和Kinetix模拟器的像素观测任务中，FGE学习的策略比现有最佳方法覆盖范围提高50%以上

Conclusion: FGE有效解决了强化学习与可达性问题的不匹配，通过同时探索可行性和学习策略，显著提高了安全策略的覆盖范围

Abstract: Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. We propose Feasibility-Guided Exploration (FGE), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. Empirical results demonstrate that FGE learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the MuJoCo simulator and the Kinetix simulator with pixel observations.

</details>


### [175] [Stabilizing Test-Time Adaptation of High-Dimensional Simulation Surrogates via D-Optimal Statistics](https://arxiv.org/abs/2602.15820)
*Anna Zimmel,Paul Setinek,Gianluca Galletti,Johannes Brandstetter,Werner Zellinger*

Main category: cs.LG

TL;DR: 提出基于D-最优统计量的测试时适应框架，用于解决机器学习代理模型在工程仿真中的分布偏移问题，显著提升高维回归任务的性能


<details>
  <summary>Details</summary>
Motivation: 机器学习代理模型在工程仿真中广泛应用，但训练与部署间的分布偏移会导致性能严重下降。现有测试时适应方法主要针对低维分类任务，不适用于高维、非结构化的仿真回归问题

Method: 提出基于D-最优统计量的测试时适应框架，通过存储最大化信息统计量，实现稳定适应和测试时的参数选择

Result: 在预训练的仿真代理模型上应用该方法，在分布外数据上获得高达7%的性能提升，计算成本可忽略不计。在SIMSHIFT和EngiBench基准测试中验证有效

Conclusion: 这是首个系统展示在高维仿真回归和生成设计优化中有效测试时适应的方法，为解决工程仿真中的分布偏移问题提供了实用解决方案

Abstract: Machine learning surrogates are increasingly used in engineering to accelerate costly simulations, yet distribution shifts between training and deployment often cause severe performance degradation (e.g., unseen geometries or configurations). Test-Time Adaptation (TTA) can mitigate such shifts, but existing methods are largely developed for lower-dimensional classification with structured outputs and visually aligned input-output relationships, making them unstable for the high-dimensional, unstructured and regression problems common in simulation. We address this challenge by proposing a TTA framework based on storing maximally informative (D-optimal) statistics, which jointly enables stable adaptation and principled parameter selection at test time. When applied to pretrained simulation surrogates, our method yields up to 7% out-of-distribution improvements at negligible computational cost. To the best of our knowledge, this is the first systematic demonstration of effective TTA for high-dimensional simulation regression and generative design optimization, validated on the SIMSHIFT and EngiBench benchmarks.

</details>


### [176] [CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing](https://arxiv.org/abs/2602.15823)
*Zarif Ikram,Arad Firouzkouhi,Stephen Tu,Mahdi Soltanolkotabi,Paria Rashidinejad*

Main category: cs.LG

TL;DR: CrispEdit是一个可扩展的二阶编辑算法，通过将能力保持作为显式约束，解决LLM编辑中的能力退化问题，在保持高编辑成功率的同时将能力退化控制在1%以下。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型编辑中的核心挑战是能力保持：成功改变目标行为的方法可能会悄悄操纵编辑代理并损害通用能力，产生类似代理/奖励破解的退化行为。

Method: 将编辑建模为约束优化问题，通过将编辑更新投影到能力损失景观的低曲率子空间来强制执行约束。使用Bregman散度表达能力约束，通过Kronecker分解近似曲率（K-FAC）和新型矩阵自由投影器实现高效二阶计算。

Result: 在标准模型编辑基准测试中，CrispEdit实现了高编辑成功率，同时在多个数据集上平均将能力退化保持在1%以下，显著优于先前编辑方法。

Conclusion: CrispEdit提供了一个可扩展且原则性的二阶编辑框架，通过显式约束能力保持，有效解决了LLM编辑中的能力退化问题，统一并推广了多种现有编辑方法。

Abstract: A central challenge in large language model (LLM) editing is capability preservation: methods that successfully change targeted behavior can quietly game the editing proxy and corrupt general capabilities, producing degenerate behaviors reminiscent of proxy/reward hacking. We present CrispEdit, a scalable and principled second-order editing algorithm that treats capability preservation as an explicit constraint, unifying and generalizing several existing editing approaches. CrispEdit formulates editing as constrained optimization and enforces the constraint by projecting edit updates onto the low-curvature subspace of the capability-loss landscape. At the crux of CrispEdit is expressing capability constraint via Bregman divergence, whose quadratic form yields the Gauss-Newton Hessian exactly and even when the base model is not trained to convergence. We make this second-order procedure efficient at the LLM scale using Kronecker-factored approximate curvature (K-FAC) and a novel matrix-free projector that exploits Kronecker structure to avoid constructing massive projection matrices. Across standard model-editing benchmarks, CrispEdit achieves high edit success while keeping capability degradation below 1% on average across datasets, significantly improving over prior editors.

</details>


### [177] [Operationalising the Superficial Alignment Hypothesis via Task Complexity](https://arxiv.org/abs/2602.15829)
*Tomás Vergara-Browne,Darshan Patil,Ivan Titov,Siva Reddy,Tiago Pimentel,Marius Mosbach*

Main category: cs.LG

TL;DR: 论文提出"任务复杂度"新指标来形式化"表面对齐假说"，发现预训练模型大幅降低任务复杂度，后训练进一步将复杂度降低数个数量级，任务适应通常只需极少信息（常仅几KB）。


<details>
  <summary>Details</summary>
Motivation: 表面对齐假说缺乏精确定义，导致支持论点相互正交且受到重要批评。需要形式化框架来统一理解预训练和后训练在知识获取中的作用。

Method: 提出"任务复杂度"新指标：达到目标任务性能的最短程序长度。通过该框架将SAH形式化为"预训练模型大幅降低许多任务的复杂度"。实验估计数学推理、机器翻译和指令跟随的任务复杂度。

Result: 预训练模型能访问任务的高性能，但可能需要GB级程序长度；后训练将达到相同性能的复杂度降低数个数量级。任务适应通常只需极少信息（常仅几KB）。

Conclusion: 任务复杂度框架为表面对齐假说提供了精确形式化，统一了先前论点。预训练大幅降低任务复杂度，后训练进一步大幅压缩复杂度，表明任务适应所需信息量通常很小。

Abstract: The superficial alignment hypothesis (SAH) posits that large language models learn most of their knowledge during pre-training, and that post-training merely surfaces this knowledge. The SAH, however, lacks a precise definition, which has led to (i) different and seemingly orthogonal arguments supporting it, and (ii) important critiques to it. We propose a new metric called task complexity: the length of the shortest program that achieves a target performance on a task. In this framework, the SAH simply claims that pre-trained models drastically reduce the complexity of achieving high performance on many tasks. Our definition unifies prior arguments supporting the SAH, interpreting them as different strategies to find such short programs. Experimentally, we estimate the task complexity of mathematical reasoning, machine translation, and instruction following; we then show that these complexities can be remarkably low when conditioned on a pre-trained model. Further, we find that pre-training enables access to strong performances on our tasks, but it can require programs of gigabytes of length to access them. Post-training, on the other hand, collapses the complexity of reaching this same performance by several orders of magnitude. Overall, our results highlight that task adaptation often requires surprisingly little information -- often just a few kilobytes.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [178] [The underwater Brachistochrone](https://arxiv.org/abs/2602.15133)
*Mohammad-Reza Alam*

Main category: physics.flu-dyn

TL;DR: 水下最速降线问题：考虑浮力、粘性阻力和附加质量效应，经典摆线不再是水下最优路径，密度比和雷诺数对轨迹有显著影响。


<details>
  <summary>Details</summary>
Motivation: 经典最速降线问题（摆线）假设无摩擦，但水下环境中浮力、粘性阻力和附加质量效应会显著改变问题。需要研究这些流体力学效应如何影响水下物体的最快下降轨迹。

Method: 建立并求解水下最速降线问题的数学模型，综合考虑浮力、粘性阻力（含雷诺数依赖的阻力系数）和附加质量效应。扩展至包含中间航点的三点最速降线问题。

Result: 当物体密度接近流体密度时，经典摆线变得次优；低于临界密度比时甚至无法到达终点。在阻力危机临界雷诺数附近，最优轨迹对密度比和物体尺寸极为敏感。忽略附加质量会低估约20%的通过时间。

Conclusion: 水下最速降线问题为浮力驱动水下航行器的短程轨迹规划提供了简单工具，揭示了经典问题中不存在的有限可达域特性。

Abstract: The brachistochrone, the curve of fastest descent under gravity, is a cycloid when friction is absent. Underwater, however, buoyancy, viscous drag, and the added mass of entrained fluid fundamentally alter the problem. We formulate and solve the brachistochrone for a body moving through a dense fluid, incorporating all three effects together with a Reynolds-number-dependent drag coefficient. The classical cycloid becomes increasingly suboptimal as the body density approaches the fluid density, and below a critical density ratio it fails to reach the endpoint altogether. Near the critical Reynolds number for the drag crisis, the optimal trajectory is acutely sensitive to the density ratio and object size; constant-drag approximations can yield qualitatively incorrect paths. A decomposition of physical effects shows that neglecting drag and added mass together yields a predicted transit time roughly half the realised minimum, and that omitting added mass alone underestimates the transit time by approximately 20%. We extend the formulation to a three-point brachistochrone in which the trajectory must pass through an intermediate waypoint, revealing a finite reachable domain that is absent in the classical problem. The underwater brachistochrone as presented here provides a simple planning tool for short-range trajectories of buoyancy-driven underwater vehicles.

</details>


### [179] [Time-resolved X-ray radiography of through-thickness liquid transport in partly saturated needle-punched nonwovens](https://arxiv.org/abs/2602.15176)
*Patrick Wegele,Zisheng Yao,Jonas Tejbo,Julia K. Rogalinski,Tomas Rosén,Alexander Groetsch,Kim Nygård,Eleni Myrto Asimakopoulou,Pablo Villanueva-Perez,L. Daniel Söderberg*

Main category: physics.flu-dyn

TL;DR: 研究针刺非织造布中液体在厚度方向的动态传输特性，发现传输速率随饱和度呈指数关系，针刺强度通过形成优先流动通道增强厚度方向传输


<details>
  <summary>Details</summary>
Motivation: 针刺非织造布在过滤、绝缘和土工织物中应用广泛，其液体吸收、再分布和释放性能至关重要。针刺工艺通过机械缠结纤维并部分重新定向到厚度方向，形成异质结构，但厚度方向的动态传输特性由于材料不透明性和亚秒级时间尺度而难以研究

Method: 结合微CT（μCT）分析干燥结构，使用时间分辨X射线放射成像技术监测液滴添加过程，采用紧凑的Washburn型描述符量化厚度方向传输与饱和度和针刺强度的关系

Result: 厚度方向液体传输速率与饱和度呈指数依赖关系，与先前非织造布面内相对渗透率模型一致；针刺强度增加使纤维向厚度方向重新定向，形成优先流动通道，增强厚度方向传输，即使单相渗透率降低

Conclusion: 针刺工艺是调控非织造布液体传输的关键设计参数，该方法为不透明纤维材料中毛细驱动的动态传输提供了实验和建模框架

Abstract: Nonwoven fibre networks underpin filtration, insulation and geotextiles, where liquid uptake, redistribution and release govern performance. In needle-punched felts, barbed needles mechanically entangle fibres and partially reorient them toward the thickness direction ($z$), creating out-of-plane "pillars" and heterogeneity. While mechanical and structural consequences of needling are well documented, dynamic $z$-direction transport in partly saturated networks remains difficult to access due to opacity and sub-second timescales. Here we combine micro-CT ($μ$CT) of dry structure with time-resolved X-ray radiography during droplet addition to quantify through-thickness transport as a function of saturation and needling intensity, using a compact Washburn-type descriptor for dynamics. Results show an exponential dependence of $z$-directional liquid transport on saturation, consistent with previous models for in-plane relative permeability of nonwoven networks. Additionally, increased needle-punch intensity reorients fibres toward the $z$-direction, forming preferential flow pathways that enhance through-thickness transport, even as single-phase permeability decreases. These findings underscore needle-punch as a key design parameter for tuning liquid transport in nonwoven fibre networks. The approach provides an experimental and modelling framework for dynamic, capillarity-driven transport in opaque fibrous materials.

</details>


### [180] [Global phase-space geometry of three-dimensional gliding: terminal velocity manifolds, separatrices, and stability structure](https://arxiv.org/abs/2602.15234)
*Mohamed Zakaria,Shane D. Ross*

Main category: physics.flu-dyn

TL;DR: 本文开发了一个三维动力系统框架来分析被动滑翔，识别了组织滑翔运动的全局相空间结构，揭示了终端速度流形和分界面如何决定滑翔效率。


<details>
  <summary>Details</summary>
Motivation: 扩展先前二维非平衡滑翔模型，建立统一的三维几何框架来分析生物和工程滑翔器的全局动力学行为，理解滑翔效率与初始条件的关系。

Method: 开发三维动力系统框架，识别终端速度流形(TVM)和分界面结构；使用三种代表性翼型（蛇启发钝体、飞蜥Zimmerman翼型、NACA 0012）的升阻数据计算平衡曲面，分析俯仰-滚转分岔，重建三维TVM和分界面几何。

Result: 发现：(1)平衡稳定性随俯仰和滚转共同变化；(2)分界面几何决定浅滑翔的动态可达性；(3)生物启发翼型具有紧凑的分界面区域，使高效滑翔在广泛初始条件下保持鲁棒性。

Conclusion: 该工作将生物和工程滑翔器统一在单一全局几何框架中，确立了TVM上的分界面几何作为滑翔鲁棒性的原则性诊断工具。

Abstract: We develop a three-dimensional dynamical-systems framework for passive gliding and identify the global phase-space structures that organize its motion. Extending previous two-dimensional models of non-equilibrium gliding, we show that the 3D velocity dynamics possess an attracting, normally hyperbolic invariant surface, the terminal velocity manifold (TVM), onto which all trajectories rapidly collapse before evolving slowly toward a glide equilibrium. There is also a separatrix surface associated with an invariant manifold of an unstable equilibrium within the TVM, which partitions initial conditions into qualitatively distinct descent behaviors: efficient shallow glides versus steep, drag-dominated descent. Using lift-drag data from three representative airfoils--a snake-inspired bluff body, the Zimmerman planform characteristic of Draco lizards, and the classical NACA 0012--we compute the full equilibrium surfaces, analyze their pitch-roll bifurcations, and reconstruct the TVM and separatrix geometry in three dimensions. The results reveal that (i) equilibrium stability changes with both pitch and roll, rather than pitch alone; (ii) separatrix geometry determines the dynamic accessibility of shallow glides; and (iii) bio-inspired airfoils possess compact separatrix regions that make efficient gliding robust across a wide range of initial jump conditions. This work unifies biological and engineered gliders within a single global geometric framework and establishes separatrix geometry on the TVM as a principled diagnostic for glide robustness.

</details>


### [181] [A Robust Truncated-Domain Approach for Cone--Jet Simulations in Electrospinning and Electrospraying](https://arxiv.org/abs/2602.15416)
*Ghanashyam K. C.,Satyavrata Samavedi,Harish N Dixit*

Main category: physics.flu-dyn

TL;DR: 提出一种截断域电液动力学模拟框架，通过全域静电模拟获取精确电场边界条件，准确预测锥射流模式，显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 传统电纺丝和电喷雾全数值模拟计算量大，现有截断域方法依赖经验调整，预测能力有限，需要一种更准确、无需经验调参的模拟框架

Method: 利用低成本全域静电模拟获取针尖附近精确电场和电势分布，作为边界条件施加在截断域上进行电液动力学模拟

Result: 与全域EHD模拟和实验数据对比，该方法准确再现锥射流形状及关键物理量（电流、电荷分布、速度场、麦克斯韦应力），收敛域尺寸显著减小

Conclusion: 该框架消除了可调参数，无需先验锥射流配置知识，显著降低计算成本，为研究电液动力学锥射流提供了可靠且具预测性的模拟方法

Abstract: Direct numerical simulations of electrospinning and electrospraying are computationally demanding due to large-scale separation between the needle and the tip-to-collector distance. The cone-jet mode that occurs in the vicinity of the needle arises from a delicate balance between surface tension, viscous stresses, inertia, and electric stresses. This mode has a central role in determining the subsequent instabilities of the jet and the eventual outcomes on the collector. Truncated-domain simulations offer a viable alternative but depend critically on the accuracy of far-field electrostatic boundary conditions. Existing truncated-domain approaches based on analytical expressions for the electric potential systematically underestimate the electric field near the needle tip and require empirical tuning informed by prior experiments or full-domain simulations, thereby limiting their predictive capability. Here, we present a general truncated-domain framework for electrohydrodynamic (EHD) simulations of the cone-jet mode that avoids these limitations. Our approach exploits inexpensive full-domain electrostatic simulations to obtain the exact electric field and potential distributions near the needle, which are then imposed as boundary conditions in an EHD simulation carried out on a truncated domain. Comparisons with full-domain EHD simulations and experimental data demonstrate that the proposed approach accurately reproduces cone-jet shapes as well as key physical quantities, including electric currents, charge distributions, velocity fields, and Maxwell stresses, while converging at substantially smaller domain sizes. The formulation eliminates tunable parameters, does not require prior knowledge of the cone-jet configuration, and significantly reduces computational cost, providing a reliable and predictive framework for studying electrohydrodynamic cone-jet flows.

</details>


### [182] [Fluids You Can Trust: Property-Preserving Operator Learning for Incompressible Flows](https://arxiv.org/abs/2602.15472)
*Ramansh Sharma,Matthew Lowery,Houman Owhadi,Varun Shankar*

Main category: physics.flu-dyn

TL;DR: 提出一种基于核的算子学习方法，用于不可压缩流动，能解析地保持不可压缩性、周期性和湍流等物理特性，相比神经算子精度更高、训练更快。


<details>
  <summary>Details</summary>
Motivation: 传统数值求解器在保持不可压缩性时计算成本高，而现有的神经算子方法无法精确强制执行不可压缩性、周期性和湍流等物理特性，需要一种能解析保持这些物理特性的高效替代模型。

Method: 使用基于核的算子学习方法，将输入函数映射到输出函数在属性保持核基中的展开系数，确保预测的速度场能解析且同时保持不可压缩性、周期性和湍流等物理特性。

Result: 在2D和3D层流和湍流不可压缩流动问题上，该方法相比神经算子实现了高达6个数量级更低的相对ℓ₂误差，训练速度快达5个数量级，并能解析地强制执行不可压缩性，而神经算子则表现出很大偏差。

Conclusion: 该方法为不可压缩流动提供了一个准确且高效的替代模型，能解析地保持关键物理特性，在精度和效率方面显著优于现有的神经算子方法。

Abstract: We present a novel property-preserving kernel-based operator learning method for incompressible flows governed by the incompressible Navier-Stokes equations. Traditional numerical solvers incur significant computational costs to respect incompressibility. Operator learning offers efficient surrogate models, but current neural operators fail to exactly enforce physical properties such as incompressibility, periodicity, and turbulence. Our method maps input functions to expansion coefficients of output functions in a property-preserving kernel basis, ensuring that predicted velocity fields analytically and simultaneously preserve the aforementioned physical properties. We evaluate the method on challenging 2D and 3D, laminar and turbulent, incompressible flow problems. Our method achieves up to six orders of magnitude lower relative $\ell_2$ errors upon generalization and trains up to five orders of magnitude faster compared to neural operators. Moreover, while our method enforces incompressibility analytically, neural operators exhibit very large deviations. Our results show that our method provides an accurate and efficient surrogate for incompressible flows.

</details>


### [183] [Novel distance-based masking and adaptive alpha-shape methods for CNN-ready reconstruction of arbitrary 2D CFD flow domains](https://arxiv.org/abs/2602.15536)
*Mehran Sharifi,Gorka S. Larraona,Alejandro Rivas*

Main category: physics.flu-dyn

TL;DR: 提出两种从散射CFD数据重建几何掩码的方法：基于距离的掩码和自适应alpha-shape方法，相比传统alpha-shape方法更稳定、快速且需要较少调参。


<details>
  <summary>Details</summary>
Motivation: 将散射的CFD数据集插值到均匀笛卡尔网格会扭曲真实几何形状，产生凸包类型包络并激活非物理区域，需要恢复物理一致的掩码以生成CNN就绪的场。

Method: 提出两种新策略：1) 基于距离的掩码方法，使用最小CFD网格间距作为阈值；2) 自适应alpha-shape方法，根据局部数据分辨率归一化alpha参数。引入拓扑感知的定量评估指标，并采用轻量级边界膨胀后处理。

Result: 基于距离的方法在相同阈值规则下对考虑的所有几何形状都稳健，比传统alpha-shape快500-800倍。自适应alpha-shape在控制参数设为1时保持稳定，比传统变体快1.7-2.6倍。边界膨胀后处理可将保留率提高达2.96%，非支持激活可忽略不计(小于0.08%)。

Conclusion: 推荐基于距离的方法作为默认选择，因其准确性、稳定性、最小调参需求和低成本；当网格间距信息不可用时，自适应alpha-shape是强有力的替代方案。提供了配套的Web应用程序实现端到端工作流程。

Abstract: Interpolating scattered CFD datasets onto a uniform Cartesian grid can distort the true geometry, producing a convex-hull type envelope and activating nonphysical regions. This work presents a reconstruction framework that recovers physically consistent masks before exporting CNN-ready fields. It introduces two novel strategies, distance-based masking and an adaptive alpha-shape formulation that normalizes alpha using local data resolution, and evaluates them against classical alpha-shape boundary recovery. A quantitative, topology-aware metric suite is introduced to assess retention, suppression of unsupported regions, overlap consistency, and connectivity. The novel distance-based method is robust across the geometries considered under the same threshold rule, with tau set to the minimum CFD grid spacing, and achieves 500-800 times speedups over classical alpha-shapes. The adaptive alpha-shape remains stable when its control parameter is set to 1 and is 1.7-2.6 times faster than the classical variant, which requires geometry-specific alpha tuning. A lightweight boundary inflation post-process using a minimal dilation further improves retention by up to 2.96% with negligible unsupported activation (less than 0.08%). Overall, the distance-based method is recommended as the default due to its accuracy, stability, minimal tuning, and low cost, while the adaptive alpha-shape is a strong alternative when grid-spacing information for threshold selection is unavailable. A companion web application operationalizes the workflow end to end, enabling 2D ASCII dataset upload, parameter tuning, mask and boundary generation, and export of CNN-ready outputs.

</details>


### [184] [Uni-Flow: a unified autoregressive-diffusion model for complex multiscale flows](https://arxiv.org/abs/2602.15592)
*Xiao Xue,Tianyue Yang,Mingyang Gao,Leyu Pan,Maida Wang,Kewei Zhu,Shuo Wang,Jiuling Li,Marco F. P. ten Eikelder,Peter V. Coveney*

Main category: physics.flu-dyn

TL;DR: Uni-Flow：一种统一的自回归-扩散框架，通过分离时间演化和空间细化来建模复杂动力系统，实现长期稳定预测和高分辨率重建。


<details>
  <summary>Details</summary>
Motivation: 时空流控制着物理、生物和工程领域的多种现象，但建模其多尺度动力学仍是一个核心挑战。现有物理信息机器学习方法难以同时保持长期时间演化和解析混沌、湍流及生理状态下的精细尺度结构。

Method: 提出Uni-Flow统一框架，将时间演化与空间细化分离：自回归组件学习低分辨率潜在动力学以保持大尺度结构和确保稳定长期预测；扩散组件重建高分辨率物理场，在少量去噪步骤中恢复精细尺度特征。

Result: 在多个基准测试中验证：二维Kolmogorov流、三维湍流通道流入生成（使用量子信息自回归先验）、基于高保真格子Boltzmann血流动力学求解器的主动脉缩窄患者特异性模拟。在心血管应用中，实现比实时更快的脉动血流动力学推理，秒级重建高分辨率压力场。

Conclusion: Uni-Flow将高保真血流动力学模拟从离线、HPC绑定的过程转变为可部署的替代模型，为复杂多尺度流的比实时更快建模建立了途径，对流动物理中的科学机器学习具有广泛意义。

Abstract: Spatiotemporal flows govern diverse phenomena across physics, biology, and engineering, yet modelling their multiscale dynamics remains a central challenge. Despite major advances in physics-informed machine learning, existing approaches struggle to simultaneously maintain long-term temporal evolution and resolve fine-scale structure across chaotic, turbulent, and physiological regimes. Here, we introduce Uni-Flow, a unified autoregressive-diffusion framework that explicitly separates temporal evolution from spatial refinement for modelling complex dynamical systems. The autoregressive component learns low-resolution latent dynamics that preserve large-scale structure and ensure stable long-horizon rollouts, while the diffusion component reconstructs high-resolution physical fields, recovering fine-scale features in a small number of denoising steps. We validate Uni-Flow across canonical benchmarks, including two-dimensional Kolmogorov flow, three-dimensional turbulent channel inflow generation with a quantum-informed autoregressive prior, and patient-specific simulations of aortic coarctation derived from high-fidelity lattice Boltzmann hemodynamic solvers. In the cardiovascular setting, Uni-Flow enables task-level faster than real-time inference of pulsatile hemodynamics, reconstructing high-resolution pressure fields over physiologically relevant time horizons in seconds rather than hours. By transforming high-fidelity hemodynamic simulation from an offline, HPC-bound process into a deployable surrogate, Uni-Flow establishes a pathway to faster-than-real-time modelling of complex multiscale flows, with broad implications for scientific machine learning in flow physics.

</details>


### [185] [Influence of the Inhalation Route on Tracheal Flow Structures in Patient-Specific Airways using 3D PTV](https://arxiv.org/abs/2602.15599)
*Benedikt H. Johanning-Meiners,Luca Mayolle,Dominik Krug,Michael Klaas*

Main category: physics.flu-dyn

TL;DR: 研究通过体外实验和3D粒子追踪测速技术，发现吸入路径（口或鼻）对气管内流场结构影响极小，但上呼吸道（鼻腔和/或口腔）的存在会显著改变下呼吸道流场，与理想化充分发展入流条件不同。


<details>
  <summary>Details</summary>
Motivation: 气管流场影响颗粒物进入下呼吸道，这对吸入病原体传播和气溶胶治疗有效性至关重要。了解不同吸入路径如何改变流场对理解下呼吸道疾病传播和指导靶向药物输送具有重要意义。

Method: 使用非顺应性、折射率匹配的硅胶人体呼吸道模型进行体外实验，研究稳态吸入和模拟平静呼吸的振荡流。采用正弦波形近似真实呼吸模式，基于气管水力直径和最大体积流量下的整体速度，研究两个雷诺数（Re_Tr = [400, 1200]）和两个沃默斯利数（Wo = [3, 4.5]）。使用Shake-The-Box算法进行3D粒子追踪测速测量，采用水和甘油的折射率匹配流体完全解析气管内复杂流场结构。

Result: PTV测量证实分析下呼吸道流场时必须考虑鼻腔和/或口腔的存在。研究发现两个腔室的存在显著改变了流场，与理想化充分发展入流条件不同。然而，气管内矢状面和冠状面的速度剖面以及归一化速度幅值的等值线图显示，口腔和鼻腔吸入的流场结构几乎相同，表明吸入路径的影响极小。

Conclusion: 虽然上呼吸道（鼻腔和口腔）的存在会显著影响下呼吸道流场，但吸入路径（通过口或鼻）本身对气管内流场结构的影响可以忽略不计。这对理解呼吸道疾病传播机制和气溶胶治疗策略具有重要意义。

Abstract: The tracheal flow field shapes particle transport into the lower airways and thus influences both the spread of inhaled pathogens and the effectiveness of aerosol-based therapies. Identifying how different inhalation routes modify the flow field is therefore crucial for understanding lower-airway disease transmission and for guiding targeted drug delivery. To gain a detailed understanding of the influence of the inhalation route on the flow structures in the human trachea, the flow field in the trachea is investigated in vitro in a non-compliant, refractive-index matched silicone model of the human respiratory tract. The investigations comprise steady inhalation, and oscillatory flow to simulate calm breathing. A realistic breathing pattern is approximated by a sinusoidal waveform for two Reynolds numbers of $Re_{Tr} = [400, 1200]$, based on the bulk velocity at maximum volume flux and the hydraulic diameter of the trachea and two Womersley numbers of $Wo = [3, 4.5]$, representing the oscillation time scales. To capture the inherently three-dimensional and asymmetric nature of the flow field, 3D particle-tracking velocimetry measurements are performed using the Shake-The-Box algorithm. Using a refractive-index matched fluid consisting of water and glycerin, the complex flow structures inside the trachea are fully resolved. The PTV measurements confirm that the nasal and/or oral cavity must be considered when analyzing the flow field in the lower respiratory tract. In particular, we find that the presence of both cavities significantly alters the flow field compared to idealised, fully developed inflow conditions. However, velocity profiles in the sagittal and coronal plane in the trachea as well as contour plots of the of the normalized velocity magnitude evidence nearly identical flow structures for oral and nasal inhalation, indicating minimal influence of the inhalation route.

</details>


### [186] [Equilibrium statistical mechanics of waves in inhomogeneous moving media](https://arxiv.org/abs/2602.15639)
*Alexandre Tlili,Basile Gallet*

Main category: physics.flu-dyn

TL;DR: 将平衡统计力学的微正则框架应用于预测非均匀运动介质中短波的统计特性，通过绝对频率守恒约束下的相空间作用密度遍历性假设计算波谱


<details>
  <summary>Details</summary>
Motivation: 传统波动理论在处理非均匀运动介质中的短波统计特性时面临挑战，需要发展新的理论框架来预测这类复杂系统中的波谱分布

Method: 将平衡统计力学的微正则框架扩展到非均匀运动介质中的波动系统，基于绝对频率守恒约束下的相空间作用密度遍历性假设，计算稳态非均匀性和背景流场中的波谱

Result: 成功应用于浅水波（受背景流或地形非均匀性影响）和深水表面毛细波（在背景流上）的波谱预测，数值模拟验证了均方根表面高程和界面斜率的预测结果

Conclusion: 微正则统计力学框架能够有效预测非均匀运动介质中短波的统计特性，为复杂波动系统的谱分析提供了新的理论工具

Abstract: We adapt the microcanonical framework of equilibrium statistical mechanics to predict the statistics of short waves in inhomogeneous moving media. For steady inhomogeneities and background flow, we compute the wave spectrum at any location in the domain based on an ergodic prescription for the action density in phase space, constrained by conservation of absolute frequency. We illustrate the method for shallow-water waves subject to a background flow or to topographic inhomogeneities, and for deep-water surface capillary waves over a background flow, validating the predicted maps of rms surface elevation and interfacial slope against numerical simulations.

</details>


### [187] [Physics-informed data-driven inference of an interpretable equivariant LES model of incompressible fluid turbulence](https://arxiv.org/abs/2602.15743)
*Matteo Ugliotti,Brandon Choi,Mateo Reynoso,Daniel R. Gurevich,Roman O. Grigoriev*

Main category: physics.flu-dyn

TL;DR: 提出了一种无经验假设、无可调参数的数据驱动亚格子模型，在二维湍流中优于主流LES模型


<details>
  <summary>Details</summary>
Motivation: 传统的经验性假设限制了亚格子模型准确描述能量和涡量等关键物理量的能力，特别是在存在多种相干结构的情况下

Method: 采用符号数据驱动方法，结合先验和后验基准测试，通过LES风格的空间粗粒化推断模型，但结构更接近RANS模型，使用额外的二阶张量场描述亚格子尺度

Result: 模型在广泛的二维湍流中准确预测了包括局部通量在内的各种物理量，性能优于主流LES模型

Conclusion: 该数据驱动亚格子模型无需经验假设和可调参数，通过引入二阶张量结构的额外场，能够正确表示亚格子应力张量的分量和各种通量

Abstract: Restrictive phenomenological assumptions represent a major roadblock for the development of accurate subgrid-scale models of fluid turbulence. Specifically, these assumptions limit a model's ability to describe key quantities of interest, such as local fluxes of energy and enstrophy, in the presence of diverse coherent structures. This paper introduces a symbolic data-driven subgrid-scale model that requires no phenomenological assumptions and has no adjustable parameters, yet it outperforms leading LES models. A combination of a priori and a posteriori benchmarks shows that the model produces accurate predictions of various quantities including local fluxes across a broad range of two-dimensional turbulent flows. While the model is inferred using LES-style spatial coarse-graining, its structure is more similar to RANS models, as it employs an additional field to describe subgrid scales. We find that this field must have a rank-two tensor structure in order to correctly represent both the components of the subgrid-scale stress tensor and the various fluxes.

</details>


### [188] [Effect of flexibility on the pitch-heave flutter instability of a flexible foil elastically supported on its leading edge](https://arxiv.org/abs/2602.15744)
*Ramon Fernandez-Feria*

Main category: physics.flu-dyn

TL;DR: 提出分析工具计算二维弹性安装柔性翼片的颤振不稳定参数区域，基于小振幅振荡和变形的非定常流固耦合新解析公式，扩展了先前分析，包含重力和第二弯曲模态效应。


<details>
  <summary>Details</summary>
Motivation: 开发分析工具来预测柔性振荡翼片系统的颤振不稳定区域，为基于柔性振荡翼片的未来涡轮机设计提供指导。

Method: 提出新的解析公式，适用于小振幅振荡和变形的非定常流固耦合，扩展先前分析包含重力和第二弯曲模态效应，增加对较小刚度的有效性范围。

Result: 解析结果与现有数值结果验证，捕捉到刚度参数S低至10^{-1}量级的前两个自然弯曲模态。识别了不同约束条件下的稳定/不稳定区域，发现柔性翼片中弯曲不稳定模态与弹簧不稳定模态耦合，扩大了颤振不稳定的质量比范围并增加了增长率。

Conclusion: 该分析工具能轻松表征颤振不稳定的参数区域，提供相应频率和临界颤振速度，为基于柔性振荡翼片的未来涡轮机设计提供有用指导。

Abstract: An analytical tool is presented to compute the parametric regions of flutter instabilities of a two-dimensional flexible foil elastically mounted. It is based on a new analytical formulation of the unsteady fluid-estructure interaction valid for small-amplitude oscillations and deformations of the foil immersed in an inviscid fluid. The formulation extends a previous analysis by including the effects of gravity and a second flexural mode, increasing its validity range to much smaller rigidities. The analytical results are validated with available numerical results, capturing the first two natural flexural modes down to values of the stiffness parameter $S$ of order $10^{-1}$. When only passive heave, or only passive pitch, is allowed, the rigid foil is stable, existing an upper stiffness bound for the flexural instabilities, wich become coupled with the spring instability mode for small spring constant increasing the growth rate. These coupled spring (linear or torsional) and flexural instability modes occur below a threshold value of $S$ and above a threshold value of $R$, both depending on the corresponding spring constant. Coupled pitch-heave flutter instabilities of a rigid foil occur in a region below a curve of the parametric plane of the two springs constants that depends on $R$, which shrinks to zero as $R$ decreases. For a flexible foil, the flexural unstable modes become coupled with the springs unstable mode as $S$ decreases from infinity, enlarging the mass ratio range for flutter instability and increasing its growth rate, the more so the smaller the springs constants. The parametric regions for flutter instabilities are easily characterized with the present analytical tool, providing the corresponding frequency and critical flutter velocity. The present results can be useful as a guide in the design of future turbines based on flexible oscillating foils.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [189] [Certified Reduced-Order Surrogates and Stability Margins in Viscous Incompressible Flow and Fluid--Structure Interaction](https://arxiv.org/abs/2602.15059)
*Chandrasekhar Gokavarapu,Naveen Kumar Kakumanu,Anjali Datla,Githa Harshitha Noolu*

Main category: math.NA

TL;DR: 该论文为不可压缩Navier-Stokes方程构建了一个具有能量不等式认证的降阶模型，提供了后验误差界、过渡指标和流体-结构相互作用模型的稳定性裕度。


<details>
  <summary>Details</summary>
Motivation: 为Navier-Stokes方程的降阶模型提供严格的数学保证，包括能量稳定性、误差界和过渡阈值，以增强计算流体动力学模拟的可靠性。

Method: 构建约束降阶模型使其满足认证的能量不等式，推导后验误差界，从能量和涡量预算中推导过渡指标，分析流体-结构相互作用模型的稳定性条件。

Result: 获得了具有显式常数C的后验误差界，建立了过渡阈值不等式，推导了流体-结构相互作用模型的稳定性裕度和显式约束条件。

Conclusion: 该方法为降阶模型提供了严格的数学认证框架，包括稳定性保证、误差控制和过渡检测，特别适用于需要可靠计算的流体动力学问题。

Abstract: Let $(u,p)$ solve the incompressible Navier--Stokes equations in a regime in which an energy inequality is available and each constant in that inequality is computable from declared data. We construct a reduced-order model $u_n$ constrained so that its discrete evolution satisfies a certified energy inequality. This certificate yields global-in-time boundedness of the ROM energy and a regime-of-validity test that fails when a stated hypothesis fails.
  It follows that one can attach a computable residual functional $\mathcal{R}_n$ to the ROM trajectory. We prove an a posteriori bound of the form \[ \norm{u-u_n}_{\mathsf{X}(0,T)} \le C(\text{declared data})\,\mathcal{R}_n, \] with $C$ explicit and with $\mathcal{R}_n$ computed from the ROM and the discretization operators. Conversely, if the certificate constraint is relaxed, the bound can fail even for stable full-order dynamics, by an explicit instability mechanism recorded in the text.
  We then derive transition indicators from rigorous energy and enstrophy budgets in simplified geometries. Each indicator is an inequality involving declared quantities such as forcing norms, viscosity, Poincaré-type constants, and a computable resolvent surrogate. These inequalities provide thresholds that preclude transition, or else certify the presence of transient growth beyond a stated level.
  Finally, for a class of fluid--structure interaction models, we identify a parameter regime that implies existence and uniqueness of weak solutions. We derive discrete coupled energy estimates that produce computable stability margins. These margins yield explicit constraints on time step and mesh parameters. They are stated as inequalities with constants determined by fluid viscosity, structure stiffness, density ratios, and interface trace bounds.

</details>


### [190] [A Unified Benchmark of Physics-Informed Neural Networks and Kolmogorov-Arnold Networks for Ordinary and Partial Differential Equations](https://arxiv.org/abs/2602.15068)
*Salvador K. Dzimah,Sonia Rubio Herranz,Fernando Carlos Lopez Hernandez,Antonio López Montes*

Main category: math.NA

TL;DR: PIKANs（基于KAN的物理信息网络）相比传统MLP-based PINNs在求解微分方程时表现更优，具有更高精度、更快收敛和更好的梯度估计能力。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs使用多层感知机（MLPs），其固定的激活函数和全局近似偏差在处理振荡行为、多尺度动态或陡峭梯度问题时性能受限。而KANs（Kolmogorov-Arnold网络）作为功能自适应架构，具有可学习的单变量变换，能提供更丰富的局部近似和更强的表达能力。

Method: 对标准MLP-based PINNs和基于KAN的PIKANs进行系统化、受控比较，使用相同的物理信息公式和匹配的参数预算来隔离架构效应。在代表性ODE和PDE集合上进行评估，包括具有已知解析解的情况，以直接评估梯度重建精度。

Result: PIKANs在多个测试中一致地实现了更准确的解，收敛所需的迭代次数更少，并产生更优的梯度估计。这突显了PIKANs在物理信息学习中的优势。

Conclusion: KAN-based架构作为科学机器学习的新一代方法具有巨大潜力，为微分方程求解中的模型选择提供了严谨证据。PIKANs相比传统PINNs在精度、收敛速度和梯度估计方面表现更优。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful mesh-free framework for solving ordinary and partial differential equations by embedding the governing physical laws directly into the loss function. However, their classical formulation relies on multilayer perceptrons (MLPs), whose fixed activation functions and global approximation biases limit performance in problems with oscillatory behavior, multiscale dynamics, or sharp gradients. In parallel, Kolmogorov-Arnold Networks (KANs) have been introduced as a functionally adaptive architecture based on learnable univariate transformations along each edge, providing richer local approximations and improved expressivity. This work presents a systematic and controlled comparison between standard MLP-based PINNs and their KAN-based counterparts, Physics-Informed Kolmogorov-Arnold Networks (PIKANs), using identical physics-informed formulations and matched parameter budgets to isolate the architectural effect. Both models are evaluated across a representative collection of ODEs and PDEs, including cases with known analytical solutions that allow direct assessment of gradient reconstruction accuracy. The results show that PIKANs consistently achieve more accurate solutions, converge in fewer iterations, and yield superior gradient estimates, highlighting their advantage for physics-informed learning. These findings underline the potential of KAN-based architectures as a next-generation approach for scientific machine learning and provide rigorous evidence to guide model selection in differential equation solving.

</details>


### [191] [A structure-preserving & objective discretisation of SO(3)-matrix rotation fields for finite Cosserat micropolar continua](https://arxiv.org/abs/2602.15147)
*Lucca Schek,Peter Lewintan,Wolfgang Müller,Ingo Muench,Andreas Zilian,Stéphane P. A. Bordas,Patrizio Neff,Adam Sky*

Main category: math.NA

TL;DR: 提出Γ-SPIN方法，通过测地线插值保持Cosserat旋转张量的客观性，同时通过降正则性投影缓解锁定效应，确保材料参数极限下的物理约束和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统插值方法在有限应变Cosserat微极模型中难以同时保持物理约束（材料参数极限）和客观性（刚体运动不变性），且存在锁定效应问题。

Method: 1) 使用测地线元素插值Cosserat旋转张量以保持客观性；2) 通过降正则性投影缓解锁定：先将旋转张量插值到Nédélec空间降低正则性，再投影回旋转李群；3) 构建低正则性投影插值，使离散Cosserat旋转张量与离散变形张量的极分解部分匹配。

Result: 方法在多个基准问题上证明了其一致性、稳定性和最优性，在复杂弯曲域上相比传统插值技术表现出更优效果，特别是在Cosserat偶极模量趋于无穷大的渐近极限下保持稳定行为。

Conclusion: Γ-SPIN方法成功解决了Cosserat微极模型插值中的客观性保持、物理约束满足和锁定效应缓解问题，为复杂几何域上的数值模拟提供了可靠工具。

Abstract: We introduce a new method, dubbed \textbf{\textit{Geometric Structure-Preserving Interpolation (Γ-SPIN)}}, to simultaneously preserve physics-constraints inherent in the material parameter limits of the finite-strain Cosserat micropolar model, and satisfy objectivity under superimposed rigid body motions. The method advocates to interpolate the Cosserat rotation tensor using geodesic elements, which maintain objectivity and correctly represent curvature measures. At the same time, it proposes relaxing the interaction between the rotation tensor and the deformation tensor to alleviate locking effects. This relaxation is achieved in two steps. First, the regularity of the Cosserat rotation tensor is reduced by interpolating it into the Nédélec space. Second, the resulting field is projected back onto the Lie-group of rotations. Together, these steps define a lower-regularity projection-based interpolation. This construction allows the discrete Cosserat rotation tensor to match the polar part of the discrete deformation tensor while remaining objective. This ensures stable behaviour in the asymptotic regime as the Cosserat couple modulus tends to infinity, which constrains the model towards its couple-stress limit. We establish the consistency, stability, and optimality of the proposed method through several benchmark problems. The study culminates in a demonstration of its efficacy on a more intricate curved domain, contrasted with outcomes obtained from conventional interpolation techniques.

</details>


### [192] [Equivalence of mixed and nonconforming methods on general polytopal partitions. Part I: Multiscale and projection methods](https://arxiv.org/abs/2602.15193)
*Simon Lemaire*

Main category: math.NA

TL;DR: 研究变量扩散问题中混合方法与非协调方法的等价性，聚焦多尺度方法和投影方法


<details>
  <summary>Details</summary>
Motivation: 探索在一般多面体剖分上，混合方法与非协调方法之间的等价关系，为数值方法提供理论支撑

Method: 建立多尺度方法中四种不同（无超采样）方法的一级等价性；为投影方法提供简单判据来验证原问题/混合问题的适定性和等价性

Result: 扩展了已有文献结果，建立了多尺度方法的等价关系；为投影方法提供了实用的检验判据；对自稳定混合方法提供了新视角

Conclusion: 本文建立了变量扩散问题中混合与非协调方法的等价性理论框架，为后续研究一般多面体单元方法奠定基础

Abstract: We study equivalence, in the context of a variable diffusion problem, between (conforming) mixed methods and (primal) nonconforming methods defined on potentially general polytopal partitions. In this first paper of a series of two, we focus on multiscale and projection methods. For multiscale methods, we establish the first-level equivalence between four different (oversampling-free) approaches, thereby broadening the results of [Chaumont-Frelet, Ern, Lemaire, Valentin; M2AN, 2022]. For projection methods, in turn, we provide a simple criterion (to be checked in practice) for primal/mixed well-posedness and equivalence to hold true. In the process, we also shed a new light on some self-stabilized hybrid methods. Part II of this work will address (general) polytopal element methods.

</details>


### [193] [A Patankar predictor-corrector approach for positivity-preserving time integration](https://arxiv.org/abs/2602.15271)
*Kamila Nurkhametova,Reid J. Gomillion,Amit N. Subrahmanya,Adrian Sandu*

Main category: math.NA

TL;DR: 提出一种模块化修正策略，应用于隐式Runge-Kutta方法（特别是SDIRK），通过阶段裁剪和比例缩放保证非负性和守恒性，为刚性生产-破坏系统构建保正性积分器。


<details>
  <summary>Details</summary>
Motivation: 许多自然过程（如化学反应、波动力学）建模为生产-破坏系统，需要保持正性和线性守恒律。经典时间积分器无法保证正性，可能产生负值或非物理解。

Method: 提出模块化修正策略，结合阶段裁剪和基于比例缩放的方法，应用于隐式Runge-Kutta方案（特别是SDIRK方法）。修正可在所有阶段或仅最终阶段应用，确保非负性和守恒律。

Result: 修正后的SDIRK方法在刚性ODE系统（Robertson、MAPK、平流层化学）和非线性PDE（KdV方程）中成功保持正性和守恒律，精度损失不大。仅最终阶段修正通常足够，全阶段修正可能在某些情况下扭曲动力学。显式RK方法修正后保持正性但收敛阶降至一阶。

Conclusion: 该框架为刚性生产-破坏系统提供了一种简单有效的保正性积分器构造方法，修正策略在保持数值解物理合理性的同时维持了可接受的精度。

Abstract: Many natural processes, such as chemical reactions and wave dynamics, are modeled as production-destruction (PD) systems that obey positivity and linear conservation laws. Classical time integrators do not guarantee positivity and can produce negative or nonphysical numerical solutions. This paper presents a modular correction strategy that can be applied to implicit Runge-Kutta schemes, in particular SDIRK methods. The strategy combines stage-wise clipping with a ratio-based scaling that enforces invariants and is guaranteed to yield nonnegative, conservative solutions. We provide a theoretical analysis of the corrected schemes and characterize their worst-case order of accuracy relative to the underlying base method. Numerical experiments on stiff ODE systems (Robertson, MAPK, stratospheric chemistry) and a nonlinear PDE (the Korteweg-De Vries equation) demonstrate that the corrected SDIRK methods preserve positivity and invariants without significant loss of accuracy. Importantly, corrections applied only to the final stage are sufficient in practice, while applying them at all stages may distort dynamics in some cases. For explicit Runge-Kutta schemes, the correction maintained positivity but reduced convergence to first order. These results show that the proposed framework provides a simple and effective way to construct positivity-preserving integrators for stiff PD systems.

</details>


### [194] [Total variation regularization with reduced basis in electrical impedance tomography](https://arxiv.org/abs/2602.15399)
*A. Hannukainen,N. Hyvönen,V. Toresen*

Main category: math.NA

TL;DR: 该研究将降基技术应用于总变分正则化的电阻抗断层成像，显著加速了重建算法，在保持重建质量和边缘增强特性的同时，将在线重建时间缩短至几秒。


<details>
  <summary>Details</summary>
Motivation: 电阻抗断层成像等逆椭圆边值问题中，总变分正则化虽然能有效增强边缘，但计算成本高昂。研究旨在通过降基技术加速重建过程，同时保持重建质量。

Method: 将降基技术与（平滑化）总变分正则化结合，采用滞后扩散算法、序列线性化和预条件LSQR迭代的组合重建算法，并在三维非结构化有限元网格上进行数值测试。

Result: 降基技术显著加速了重建过程，在模拟和实验数据上均实现了几秒内的在线重建时间，且没有显著损失重建质量或边缘增强特性。

Conclusion: 降基技术能有效加速总变分正则化在逆椭圆边值问题中的应用，为实时或近实时成像提供了可行方案，该方法也可推广到其他类似问题。

Abstract: This work considers using reduced basis techniques in connection to (smoothened) total variation regularization in electrical impedance tomography, but analogous ideas can also be used for other inverse elliptic boundary value problems. It is demonstrated that resorting to reduced bases can speed up a reconstruction algorithm based on combining the lagged diffusivity algorithm with sequential linearizations and preconditioned LSQR iteration without any significant loss of reconstruction quality or of the edge-enhancing nature of total variation regularization. The ideas are numerically tested in three dimensions on unstructured finite element meshes with both simulated and experimental data, resulting in online reconstruction times of only a few seconds on a standard laptop computer.

</details>


### [195] [A discrete gradient scheme for preserving QSR-dissipativity](https://arxiv.org/abs/2602.15445)
*Attila Karsai,Philipp Schulze*

Main category: math.NA

TL;DR: 提出基于离散梯度的结构保持时间离散化方法，用于保持具有二次供给率耗散系统的耗散特性


<details>
  <summary>Details</summary>
Motivation: 耗散动力系统的数值计算中，耗散特性容易恶化，特别是在非线性系统中，需要开发能保持系统结构特性的数值方法

Method: 基于离散梯度方法，为具有二次供给率的耗散系统设计结构保持时间离散化方案

Result: 提出了一类新的数值离散方案，能够在数值计算中保持系统的耗散特性

Conclusion: 离散梯度方法能有效解决耗散系统数值计算中特性恶化问题，为这类系统提供了可靠的数值离散方案

Abstract: The notion of dissipative dynamical systems provides a formal description of processes that cannot generate energy internally. For these systems, changes in energy can only occur due to an external energy supply or dissipation effects. Unfortunately, dissipative properties tend to deteriorate in numerical computations, especially in nonlinear systems. Discrete gradient methods can help mitigate this problem. In this paper, we present a class of structure-preserving time discretization schemes based on discrete gradients for a special class of systems that are dissipative with respect to a quadratic supply rate.

</details>


### [196] [A Model Order Reduction Method for Seismic Applications Using the Laplace Transform](https://arxiv.org/abs/2602.15517)
*Fernando Henriquez,Matthias Schlottbom*

Main category: math.NA

TL;DR: 提出了一种针对抽象波动问题的降阶建模策略，使用缩减基方法处理具有Ricker小波源项的波动方程，证明了指数收敛性并建立了与参数无关的误差界。


<details>
  <summary>Details</summary>
Motivation: 针对地震建模中的声波和弹性波方程，需要处理具有Ricker小波源项的波动问题。现有方法在时间域中的收敛性分析不足，特别是对于小波形状和宽度参数的影响缺乏明确的理论保证。

Method: 采用缩减基模型降阶方法，基于拉普拉斯域MOR方法构建缩减基，用于近似时间域解。通过理论分析建立了收敛界，该界对控制Ricker小波形状和宽度的参数具有鲁棒性。

Result: 证明了该方法能够以指数精度近似时间域解，收敛界明确且与参数无关，识别了由小波初始值决定的内在精度限制。误差界独立于底层Galerkin离散化空间，提供了可计算的指数收敛条件。

Conclusion: 该方法为具有Ricker小波源项的波动问题提供了有效的模型降阶策略，具有理论保证的指数收敛性，适用于地震建模等应用场景。

Abstract: We devise and analyze a reduced basis model order reduction (MOR) strategy for an abstract wave problem with vanishing initial conditions and a source term given by the product of a temporal Ricker wavelet and a spatial profile. Such wave problems comprise the acoustic and elastic wave equations, with applications in seismic modeling. Motivated by recent Laplace-domain MOR methodologies, we construct reduced bases that approximate the time-domain solution with exponential accuracy. We prove convergence bounds that are explicit and robust with respect to the parameters controlling the Ricker wavelet's shape and width and identify an intrinsic accuracy limit dictated by the wavelet's value at the initial time. In particular, the resulting error bound is independent of the underlying Galerkin discretization space and yields computable criteria for the regime in which exponential convergence is observed.

</details>
