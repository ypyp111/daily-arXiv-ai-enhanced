<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 156]
- [cs.CL](#cs.CL) [Total: 81]
- [math.NA](#math.NA) [Total: 12]
- [cs.LG](#cs.LG) [Total: 110]
- [cs.AI](#cs.AI) [Total: 55]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 12]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones](https://arxiv.org/abs/2508.11696)
*Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman*

Main category: cs.CV

TL;DR: 基于YOLOv8改进的深度学习实时吸烟检测系统，在消防出口监控中达到78.90%的回归率和83.70% mAP，在Jetson Xavier NX边缘设备上实现了52-97ms的每次推理速度


<details>
  <summary>Details</summary>
Motivation: 为满足消防出口监控的关键安全要求，需要开发能够在复杂监控环境下准确检测吸烟行为的实时系统

Method: 使用8,124张图片的数据集，包含20种不同场景和2,708个低光环境样本。评估YOLOv8、YOLOv11、YOLOv12三种模型，并在YOLOv8基础上增加特殊结构构建自定义模型

Result: 提出模型表现最优，达到78.90%回归率和83.70% mAP@50，在多种环境下都能实现优秀的目标检测。在Jetson Xavier NX边缘设备上通过多线程运算实现了52-97ms/次的推理速度

Conclusion: 该系统为公共安全监控提供了稳健且适应性强的平台，能够支持自动遵循监管要求，适合实时性要求高的应用场景

Abstract: A deep learning real-time smoking detection system for CCTV surveillance of
fire exit areas is proposed due to critical safety requirements. The dataset
contains 8,124 images from 20 different scenarios along with 2,708 raw samples
demonstrating low-light areas. We evaluated three advanced object detection
models: YOLOv8, YOLOv11, and YOLOv12, followed by development of a custom model
derived from YOLOv8 with added structures for challenging surveillance
contexts. The proposed model outperformed the others, achieving a recall of
78.90 percent and mAP at 50 of 83.70 percent, delivering optimal object
detection across varied environments. Performance evaluation on multiple edge
devices using multithreaded operations showed the Jetson Xavier NX processed
data at 52 to 97 milliseconds per inference, establishing its suitability for
time-sensitive operations. This system offers a robust and adaptable platform
for monitoring public safety and enabling automatic regulatory compliance.

</details>


### [2] [Separating Knowledge and Perception with Procedural Data](https://arxiv.org/abs/2508.11697)
*Adrián Rodríguez-Muñoz,Manel Baradad,Phillip Isola,Antonio Torralba*

Main category: cs.CV

TL;DR: 通过仅使用程序生成数据训练表征模型，结合视觉内存数据库实现了与实际图片完全隔离的强大性能，在多个认知任务上接近或超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统视觉模型依赖实际图片数据的问题，通过程序生成数据实现完全的数据隔离，同时保持强大的表征学习能力。

Method: 仅使用程序生成数据训练表征模型，通过显式的视觉内存数据库（参考图片嵌入集合）来处理视视似性、分类和语义分割任务，无需进一步训练。

Result: 在NIGHTS视视似性任务上与Places训练模型相差仅1%，在CUB200和Flowers102细粒度分类任务上分别超15%和8%，在ImageNet-1K分类上相差10%。零样本分割任务上COCO的R²指标与实际数据训练模型相差10%以内。

Conclusion: 程序生成数据模型可以实现与实际图片完全隔离的同时保持强大性能。性能差距的主要原因是程序模型中同一物体不同部分的表征相似性低，导致内存搜索错误。

Abstract: We train representation models with procedural data only, and apply them on
visual similarity, classification, and semantic segmentation tasks without
further training by using visual memory -- an explicit database of reference
image embeddings. Unlike prior work on visual memory, our approach achieves
full compartmentalization with respect to all real-world images while retaining
strong performance. Compared to a model trained on Places, our procedural model
performs within $1\%$ on NIGHTS visual similarity, outperforms by $8\%$ and
$15\%$ on CUB200 and Flowers102 fine-grained classification, and is within
$10\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot
segmentation, achieving an $R^2$ on COCO within $10\%$ of the models trained on
real data. Finally, we analyze procedural versus real data models, showing that
parts of the same object have dissimilar representations in procedural models,
resulting in incorrect searches in memory and explaining the remaining
performance gap.

</details>


### [3] [FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis](https://arxiv.org/abs/2508.11721)
*Ke Zou,Jocelyn Hui Lin Goh,Yukun Zhou,Tian Lin,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Rui Santos,Gabor M. Somfai,Huazhu Fu,Haoyu Chen,Pearse A. Keane,Ching-Yu Cheng,Yih Chung Tham*

Main category: cs.CV

TL;DR: 这是首次系统性评估眼科基础模型的研究，包括单模型和融合模型的性能测试，发现DINORET和RetiZero在眼部和系统性疾病预测中表现最佳，融合策略在某些病正中有轻微改善


<details>
  <summary>Details</summary>
Motivation: 眼科基础模型很多，但不清楚哪个性能最好，是否在不同任务上都表现一致，以及融合所有模型的效果如何

Method: 提出FusionFM评估框架，包括两种融合方法，测试4个先进基础模型（RETFound、VisionFM、RetiZero、DINORET）在眼部疾病检测（青光眼、糖尿病视网膜病变、黄斑变性）和系统性疾病预测（糖尿病、高血压）中的表现

Result: DINORET和RetiZero在眼部和系统性疾病任务中表现最优，RetiZero在外部数据集上具有更强的沿午性。融合策略在预测青光眼、黄斑变性和高血压时有轻微改善，但预测系统性疾病特别是外部群体的高血压仍面临挑战

Conclusion: 研究提供了基于证据的眼科基础模型评估，强调了模型融合的优势，并指明了提高临床应用性的策略

Abstract: Foundation models (FMs) have shown great promise in medical image analysis by
improving generalization across diverse downstream tasks. In ophthalmology,
several FMs have recently emerged, but there is still no clear answer to
fundamental questions: Which FM performs the best? Are they equally good across
different tasks? What if we combine all FMs together? To our knowledge, this is
the first study to systematically evaluate both single and fused ophthalmic
FMs. To address these questions, we propose FusionFM, a comprehensive
evaluation suite, along with two fusion approaches to integrate different
ophthalmic FMs. Our framework covers both ophthalmic disease detection
(glaucoma, diabetic retinopathy, and age-related macular degeneration) and
systemic disease prediction (diabetes and hypertension) based on retinal
imaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM,
RetiZero, and DINORET) using standardized datasets from multiple countries and
evaluated their performance using AUC and F1 metrics. Our results show that
DINORET and RetiZero achieve superior performance in both ophthalmic and
systemic disease tasks, with RetiZero exhibiting stronger generalization on
external datasets. Regarding fusion strategies, the Gating-based approach
provides modest improvements in predicting glaucoma, AMD, and hypertension.
Despite these advances, predicting systemic diseases, especially hypertension
in external cohort remains challenging. These findings provide an
evidence-based evaluation of ophthalmic FMs, highlight the benefits of model
fusion, and point to strategies for enhancing their clinical applicability.

</details>


### [4] [UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction](https://arxiv.org/abs/2508.11728)
*Chunxia Ren,Ning Zhu,Yue Lai,Gui Chen,Ruijie Wang,Yangyi Hu,Suyao Liu,Shuwen Mao,Hong Su,Yu Zhang,Li Xiao*

Main category: cs.CV

TL;DR: UniDCF是一个统一的多模态深度学习框架，能够通过点云和多视角图像的融合编码来重建多种牙颌面硬组织，解决了现有单模态方法在解剖保真度、计算效率和跨组织适应性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 牙颌面硬组织缺损严重影响患者的生理功能、面部美观和心理健康，当前深度学习模型仅限于单组织场景和特定模态成像输入，导致泛化能力差，需要在解剖保真度、计算效率和跨组织适应性之间做出权衡。

Method: UniDCF采用多模态融合编码方法，结合点云和多视角图像的互补优势，并引入基于分数的去噪模块来优化表面平滑度。研究构建了最大的多模态数据集，包含6,609名患者的口内扫描、CBCT和CT数据，共计54,555个标注实例。

Result: 评估显示UniDCF在几何精度、结构完整性和空间准确性方面优于现有最先进方法。临床模拟表明UniDCF将重建设计时间减少了99%，临床医生接受度超过94%。

Conclusion: UniDCF实现了快速、自动化、高保真度的重建，支持个性化和精确的修复治疗，简化了临床工作流程，改善了患者治疗效果。

Abstract: Dentocraniofacial hard tissue defects profoundly affect patients'
physiological functions, facial aesthetics, and psychological well-being,
posing significant challenges for precise reconstruction. Current deep learning
models are limited to single-tissue scenarios and modality-specific imaging
inputs, resulting in poor generalizability and trade-offs between anatomical
fidelity, computational efficiency, and cross-tissue adaptability. Here we
introduce UniDCF, a unified framework capable of reconstructing multiple
dentocraniofacial hard tissues through multimodal fusion encoding of point
clouds and multi-view images. By leveraging the complementary strengths of each
modality and incorporating a score-based denoising module to refine surface
smoothness, UniDCF overcomes the limitations of prior single-modality
approaches. We curated the largest multimodal dataset, comprising intraoral
scans, CBCT, and CT from 6,609 patients, resulting in 54,555 annotated
instances. Evaluations demonstrate that UniDCF outperforms existing
state-of-the-art methods in terms of geometric precision, structural
completeness, and spatial accuracy. Clinical simulations indicate UniDCF
reduces reconstruction design time by 99% and achieves clinician-rated
acceptability exceeding 94%. Overall, UniDCF enables rapid, automated, and
high-fidelity reconstruction, supporting personalized and precise restorative
treatments, streamlining clinical workflows, and enhancing patient outcomes.

</details>


### [5] [Ovis2.5 Technical Report](https://arxiv.org/abs/2508.11737)
*Shiyin Lu,Yang Li,Yu Xia,Yuwei Hu,Shanshan Zhao,Yanqing Ma,Zhichao Wei,Yinglun Li,Lunhao Duan,Jianshan Zhao,Yuxuan Han,Haijun Li,Wanying Chen,Junke Tang,Chengkun Hou,Zhixing Du,Tianli Zhou,Wenjie Zhang,Huping Ding,Jiahe Li,Wen Li,Gui Hu,Yiliang Gu,Siran Yang,Jiamang Wang,Hailong Sun,Yibo Wang,Hui Sun,Jinlong Huang,Yuping He,Shengze Shi,Weihong Zhang,Guodong Zheng,Junpeng Jiang,Sensen Gao,Yi-Feng Wu,Sijia Chen,Yuhui Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: Ovis2.5是Ovis2的升级版本，采用原生分辨率视觉Transformer处理图像，避免固定分辨率分块带来的质量下降，并引入反射推理能力。模型通过五阶段课程训练，在OpenCompass多模态排行榜上取得78.3分，在40B参数以下开源MLLM中达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 为了解决固定分辨率图像处理导致的细节丢失问题，并提升多模态推理能力，特别是在视觉密集内容（如复杂图表）上的表现。

Method: 集成原生分辨率视觉Transformer处理可变分辨率图像；训练模型进行反射推理（自检查和修订）；采用五阶段课程训练（视觉预训练、多模态预训练、大规模指令调优、DPO和GRPO对齐增强）；使用多模态数据打包和混合并行技术加速训练。

Result: Ovis2.5-9B在OpenCompass平均得分78.3，相比前代Ovis2-8B有显著提升；Ovis2.5-2B得分73.9，在同规模模型中达到SOTA；在STEM基准测试、接地任务、视频任务和复杂图表分析方面均取得领先结果。

Conclusion: Ovis2.5通过原生分辨率处理和反射推理机制，在多模态理解和推理能力上实现了显著提升，特别是在资源受限的设备上表现出色，为开源MLLM设立了新的性能标杆。

Abstract: We present Ovis2.5, a successor to Ovis2 designed for native-resolution
visual perception and strong multimodal reasoning. Ovis2.5 integrates a
native-resolution vision transformer that processes images at their native,
variable resolutions, avoiding the degradation from fixed-resolution tiling and
preserving both fine detail and global layout -- crucial for visually dense
content like complex charts. To strengthen reasoning, we train the model to
move beyond linear chain-of-thought and perform reflection -- including
self-checking and revision. This advanced capability is exposed as an optional
"thinking mode" at inference time, allowing users to trade latency for enhanced
accuracy on difficult inputs. The model is trained via a comprehensive
five-phase curriculum that progressively builds its skills. The process begins
with foundational visual and multimodal pretraining, advances through
large-scale instruction tuning, and culminates in alignment and reasoning
enhancement using DPO and GRPO. To scale these upgrades efficiently, we employ
multimodal data packing and hybrid parallelism, yielding a significant
end-to-end speedup. We release two open-source models: Ovis2.5-9B and
Ovis2.5-2B. The latter continues the "small model, big performance" philosophy
of Ovis2, making it ideal for resource-constrained, on-device scenarios. On the
OpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a
substantial improvement over its predecessor, Ovis2-8B, and achieving
state-of-the-art results among open-source MLLMs in the sub-40B parameter
range; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate
scores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong
capabilities on grounding and video tasks, and achieves open-source SOTA at its
scale for complex chart analysis.

</details>


### [6] [VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models](https://arxiv.org/abs/2508.11801)
*Ming Cheng,Tong Wu,Jiazhen Hu,Jiaying Gong,Hoda Eldardiry*

Main category: cs.CV

TL;DR: 首个公开的视频到文本电商属性值提取数据集VideoAVE，涵盖14个领域和172个属性，通过CLIP-MoE筛选系统确保数据质量，并建立了基准测试显示视频AVE任务仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有AVE数据集主要限于文本到文本或图像到文本设置，缺乏对产品视频、多样属性覆盖和公开可用性的支持。

Method: 提出CLIP基础的混合专家系统(CLIP-MoE)进行后置筛选，移除不匹配的视频-产品对，构建了224k训练数据和25k评估数据的精细数据集。

Result: 通过评测多个状态上的视频视觉语言模型，发现视频到文本AVE任务仍具有挑战性，尤其是在开放设置下，现有模型在利用时间信息方面仍有提升空间。

Conclusion: VideoAVE为视频基于的属性值提取提供了重要的数据资源和评估标准，显示了该领域的挑战性和发展潜力，促进更先进视觉语言模型的发展。

Abstract: Attribute Value Extraction (AVE) is important for structuring product
information in e-commerce. However, existing AVE datasets are primarily limited
to text-to-text or image-to-text settings, lacking support for product videos,
diverse attribute coverage, and public availability. To address these gaps, we
introduce VideoAVE, the first publicly available video-to-text e-commerce AVE
dataset across 14 different domains and covering 172 unique attributes. To
ensure data quality, we propose a post-hoc CLIP-based Mixture of Experts
filtering system (CLIP-MoE) to remove the mismatched video-product pairs,
resulting in a refined dataset of 224k training data and 25k evaluation data.
In order to evaluate the usability of the dataset, we further establish a
comprehensive benchmark by evaluating several state-of-the-art video vision
language models (VLMs) under both attribute-conditioned value prediction and
open attribute-value pair extraction tasks. Our results analysis reveals that
video-to-text AVE remains a challenging problem, particularly in open settings,
and there is still room for developing more advanced VLMs capable of leveraging
effective temporal information. The dataset and benchmark code for VideoAVE are
available at: https://github.com/gjiaying/VideoAVE

</details>


### [7] [An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation](https://arxiv.org/abs/2508.11803)
*Azam Nouri*

Main category: cs.CV

TL;DR: 研究表明仅使用二阶几何特征（平面曲率大小、曲率符号和梯度方向）就能驱动MLP分类器实现手写字符识别，在MNIST数字上达到97%准确率，在EMNIST字母上达到89%准确率。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以不依赖卷积神经网络，仅使用二阶几何特征就能实现有效的手写字符识别，提供一种可解释的替代方案。

Method: 使用手工设计的三个特征图（曲率大小、曲率符号、梯度方向）作为多层感知机(MLP)的输入进行分类。

Result: 在MNIST数字数据集上达到97%准确率，在EMNIST字母数据集上达到89%准确率。

Conclusion: 曲率基表示对手写字符图像具有强大的判别能力，深度学习优势可以通过可解释的手工设计特征实现。

Abstract: This study investigates whether second-order geometric cues - planar
curvature magnitude, curvature sign, and gradient orientation - are sufficient
on their own to drive a multilayer perceptron (MLP) classifier for handwritten
character recognition (HCR), offering an alternative to convolutional neural
networks (CNNs). Using these three handcrafted feature maps as inputs, our
curvature-orientation MLP achieves 97 percent accuracy on MNIST digits and 89
percent on EMNIST letters. These results underscore the discriminative power of
curvature-based representations for handwritten character images and
demonstrate that the advantages of deep learning can be realized even with
interpretable, hand-engineered features.

</details>


### [8] [Labels or Input? Rethinking Augmentation in Multimodal Hate Detection](https://arxiv.org/abs/2508.11808)
*Sahajpreet Singh,Rongxin Ouyang,Subhayan Mukerjee,Kokil Jaidka*

Main category: cs.CV

TL;DR: 这篇论文提出了一种双重探索方法来改善多模态恨恼伪装内容检测，包括提示优化框架和多模态数据增强管道，以提升模型的稳健性和普通性。


<details>
  <summary>Details</summary>
Motivation: 现代网络中多模态恨恼伪装内容流行，有害意图通过文本和图像的细微交互以幽默或让谐的形式传递。虽然视觉-语言模型有进步，但缺乏细粒度监督支持且容易受隐式恨恼语言影响。

Method: 1）提出提示优化框架，系统性变化提示结构、监督细度和训练模态。
2）引入多模态数据增强管道，通过多代理LLM-VLM设置生成2,479个反事实中立伪装内容，通过隔离和重写恨恼模态来减少偏偏相关性。

Result: 结构化提示提高了小模型的稳健性，InternVL2在二元和级别设置中获得最佳F1分数。数据增强管道成功减少了偏偏相关性，改善了分类器的普通性。

Conclusion: 提示结构和数据组成与模型大小同样关键，目标增强可支持更可信豖和上下文敏感的恨恼检测，为构建稳健公平的视觉-语言模型提供了新方向。

Abstract: The modern web is saturated with multimodal content, intensifying the
challenge of detecting hateful memes, where harmful intent is often conveyed
through subtle interactions between text and image under the guise of humor or
satire. While recent advances in Vision-Language Models (VLMs) show promise,
these models lack support for fine-grained supervision and remain susceptible
to implicit hate speech. In this paper, we present a dual-pronged approach to
improve multimodal hate detection. First, we propose a prompt optimization
framework that systematically varies prompt structure, supervision granularity,
and training modality. We show that prompt design and label scaling both
influence performance, with structured prompts improving robustness even in
small models, and InternVL2 achieving the best F1-scores across binary and
scaled settings. Second, we introduce a multimodal data augmentation pipeline
that generates 2,479 counterfactually neutral memes by isolating and rewriting
the hateful modality. This pipeline, powered by a multi-agent LLM-VLM setup,
successfully reduces spurious correlations and improves classifier
generalization. Our approaches inspire new directions for building synthetic
data to train robust and fair vision-language models. Our findings demonstrate
that prompt structure and data composition are as critical as model size, and
that targeted augmentation can support more trustworthy and context-sensitive
hate detection.

</details>


### [9] [Towards Understanding 3D Vision: the Role of Gaussian Curvature](https://arxiv.org/abs/2508.11825)
*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 这篇论文研究了高斯曲率在3D表面建模中的作用，提出高斯曲率作为一种稀疏缩结表达和几何先验知识，可以改善3D重建效果并作为无监督评价指标。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法虽然在立体匹配和单目深度重建中取得显著成功，但缺乏可直接分析、跨模态转移或系统控制实验的显式3D几何模型。

Method: 通过在Middlebury立体数据集上进行实验，研究高斯曲率在3D表面建模中的特性与应用。高斯曲率是一种在观察者或坐标系变换下不变的量。

Result: 研究发现：(i)高斯曲率提供了稀疏缩结的3D表面描述；(ii)当前最先进的单目和立体方法隐式考虑了高斯曲率，但无法提取显式模块；(iii)高斯曲率可作为几何先验知识改善3D表面重建；(iv)可作为立体方法的无监督评价指标。

Conclusion: 高斯曲率在3D表面建模中具有重要价值，既可作为稀疏表征描述，也可作为几何先验知识提升3D重建质量，还可用于无监督评价，为现代计算机视觉方法提供了可解释的几何基础。

Abstract: Recent advances in computer vision have predominantly relied on data-driven
approaches that leverage deep learning and large-scale datasets. Deep neural
networks have achieved remarkable success in tasks such as stereo matching and
monocular depth reconstruction. However, these methods lack explicit models of
3D geometry that can be directly analyzed, transferred across modalities, or
systematically modified for controlled experimentation. We investigate the role
of Gaussian curvature in 3D surface modeling. Besides Gaussian curvature being
an invariant quantity under change of observers or coordinate systems, we
demonstrate using the Middlebury stereo dataset that it offers: (i) a sparse
and compact description of 3D surfaces, (ii) state-of-the-art monocular and
stereo methods seem to implicitly consider it, but no explicit module of such
use can be extracted, (iii) a form of geometric prior that can inform and
improve 3D surface reconstruction, and (iv) a possible use as an unsupervised
metric for stereo methods.

</details>


### [10] [From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images](https://arxiv.org/abs/2508.11826)
*Dehn Xu,Tim Katzke,Emmanuel Müller*

Main category: cs.CV

TL;DR: 这篇论文系统性评估了多种图像到图表示转换方法在图级异常检测任务中的效果，发现颜色描述符最重要，形状和纹理特征能显著提升性能，在无监督、弱监督和全监督模式下都取得了竞争力的AUC-ROC成绩。


<details>
  <summary>Details</summary>
Motivation: 虽然图神经网络已广泛应用于图像演算的图表示下游任务，但尚无研究系统性比较不同图像到图转换方法在图级异常检测任务中的效果。

Method: 系统性评估多种分割方案、边缘构建策略和节点特征集（包括颜色、纹理、形状描述符），在皮肤镜图像上进行广泛实验，测试无监督、弱监督和全监督三种模式下的性能和效率。

Result: 颜色描述符单独使用效果最佳，加入形状和纹理特征能持续提升检测效果。最佳无监督配置达到0.805 AUC-ROC，弱监督提升至0.872，全监督达到0.914 AUC-ROC。

Conclusion: 该研究为图像到图转换方法的选择提供了系统性指南，证明了这些方法在图级异常检测任务中的效果，而且无需依赖预训练的基础模型。

Abstract: Graph Neural Networks (GNNs) have emerged as a powerful approach for
graph-based machine learning tasks. Previous work applied GNNs to image-derived
graph representations for various downstream tasks such as classification or
anomaly detection. These transformations include segmenting images, extracting
features from segments, mapping them to nodes, and connecting them. However, to
the best of our knowledge, no study has rigorously compared the effectiveness
of the numerous potential image-to-graph transformation approaches for
GNN-based graph-level anomaly detection (GLAD). In this study, we
systematically evaluate the efficacy of multiple segmentation schemes, edge
construction strategies, and node feature sets based on color, texture, and
shape descriptors to produce suitable image-derived graph representations to
perform graph-level anomaly detection. We conduct extensive experiments on
dermoscopic images using state-of-the-art GLAD models, examining performance
and efficiency in purely unsupervised, weakly supervised, and fully supervised
regimes. Our findings reveal, for example, that color descriptors contribute
the best standalone performance, while incorporating shape and texture features
consistently enhances detection efficacy. In particular, our best unsupervised
configuration using OCGTL achieves a competitive AUC-ROC score of up to 0.805
without relying on pretrained backbones like comparable image-based approaches.
With the inclusion of sparse labels, the performance increases substantially to
0.872 and with full supervision to 0.914 AUC-ROC.

</details>


### [11] [Recent Advances in Transformer and Large Language Models for UAV Applications](https://arxiv.org/abs/2508.11834)
*Hamza Kheddar,Yassine Habchi,Mohamed Chahine Ghanem,Mustapha Hemis,Dusit Niyato*

Main category: cs.CV

TL;DR: 这篇综述性论文系统分析了Transformer模型在无人机系统中的应用，包括关注机制、混合结构、强化学习咊大语言模型，并提出统一分类法和性能对比。


<details>
  <summary>Details</summary>
Motivation: 追踪Transformer模型在无人机领域的快速发展，系统化总结并引导研究者理解和推进该技术。

Method: 采用结构化的综述方法，包括统一分类、性能对比表格、数据集评估和模拟器分析。

Result: 完整展示了Transformer在精准农业、自主导航等UAV应用中的进展，持续性能分析和问题识别。

Conclusion: 识别了计算效率和实时部署的挑战，并提出了未来研究方向，为Transformer驱动的UAV技术提供了指导。

Abstract: The rapid advancement of Transformer-based models has reshaped the landscape
of uncrewed aerial vehicle (UAV) systems by enhancing perception,
decision-making, and autonomy. This review paper systematically categorizes and
evaluates recent developments in Transformer architectures applied to UAVs,
including attention mechanisms, CNN-Transformer hybrids, reinforcement learning
Transformers, and large language models (LLMs). Unlike previous surveys, this
work presents a unified taxonomy of Transformer-based UAV models, highlights
emerging applications such as precision agriculture and autonomous navigation,
and provides comparative analyses through structured tables and performance
benchmarks. The paper also reviews key datasets, simulators, and evaluation
metrics used in the field. Furthermore, it identifies existing gaps in the
literature, outlines critical challenges in computational efficiency and
real-time deployment, and offers future research directions. This comprehensive
synthesis aims to guide researchers and practitioners in understanding and
advancing Transformer-driven UAV technologies.

</details>


### [12] [ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages](https://arxiv.org/abs/2508.11854)
*Matthew Hull,Haoyang Yang,Pratham Mehta,Mansi Phute,Aeree Cho,Haorang Wang,Matthew Lau,Wenke Lee,Wilian Lunardi,Martin Andreoni,Polo Chau*

Main category: cs.CV

TL;DR: 首个针对3D高斯拟合的黑盒攻击，通过视角依赖性调色在特定视角嵌入恶意内容，影响多种目标检测器


<details>
  <summary>Details</summary>
Motivation: 3D高斯拟合技术在安全关键任务中快速应用，需要研究恶意攻击者如何突破其安全性，曝露潜在风险

Method: 利用标准3DGS晕写方法创建视角特异性调色，在物体表面嵌入仅在特定视角可见的恶意内容，无需模型架构或权重信息

Result: 攻击在真实物体重建和合成场景中都有效，能够成功攻击单阶段、多阶段和Transformer基础的多种目标检测器

Conclusion: 曝露了3DGS在自主导航等关键任务中的新形安全风险，需要重视这种黑盒攻击潜在威胁

Abstract: As 3D Gaussian Splatting (3DGS) gains rapid adoption in safety-critical tasks
for efficient novel-view synthesis from static images, how might an adversary
tamper images to cause harm? We introduce ComplicitSplat, the first attack that
exploits standard 3DGS shading methods to create viewpoint-specific camouflage
- colors and textures that change with viewing angle - to embed adversarial
content in scene objects that are visible only from specific viewpoints and
without requiring access to model architecture or weights. Our extensive
experiments show that ComplicitSplat generalizes to successfully attack a
variety of popular detector - both single-stage, multi-stage, and
transformer-based models on both real-world capture of physical objects and
synthetic scenes. To our knowledge, this is the first black-box attack on
downstream object detectors using 3DGS, exposing a novel safety risk for
applications like autonomous navigation and other mission-critical robotic
systems.

</details>


### [13] [Impact of Clinical Image Quality on Efficient Foundation Model Finetuning](https://arxiv.org/abs/2508.11864)
*Yucheng Tang,Pawel Rajwa,Alexander Ng,Yipei Wang,Wen Yan,Natasha Thorley,Aqua Asif,Clare Allen,Louise Dickinson,Francesco Giganti,Shonit Punwani,Daniel C. Alexander,Veeru Kasivisvanathan,Yipeng Hu*

Main category: cs.CV

TL;DR: 本文评估了医学影像基础模型ProFound在前列腺多参数MRI中的标签效率，发现图像质量分布及其在微调与测试之间的不匹配显著影响模型性能。当质量比例一致时，微调需要的标注数据远少于从头训练，但标签效率取决于图像质量分布。


<details>
  <summary>Details</summary>
Motivation: 医学影像基础模型在标签效率方面显示出潜力，但图像质量变化如何影响标签高效的微调以及微调模型的泛化能力尚不清楚。本文旨在系统评估前列腺MRI中图像质量分布对基础模型微调性能的影响。

Method: 使用在前列腺MRI大数据集上预训练的领域特定视觉基础模型ProFound，通过系统变化微调和评估集中的高/低质量图像比例来实验研究图像质量分布对模型泛化能力的影响。

Result: 研究发现：a) 微调集和测试集之间高/低质量图像比例的变化导致下游性能显著差异；b) 微调集中足够高质量图像对维持强性能至关重要；c) 当质量比例一致时，微调需要的标注数据远少于从头训练，但标签效率取决于图像质量分布。

Conclusion: 研究强调了在微调和部署之间评估和对齐质量分布的重要性，以及为特定下游任务制定微调数据质量标准的必要性。量化微调和部署中的图像质量对于充分实现基础模型的数据和计算效率优势具有重要价值。

Abstract: Foundation models in medical imaging have shown promising label efficiency,
achieving high downstream performance with only a fraction of annotated data.
Here, we evaluate this in prostate multiparametric MRI using ProFound, a
domain-specific vision foundation model pretrained on large-scale prostate MRI
datasets. We investigate how variable image quality affects label-efficient
finetuning by measuring the generalisability of finetuned models. Experiments
systematically vary high-/low-quality image ratios in finetuning and evaluation
sets. Our findings indicate that image quality distribution and its
finetune-and-test mismatch significantly affect model performance. In
particular: a) Varying the ratio of high- to low-quality images between
finetuning and test sets leads to notable differences in downstream
performance; and b) The presence of sufficient high-quality images in the
finetuning set is critical for maintaining strong performance, whilst the
importance of matched finetuning and testing distribution varies between
different downstream tasks, such as automated radiology reporting and prostate
cancer detection.When quality ratios are consistent, finetuning needs far less
labeled data than training from scratch, but label efficiency depends on image
quality distribution. Without enough high-quality finetuning data, pretrained
models may fail to outperform those trained without pretraining. This
highlights the importance of assessing and aligning quality distributions
between finetuning and deployment, and the need for quality standards in
finetuning data for specific downstream tasks. Using ProFound, we show the
value of quantifying image quality in both finetuning and deployment to fully
realise the data and compute efficiency benefits of foundation models.

</details>


### [14] [AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition](https://arxiv.org/abs/2508.11870)
*Ying Huang,Yuanbin Man,Wenqi Jia,Zhengzhong Tu,Junzhou Huang,Miao Yin*

Main category: cs.CV

TL;DR: 通过张量环分解技术，AdaRing框架在保持性能的同时将训练参数量减少90%，实现了超轻量的视觉-语言模型微调


<details>
  <summary>Details</summary>
Motivation: 解决现有adapter微调方法的两大问题：跨层冗余导致压缩率有限，同质化adapter表征能力不足

Method: 采用张量环分解技术，将adapter构造为层共享的张量核和层特异的切片，并在泛化感知指导下使不同秩的adapter协作完成任务

Result: 在各种任务上达到了最先进的性能水平，同时平均训练参数量减少90%

Conclusion: AdaRing提供了一种高效的超轻量视觉-语言模型微调方案，通过张量分解和多样化adapter协作有效解决了现有方法的限制

Abstract: Adapter-based fine-tuning has gained remarkable attention in adapting large
pre-trained vision language models (VLMs) for a wide range of downstream tasks
efficiently. In this paradigm, only the inserted adapters are fine-tuned,
without the need for training the original VLM backbone. Existing works scale
adapters by integrating them into every layer of VLMs to increase the capacity
of adapters. However, these methods face two primary limitations: 1) limited
compression rate due to ignoring cross-layer redundancy, and 2) limited
representational capacity across homogeneous adapters. In this paper, we
propose a novel vision-language fine-tuning framework based on cross-layer
tensor ring decomposition (TRD) with the integration and collaboration of
diverse adapters, called AdaRing, achieving ultra-light parameter-efficient
adaptation of VLMs on various tasks. To remove the high redundancy that exists
among adapters across layers, we exploit the tensor-level low-rankness to
formulate adapters as layer-shared tensor cores and layer-specific slices.
Moreover, guided by generalization-aware fine-tuning, diverse rank-driven
adapters cooperate to handle tasks that require different representations. Our
experiments show that the proposed AdaRing achieves the state-of-the-art
performance while reducing average training parameters by 90%.

</details>


### [15] [EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models](https://arxiv.org/abs/2508.11886)
*Wenhui Zhu,Xiwen Chen,Zhipeng Wang,Shao Tang,Sayan Ghosh,Xuanzhao Dong,Rajat Koner,Yalin Wang*

Main category: cs.CV

TL;DR: 通过视觉token剪枝技术，在保持分割准确性的同时实现图像任务5倍、视频任务3.5倍的速度提升


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在指令视觉分割任务中的推理成本过高，特别是在视频处理时

Method: 提出EVTP-IV方法，基于k-center算法集成空间信息，选择突出代表性的视觉token子集

Result: 在标准IVS测试集上实现5倍速度提升（视频）和3.5倍（图像），仅使用20%token却保持相当的准确性

Conclusion: 该方法通过简单有效的token剪枝，在大幅提升MLLM模型推理效率的同时保持了分割性能

Abstract: Instructed Visual Segmentation (IVS) tasks require segmenting objects in
images or videos based on natural language instructions. While recent
multimodal large language models (MLLMs) have achieved strong performance on
IVS, their inference cost remains a major bottleneck, particularly in video. We
empirically analyze visual token sampling in MLLMs and observe a strong
correlation between subset token coverage and segmentation performance. This
motivates our design of a simple and effective token pruning method that
selects a compact yet spatially representative subset of tokens to accelerate
inference. In this paper, we introduce a novel visual token pruning method for
IVS, called EVTP-IV, which builds upon the k-center by integrating spatial
information to ensure better coverage. We further provide an
information-theoretic analysis to support our design. Experiments on standard
IVS benchmarks show that our method achieves up to 5X speed-up on video tasks
and 3.5X on image tasks, while maintaining comparable accuracy using only 20%
of the tokens. Our method also consistently outperforms state-of-the-art
pruning baselines under varying pruning ratios.

</details>


### [16] [Large Kernel Modulation Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.11893)
*Quanwei Hu,Yinggan Tang,Xuguang Zhang*

Main category: cs.CV

TL;DR: \u57fa\u4e8eCNN\u7684\u5927\u5185\u6838\u8c03\u5236\u7f51\u7edc(LKMN)\uff0c\u901a\u8fc7\u589e\u5f3a\u90e8\u5206\u5927\u5185\u6838\u5757\u548c\u4ea4\u53c9\u95e8\u63a7\u524d\u7f00\u7f51\u7edc\uff0c\u5728\u8d28\u91cf\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4f18\u5f02\u5e73\u8861\uff0c\u8d85\u8d8a\u73b0\u6709\u8f7b\u91cf\u7ea7\u8d85\u5206\u8fa8\u6a21\u578b


<details>
  <summary>Details</summary>
Motivation: \u89e3\u51b3\u8d85\u5206\u8fa8\u4efb\u52a1\u4e2d\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u7684\u6a21\u578b\u8bbe\u8ba1\u6311\u6218\uff1aCNN\u6a21\u578b\u5ef6\u8fdf\u4f4e\u4f46\u7f3a\u4e4f\u975e\u5c40\u90e8\u7279\u5f81\u6350\u6355\u80fd\u529b\uff0c\u800cTransformer\u6a21\u578b\u80fd\u6355\u6350\u975e\u5c40\u90e8\u7279\u5f81\u4f46\u63a8\u7406\u901f\u5ea6\u6162

Method: \u63d0\u51fa\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u589e\u5f3a\u90e8\u5206\u5927\u5185\u6838\u5757(EPLKB)\u901a\u8fc7\u9891\u9053\u6df7\u6dc6\u3001\u9891\u9053\u6ce8\u610f\u529b\u548c\u5927\u5185\u6838\u6761\u5f62\u5377\u79ef\u63d0\u5347\u9891\u9053\u4ea4\u4e92\u548c\u975e\u5c40\u90e8\u7279\u5f81\u63d0\u53d6\uff1b\u4ea4\u53c9\u95e8\u63a7\u524d\u7f00\u7f51\u7edc(CGFN)\u901a\u8fc7\u53ef\u5b66\u4e60\u7f29\u653e\u56e0\u5b50\u548c\u4ea4\u53c9\u95e8\u7b56\u7565\u52a8\u6001\u8c03\u8282\u548c\u878d\u5408\u4e0d\u540c\u7279\u5f81

Result: \u5728Manga109\u6570\u636e\u96c6\u4e0a\u4ee5\u00d74\u500d\u8d85\u5206\u8fa8\u65f6\uff0cLKMN-L\u6a21\u578b\u6bd4DAT-light\u63d0\u5347\u4e860.23 dB PSNR\uff0c\u540c\u65f6\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u4e86\u7ea64.8\u500d\uff0c\u5728\u8d28\u91cf\u548c\u6548\u7387\u65b9\u9762\u90fd\u8d85\u8fc7\u4e86\u73b0\u6709\u6700\u4f18\u8f7b\u91cf\u7ea7\u8d85\u5206\u8fa8\u6a21\u578b

Conclusion: LKMN\u6210\u529f\u5730\u572mpure CNN\u6846\u67b6\u4e0b\u5b9e\u73b0\u4e86Transformer\u7684\u975e\u5c40\u90e8\u7279\u5f81\u6355\u6350\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86CNN\u7684\u9ad8\u6548\u63a8\u7406\u901f\u5ea6\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u7684\u8f7b\u91cf\u7ea7\u8d85\u5206\u8fa8\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848

Abstract: Image super-resolution (SR) in resource-constrained scenarios demands
lightweight models balancing performance and latency. Convolutional neural
networks (CNNs) offer low latency but lack non-local feature capture, while
Transformers excel at non-local modeling yet suffer slow inference. To address
this trade-off, we propose the Large Kernel Modulation Network (LKMN), a pure
CNN-based model. LKMN has two core components: Enhanced Partial Large Kernel
Block (EPLKB) and Cross-Gate Feed-Forward Network (CGFN). The EPLKB utilizes
channel shuffle to boost inter-channel interaction, incorporates channel
attention to focus on key information, and applies large kernel strip
convolutions on partial channels for non-local feature extraction with reduced
complexity. The CGFN dynamically adjusts discrepancies between input, local,
and non-local features via a learnable scaling factor, then employs a
cross-gate strategy to modulate and fuse these features, enhancing their
complementarity. Extensive experiments demonstrate that our method outperforms
existing state-of-the-art (SOTA) lightweight SR models while balancing quality
and efficiency. Specifically, LKMN-L achieves 0.23 dB PSNR improvement over
DAT-light on the Manga109 dataset at $\times$4 upscale, with nearly $\times$4.8
times faster. Codes are in the supplementary materials. The code is available
at https://github.com/Supereeeee/LKMN.

</details>


### [17] [A Sobel-Gradient MLP Baseline for Handwritten Character Recognition](https://arxiv.org/abs/2508.11902)
*Azam Nouri*

Main category: cs.CV

TL;DR: 重新使用Sobel边缘检测器的一阶导数作为输入，通过密集多层感知机实现手写字符识别，达到了接近卷积神经网络的性能，但更节省内存且具有透明性。


<details>
  <summary>Details</summary>
Motivation: 探索仅使用一阶导数边缘地图是否足以驱动密集多层感知机实现高效的手写字符识别，作为卷积神经网络的替代方案。

Method: 仅使用水平和垂直Sobel导数作为输入，在MNIST和EMNIST Letters数据集上训练密集多层感知机(MLP)网络。

Result: 在MNIST数字上达到98%准确率，在EMNIST字母上达到92%准确率，性能接近CNN但内存占用更小且特征更透明。

Conclusion: 手写字符图像中的类别区分信息大部分已被一阶梯度捐捕，边缘感知MLP是手写字符识别的一个简洁而高效的选择。

Abstract: We revisit the classical Sobel operator to ask a simple question: Are
first-order edge maps sufficient to drive an all-dense multilayer perceptron
(MLP) for handwritten character recognition (HCR), as an alternative to
convolutional neural networks (CNNs)? Using only horizontal and vertical Sobel
derivatives as input, we train an MLP on MNIST and EMNIST Letters. Despite its
extreme simplicity, the resulting network reaches 98% accuracy on MNIST digits
and 92% on EMNIST letters -- approaching CNNs while offering a smaller memory
footprint and transparent features. Our findings highlight that much of the
class-discriminative information in handwritten character images is already
captured by first-order gradients, making edge-aware MLPs a compelling option
for HCR.

</details>


### [18] [OVG-HQ: Online Video Grounding with Hybrid-modal Queries](https://arxiv.org/abs/2508.11903)
*Runhao Zeng,Jiaqi Mao,Minghao Lai,Minh Hieu Phan,Yanjie Dong,Wei Wang,Qi Chen,Xiping Hu*

Main category: cs.CV

TL;DR: 提出了在线视频定位新任务OVG-HQ，支持多模态查询，解决了传统方法在流媒体视频和视觉查询场景的局限性，并提出了统一框架OVG-HQ-Unify和新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 传统视频定位方法在处理流媒体视频和使用视觉线索的查询时存在局限，需要支持在线设置和多模态查询的新解决方案。

Method: 提出OVG-HQ-Unify统一框架，包含参数化记忆块(PMB)来保留历史知识，以及跨模态蒸馏策略来平衡不同模态的学习。构建了QVHighlights-Unify多模态数据集，并设计了在线评估指标oR@n, IoU=m和omAP。

Result: 实验表明OVG-HQ-Unify优于现有模型，为在线混合模态视频定位提供了鲁棒解决方案。

Conclusion: 该工作填补了在线视频定位和多模态查询的空白，提出的框架和评估指标有效解决了上下文有限和模态不平衡的挑战。

Abstract: Video grounding (VG) task focuses on locating specific moments in a video
based on a query, usually in text form. However, traditional VG struggles with
some scenarios like streaming video or queries using visual cues. To fill this
gap, we present a new task named Online Video Grounding with Hybrid-modal
Queries (OVG-HQ), which enables online segment localization using text, images,
video segments, and their combinations. This task poses two new challenges:
limited context in online settings and modality imbalance during training,
where dominant modalities overshadow weaker ones. To address these, we propose
OVG-HQ-Unify, a unified framework featuring a Parametric Memory Block (PMB)
that retain previously learned knowledge to enhance current decision and a
cross-modal distillation strategy that guides the learning of non-dominant
modalities. This design enables a single model to effectively handle
hybrid-modal queries. Due to the lack of suitable datasets, we construct
QVHighlights-Unify, an expanded dataset with multi-modal queries. Besides,
since offline metrics overlook prediction timeliness, we adapt them to the
online setting, introducing oR@n, IoU=m, and online mean Average Precision
(omAP) to evaluate both accuracy and efficiency. Experiments show that our
OVG-HQ-Unify outperforms existing models, offering a robust solution for
online, hybrid-modal video grounding. Source code and datasets are available at
https://github.com/maojiaqi2324/OVG-HQ.

</details>


### [19] [SafeCtrl: Region-Based Safety Control for Text-to-Image Diffusion via Detect-Then-Suppress](https://arxiv.org/abs/2508.11904)
*Lingyun Zhang,Yu Xie,Yanwei Fu,Ping Chen*

Main category: cs.CV

TL;DR: SafeCtrl是一个轻量级非侵入式插件，通过检测-抑制范式来提升文本到图像模型的安全性，在保持生成质量的同时有效防止有害内容生成


<details>
  <summary>Details</summary>
Motivation: 现有安全方法（如提示词重写或模型微调）在安全性和保真度之间存在权衡，基于定位的方法依赖显式概念替换可能导致语义不连贯

Method: 采用检测-抑制范式，首先精确定位不安全内容，然后抑制有害语义而非硬替换，使用DPO训练策略利用图像级偏好数据学习抑制行为

Result: 在安全性和保真度保持方面显著优于现有最先进方法

Conclusion: 解耦的基于抑制的控制是构建更负责任生成模型的高效且可扩展方向

Abstract: The widespread deployment of text-to-image models is challenged by their
potential to generate harmful content. While existing safety methods, such as
prompt rewriting or model fine-tuning, provide valuable interventions, they
often introduce a trade-off between safety and fidelity. Recent
localization-based approaches have shown promise, yet their reliance on
explicit ``concept replacement" can sometimes lead to semantic incongruity. To
address these limitations, we explore a more flexible detect-then-suppress
paradigm. We introduce SafeCtrl, a lightweight, non-intrusive plugin that first
precisely localizes unsafe content. Instead of performing a hard A-to-B
substitution, SafeCtrl then suppresses the harmful semantics, allowing the
generative process to naturally and coherently resolve into a safe,
context-aware alternative. A key aspect of our work is a novel training
strategy using Direct Preference Optimization (DPO). We leverage readily
available, image-level preference data to train our module, enabling it to
learn nuanced suppression behaviors and perform region-guided interventions at
inference without requiring costly, pixel-level annotations. Extensive
experiments show that SafeCtrl significantly outperforms state-of-the-art
methods in both safety efficacy and fidelity preservation. Our findings suggest
that decoupled, suppression-based control is a highly effective and scalable
direction for building more responsible generative models.

</details>


### [20] [TimeSenCLIP: A Vision-Language Model for Remote Sensing Using Single-Pixel Time Series](https://arxiv.org/abs/2508.11919)
*Pallavi Jain,Diego Marcos,Dino Ienco,Roberto Interdonato,Tristan Berchoux*

Main category: cs.CV

TL;DR: TimeSenCLIP是一个轻量级框架，通过利用单像素的时空和光谱维度进行LULC分类，减少了对大空间图块和文本监督的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在遥感应用中面临两个关键挑战：依赖大空间图块增加计算成本，以及依赖文本监督但文本数据往往不易获得。

Method: 利用Sentinel-2影像的光谱和时间信息，结合地理标记的地面照片进行跨视角学习，最小化基于标题的训练需求，同时保持卫星和地面视角之间的语义对齐。

Result: 研究表明，单像素输入结合时空和光谱线索足以进行专题制图，为大规模遥感应用提供了可扩展且高效的替代方案。

Conclusion: TimeSenCLIP框架通过重新评估空间上下文的作用，证明了单像素时空光谱信息在LULC分类中的有效性，为遥感应用提供了更轻量级的解决方案。

Abstract: Vision-language models have shown significant promise in remote sensing
applications, particularly for land-use and land-cover (LULC) via zero-shot
classification and retrieval. However, current approaches face two key
challenges: reliance on large spatial tiles that increase computational cost,
and dependence on text-based supervision, which is often not readily available.
In this work, we present TimeSenCLIP, a lightweight framework that reevaluate
the role of spatial context by evaluating the effectiveness of a single pixel
by leveraging its temporal and spectral dimensions, for classifying LULC and
ecosystem types. By leveraging spectral and temporal information from
Sentinel-2 imagery and cross-view learning with geo-tagged ground-level photos,
we minimises the need for caption-based training while preserving semantic
alignment between overhead (satellite) and ground perspectives. Our approach is
grounded in the LUCAS and Sen4Map datasets, and evaluated on classification
tasks including LULC, crop type, and ecosystem type. We demonstrate that single
pixel inputs, when combined with temporal and spectral cues, are sufficient for
thematic mapping, offering a scalable and efficient alternative for large-scale
remote sensing applications. Code is available at
https://github.com/pallavijain-pj/TimeSenCLIP

</details>


### [21] [Assessment of Using Synthetic Data in Brain Tumor Segmentation](https://arxiv.org/abs/2508.11922)
*Aditi Jahagirdar,Sameer Joshi*

Main category: cs.CV

TL;DR: 使用GAN生成的合成MRI数据来补充真实数据训练U-Net脱脖脸部脱脖分割模型，在整体性能上与真实数据相当，但在40%真实+60%合成数据组合下改善了脱脖边界划分效果


<details>
  <summary>Details</summary>
Motivation: 解决手动脱脖脸部脱脖分割面临的挑战：脱脖异质性、标注数据稀缺、类别不平衡，通过生成式模型产生合成数据来提升数据集多样性

Method: 使用预训练GAN模型(medigan库)生成合成MRI数据，组建不同比例的真实+合成混合数据集，训练U-Net分割网络，使用BraTS 2020数据集进行实验

Result: 整体量化性能(Dice系数、IoU、精度、召回率、准确度)在真实数据和混合数据之间相似，但质量分析显示40%真实+60%合成数据组合改善了整体脱脖边界划分，脱脖核心和增强脱脖区域的准确度仍较低

Conclusion: 合成数据作为数据增强策略在脱脖脸部脱脖分割中具有可行性，但需要进一步大规模实验、确保体积数据一致性并解决类别不平衡问题

Abstract: Manual brain tumor segmentation from MRI scans is challenging due to tumor
heterogeneity, scarcity of annotated data, and class imbalance in medical
imaging datasets. Synthetic data generated by generative models has the
potential to mitigate these issues by improving dataset diversity. This study
investigates, as a proof of concept, the impact of incorporating synthetic MRI
data, generated using a pre-trained GAN model, into training a U-Net
segmentation network. Experiments were conducted using real data from the BraTS
2020 dataset, synthetic data generated with the medigan library, and hybrid
datasets combining real and synthetic samples in varying proportions. While
overall quantitative performance (Dice coefficient, IoU, precision, recall,
accuracy) was comparable between real-only and hybrid-trained models,
qualitative inspection suggested that hybrid datasets, particularly with 40%
real and 60% synthetic data, improved whole tumor boundary delineation.
However, region-wise accuracy for the tumor core and the enhancing tumor
remained lower, indicating a persistent class imbalance. The findings support
the feasibility of synthetic data as an augmentation strategy for brain tumor
segmentation, while highlighting the need for larger-scale experiments,
volumetric data consistency, and mitigating class imbalance in future work.

</details>


### [22] [Deep Learning For Point Cloud Denoising: A Survey](https://arxiv.org/abs/2508.11932)
*Chengwei Zhang,Xueyi Zhang,Mingrui Lao,Tao Jiang,Xinhao Xu,Wenjie Li,Fubo Zhang,Longyong Chen*

Main category: cs.CV

TL;DR: 这是一份关于深度学习基于点云去噪的综述性论文，系统分类了现有方法，提出了两步去噪模型，并讨论了研究挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 实际环境中的点云数据存在各种模态和强度的噪声，深度学习基于点云去噪方法虽然表现优异但缺乏系统的综述性研究。

Method: 将点云去噪模型化为两个步骤：离群点移除和表面噪声恢复，并为去噪任务量身定制了分类系统。通过比较各方法的相似性、差异性和各自优势来进行分析。

Result: 该论文提供了一个系统的分类框架，包含了大部分点云去噪场景和需求，为领域研究者提供了全面的技术视野。

Conclusion: 论文填补了深度学习基于点云去噪领域的综述性研究空白，为进一步的技术发展提供了重要的见解和指导方向。

Abstract: Real-world environment-derived point clouds invariably exhibit noise across
varying modalities and intensities. Hence, point cloud denoising (PCD) is
essential as a preprocessing step to improve downstream task performance. Deep
learning (DL)-based PCD models, known for their strong representation
capabilities and flexible architectures, have surpassed traditional methods in
denoising performance. To our best knowledge, despite recent advances in
performance, no comprehensive survey systematically summarizes the developments
of DL-based PCD. To fill the gap, this paper seeks to identify key challenges
in DL-based PCD, summarizes the main contributions of existing methods, and
proposes a taxonomy tailored to denoising tasks. To achieve this goal, we
formulate PCD as a two-step process: outlier removal and surface noise
restoration, encompassing most scenarios and requirements of PCD. Additionally,
we compare methods in terms of similarities, differences, and respective
advantages. Finally, we discuss research limitations and future directions,
offering insights for further advancements in PCD.

</details>


### [23] [DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects](https://arxiv.org/abs/2508.11950)
*Tingbang Liang,Yixin Zeng,Jiatong Xie,Boyu Zhou*

Main category: cs.CV

TL;DR: DynamicPose是一个无需重新训练的6D姿态跟踪框架，专门针对快速移动的相机和物体场景，通过视觉-惯性里程计、深度感知2D跟踪器和VIO引导的卡尔曼滤波器实现鲁棒的实时跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要适用于静态或准静态场景，在相机和物体同时快速移动时性能显著下降，需要解决快速运动场景下的6D姿态跟踪鲁棒性问题。

Method: 提出三个协同组件：1）视觉-惯性里程计补偿相机运动引起的ROI偏移；2）深度感知2D跟踪器校正大物体平移引起的ROI偏差；3）VIO引导的卡尔曼滤波器预测物体旋转并生成候选姿态进行分层细化。形成闭环系统确保精确的姿态初始化和跟踪。

Result: 仿真和真实世界实验证明该方法有效，能够实现快速移动相机和物体的实时鲁棒6D姿态跟踪。

Conclusion: DynamicPose框架成功解决了快速运动场景下的6D姿态跟踪挑战，通过协同组件和闭环系统实现了鲁棒的实时性能。

Abstract: We present DynamicPose, a retraining-free 6D pose tracking framework that
improves tracking robustness in fast-moving camera and object scenarios.
Previous work is mainly applicable to static or quasi-static scenes, and its
performance significantly deteriorates when both the object and the camera move
rapidly. To overcome these challenges, we propose three synergistic components:
(1) A visual-inertial odometry compensates for the shift in the Region of
Interest (ROI) caused by camera motion; (2) A depth-informed 2D tracker
corrects ROI deviations caused by large object translation; (3) A VIO-guided
Kalman filter predicts object rotation, generates multiple candidate poses, and
then obtains the final pose by hierarchical refinement. The 6D pose tracking
results guide subsequent 2D tracking and Kalman filter updates, forming a
closed-loop system that ensures accurate pose initialization and precise pose
tracking. Simulation and real-world experiments demonstrate the effectiveness
of our method, achieving real-time and robust 6D pose tracking for fast-moving
cameras and objects.

</details>


### [24] [Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection](https://arxiv.org/abs/2508.11951)
*Hao Peng,Hong Sang,Yajing Ma,Ping Qiu,Chao Ji*

Main category: cs.CV

TL;DR: 通过知识萌粉从单一邻域近似多尺度特征，设计可转移特征嵌入机制和中心加权IoU，在节省计算资源的同时提高点云物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 多尺度特征对点云物体检测至关重要，但传统方法需多次邻域搜索和尺度感知层，计算成本高且不利于轻量级模型发展。

Method: 基于知识萌粉从单一邻域近似多尺度特征，设计类别感知统计量作为可转移特征，并提出中心加权IoU以缓解位置偏移导致的对齐问题。

Result: 在公开数据集上的广泛实验证明了方法的有效性，同时节省了计算成本。

Conclusion: 该方法通过创新的特征近似和转移机制，在低计算成本下实现了高效的点云物体检测，为轻量级模型研究提供了新思路。

Abstract: This paper investigates multi-scale feature approximation and transferable
features for object detection from point clouds. Multi-scale features are
critical for object detection from point clouds. However, multi-scale feature
learning usually involves multiple neighborhood searches and scale-aware
layers, which can hinder efforts to achieve lightweight models and may not be
conducive to research constrained by limited computational resources. This
paper approximates point-based multi-scale features from a single neighborhood
based on knowledge distillation. To compensate for the loss of constructive
diversity in a single neighborhood, this paper designs a transferable feature
embedding mechanism. Specifically, class-aware statistics are employed as
transferable features given the small computational cost. In addition, this
paper introduces the central weighted intersection over union for localization
to alleviate the misalignment brought by the center offset in optimization.
Note that the method presented in this paper saves computational costs.
Extensive experiments on public datasets demonstrate the effectiveness of the
proposed method.

</details>


### [25] [UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding](https://arxiv.org/abs/2508.11952)
*Yueming Xu,Jiahui Zhang,Ze Huang,Yurui Chen,Yanpeng Zhou,Zhenyu Chen,Yu-Jie Yuan,Pengxiang Xia,Guowei Huang,Xinyue Cai,Zhongang Qi,Xingyue Quan,Jianye Hao,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: UniUGG是首个统一的3D模态理解和生成框架，使用LLM处理文本和3D表示，核心采用潜在扩散模型的空间解码器生成高质量3D内容，支持基于参考图像和视角变换的3D场景生成与空间VQA任务。


<details>
  <summary>Details</summary>
Motivation: 尽管近期统一架构在图像理解和生成方面取得显著进展，但3D任务的整合仍然具有挑战性且探索不足，需要开发能够同时处理3D理解和生成的统一框架。

Method: 提出UniUGG框架：1）使用LLM理解和解码句子与3D表示；2）核心采用潜在扩散模型的空间解码器生成3D表示；3）提出几何-语义学习策略预训练视觉编码器，联合捕获输入的语义和几何线索。

Result: 大量实验结果表明，该方法在视觉表示、空间理解和3D生成方面表现出优越性能。

Conclusion: UniUGG成功实现了3D模态的统一理解和生成，通过创新的空间解码器和几何-语义学习策略，显著提升了3D场景的空间理解和生成能力。

Abstract: Despite the impressive progress on understanding and generating images shown
by the recent unified architectures, the integration of 3D tasks remains
challenging and largely unexplored. In this paper, we introduce UniUGG, the
first unified understanding and generation framework for 3D modalities. Our
unified framework employs an LLM to comprehend and decode sentences and 3D
representations. At its core, we propose a spatial decoder leveraging a latent
diffusion model to generate high-quality 3D representations. This allows for
the generation and imagination of 3D scenes based on a reference image and an
arbitrary view transformation, while remaining supports for spatial visual
question answering (VQA) tasks. Additionally, we propose a geometric-semantic
learning strategy to pretrain the vision encoder. This design jointly captures
the input's semantic and geometric cues, enhancing both spatial understanding
and generation. Extensive experimental results demonstrate the superiority of
our method in visual representation, spatial understanding, and 3D generation.
The source code will be released upon paper acceptance.

</details>


### [26] [SAMDWICH: Moment-aware Video-text Alignment for Referring Video Object Segmentation](https://arxiv.org/abs/2508.11955)
*Seunghun Lee,Jiwan Seo,Jeonghoon Kim,Siwon Kim,Haeun Yun,Hyogyeong Jeon,Wonhyeok Choi,Jaehoon Jeong,Zane Durante,Sang Hyun Park,Sunghoon Im*

Main category: cs.CV

TL;DR: SAMDWICH是一个基于时刻感知的Referring Video Object Segmentation框架，通过新标注的MeViS-M数据集和时刻引导的双路径传播策略，解决了现有方法中的语义错位问题，在复杂场景下实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Referring Video Object Segmentation方法存在语义错位问题，主要原因是训练时对所有可见对象进行无差别帧采样和监督，而不考虑它们与文本查询的实际相关性。

Method: 提出了SAMDWICH框架，包含：1）新标注的MeViS-M数据集，手动标注了每个对象被表达式引用的时间时刻；2）时刻引导的双路径传播（MDP）策略，通过时刻中心记忆机制在相关和不相关帧上进行训练；3）对象级选择性监督（OSS），只监督与表达式时间对齐的对象。

Result: 在具有挑战性的MeViS基准测试中实现了最先进的性能，特别是在涉及多样化表达式的复杂场景中表现出色。

Conclusion: 通过时刻感知的监督和选择性训练策略，SAMDWICH显著增强了视频-文本对齐和参考理解能力，为Referring Video Object Segmentation任务提供了有效的解决方案。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment and track objects
in videos based on natural language expressions, requiring precise alignment
between visual content and textual queries. However, existing methods often
suffer from semantic misalignment, largely due to indiscriminate frame sampling
and supervision of all visible objects during training -- regardless of their
actual relevance to the expression. To address this, we introduce a
moment-aware RVOS framework named SAMDWICH, along with a newly annotated
dataset, MeViS-M, built upon the challenging MeViS benchmark. We manually
annotate temporal moments indicating when each object is referred to by the
expression, enabling semantically grounded supervision that strengthens
video-text alignment. SAMDWICH leverages these aligned text-to-clip pairs to
guide training, significantly enhancing referential understanding. Building
upon this framework, we propose Moment-guided Dual-path Propagation (MDP), a
moment-aware propagation strategy that improves both object grounding and
tracking by training on both relevant and irrelevant frames through a
moment-centric memory mechanism. In addition, we introduce Object-level
Selective Supervision (OSS), an object-level filtering strategy that supervises
only the objects temporally aligned with the expression in each training clip.
This selective supervision reduces semantic noise and reinforces
language-conditioned learning. Extensive experiments show that SAMDWICH
achieves state-of-the-art performance on challenging MeViS benchmark,
particularly excelling in complex scenarios involving diverse expressions.

</details>


### [27] [PEdger++: Practical Edge Detection via Assembling Cross Information](https://arxiv.org/abs/2508.11961)
*Yuanbin Fu,Liang Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: PEdger++是一个协作学习框架，通过在异构架构、不同训练时刻和参数采样之间共享跨信息，实现高精度边缘检测的同时降低计算成本和模型大小。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习边缘检测器在资源受限设备上部署时面临的高计算成本问题，平衡检测精度与计算复杂度。

Method: 提出协作学习框架PEdger++，利用异构架构、多样训练时刻和多重参数采样的跨信息增强学习，从集成角度提升性能。

Result: 在BSDS500、NYUD和Multicue数据集上取得显著效果，定量和定性分析均显示优于现有方法，并提供不同计算需求的多个模型版本。

Conclusion: PEdger++通过协作学习有效解决了边缘检测中精度与效率的平衡问题，具有良好的资源适应性。

Abstract: Edge detection serves as a critical foundation for numerous computer vision
applications, including object detection, semantic segmentation, and image
editing, by extracting essential structural cues that define object boundaries
and salient edges. To be viable for broad deployment across devices with
varying computational capacities, edge detectors shall balance high accuracy
with low computational complexity. While deep learning has evidently improved
accuracy, they often suffer from high computational costs, limiting their
applicability on resource-constrained devices. This paper addresses the
challenge of achieving that balance: \textit{i.e.}, {how to efficiently capture
discriminative features without relying on large-size and sophisticated
models}. We propose PEdger++, a collaborative learning framework designed to
reduce computational costs and model sizes while improving edge detection
accuracy. The core principle of our PEdger++ is that cross-information derived
from heterogeneous architectures, diverse training moments, and multiple
parameter samplings, is beneficial to enhance learning from an ensemble
perspective. Extensive experimental results on the BSDS500, NYUD and Multicue
datasets demonstrate the effectiveness of our approach, both quantitatively and
qualitatively, showing clear improvements over existing methods. We also
provide multiple versions of the model with varying computational requirements,
highlighting PEdger++'s adaptability with respect to different resource
constraints. Codes are accessible at
https://github.com/ForawardStar/EdgeDetectionviaPEdgerPlus/.

</details>


### [28] [Exploring Spatial-Temporal Dynamics in Event-based Facial Micro-Expression Analysis](https://arxiv.org/abs/2508.11988)
*Nicolas Mastropasqua,Ignacio Bugueno-Cordova,Rodrigo Verschae,Daniel Acevedo,Pablo Negri,Maria E. Buemi*

Main category: cs.CV

TL;DR: 事件相机在微表情分析中显示出优势，通过新的多模态数据集和基线方法在AU分类和帧重建任务上获得更好结果


<details>
  <summary>Details</summary>
Motivation: 微表情分析在人机交互和驾驶监控中有重要应用，但传统RGB相机在抓取细微快速面部运动时遇到时间分辨率和运动模糊的限制

Method: 提出了一个新的多分辨率多模态微表情数据集，使用同步的RGB和事件相机在变化光照条件下记录，并使用脏细胞神经网络进行行为单元分类，以及条件变分自动编码器进行帧重建

Result: 事件相机在AU分类任务上达到51.23%准确率（RGB仅23.12%），在帧重建任务上达到SSIM=0.8513和PSNR=26.89dB

Conclusion: 事件基于数据可以有效用于微表情识别和帧重建，为微表情分析领域提供了新的技术途径

Abstract: Micro-expression analysis has applications in domains such as Human-Robot
Interaction and Driver Monitoring Systems. Accurately capturing subtle and fast
facial movements remains difficult when relying solely on RGB cameras, due to
limitations in temporal resolution and sensitivity to motion blur. Event
cameras offer an alternative, with microsecond-level precision, high dynamic
range, and low latency. However, public datasets featuring event-based
recordings of Action Units are still scarce. In this work, we introduce a
novel, preliminary multi-resolution and multi-modal micro-expression dataset
recorded with synchronized RGB and event cameras under variable lighting
conditions. Two baseline tasks are evaluated to explore the spatial-temporal
dynamics of micro-expressions: Action Unit classification using Spiking Neural
Networks (51.23\% accuracy with events vs. 23.12\% with RGB), and frame
reconstruction using Conditional Variational Autoencoders, achieving SSIM =
0.8513 and PSNR = 26.89 dB with high-resolution event input. These promising
results show that event-based data can be used for micro-expression recognition
and frame reconstruction.

</details>


### [29] [MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2508.11999)
*Daoze Zhang,Zhanheng Nie,Jianyu Liu,Chenghan Fu,Wanxian Guan,Yuan Gao,Jun Song,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: MOON是首个基于生成式多模态大语言模型的产品表示学习模型，通过引导式专家混合模块、核心语义区域检测和专业化负采样策略，解决了产品图像-文本多对一对齐、背景噪声干扰等挑战，并在多个下游任务中展现出优异的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有判别式双流架构难以建模产品多图像与文本之间的多对一对齐关系，而生成式多模态大语言模型在提升产品表示学习方面具有巨大潜力，但面临缺乏多模态建模模块、产品图像背景噪声干扰以及缺乏标准评估基准等挑战。

Method: 1) 采用引导式专家混合(MoE)模块进行多模态和特定方面的目标建模；2) 有效检测产品图像中的核心语义区域以减少背景噪声干扰；3) 引入专业化负采样策略增加负样本难度和多样性；4) 发布大规模多模态基准MBE。

Result: 模型在自建基准和公共数据集上均表现出竞争力的零样本性能，在跨模态检索、产品分类和属性预测等各种下游任务中展现出强大的泛化能力。案例研究和可视化证明了MOON在产品理解方面的有效性。

Conclusion: MOON成功解决了产品表示学习中的关键挑战，证明了生成式多模态大语言模型在该领域的潜力，为产品理解任务提供了有效的解决方案和标准评估基准。

Abstract: With the rapid advancement of e-commerce, exploring general representations
rather than task-specific ones has attracted increasing research attention. For
product understanding, although existing discriminative dual-flow architectures
drive progress in this field, they inherently struggle to model the many-to-one
alignment between multiple images and texts of products. Therefore, we argue
that generative Multimodal Large Language Models (MLLMs) hold significant
potential for improving product representation learning. Nevertheless,
achieving this goal still remains non-trivial due to several key challenges:
the lack of multimodal and aspect-aware modeling modules in typical LLMs; the
common presence of background noise in product images; and the absence of a
standard benchmark for evaluation. To address these issues, we propose the
first generative MLLM-based model named MOON for product representation
learning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for
targeted modeling of multimodal and aspect-specific product content; (2)
effectively detects core semantic regions in product images to mitigate the
distraction and interference caused by background noise; and (3) introduces the
specialized negative sampling strategy to increase the difficulty and diversity
of negative samples. In addition, we release a large-scale multimodal benchmark
MBE for various product understanding tasks. Experimentally, our model
demonstrates competitive zero-shot performance on both our benchmark and the
public dataset, showcasing strong generalization across various downstream
tasks, including cross-modal retrieval, product classification, and attribute
prediction. Furthermore, the case study and visualization illustrate the
effectiveness of MOON for product understanding.

</details>


### [30] [InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes](https://arxiv.org/abs/2508.12015)
*Hongyuan Liu,Haochen Yu,Jianfei Jiang,Qiankun Liu,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: InstDrive是一个针对动态驾驶场景的实例感知3D高斯泼溅框架，通过SAM生成的掩码作为伪真值指导2D特征学习，在3D层面引入正则化和体素损失来实现实例一致性，无需数据预处理即可实现动态开放世界驾驶场景的3D实例分割。


<details>
  <summary>Details</summary>
Motivation: 现有的动态驾驶场景重建方法通常将所有背景元素统一为单一表示，限制了实例级理解和灵活的场景编辑能力。现有方法多针对室内场景设计，不适用于室外驾驶场景，且需要预处理实例ID或复杂管道。

Method: 使用SAM生成的掩码作为伪真值，通过对比损失和伪监督目标指导2D特征学习；在3D层面引入正则化隐式编码实例身份，通过体素损失强制一致性；使用轻量级静态码本桥接连续特征和离散身份。

Result: 定量和定性实验证明了InstDrive的有效性，据作者所知，这是首个在动态开放世界驾驶场景中实现3D实例分割的框架。

Conclusion: InstDrive提供了一个无需数据预处理或复杂优化的解决方案，成功实现了动态驾驶场景的实例感知3D重建，为自动驾驶和场景理解提供了更好的实例级分析能力。

Abstract: Reconstructing dynamic driving scenes from dashcam videos has attracted
increasing attention due to its significance in autonomous driving and scene
understanding. While recent advances have made impressive progress, most
methods still unify all background elements into a single representation,
hindering both instance-level understanding and flexible scene editing. Some
approaches attempt to lift 2D segmentation into 3D space, but often rely on
pre-processed instance IDs or complex pipelines to map continuous features to
discrete identities. Moreover, these methods are typically designed for indoor
scenes with rich viewpoints, making them less applicable to outdoor driving
scenarios. In this paper, we present InstDrive, an instance-aware 3D Gaussian
Splatting framework tailored for the interactive reconstruction of dynamic
driving scene. We use masks generated by SAM as pseudo ground-truth to guide 2D
feature learning via contrastive loss and pseudo-supervised objectives. At the
3D level, we introduce regularization to implicitly encode instance identities
and enforce consistency through a voxel-based loss. A lightweight static
codebook further bridges continuous features and discrete identities without
requiring data pre-processing or complex optimization. Quantitative and
qualitative experiments demonstrate the effectiveness of InstDrive, and to the
best of our knowledge, it is the first framework to achieve 3D instance
segmentation in dynamic, open-world driving scenes.More visualizations are
available at our project page.

</details>


### [31] [WiseLVAM: A Novel Framework For Left Ventricle Automatic Measurements](https://arxiv.org/abs/2508.12023)
*Durgesh Kumar Singh,Qing Cao,Sarina Thomas,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 提出WiseLVAM全自动框架，通过轮廓感知扫描线放置和AMM模式测量，解决左心室线性测量自动化问题


<details>
  <summary>Details</summary>
Motivation: 现有自动化方法直接从B超图像估计标志点，即使微小偏移也会导致显著测量误差，降低临床可靠性

Method: 使用弱监督B超标志点检测器估计LV轮廓，推断LV长轴和基底水平放置扫描线，然后在AMM模式下自动进行线性测量

Result: 结合B超图像的结构感知和AMM模式的运动感知，提高了鲁棒性和准确性

Conclusion: WiseLVAM为常规临床应用提供了实用的全自动化解决方案，同时保持手动适应性

Abstract: Clinical guidelines recommend performing left ventricular (LV) linear
measurements in B-mode echocardiographic images at the basal level -- typically
at the mitral valve leaflet tips -- and aligned perpendicular to the LV long
axis along a virtual scanline (SL). However, most automated methods estimate
landmarks directly from B-mode images for the measurement task, where even
small shifts in predicted points along the LV walls can lead to significant
measurement errors, reducing their clinical reliability. A recent
semi-automatic method, EnLVAM, addresses this limitation by constraining
landmark prediction to a clinician-defined SL and training on generated
Anatomical Motion Mode (AMM) images to predict LV landmarks along the same. To
enable full automation, a contour-aware SL placement approach is proposed in
this work, in which the LV contour is estimated using a weakly supervised
B-mode landmark detector. SL placement is then performed by inferring the LV
long axis and the basal level-mimicking clinical guidelines. Building on this
foundation, we introduce \textit{WiseLVAM} -- a novel, fully automated yet
manually adaptable framework for automatically placing the SL and then
automatically performing the LV linear measurements in the AMM mode.
\textit{WiseLVAM} utilizes the structure-awareness from B-mode images and the
motion-awareness from AMM mode to enhance robustness and accuracy with the
potential to provide a practical solution for the routine clinical application.

</details>


### [32] [Q-FSRU: Quantum-Augmented Frequency-Spectral Fusion for Medical Visual Question Answering](https://arxiv.org/abs/2508.12036)
*Rakesh Thakur,Yusra Tariq*

Main category: cs.CV

TL;DR: Q-FSRU是一个结合频域表示和量子检索增强生成的医疗视觉问答模型，在VQA-RAD数据集上表现优异


<details>
  <summary>Details</summary>
Motivation: 解决需要图像和文本双重理解的临床难题是医疗AI的主要挑战

Method: 使用FFT将医学图像和文本特征转换到频域，结合量子检索系统从外部源获取医学知识，融合频域特征进行推理

Result: 在VQA-RAD数据集上超越了先前模型，特别是在需要图像-文本推理的复杂案例中表现突出

Conclusion: 频域和量子信息的结合提高了性能和可解释性，为医生构建智能、清晰、有用的AI工具提供了有前景的方法

Abstract: Solving tough clinical questions that require both image and text
understanding is still a major challenge in healthcare AI. In this work, we
propose Q-FSRU, a new model that combines Frequency Spectrum Representation and
Fusion (FSRU) with a method called Quantum Retrieval-Augmented Generation
(Quantum RAG) for medical Visual Question Answering (VQA). The model takes in
features from medical images and related text, then shifts them into the
frequency domain using Fast Fourier Transform (FFT). This helps it focus on
more meaningful data and filter out noise or less useful information. To
improve accuracy and ensure that answers are based on real knowledge, we add a
quantum-inspired retrieval system. It fetches useful medical facts from
external sources using quantum-based similarity techniques. These details are
then merged with the frequency-based features for stronger reasoning. We
evaluated our model using the VQA-RAD dataset, which includes real radiology
images and questions. The results showed that Q-FSRU outperforms earlier
models, especially on complex cases needing image-text reasoning. The mix of
frequency and quantum information improves both performance and explainability.
Overall, this approach offers a promising way to build smart, clear, and
helpful AI tools for doctors.

</details>


### [33] [VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models](https://arxiv.org/abs/2508.12081)
*Haidong Xu,Guangwei Xu,Zhedong Zheng,Xiatian Zhu,Wei Ji,Xiangtai Li,Ruijie Guo,Meishan Zhang,Min zhang,Hao Fei*

Main category: cs.CV

TL;DR: VimoRAG是一个基于视频检索增强的运动生成框架，通过从大规模视频数据库中检索相关2D人体运动信号来解决运动大语言模型的数据不足问题，显著提升了仅使用文本输入的运动生成性能。


<details>
  <summary>Details</summary>
Motivation: 运动大语言模型由于标注数据有限而面临严重的领域外/词汇外问题，需要利用大规模野外视频数据库来增强3D运动生成能力。

Method: 设计了Gemini Motion Video Retriever机制进行有效的运动中心视频检索，以及Motion-centric Dual-alignment DPO Trainer来缓解检索结果不佳导致的误差传播问题。

Result: 实验结果表明VimoRAG显著提升了仅使用文本输入的运动大语言模型的性能。

Conclusion: VimoRAG通过视频检索增强的方法有效解决了运动生成中的数据稀缺问题，为运动大语言模型提供了新的性能提升途径。

Abstract: This paper introduces VimoRAG, a novel video-based retrieval-augmented motion
generation framework for motion large language models (LLMs). As motion LLMs
face severe out-of-domain/out-of-vocabulary issues due to limited annotated
data, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D
motion generation by retrieving relevant 2D human motion signals. While
video-based motion RAG is nontrivial, we address two key bottlenecks: (1)
developing an effective motion-centered video retrieval model that
distinguishes human poses and actions, and (2) mitigating the issue of error
propagation caused by suboptimal retrieval results. We design the Gemini Motion
Video Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,
enabling effective retrieval and generation processes. Experimental results
show that VimoRAG significantly boosts the performance of motion LLMs
constrained to text-only input.

</details>


### [34] [Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity](https://arxiv.org/abs/2508.12082)
*Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee*

Main category: cs.CV

TL;DR: 自动化对检测器评估的PCR方法，通过分析NMS前后检测框的空间一致性和可靠性来预测性能，避免人工标注成本


<details>
  <summary>Details</summary>
Motivation: 当前对检测器的性能评估依靠成本高昂的人工标注，需要一种自动化的评估方法来提高效率

Method: 提出预测一致性和可靠性(PCR)方法，聚合分析NMS前后检测框的空间一致性和重叠框的信心度来预测检测性能

Result: PCR方法在构建的元数据集上表现超过现有自动评估方法，能够提供更准确的性能估计

Conclusion: 该研究为对检测器的自动化评估提供了有效方法，PCR方法能够在无需真实标签的情况下准确预测检测性能

Abstract: Recent advances in computer vision have made training object detectors more
efficient and effective; however, assessing their performance in real-world
applications still relies on costly manual annotation. To address this
limitation, we develop an automated model evaluation (AutoEval) framework for
object detection. We propose Prediction Consistency and Reliability (PCR),
which leverages the multiple candidate bounding boxes that conventional
detectors generate before non-maximum suppression (NMS). PCR estimates
detection performance without ground-truth labels by jointly measuring 1) the
spatial consistency between boxes before and after NMS, and 2) the reliability
of the retained boxes via the confidence scores of overlapping boxes. For a
more realistic and scalable evaluation, we construct a meta-dataset by applying
image corruptions of varying severity. Experimental results demonstrate that
PCR yields more accurate performance estimates than existing AutoEval methods,
and the proposed meta-dataset covers a wider range of detection performance.
The code is available at https://github.com/YonseiML/autoeval-det.

</details>


### [35] [Generic Event Boundary Detection via Denoising Diffusion](https://arxiv.org/abs/2508.12084)
*Jaejun Hwang,Dayoung Gong,Manjin Kim,Minsu Cho*

Main category: cs.CV

TL;DR: 提出DiffGEBD，一种基于扩散模型的通用事件边界检测方法，通过生成式视角解决事件边界检测问题，能够产生多样化的合理边界预测。


<details>
  <summary>Details</summary>
Motivation: 传统方法专注于确定性预测，忽视了事件边界检测中固有的主观性和解决方案的多样性问题。

Method: 使用扩散模型编码相邻帧间的时序自相似性变化，然后通过迭代去噪将随机噪声解码为合理的事件边界，采用分类器自由引导控制多样性。

Result: 在Kinetics-GEBD和TAPOS两个标准基准测试中取得了强劲性能，能够生成多样且合理的事件边界。

Conclusion: 扩散模型为通用事件边界检测提供了有效的生成式解决方案，能够处理该任务的主观性和多样性特点。

Abstract: Generic event boundary detection (GEBD) aims to identify natural boundaries
in a video, segmenting it into distinct and meaningful chunks. Despite the
inherent subjectivity of event boundaries, previous methods have focused on
deterministic predictions, overlooking the diversity of plausible solutions. In
this paper, we introduce a novel diffusion-based boundary detection model,
dubbed DiffGEBD, that tackles the problem of GEBD from a generative
perspective. The proposed model encodes relevant changes across adjacent frames
via temporal self-similarity and then iteratively decodes random noise into
plausible event boundaries being conditioned on the encoded features.
Classifier-free guidance allows the degree of diversity to be controlled in
denoising diffusion. In addition, we introduce a new evaluation metric to
assess the quality of predictions considering both diversity and fidelity.
Experiments show that our method achieves strong performance on two standard
benchmarks, Kinetics-GEBD and TAPOS, generating diverse and plausible event
boundaries.

</details>


### [36] [Enhancing 3D point accuracy of laser scanner through multi-stage convolutional neural network for applications in construction](https://arxiv.org/abs/2508.12089)
*Qinyuan Fan,Clemens Gühmann*

Main category: cs.CV

TL;DR: 使用多步卷积神经网络和高低端扫描仪配对方法，通过统计学习量化系统错误，将低端扫描仪的3D点精度提升到接近高端设备的水平


<details>
  <summary>Details</summary>
Motivation: 解决因设备限制和环境因素导致的高低端光电扫描仪位置误差问题，为精确几何模型创建和改造提供更准确的空间测量

Method: 将高精度扫描仪作为参考，与低精度扫描仪在同一环境下配对测量，通过统计关系建立测量偏差与空间分布的关联，结合传统几何处理和神经网络精细化构建系统错误纠正框架

Result: 在粗糙室内环境数据集中，平均方误差降低超70%以上，峰值信噪比提升约6分贝，低端设备无需硬件改造即可达到接近高端设备的测量精度

Conclusion: 该方法通过机器学习技术有效减少光电扫描仪的系统错误，为低成本高精度测量提供了可行方案，对于实际应用具有重要意义

Abstract: We propose a multi-stage convolutional neural network (MSCNN) based
integrated method for reducing uncertainty of 3D point accuracy of lasar
scanner (LS) in rough indoor rooms, providing more accurate spatial
measurements for high-precision geometric model creation and renovation. Due to
different equipment limitations and environmental factors, high-end and low-end
LS have positional errors. Our approach pairs high-accuracy scanners (HAS) as
references with corresponding low-accuracy scanners (LAS) of measurements in
identical environments to quantify specific error patterns. By establishing a
statistical relationship between measurement discrepancies and their spatial
distribution, we develop a correction framework that combines traditional
geometric processing with targeted neural network refinement. This method
transforms the quantification of systematic errors into a supervised learning
problem, allowing precise correction while preserving critical geometric
features. Experimental results in our rough indoor rooms dataset show
significant improvements in measurement accuracy, with mean square error (MSE)
reductions exceeding 70% and peak signal-to-noise ratio (PSNR) improvements of
approximately 6 decibels. This approach enables low-end devices to achieve
measurement uncertainty levels approaching those of high-end devices without
hardware modifications.

</details>


### [37] [Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion](https://arxiv.org/abs/2508.12094)
*Songwei Liu,Hong Liu,Fangmin Chen,Xurui Peng,Chenqian Yan,Lean Fu,Xing Mei*

Main category: cs.CV

TL;DR: 通过理论框架形式化错误传播机制，提出时间步感知的累积错误补偿方案，有效减少迭代去噪过程中的量化错误累积，提升低精度模型的输出质量。


<details>
  <summary>Details</summary>
Motivation: 散布模型在迭代去噪过程中存在步进式量化错误累积问题，影响低精度模型的输出保真度，需要解决错误传播挑战。

Method: 建立理论框架数学形式化错误传播机制，求解每步量化错误传播方程，得出累积错误的闭式解，基于此设计时间步感知的累积错误补偿策略。

Result: 在多个图像数据集上的实验表明，该补偿策略有效减轻错误传播，显著提升现有PTQ方法的性能，在低精度散布模型上达到最先进水平。

Conclusion: 通过理论分析错误传播机制并设计相应补偿方案，可以有效解决散布模型量化中的错误累积问题，为低精度模型的实际部署提供了有效觤决方案。

Abstract: Diffusion models have transformed image synthesis by establishing
unprecedented quality and creativity benchmarks. Nevertheless, their
large-scale deployment faces challenges due to computationally intensive
iterative denoising processes. Although post-training quantization(PTQ)
provides an effective pathway for accelerating sampling, the iterative nature
of diffusion models causes stepwise quantization errors to accumulate
progressively during generation, inevitably compromising output fidelity. To
address this challenge, we develop a theoretical framework that mathematically
formulates error propagation in Diffusion Models (DMs), deriving per-step
quantization error propagation equations and establishing the first closed-form
solution for cumulative error. Building on this theoretical foundation, we
propose a timestep-aware cumulative error compensation scheme. Extensive
experiments across multiple image datasets demonstrate that our compensation
strategy effectively mitigates error propagation, significantly enhancing
existing PTQ methods to achieve state-of-the-art(SOTA) performance on
low-precision diffusion models.

</details>


### [38] [VELVET-Med: Vision and Efficient Language Pre-training for Volumetric Imaging Tasks in Medicine](https://arxiv.org/abs/2508.12108)
*Ziyang Zhang,Yang Yu,Xulei Yang,Si Yong Yeo*

Main category: cs.CV

TL;DR: VELVET-Med是一个针对有限3D医学数据（如CT扫描和放射报告）的视觉语言预训练框架，通过自监督学习、新型语言编码器TriBERT和分层对比学习，在少量数据上实现优异的下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 医学领域中3D体积数据（如CT扫描）与文本的配对数据收集困难且耗时，限制了视觉语言模型在医学下游任务中的表现，需要开发针对有限数据的有效预训练方法。

Method: 提出VELVET-Med框架：1）将单模态自监督学习融入VLP框架；2）设计TriBERT语言编码器学习多层次文本语义；3）采用分层对比学习捕获多层次视觉-语言对应关系。仅使用38,875个扫描-报告对。

Result: 学习到的编码器展现出强大的迁移能力，在3D分割、跨模态检索、视觉问答和报告生成等多种下游任务中达到最先进的性能。

Conclusion: 该方法证明了即使使用有限的3D医学数据，通过精心设计的预训练目标和模型架构，也能有效挖掘体积医学图像和临床叙述中的丰富空间和语义关系，提升编码器的泛化能力。

Abstract: Vision-and-language models (VLMs) have been increasingly explored in the
medical domain, particularly following the success of CLIP in general domain.
However, unlike the relatively straightforward pairing of 2D images and text,
curating large-scale paired data in the medical field for volumetric modalities
such as CT scans remains a challenging and time-intensive process. This
difficulty often limits the performance on downstream tasks. To address these
challenges, we propose a novel vision-language pre-training (VLP) framework,
termed as \textbf{VELVET-Med}, specifically designed for limited volumetric
data such as 3D CT and associated radiology reports. Instead of relying on
large-scale data collection, our method focuses on the development of effective
pre-training objectives and model architectures. The key contributions are: 1)
We incorporate uni-modal self-supervised learning into VLP framework, which are
often underexplored in the existing literature. 2) We propose a novel language
encoder, termed as \textbf{TriBERT}, for learning multi-level textual
semantics. 3) We devise the hierarchical contrastive learning to capture
multi-level vision-language correspondence. Using only 38,875 scan-report
pairs, our approach seeks to uncover rich spatial and semantic relationships
embedded in volumetric medical images and corresponding clinical narratives,
thereby enhancing the generalization ability of the learned encoders. The
resulting encoders exhibit strong transferability, achieving state-of-the-art
performance across a wide range of downstream tasks, including 3D segmentation,
cross-modal retrieval, visual question answering, and report generation.

</details>


### [39] [Simple o3: Towards Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2508.12109)
*Ye Wang,Qianglong Chen,Zejun Li,Siyuan Wang,Shijie Guo,Zhirui Zhang,Zhongyu Wei*

Main category: cs.CV

TL;DR: Simple o3是一个端到端的多模态推理框架，通过监督微调整合动态视觉工具操作（裁剪、缩放、重用）到交错的视觉-语言推理中，显著提升了多模态大语言模型的长链思维能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在视觉语言任务上表现优异，但在多模态场景中的长链思维推理能力尚未得到充分探索，需要开发能够模拟人类"图像思维"的迭代推理方法。

Method: 提出Simple o3框架，通过"观察-推理-行动"循环生成高质量的交错视觉-语言推理链，整合动态工具交互（裁剪、缩放、重用），并创建了TWI-Tools-146K数据集进行监督微调。

Result: 实验结果显示Simple o3在多个基准测试中表现优异，优于现有方法。通过引入额外的视觉token进行交错推理，重用和放大原始图像显著改善了视觉推理和细粒度感知能力。

Conclusion: Simple o3建立了一个强大且计算效率高的多模态推理范式，首次深入分析了不同交错推理策略对模型性能的影响，为推进多模态推理提供了重要见解。

Abstract: Multimodal Large Language Models (MLLMs) have shown impressive performance on
vision-language tasks, but their long Chain-of-Thought (CoT) capabilities in
multimodal scenarios remain underexplored. Inspired by OpenAI's o3 model, which
emulates human-like ''thinking with image'' through iterative visual
transformations and linguistic reasoning, we propose Simple o3, an end-to-end
framework that integrates dynamic tool interactions (e.g., cropping, zooming,
and reusing) into interleaved vision-language reasoning via supervised
fine-tuning (SFT). Our approach features a scalable data synthesis pipeline
that generates high-quality interleaved vision-language reasoning chains via an
''observe-reason-act'' cycle, complete with executable visual operations and
rigorous verification, yielding the open-source TWI-Tools-146K dataset.
Experimental results demonstrate Simple o3's superior performance on diverse
benchmarks, outperforming existing approaches. By combining enhanced reasoning
capabilities, Simple o3 establishes a powerful yet computationally affordable
paradigm for advancing multimodal reasoning. Remarkably, we provide the first
in-depth analysis of different interleaved reasoning strategies, offering
insights into their impact on model performance. We found that by introducing
additional visual tokens for interleaved vision-language reasoning, reusing and
magnifying the original image significantly improves the model's visual
reasoning and fine-grained perception, while image cropping based on precise
visual grounding allows the model to effectively focus on key entities or
regions, further enhancing its capabilities.

</details>


### [40] [DualFit: A Two-Stage Virtual Try-On via Warping and Synthesis](https://arxiv.org/abs/2508.12131)
*Minh Tran,Johnmark Clements,Annie Prasanna,Tri Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DualFit是一个两阶段的虚拟试穿混合管道，通过流场变形保持服装细节，结合保真度保持的合成模块，在保持高频细节和视觉真实感之间取得平衡


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的免变形方法虽然提高了感知质量，但往往无法保留细粒度的服装细节（如logo和印刷文本元素），这些细节对品牌完整性和客户信任至关重要

Method: 两阶段方法：第一阶段使用学习到的流场将目标服装变形以对齐人物图像；第二阶段通过保真度保持试穿模块，使用保留区域输入和修复掩码来合成最终输出，保留关键区域并仅在必要区域重新生成

Result: 广泛的定性结果显示DualFit实现了视觉上无缝的试穿结果，同时忠实地保持了高频服装细节

Conclusion: DualFit在重建准确性和感知真实感之间取得了有效平衡，解决了现有方法在保留服装细节方面的局限性

Abstract: Virtual Try-On technology has garnered significant attention for its
potential to transform the online fashion retail experience by allowing users
to visualize how garments would look on them without physical trials. While
recent advances in diffusion-based warping-free methods have improved
perceptual quality, they often fail to preserve fine-grained garment details
such as logos and printed text elements that are critical for brand integrity
and customer trust. In this work, we propose DualFit, a hybrid VTON pipeline
that addresses this limitation by two-stage approach. In the first stage,
DualFit warps the target garment to align with the person image using a learned
flow field, ensuring high-fidelity preservation. In the second stage, a
fidelity-preserving try-on module synthesizes the final output by blending the
warped garment with preserved human regions. Particularly, to guide this
process, we introduce a preserved-region input and an inpainting mask, enabling
the model to retain key areas and regenerate only where necessary, particularly
around garment seams. Extensive qualitative results show that DualFit achieves
visually seamless try-on results while faithfully maintaining high-frequency
garment details, striking an effective balance between reconstruction accuracy
and perceptual realism.

</details>


### [41] [TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks](https://arxiv.org/abs/2508.12132)
*Amira Guesmi,Bassem Ouni,Muhammad Shafique*

Main category: cs.CV

TL;DR: TriQDef是一个三级量化感知防御框架，通过特征错位惩罚和梯度感知失谐惩罚来破坏跨位宽的补丁对抗攻击的可迁移性，在保持高清洁精度的同时将攻击成功率降低40%以上。


<details>
  <summary>Details</summary>
Motivation: 量化神经网络(QNNs)虽然对传统像素级攻击具有鲁棒性，但对跨位宽的补丁对抗攻击仍然脆弱。现有防御方法要么过拟合到固定量化设置，要么无法解决这种跨位泛化漏洞。

Method: TriQDef包含三个核心组件：(1)特征错位惩罚(FDP)通过惩罚中间表示的感知相似性来强制语义不一致；(2)梯度感知失谐惩罚(GPDP)通过边缘IoU和HOG余弦度量最小化结构性和方向性一致性来显式错位输入梯度；(3)联合量化感知训练协议，在多个量化级别上统一这些惩罚。

Result: 在CIFAR-10和ImageNet上的广泛实验表明，TriQDef在未见过的补丁和量化组合上将攻击成功率(ASR)降低了40%以上，同时保持了高清洁精度。

Conclusion: 研究强调了破坏语义和感知梯度对齐对于减轻QNNs中补丁可迁移性的重要性，TriQDef框架有效解决了跨位宽补丁攻击的转移性问题。

Abstract: Quantized Neural Networks (QNNs) are increasingly deployed in edge and
resource-constrained environments due to their efficiency in computation and
memory usage. While shown to distort the gradient landscape and weaken
conventional pixel-level attacks, it provides limited robustness against
patch-based adversarial attacks-localized, high-saliency perturbations that
remain surprisingly transferable across bit-widths. Existing defenses either
overfit to fixed quantization settings or fail to address this cross-bit
generalization vulnerability. We introduce \textbf{TriQDef}, a tri-level
quantization-aware defense framework designed to disrupt the transferability of
patch-based adversarial attacks across QNNs. TriQDef consists of: (1) a Feature
Disalignment Penalty (FDP) that enforces semantic inconsistency by penalizing
perceptual similarity in intermediate representations; (2) a Gradient
Perceptual Dissonance Penalty (GPDP) that explicitly misaligns input gradients
across bit-widths by minimizing structural and directional agreement via Edge
IoU and HOG Cosine metrics; and (3) a Joint Quantization-Aware Training
Protocol that unifies these penalties within a shared-weight training scheme
across multiple quantization levels. Extensive experiments on CIFAR-10 and
ImageNet demonstrate that TriQDef reduces Attack Success Rates (ASR) by over
40\% on unseen patch and quantization combinations, while preserving high clean
accuracy. Our findings underscore the importance of disrupting both semantic
and perceptual gradient alignment to mitigate patch transferability in QNNs.

</details>


### [42] [Infusing fine-grained visual knowledge to Vision-Language Models](https://arxiv.org/abs/2508.12137)
*Nikolaos-Antonios Ypsilantis,Kaifeng Chen,André Araujo,Ondřej Chum*

Main category: cs.CV

TL;DR: 这篇论文提出了一种细粒度视觉-语言模型微调方法，能够在保持预训练模型多模态知识的同时，完成基于域特定数据的细粒度调整，避免恐怖忘记问题。


<details>
  <summary>Details</summary>
Motivation: 大规模对比预训练的视觉-语言模型在细粒度开放集检索任务中表现仍有不足，但简单微调容易导致恐怖忘记，严重影响模型的通用能力。

Method: 受续续学习文献启发，系统分析并组合多种正则化技术，以保持预训练知识。同时重视验证集设计和超参数调整的关键作用。

Result: 在细粒度和粗粒度图像-图像、图像-文本检索测试中都获得了突出结果，在不使用文本数据或原始文本编码器的情况下仍能保持视觉-文本对齐能力。

Conclusion: 该方法能够有效平衡域适应和知识保持，为细粒度视觉检索提供了一种可靠的微调方案，保持了模型的多模态通用性能。

Abstract: Large-scale contrastive pre-training produces powerful Vision-and-Language
Models (VLMs) capable of generating representations (embeddings) effective for
a wide variety of visual and multimodal tasks. However, these pretrained
embeddings remain suboptimal for fine-grained open-set visual retrieval, where
state-of-the-art results require fine-tuning the vision encoder using annotated
domain-specific samples. Naively performing such fine-tuning typically leads to
catastrophic forgetting, severely diminishing the model's general-purpose
visual and cross-modal capabilities.
  In this work, we propose a fine-tuning method explicitly designed to achieve
optimal balance between fine-grained domain adaptation and retention of the
pretrained VLM's broad multimodal knowledge. Drawing inspiration from continual
learning literature, we systematically analyze standard regularization
techniques aimed at knowledge retention and propose an efficient and effective
combination strategy. Additionally, we address the commonly overlooked yet
critical aspects of validation set design and hyperparameter tuning to ensure
reproducibility and robust generalization across datasets and pretrained
models. We extensively evaluate our method on both fine-grained and
coarse-grained image-image and image-text retrieval benchmarks. Our approach
consistently achieves strong results, notably retaining the visual-text
alignment without utilizing any text data or the original text encoder during
fine-tuning. Code and model checkpoints: https://github.com/nikosips/infusing .

</details>


### [43] [KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction](https://arxiv.org/abs/2508.12147)
*Donghang Lyu,Marius Staring,Mariya Doneva,Hildo J. Lamb,Nicola Pezzotti*

Main category: cs.CV

TL;DR: KP-INR是一种用于心脏电影MRI重建的双分支隐式神经表示方法，通过在k空间坐标位置嵌入和局部多尺度特征表示之间进行交叉分支交互，实现了比基线模型更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的INR方法主要关注基于坐标的位置嵌入来学习映射，但忽略了目标点及其邻域上下文的特征表示，这限制了在具有挑战性的笛卡尔k空间数据上的重建性能。

Method: 提出KP-INR双分支INR方法：一个分支处理k空间坐标的位置嵌入，另一个分支学习这些坐标处的局部多尺度k空间特征表示，通过跨分支交互来近似目标k空间值。

Result: 在CMRxRecon2024数据集上的实验证实，KP-INR相比基线模型具有改进的性能，在心脏电影MRI重建领域展现出潜力。

Conclusion: KP-INR通过结合位置嵌入和局部特征表示的双分支方法，有效提升了心脏电影MRI的重建质量，为快速采集技术下的高质量图像恢复提供了新思路。

Abstract: Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for
assessing cardiac structure, function, and blood flow. Cine MRI extends this by
capturing heart motion, providing detailed insights into cardiac mechanics. To
reduce scan time and breath-hold discomfort, fast acquisition techniques have
been utilized at the cost of lowering image quality. Recently, Implicit Neural
Representation (INR) methods have shown promise in unsupervised reconstruction
by learning coordinate-to-value mappings from undersampled data, enabling
high-quality image recovery. However, current existing INR methods primarily
focus on using coordinate-based positional embeddings to learn the mapping,
while overlooking the feature representations of the target point and its
neighboring context. In this work, we propose KP-INR, a dual-branch INR method
operating in k-space for cardiac cine MRI reconstruction: one branch processes
the positional embedding of k-space coordinates, while the other learns from
local multi-scale k-space feature representations at those coordinates. By
enabling cross-branch interaction and approximating the target k-space values
from both branches, KP-INR can achieve strong performance on challenging
Cartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its
improved performance over baseline models and highlights its potential in this
field.

</details>


### [44] [Demystifying Foreground-Background Memorization in Diffusion Models](https://arxiv.org/abs/2508.12148)
*Jimmy Z. Di,Yiwei Lu,Yaoliang Yu,Gautam Kamath,Adam Dziedzic,Franziska Boenisch*

Main category: cs.CV

TL;DR: 提出了FB-Mem方法，通过分割技术量化扩散模型中图像生成的记忆化现象，发现记忆化比之前认知的更普遍，现有缓解方法效果有限


<details>
  <summary>Details</summary>
Motivation: 现有检测方法只能识别完全相同的记忆化复制，无法量化局部区域的记忆化现象，也无法捕捉超越特定提示-图像对的复杂记忆化模式

Method: 提出前景背景记忆化(FB-Mem)度量方法，基于分割技术对生成图像中的记忆化区域进行分类和量化分析

Result: 发现记忆化现象更加普遍：单个提示可能关联到多个相似训练图像的聚类；现有缓解方法无法消除局部记忆化，特别是前景区域的记忆化持续存在

Conclusion: 建立了一个有效的扩散模型记忆化测量框架，证明了现有缓解方法的不足，并提出基于聚类方法的更强缓解策略

Abstract: Diffusion models (DMs) memorize training images and can reproduce
near-duplicates during generation. Current detection methods identify verbatim
memorization but fail to capture two critical aspects: quantifying partial
memorization occurring in small image regions, and memorization patterns beyond
specific prompt-image pairs. To address these limitations, we propose
Foreground Background Memorization (FB-Mem), a novel segmentation-based metric
that classifies and quantifies memorized regions within generated images. Our
method reveals that memorization is more pervasive than previously understood:
(1) individual generations from single prompts may be linked to clusters of
similar training images, revealing complex memorization patterns that extend
beyond one-to-one correspondences; and (2) existing model-level mitigation
methods, such as neuron deactivation and pruning, fail to eliminate local
memorization, which persists particularly in foreground regions. Our work
establishes an effective framework for measuring memorization in diffusion
models, demonstrates the inadequacy of current mitigation approaches, and
proposes a stronger mitigation method using a clustering approach.

</details>


### [45] [RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis](https://arxiv.org/abs/2508.12163)
*Wenqing Wang,Yun Fu*

Main category: cs.CV

TL;DR: RealTalk是一个用于合成情感化说话头像的新框架，通过结合VAE、ResNet和NeRF技术，在情感准确性、可控性和身份保持方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前方法在唇形同步和图像质量方面表现优秀，但在生成准确可控的情感表达同时保持身份特征方面存在不足，需要解决情感化说话头像合成的挑战。

Method: 使用变分自编码器(VAE)从音频生成3D面部标志点，通过ResNet-based的地标变形模型(LDM)结合情感标签嵌入生成情感化地标，最后使用三平面注意力NeRF合成高真实度的情感化说话头像。

Result: 大量实验证明RealTalk在情感准确性、可控性和身份保持方面均优于现有方法。

Conclusion: RealTalk推动了社交智能AI系统的发展，为情感化说话头像合成提供了有效的解决方案。

Abstract: Emotion is a critical component of artificial social intelligence. However,
while current methods excel in lip synchronization and image quality, they
often fail to generate accurate and controllable emotional expressions while
preserving the subject's identity. To address this challenge, we introduce
RealTalk, a novel framework for synthesizing emotional talking heads with high
emotion accuracy, enhanced emotion controllability, and robust identity
preservation. RealTalk employs a variational autoencoder (VAE) to generate 3D
facial landmarks from driving audio, which are concatenated with emotion-label
embeddings using a ResNet-based landmark deformation model (LDM) to produce
emotional landmarks. These landmarks and facial blendshape coefficients jointly
condition a novel tri-plane attention Neural Radiance Field (NeRF) to
synthesize highly realistic emotional talking heads. Extensive experiments
demonstrate that RealTalk outperforms existing methods in emotion accuracy,
controllability, and identity preservation, advancing the development of
socially intelligent AI systems.

</details>


### [46] [Scalable RF Simulation in Generative 4D Worlds](https://arxiv.org/abs/2508.12176)
*Zhiwei Zheng,Dongyin Hu,Mingmin Zhao*

Main category: cs.CV

TL;DR: WaveVerse是一个基于提示的RF信号仿真框架，能够从生成的室内场景和人体运动中生成逼真的射频信号，解决了RF数据采集的挑战。


<details>
  <summary>Details</summary>
Motivation: RF传感作为视觉方法的隐私保护替代方案在室内感知中很重要，但在动态多样的室内环境中收集高质量RF数据仍然是一个主要挑战。

Method: WaveVerse包含语言引导的4D世界生成器（使用状态感知因果变换器生成受空间约束和文本条件控制的人体运动）和相位相干射线追踪模拟器（模拟准确相干的RF信号）。

Result: 实验证明了在条件人体运动生成方面的有效性，展示了相位相干性在波束成形和呼吸监测中的应用。两个案例研究显示WaveVerse不仅首次实现了RF成像数据生成，而且在数据有限和数据充足场景下都能获得性能提升。

Conclusion: WaveVerse提供了一个可扩展的框架，能够生成逼真的RF信号，解决了RF数据采集的难题，为RF感知应用提供了有效的数据生成解决方案。

Abstract: Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving
alternative to vision-based methods for indoor perception tasks. However,
collecting high-quality RF data in dynamic and diverse indoor environments
remains a major challenge. To address this, we introduce WaveVerse, a
prompt-based, scalable framework that simulates realistic RF signals from
generated indoor scenes with human motions. WaveVerse introduces a
language-guided 4D world generator, which includes a state-aware causal
transformer for human motion generation conditioned on spatial constraints and
texts, and a phase-coherent ray tracing simulator that enables the simulation
of accurate and coherent RF signals. Experiments demonstrate the effectiveness
of our approach in conditioned human motion generation and highlight how phase
coherence is applied to beamforming and respiration monitoring. We further
present two case studies in ML-based high-resolution imaging and human activity
recognition, demonstrating that WaveVerse not only enables data generation for
RF imaging for the first time, but also consistently achieves performance gain
in both data-limited and data-adequate scenarios.

</details>


### [47] [Splat Feature Solver](https://arxiv.org/abs/2508.12216)
*Butian Xiong,Rong Liu,Kenneth Xu,Meida Chen,Andrew Feng*

Main category: cs.CV

TL;DR: 提出了一种统一、核和特征无关的特征提升方法，将多视图图像特征高效地映射到3D高斯表示上，通过稀疏线性逆问题求解和正则化策略实现高质量特征提升。


<details>
  <summary>Details</summary>
Motivation: 解决3D场景理解中特征提升的核心挑战，即在多视图图像不一致的情况下，如何最优地将丰富的通用图像特征（如DINO、CLIP）分配给3D基元。

Method: 将特征提升问题形式化为稀疏线性逆问题，可闭式高效求解；引入Tikhonov指导确保数值稳定性，后提升聚合通过特征聚类过滤噪声输入。

Result: 在开放词汇3D分割基准测试中达到最先进性能，优于基于训练、分组和启发式的前沿方法，且能在几分钟内生成提升特征。

Conclusion: 该方法提供了一个理论保证的全局最优误差上界，通过互补的正则化策略有效处理多视图观测中的不一致性和噪声，实现了高质量的特征提升。

Abstract: Feature lifting has emerged as a crucial component in 3D scene understanding,
enabling the attachment of rich image feature descriptors (e.g., DINO, CLIP)
onto splat-based 3D representations. The core challenge lies in optimally
assigning rich general attributes to 3D primitives while addressing the
inconsistency issues from multi-view images. We present a unified, kernel- and
feature-agnostic formulation of the feature lifting problem as a sparse linear
inverse problem, which can be solved efficiently in closed form. Our approach
admits a provable upper bound on the global optimal error under convex losses
for delivering high quality lifted features. To address inconsistencies and
noise in multi-view observations, we introduce two complementary regularization
strategies to stabilize the solution and enhance semantic fidelity. Tikhonov
Guidance enforces numerical stability through soft diagonal dominance, while
Post-Lifting Aggregation filters noisy inputs via feature clustering. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
on open-vocabulary 3D segmentation benchmarks, outperforming training-based,
grouping-based, and heuristic-forward baselines while producing the lifted
features in minutes. Code is available at
\href{https://github.com/saliteta/splat-distiller.git}{\textbf{github}}. We
also have a \href{https://splat-distiller.pages.dev/}

</details>


### [48] [C2PSA-Enhanced YOLOv11 Architecture: A Novel Approach for Small Target Detection in Cotton Disease Diagnosis](https://arxiv.org/abs/2508.12219)
*Kaiyuan Wang,Jixing Liu,Xiaobo Cai*

Main category: cs.CV

TL;DR: 基于YOLOv11的深度学习优化方案，通过C2PSA模块、动态类别权重和改进数据增帿技术，显著提升棉花病害检测精度和速度，实现了实时农业监测系统。


<details>
  <summary>Details</summary>
Motivation: 解决棉花病害检测中的三大挑战：早期小斑点检测精度低（漏检率35%）、田间环境性能下降（准确率下降25%）、多病害场景错误率高（34.7%）。

Method: 提出C2PSA模块提升小目标特征提取能力，采用动态类别权重处理样本不平衡问题，通过Mosaic-MixUp缩放技术改进数据增帿。

Result: 在4,078张图像数据集上验证：mAP50达到0.820（提升8.0%），mAP50-95达到0.705（提升10.5%），推理速度158 FPS，实现了高精度实时检测。

Conclusion: 该优化方案有效解决了棉花病害检测的关键问题，通过移动端部署实现了实时病害监测和精准治疗，为农业应用提供了有效的智能化解决方案。

Abstract: This study presents a deep learning-based optimization of YOLOv11 for cotton
disease detection, developing an intelligent monitoring system. Three key
challenges are addressed: (1) low precision in early spot detection (35%
leakage rate for sub-5mm2 spots), (2) performance degradation in field
conditions (25% accuracy drop), and (3) high error rates (34.7%) in
multi-disease scenarios. The proposed solutions include: C2PSA module for
enhanced small-target feature extraction; Dynamic category weighting to handle
sample imbalance; Improved data augmentation via Mosaic-MixUp scaling.
Experimental results on a 4,078-image dataset show: mAP50: 0.820 (+8.0%
improvement); mAP50-95: 0.705 (+10.5% improvement); Inference speed: 158 FPS.
The mobile-deployed system enables real-time disease monitoring and precision
treatment in agricultural applications.

</details>


### [49] [In vivo 3D ultrasound computed tomography of musculoskeletal tissues with generative neural physics](https://arxiv.org/abs/2508.12226)
*Zhijun Zeng,Youjia Zheng,Chang Su,Qianhang Wu,Hao Hu,Zeyuan Dong,Shan Gao,Yang Lv,Rui Tang,Ligang Cui,Zhiyong Hou,Weijun Lin,Zuoqiang Shi,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: 提出了一种结合生成式网络和物理模拟的新题床法，能够在10分钟内完成高保真的3D超声计算机成像重建，充分考虑强散射效应，在肌肉骨骼组织定量成像方面取得了类似MRI的分辨率结果。


<details>
  <summary>Details</summary>
Motivation: 传统光线基于重建方法在肌肉骨骼超声成像中存在限制，忽略了强散射效应，导致重建质量不高。需要一种能够充分考虑强散射效应的高保真、高效率的3D超声计算机成像方法。

Method: 提出了一种生成式神经物理框架，将生成式网络与物理信息神经模拟相结合。方法从仅数十张交叉模态图像中学习超声波传播的简化代替模型，将波动模型的准确性与深度学习的效率和稳定性相融合。

Result: 在合成数据和in vivo数据（乳腺、手臂、腿部）上，方法能够在10分钟内重建组织参数的3D分布图。对肌肉和骨骼的生物力学性质体现出高敏感性，分辨率可与MRI相比。能够生成超出反射模式图像的声学特性空间分布图。

Conclusion: 该方法充分考虑了强散射效应，充分结合了波动模型的准确性和深度学习的效率优势，在高保真3D超声计算机成像重建方面取得了重大突破。这为肌肉骨骼疾病的常规临床评估提供了新的技术支撑，有望推动USCT技术的临床应用。

Abstract: Ultrasound computed tomography (USCT) is a radiation-free, high-resolution
modality but remains limited for musculoskeletal imaging due to conventional
ray-based reconstructions that neglect strong scattering. We propose a
generative neural physics framework that couples generative networks with
physics-informed neural simulation for fast, high-fidelity 3D USCT. By learning
a compact surrogate of ultrasonic wave propagation from only dozens of
cross-modality images, our method merges the accuracy of wave modeling with the
efficiency and stability of deep learning. This enables accurate quantitative
imaging of in vivo musculoskeletal tissues, producing spatial maps of acoustic
properties beyond reflection-mode images. On synthetic and in vivo data
(breast, arm, leg), we reconstruct 3D maps of tissue parameters in under ten
minutes, with sensitivity to biomechanical properties in muscle and bone and
resolution comparable to MRI. By overcoming computational bottlenecks in
strongly scattering regimes, this approach advances USCT toward routine
clinical assessment of musculoskeletal disease.

</details>


### [50] [WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions](https://arxiv.org/abs/2508.12250)
*Quan Chen,Xiong Yang,Rongfeng Lu,Qianyu Zhang,Yu Liu,Xiaofei Zhou,Bolun Zheng*

Main category: cs.CV

TL;DR: 这篇论文提出了一个包含多种天气噪声的显著目标检测数据集WXSOD，并设计了一种能够利用天气特征的网络结构WFANet来提高在复杂天气条件下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前的显著目标检测方法在清晰自然场景中表现良好，但缺少针对天气噪声影响的研究，主要因为缺少包含像素级注释的天气噪声数据集。

Method: 构建了包含14,945张RGB图片的WXSOD数据集，包含合成和真实天气噪声。提出了两支架构的WFANet网络：天气预测支路挖掘天气特征，显著检测支路融合语义特征和天气特征。

Result: 在WXSOD数据集上与17种SOD方法进行了综合比较，WFANet实现了更优的性能。

Conclusion: 该研究为天气噪声条件下的显著目标检测提供了重要的数据集基准和有效的基线方法，展示了利用天气信息来提高检测精度的潜力。

Abstract: Salient object detection (SOD) in complex environments remains a challenging
research topic. Most existing methods perform well in natural scenes with
negligible noise, and tend to leverage multi-modal information (e.g., depth and
infrared) to enhance accuracy. However, few studies are concerned with the
damage of weather noise on SOD performance due to the lack of dataset with
pixel-wise annotations. To bridge this gap, this paper introduces a novel
Weather-eXtended Salient Object Detection (WXSOD) dataset. It consists of
14,945 RGB images with diverse weather noise, along with the corresponding
ground truth annotations and weather labels. To verify algorithm
generalization, WXSOD contains two test sets, i.e., a synthesized test set and
a real test set. The former is generated by adding weather noise to clean
images, while the latter contains real-world weather noise. Based on WXSOD, we
propose an efficient baseline, termed Weather-aware Feature Aggregation Network
(WFANet), which adopts a fully supervised two-branch architecture.
Specifically, the weather prediction branch mines weather-related deep
features, while the saliency detection branch fuses semantic features extracted
from the backbone with weather features for SOD. Comprehensive comparisons
against 17 SOD methods shows that our WFANet achieves superior performance on
WXSOD. The code and benchmark results will be made publicly available at
https://github.com/C-water/WXSOD

</details>


### [51] [Superpixel-informed Continuous Low-Rank Tensor Representation for Multi-Dimensional Data Recovery](https://arxiv.org/abs/2508.12261)
*Zhizhou Wang,Ruijing Zheng,Zhenyu Wu,Jianli Wang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种超像素信息化的连续低秩张量表示框架(SCTR)，解决了传统低秩张量方法在实际应用中的两大限制，在多测试集上获得了3-5 dB的PSNR提升。


<details>
  <summary>Details</summary>
Motivation: 传统低秩张量表示方法存在两个主要问题：(1)假设整体数据低秩，但实际场景中存在显著空间变化；(2)仅适用于离散网格数据，灵活性不足。

Method: 提出SCTR框架：(1)使用超像素作为基础建模单元，反映语义一致区域的强低秩特性；(2)提出非对称低秩张量分解(ALTF)，通过共享神经网络和专门头部来分离全局模式学习与局部适应，同时捐捕超像素间共性和内部变化。

Result: 在多光谱图像、视频和色彩图像等多个标准测试集上，SCTR模型相比现有低秩张量方法获得了3-5 dB的PSNR提升。

Conclusion: SCTR框架通过超像素为基础建模单元和非对称低秩张量分解，成功解决了传统方法的限制，实现了更高表达力和更好适应性的多维数据模型。

Abstract: Low-rank tensor representation (LRTR) has emerged as a powerful tool for
multi-dimensional data processing. However, classical LRTR-based methods face
two critical limitations: (1) they typically assume that the holistic data is
low-rank, this assumption is often violated in real-world scenarios with
significant spatial variations; and (2) they are constrained to discrete
meshgrid data, limiting their flexibility and applicability. To overcome these
limitations, we propose a Superpixel-informed Continuous low-rank Tensor
Representation (SCTR) framework, which enables continuous and flexible modeling
of multi-dimensional data beyond traditional grid-based constraints. Our
approach introduces two main innovations: First, motivated by the observation
that semantically coherent regions exhibit stronger low-rank characteristics
than holistic data, we employ superpixels as the basic modeling units. This
design not only encodes rich semantic information, but also enhances
adaptability to diverse forms of data streams. Second, we propose a novel
asymmetric low-rank tensor factorization (ALTF) where superpixel-specific
factor matrices are parameterized by a shared neural network with specialized
heads. By strategically separating global pattern learning from local
adaptation, this framework efficiently captures both cross-superpixel
commonalities and within-superpixel variations. This yields a representation
that is both highly expressive and compact, balancing model efficiency with
adaptability. Extensive experiments on several benchmark datasets demonstrate
that SCTR achieves 3-5 dB PSNR improvements over existing LRTR-based methods
across multispectral images, videos, and color images.

</details>


### [52] [Region-Level Context-Aware Multimodal Understanding](https://arxiv.org/abs/2508.12263)
*Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao*

Main category: cs.CV

TL;DR: 本文提出了区域级上下文感知多模态理解(RCMU)能力，并开发了RCVIT调优方法、RCMU数据集和RC&P-Bench评测标准，RC-Qwen2-VL模型在多个RCMU任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型主要关注通用视觉理解，忽视了将对象的文本上下文与视觉内容相结合的能力，影响了上下文感知多模态理解的效果。

Method: 提出Region-level Context-aware Visual Instruction Tuning (RCVIT)方法，将对象信息整合到模型输入中，利用边框坐标将对象的视觉内容与文本信息关联。构建了RCMU数据集和RC&P-Bench评测标准。

Result: 通过在Qwen2-VL模型上进行RCVIT调优，开发出RC-Qwen2-VL模型。实验结果显示该模型在多个RCMU任务上表现优异，并在多模态RAG和个性化对话中成功应用。

Conclusion: 本文成功地为MLLMs培养了区域级上下文感知多模态理解能力，提供了完整的方法、数据集和评测标准，为该领域的研究和应用基础做出了重要贡献。

Abstract: Despite significant progress, existing research on Multimodal Large Language
Models (MLLMs) mainly focuses on general visual understanding, overlooking the
ability to integrate textual context associated with objects for a more
context-aware multimodal understanding -- an ability we refer to as
Region-level Context-aware Multimodal Understanding (RCMU). To address this
limitation, we first formulate the RCMU task, which requires models to respond
to user instructions by integrating both image content and textual information
of regions or objects. To equip MLLMs with RCMU capabilities, we propose
Region-level Context-aware Visual Instruction Tuning (RCVIT), which
incorporates object information into the model input and enables the model to
utilize bounding box coordinates to effectively associate objects' visual
content with their textual information. To address the lack of datasets, we
introduce the RCMU dataset, a large-scale visual instruction tuning dataset
that covers multiple RCMU tasks. We also propose RC\&P-Bench, a comprehensive
benchmark that can evaluate the performance of MLLMs in RCMU and multimodal
personalized understanding tasks. Additionally, we propose a reference-free
evaluation metric to perform a comprehensive and fine-grained evaluation of the
region-level context-aware image descriptions. By performing RCVIT on Qwen2-VL
models with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental
results indicate that RC-Qwen2-VL models not only achieve outstanding
performance on multiple RCMU tasks but also demonstrate successful applications
in multimodal RAG and personalized conversation. Our data, model and benchmark
are available at https://github.com/hongliang-wei/RC-MLLM

</details>


### [53] [SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration](https://arxiv.org/abs/2508.12271)
*Ronghua Xu,Jin Xie,Jing Nie,Jiale Cao,Yanwei Pang*

Main category: cs.CV

TL;DR: 这篇论文提出了SNNSIR，一种专门用于双目图像恢复的简洁高效制出神经网络，通过全刻刻驱动架构实现低功耗硬件友好计算。


<details>
  <summary>Details</summary>
Motivation: 现有的混合SNN-ANN模型仍依赖浮点数运算，与SNN的二进制和事件驱动特性不相容。SNNSIR目标建立一种完全刻刻驱动的架构，以实现低功耗和硬件友好的双目图像恢复。

Method: 设计了轻量级刻刻殊式殊式基础块(SRBB)增强信息流；刻刻双目卷积调制(SSCM)模块通过元素乘法实现简化非线性和跨视角调制；刻刻双目交叉注意力(SSCA)模块支持双向特征交互。

Result: 在多种双目图像恢复任务(去雨纹、去雨滴、低光增强、超分辨率)上进行了广泛实验，模型在保持竞争性恢复性能的同时显著降低了计算开销。

Conclusion: SNNSIR为实时、低功耗的双目视觉应用提供了潜力，证明了全刻刻驱动架构在计算密集型任务中的效果。

Abstract: Spiking Neural Networks (SNNs), characterized by discrete binary activations,
offer high computational efficiency and low energy consumption, making them
well-suited for computation-intensive tasks such as stereo image restoration.
In this work, we propose SNNSIR, a simple yet effective Spiking Neural Network
for Stereo Image Restoration, specifically designed under the spike-driven
paradigm where neurons transmit information through sparse, event-based binary
spikes. In contrast to existing hybrid SNN-ANN models that still rely on
operations such as floating-point matrix division or exponentiation, which are
incompatible with the binary and event-driven nature of SNNs, our proposed
SNNSIR adopts a fully spike-driven architecture to achieve low-power and
hardware-friendly computation. To address the expressiveness limitations of
binary spiking neurons, we first introduce a lightweight Spike Residual Basic
Block (SRBB) to enhance information flow via spike-compatible residual
learning. Building on this, the Spike Stereo Convolutional Modulation (SSCM)
module introduces simplified nonlinearity through element-wise multiplication
and highlights noise-sensitive regions via cross-view-aware modulation.
Complementing this, the Spike Stereo Cross-Attention (SSCA) module further
improves stereo correspondence by enabling efficient bidirectional feature
interaction across views within a spike-compatible framework. Extensive
experiments on diverse stereo image restoration tasks, including rain streak
removal, raindrop removal, low-light enhancement, and super-resolution
demonstrate that our model achieves competitive restoration performance while
significantly reducing computational overhead. These results highlight the
potential for real-time, low-power stereo vision applications. The code will be
available after the article is accepted.

</details>


### [54] [TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform](https://arxiv.org/abs/2508.12279)
*Jun Liu,Zhenglun Kong,Pu Zhao,Weihao Zeng,Hao Tang,Xuan Shen,Changdi Yang,Wenbin Zhang,Geng Yuan,Wei Niu,Xue Lin,Yanzhi Wang*

Main category: cs.CV

TL;DR: 提出了一种针对自动驾驶硬件平台的动态可适应语义分割网络，通过三层控制机制和贝叶斯优化实现计算资源优化配置


<details>
  <summary>Details</summary>
Motivation: 自动驾驶平台面临多样化的驾驶场景和硬件资源限制，需要在嵌入式设备上考虑计算成本，根据硬件计算能力和特定场景定制语义分割网络

Method: 采用三层控制机制（宽度乘数、分类器深度、分类器核）实现细粒度模型组件控制，结合贝叶斯优化和代理模型在有限计算预算下高效探索超参数空间

Result: 实现了任务特定的学习适应(TSLA)，能够根据不同的自动驾驶任务生成定制化配置，最大化计算容量和模型精度

Conclusion: 该方法能够有效优化硬件利用率，满足自动驾驶场景特定的计算复杂度和精度需求，为嵌入式平台上的语义分割网络部署提供了有效的解决方案

Abstract: Autonomous driving platforms encounter diverse driving scenarios, each with
varying hardware resources and precision requirements. Given the computational
limitations of embedded devices, it is crucial to consider computing costs when
deploying on target platforms like the NVIDIA\textsuperscript{\textregistered}
DRIVE PX 2. Our objective is to customize the semantic segmentation network
according to the computing power and specific scenarios of autonomous driving
hardware. We implement dynamic adaptability through a three-tier control
mechanism -- width multiplier, classifier depth, and classifier kernel --
allowing fine-grained control over model components based on hardware
constraints and task requirements. This adaptability facilitates broad model
scaling, targeted refinement of the final layers, and scenario-specific
optimization of kernel sizes, leading to improved resource allocation and
performance.
  Additionally, we leverage Bayesian Optimization with surrogate modeling to
efficiently explore hyperparameter spaces under tight computational budgets.
Our approach addresses scenario-specific and task-specific requirements through
automatic parameter search, accommodating the unique computational complexity
and accuracy needs of autonomous driving. It scales its Multiply-Accumulate
Operations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in
alternative configurations tailored to diverse self-driving tasks. These TSLA
customizations maximize computational capacity and model accuracy, optimizing
hardware utilization.

</details>


### [55] [CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval](https://arxiv.org/abs/2508.12290)
*Chor Boon Tan,Conghui Hu,Gim Hee Lee*

Main category: cs.CV

TL;DR: 本文提出CLAIR方法，利用CLIP等大型基础模型生成的噪声伪标签进行弱监督零样本跨域图像检索，通过置信度评分、对比学习和跨域映射函数提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型基础模型能够轻松为大量未标注数据生成伪标签，无监督零样本跨域图像检索的重要性降低，因此转向研究利用大型模型生成噪声伪标签的弱监督方法。

Method: 提出CLAIR方法：1）使用CLIP文本和图像特征相似度计算置信度来精炼噪声伪标签；2）设计实例间和簇间对比损失编码类感知潜在空间；3）使用域间对比损失减少域差异；4）学习闭式跨域映射函数；5）引入可学习提示增强零样本泛化能力。

Result: 在TUBerlin、Sketchy、Quickdraw和DomainNet等零样本数据集上的大量实验表明，CLAIR方法相比现有最先进方法 consistently 表现出优越性能。

Conclusion: CLAIR方法有效解决了弱监督零样本跨域图像检索问题，通过精炼噪声标签、对比学习和跨域映射等技术，显著提升了检索性能和对新类别的泛化能力。

Abstract: The recent growth of large foundation models that can easily generate
pseudo-labels for huge quantity of unlabeled data makes unsupervised Zero-Shot
Cross-Domain Image Retrieval (UZS-CDIR) less relevant. In this paper, we
therefore turn our attention to weakly supervised ZS-CDIR (WSZS-CDIR) with
noisy pseudo labels generated by large foundation models such as CLIP. To this
end, we propose CLAIR to refine the noisy pseudo-labels with a confidence score
from the similarity between the CLIP text and image features. Furthermore, we
design inter-instance and inter-cluster contrastive losses to encode images
into a class-aware latent space, and an inter-domain contrastive loss to
alleviate domain discrepancies. We also learn a novel cross-domain mapping
function in closed-form, using only CLIP text embeddings to project image
features from one domain to another, thereby further aligning the image
features for retrieval. Finally, we enhance the zero-shot generalization
ability of our CLAIR to handle novel categories by introducing an extra set of
learnable prompts. Extensive experiments are carried out using TUBerlin,
Sketchy, Quickdraw, and DomainNet zero-shot datasets, where our CLAIR
consistently shows superior performance compared to existing state-of-the-art
methods.

</details>


### [56] [Improving Densification in 3D Gaussian Splatting for High-Fidelity Rendering](https://arxiv.org/abs/2508.12313)
*Xiaobin Deng,Changyu Diao,Min Li,Ruohan Yu,Duanqing Xu*

Main category: cs.CV

TL;DR: 改进3D高斯散点的密度化策略，通过边缘感知分数、长轴分割等技术提升重建质量，减少过拟合，在保持实时渲染的同时减少高斯数量


<details>
  <summary>Details</summary>
Motivation: 3D高斯散点技术虽然实现了实时渲染，但其密度化策略导致重建质量不佳，需要从时机选择、方法优化和过拟合控制三个方面进行全面改进

Method: 提出边缘感知分数来选择分割候选高斯；长轴分割策略减少克隆分割引入的几何失真；重建感知剪枝、多步更新和增长控制技术减少过拟合

Result: 方法在不增加训练或推理开销的情况下，提升了渲染保真度，并以更少的高斯数量达到了最高水平的性能

Conclusion: 该研究通过系统性的密度化管道改进，有效解决了3D高斯散点的重建质量问题，为实时高质量3D重建提供了有效的技术方案

Abstract: Although 3D Gaussian Splatting (3DGS) has achieved impressive performance in
real-time rendering, its densification strategy often results in suboptimal
reconstruction quality. In this work, we present a comprehensive improvement to
the densification pipeline of 3DGS from three perspectives: when to densify,
how to densify, and how to mitigate overfitting. Specifically, we propose an
Edge-Aware Score to effectively select candidate Gaussians for splitting. We
further introduce a Long-Axis Split strategy that reduces geometric distortions
introduced by clone and split operations. To address overfitting, we design a
set of techniques, including Recovery-Aware Pruning, Multi-step Update, and
Growth Control. Our method enhances rendering fidelity without introducing
additional training or inference overhead, achieving state-of-the-art
performance with fewer Gaussians.

</details>


### [57] [Neural Cellular Automata for Weakly Supervised Segmentation of White Blood Cells](https://arxiv.org/abs/2508.12322)
*Michael Deutges,Chen Yang,Raheleh Salehi,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 基于神经细胞自动机(NCA)的弱监督分割方法，无需重新训练即可从分类特征图中提取分割掩码，在白细胞显微镜图像上显著超过现有弱监督方法。


<details>
  <summary>Details</summary>
Motivation: 医学诊断中白细胞检测和分割需要大量标签数据，而标注过程耗时耗费，需要一种可扩展且高效的弱监督解决方案。

Method: 提出NCA-WSS方法，利用神经细胞自动机在分类过程中生成的特征图，无需分割标签重新训练即可提取分割掩码。

Result: 在三个白细胞显微镜数据集上评估，NCA-WSS方法显著超过现有的弱监督分割方法。

Conclusion: 该方法呈现了NCA在弱监督框架下同时进行分类和分割的潜力，为医学图像分析提供了可扩展且高效的解决方案。

Abstract: The detection and segmentation of white blood cells in blood smear images is
a key step in medical diagnostics, supporting various downstream tasks such as
automated blood cell counting, morphological analysis, cell classification, and
disease diagnosis and monitoring. Training robust and accurate models requires
large amounts of labeled data, which is both time-consuming and expensive to
acquire. In this work, we propose a novel approach for weakly supervised
segmentation using neural cellular automata (NCA-WSS). By leveraging the
feature maps generated by NCA during classification, we can extract
segmentation masks without the need for retraining with segmentation labels. We
evaluate our method on three white blood cell microscopy datasets and
demonstrate that NCA-WSS significantly outperforms existing weakly supervised
approaches. Our work illustrates the potential of NCA for both classification
and segmentation in a weakly supervised framework, providing a scalable and
efficient solution for medical image analysis.

</details>


### [58] [Attention Pooling Enhances NCA-based Classification of Microscopy Images](https://arxiv.org/abs/2508.12324)
*Chen Yang,Michael Deutges,Jingsong Liu,Han Li,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 通过将注意力池化机制整合到神经细胞自动机(NCA)中，显著提升了显微镜图像分类性能，在保持参数效率的同时超越了传统NCA方法和轻量级CNN/ViT架构。


<details>
  <summary>Details</summary>
Motivation: 神经细胞自动机(NCA)在图像分类中具有鲁棒性和可解释性优势，但性能仍落后于更复杂的架构。需要提升NCA在显微镜图像分析中的分类准确性。

Method: 将注意力池化机制与NCA集成，通过关注信息最丰富的区域来增强特征提取能力。

Result: 在8个不同的显微镜图像数据集上评估，该方法显著优于现有NCA方法，同时保持参数高效和可解释性。相比传统轻量级CNN和ViT架构，性能更优且参数量显著更低。

Conclusion: 基于NCA的模型具有作为可解释图像分类替代方案的巨大潜力，注意力池化的整合有效弥补了性能差距。

Abstract: Neural Cellular Automata (NCA) offer a robust and interpretable approach to
image classification, making them a promising choice for microscopy image
analysis. However, a performance gap remains between NCA and larger, more
complex architectures. We address this challenge by integrating attention
pooling with NCA to enhance feature extraction and improve classification
accuracy. The attention pooling mechanism refines the focus on the most
informative regions, leading to more accurate predictions. We evaluate our
method on eight diverse microscopy image datasets and demonstrate that our
approach significantly outperforms existing NCA methods while remaining
parameter-efficient and explainable. Furthermore, we compare our method with
traditional lightweight convolutional neural network and vision transformer
architectures, showing improved performance while maintaining a significantly
lower parameter count. Our results highlight the potential of NCA-based models
an alternative for explainable image classification.

</details>


### [59] [DoppDrive: Doppler-Driven Temporal Aggregation for Improved Radar Object Detection](https://arxiv.org/abs/2508.12330)
*Yuval Haitman,Oded Bialer*

Main category: cs.CV

TL;DR: DoppDrive是一种基于多普勒效应的雷达点云时间聚合方法，通过径向移动消除动态物体散射，提高点云密度，从而显著提升各种检测器的目标检测性能


<details>
  <summary>Details</summary>
Motivation: 雷达点云在远距离时稀疏性严重，现有时间聚合方法会引入动态物体散射，降低检测性能

Method: 提出Doppler-Driven时间聚合方法，根据多普勒动态分量径向移动历史帧点云消除径向散射，基于多普勒和角度为每个点分配独特聚合时长以减少切向散射

Result: 显著提升了各种检测器和数据集上的目标检测性能

Conclusion: DoppDrive作为点云密度增强步骤，兼容任何检测器，能有效解决雷达点云稀疏性问题

Abstract: Radar-based object detection is essential for autonomous driving due to
radar's long detection range. However, the sparsity of radar point clouds,
especially at long range, poses challenges for accurate detection. Existing
methods increase point density through temporal aggregation with ego-motion
compensation, but this approach introduces scatter from dynamic objects,
degrading detection performance. We propose DoppDrive, a novel Doppler-Driven
temporal aggregation method that enhances radar point cloud density while
minimizing scatter. Points from previous frames are shifted radially according
to their dynamic Doppler component to eliminate radial scatter, with each point
assigned a unique aggregation duration based on its Doppler and angle to
minimize tangential scatter. DoppDrive is a point cloud density enhancement
step applied before detection, compatible with any detector, and we demonstrate
that it significantly improves object detection performance across various
detectors and datasets.

</details>


### [60] [Geometry-Aware Video Inpainting for Joint Headset Occlusion Removal and Face Reconstruction in Social XR](https://arxiv.org/abs/2508.12336)
*Fatemeh Ghorbani Lohesara,Karen Eguiazarian,Sebastian Knorr*

Main category: cs.CV

TL;DR: 提出了一种基于几何感知学习的框架，能够从单视角RGB视频中联合去除头戴显示器遮挡并重建完整的3D面部几何结构


<details>
  <summary>Details</summary>
Motivation: 头戴显示器会遮挡用户上半部分面部，影响外部视频录制和社交XR应用中的面部表情和眼神交流，需要解决HMD遮挡问题

Method: 集成GAN-based视频修复网络，通过密集面部关键点和单张无遮挡参考帧指导，结合SynergyNet-based模块从修复后的帧中回归3DMM参数，并采用密集关键点优化提升质量

Result: 实验证明该框架能成功从RGB面部视频中去除HMD，保持面部身份和真实感，生成逼真的3D面部几何输出，在不同关键点密度下保持鲁棒性

Conclusion: 该框架有效解决了HMD遮挡问题，为社交XR应用提供了高质量的面部重建解决方案

Abstract: Head-mounted displays (HMDs) are essential for experiencing extended reality
(XR) environments and observing virtual content. However, they obscure the
upper part of the user's face, complicating external video recording and
significantly impacting social XR applications such as teleconferencing, where
facial expressions and eye gaze details are crucial for creating an immersive
experience. This study introduces a geometry-aware learning-based framework to
jointly remove HMD occlusions and reconstruct complete 3D facial geometry from
RGB frames captured from a single viewpoint. The method integrates a GAN-based
video inpainting network, guided by dense facial landmarks and a single
occlusion-free reference frame, to restore missing facial regions while
preserving identity. Subsequently, a SynergyNet-based module regresses 3D
Morphable Model (3DMM) parameters from the inpainted frames, enabling accurate
3D face reconstruction. Dense landmark optimization is incorporated throughout
the pipeline to improve both the inpainting quality and the fidelity of the
recovered geometry. Experimental results demonstrate that the proposed
framework can successfully remove HMDs from RGB facial videos while maintaining
facial identity and realism, producing photorealistic 3D face geometry outputs.
Ablation studies further show that the framework remains robust across
different landmark densities, with only minor quality degradation under sparse
landmark configurations.

</details>


### [61] [Semantic Discrepancy-aware Detector for Image Forgery Identification](https://arxiv.org/abs/2508.12341)
*Ziye Wang,Minghang Yu,Chunyan Xu,Zhen Cui*

Main category: cs.CV

TL;DR: 基于预训练视觉语言模型的语义差异感知检测器(SDD)，通过重构学习对齐伪造空间和语义概念空间，提升图像伪造检测性能


<details>
  <summary>Details</summary>
Motivation: 图像生成技术快速发展，需要稳健的伪造检测确保数字媒体可信质。现有方法中伪造空间与语义概念空间的不匹配影响了检测性能

Method: 设计语义标志采样模块减少无关特征带来的空间偏移，构建概念级伪造差异学习模块加强视觉语义概念与伪造迹象的交互，通过低级伪造特征增强最小化冗余信息

Result: 在两个标准图像伪造数据集上验证了SDD的有效性，达到了超过现有方法的优异结果

Conclusion: SDD通过细粒度视觉层面对齐伪造空间和语义概念空间，有效提升了图像伪造检测的性能和可靠性

Abstract: With the rapid advancement of image generation techniques, robust forgery
detection has become increasingly imperative to ensure the trustworthiness of
digital media. Recent research indicates that the learned semantic concepts of
pre-trained models are critical for identifying fake images. However, the
misalignment between the forgery and semantic concept spaces hinders the
model's forgery detection performance. To address this problem, we propose a
novel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction
learning to align the two spaces at a fine-grained visual level. By exploiting
the conceptual knowledge embedded in the pre-trained vision language model, we
specifically design a semantic token sampling module to mitigate the space
shifts caused by features irrelevant to both forgery traces and semantic
concepts. A concept-level forgery discrepancy learning module, built upon a
visual reconstruction paradigm, is proposed to strengthen the interaction
between visual semantic concepts and forgery traces, effectively capturing
discrepancies under the concepts' guidance. Finally, the low-level forgery
feature enhancemer integrates the learned concept level forgery discrepancies
to minimize redundant forgery information. Experiments conducted on two
standard image forgery datasets demonstrate the efficacy of the proposed SDD,
which achieves superior results compared to existing methods. The code is
available at https://github.com/wzy1111111/SSD.

</details>


### [62] [AquaFeat: A Features-Based Image Enhancement Model for Underwater Object Detection](https://arxiv.org/abs/2508.12343)
*Emanuel C. Silva,Tatiana T. Schein,Stephanie L. Brião,Guilherme L. M. Costa,Felipe G. Oliveira,Gustavo P. Almeida,Eduardo L. Silva,Sam S. Devincenzi,Karina S. Machado,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: AquaFeat是一个即插即用的任务驱动特征增强模块，专门针对水下目标检测任务进行优化，通过多尺度特征增强网络与检测器端到端训练，显著提升检测精度并保持实时处理速度。


<details>
  <summary>Details</summary>
Motivation: 水下环境的严重图像退化影响了目标检测模型的性能，传统的图像增强方法往往没有针对下游检测任务进行优化，需要一种专门的任务驱动特征增强方法。

Method: 提出AquaFeat模块，集成多尺度特征增强网络，与检测器端到端训练，使用检测器的损失函数来显式指导特征增强过程，优化对检测任务最相关的特征。

Result: 在YOLOv8m上集成AquaFeat，在挑战性水下数据集上达到SOTA性能：精度0.877，召回率0.624，mAP@0.5为0.677，mAP@[0.5:0.95]为0.421，处理速度46.5 FPS。

Conclusion: AquaFeat提供了一种计算高效且有效的解决方案，适用于海洋生态系统监测和基础设施检查等实际应用场景，在保持实时处理速度的同时显著提升检测精度。

Abstract: The severe image degradation in underwater environments impairs object
detection models, as traditional image enhancement methods are often not
optimized for such downstream tasks. To address this, we propose AquaFeat, a
novel, plug-and-play module that performs task-driven feature enhancement. Our
approach integrates a multi-scale feature enhancement network trained
end-to-end with the detector's loss function, ensuring the enhancement process
is explicitly guided to refine features most relevant to the detection task.
When integrated with YOLOv8m on challenging underwater datasets, AquaFeat
achieves state-of-the-art Precision (0.877) and Recall (0.624), along with
competitive mAP scores (mAP@0.5 of 0.677 and mAP@[0.5:0.95] of 0.421). By
delivering these accuracy gains while maintaining a practical processing speed
of 46.5 FPS, our model provides an effective and computationally efficient
solution for real-world applications, such as marine ecosystem monitoring and
infrastructure inspection.

</details>


### [63] [MBMamba: When Memory Buffer Meets Mamba for Structure-Aware Image Deblurring](https://arxiv.org/abs/2508.12346)
*Hu Gao,Depeng Dang*

Main category: cs.CV

TL;DR: 提出了MBMamba网络，通过内存缓冲区机制和Ising启发的正则化损失来解决Mamba架构在图像去模糊中的局部像素遗忘和通道冗余问题，在不改变原始架构的情况下提升了性能。


<details>
  <summary>Details</summary>
Motivation: Mamba架构在图像去模糊中表现出潜力，但其展平扫描策略会导致局部像素遗忘和通道冗余，现有方法通过修改扫描策略或添加局部特征模块会增加计算复杂度，影响实时性能。

Method: 设计了内存缓冲区机制来保存历史信息以供后续融合，可靠地建模相邻特征间的相关性；引入了Ising启发的正则化损失，模拟物理系统中像素间"相互吸引"的能量最小化，帮助保持图像结构和连贯性。

Result: 在广泛使用的基准测试中，该方法优于最先进的先进方法。

Conclusion: 提出的MBMamba网络通过创新的内存缓冲机制和物理启发的正则化损失，有效解决了Mamba架构在图像去模糊中的局限性，在保持原始架构的同时实现了性能提升。

Abstract: The Mamba architecture has emerged as a promising alternative to CNNs and
Transformers for image deblurring. However, its flatten-and-scan strategy often
results in local pixel forgetting and channel redundancy, limiting its ability
to effectively aggregate 2D spatial information. Although existing methods
mitigate this by modifying the scan strategy or incorporating local feature
modules, it increase computational complexity and hinder real-time performance.
In this paper, we propose a structure-aware image deblurring network without
changing the original Mamba architecture. Specifically, we design a memory
buffer mechanism to preserve historical information for later fusion, enabling
reliable modeling of relevance between adjacent features. Additionally, we
introduce an Ising-inspired regularization loss that simulates the energy
minimization of the physical system's "mutual attraction" between pixels,
helping to maintain image structure and coherence. Building on this, we develop
MBMamba. Experimental results show that our method outperforms state-of-the-art
approaches on widely used benchmarks.

</details>


### [64] [EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos](https://arxiv.org/abs/2508.12349)
*Junyi Ma,Erhang Zhang,Yin-Dong Zheng,Yuchen Xie,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: 本文提出EgoLoc，一种零样本方法，用于在自我中心视频中定位手-物体接触和分离的时间戳，解决了现有方法依赖类别标注和物体掩码的问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注交互行为的建模（如何交互），但对手与目标物体接触和分离的关键时刻（何时交互）的细粒度定位问题研究不足，这对混合现实和机器人运动规划至关重要。

Method: 提出EgoLoc方法，采用手动力学引导采样生成高质量视觉提示，利用视觉语言模型识别接触/分离属性、定位特定时间戳，并提供闭环反馈进行细化，无需物体掩码和动词-名词分类法。

Result: 在公共数据集和新基准上的综合实验表明，EgoLoc能够实现合理的时序交互定位，并能有效促进自我中心视觉和机器人操作任务中的多个下游应用。

Conclusion: EgoLoc提供了一种通用的零样本解决方案，能够准确捕捉手-物体交互的关键时刻，为VR/AR应用和机器人策略转移提供了重要技术支持。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR
applications and human-robot policy transfer. Existing research has mostly
focused on modeling the behavior paradigm of interactive actions (i.e., ``how
to interact''). However, the more challenging and fine-grained problem of
capturing the critical moments of contact and separation between the hand and
the target object (i.e., ``when to interact'') is still underexplored, which is
crucial for immersive interactive experiences in mixed reality and robotic
motion planning. Therefore, we formulate this problem as temporal interaction
localization (TIL). Some recent works extract semantic masks as TIL references,
but suffer from inaccurate object grounding and cluttered scenarios. Although
current temporal action localization (TAL) methods perform well in detecting
verb-noun action segments, they rely on category annotations during training
and exhibit limited precision in localizing hand-object contact/separation
moments. To address these issues, we propose a novel zero-shot approach dubbed
EgoLoc to localize hand-object contact and separation timestamps in egocentric
videos. EgoLoc introduces hand-dynamics-guided sampling to generate
high-quality visual prompts. It exploits the vision-language model to identify
contact/separation attributes, localize specific timestamps, and provide
closed-loop feedback for further refinement. EgoLoc eliminates the need for
object masks and verb-noun taxonomies, leading to generalizable zero-shot
implementation. Comprehensive experiments on the public dataset and our novel
benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric
videos. It is also validated to effectively facilitate multiple downstream
applications in egocentric vision and robotic manipulation tasks. Code and
relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [65] [Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data](https://arxiv.org/abs/2508.12356)
*Ahmet H. Güzel,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.CV

TL;DR: 通过生成合成数据来提升视觉离线强化学习的演算器通用性，包括数据扩充和潜空间激光模型生成数据


<details>
  <summary>Details</summary>
Motivation: 解决离线RL中因数据不够多样化导致的演算器过拟合和通用性差的问题，特别是在处理复杂视觉数据时

Method: 两步流程：先对离线数据进行扩充增加多样性，然后使用激光模型在潜空间生成额外的合成训练数据

Result: 在连续动作空间(Visual D4RL)和离散动作空间(Procgen)上都显著提升了通用性，减小了测试时的通用性差距

Conclusion: 该方法能够通过生成合成数据有效提升离线RL演算器的通用性，而无需改变现有算法，为训练更具通用性的演算器提供了新方向

Abstract: Offline reinforcement learning (RL) offers a promising framework for training
agents using pre-collected datasets without the need for further environment
interaction. However, policies trained on offline data often struggle to
generalise due to limited exposure to diverse states. The complexity of visual
data introduces additional challenges such as noise, distractions, and spurious
correlations, which can misguide the policy and increase the risk of
overfitting if the training data is not sufficiently diverse. Indeed, this
makes it challenging to leverage vision-based offline data in training robust
agents that can generalize to unseen environments. To solve this problem, we
propose a simple approach generating additional synthetic training data. We
propose a two-step process, first augmenting the originally collected offline
data to improve zero-shot generalization by introducing diversity, then using a
diffusion model to generate additional data in latent space. We test our method
across both continuous action spaces (Visual D4RL) and discrete action spaces
(Procgen), demonstrating that it significantly improves generalization without
requiring any algorithmic changes to existing model-free offline RL methods. We
show that our method not only increases the diversity of the training data but
also significantly reduces the generalization gap at test time while
maintaining computational efficiency. We believe this approach could fuel
additional progress in generating synthetic data to train more general agents
in the future.

</details>


### [66] [IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis](https://arxiv.org/abs/2508.12381)
*Guo Tang,Songhan Jiang,Jinpeng Lu,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: IPGPhormer是一个可解释的病理图-Transformer框架，用于癌症生存分析，通过建模肿瘤微环境特征和空间依赖关系，在预测准确性和可解释性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有生存分析方法在平衡长距离空间关系建模与局部上下文依赖方面存在困难，且缺乏内在可解释性，限制了临床实用性。

Method: 提出Interpretable Pathology Graph-Transformer (IPGPhormer)框架，捕捉肿瘤微环境特征并建模组织间的空间依赖关系，无需后处理手动标注即可提供组织和细胞级别的可解释性。

Result: 在四个公共基准数据集上的综合评估表明，IPGPhormer在预测准确性和可解释性方面均优于最先进方法。

Conclusion: IPGPhormer为癌症预后评估提供了一个有前景的工具，为病理学中更可靠和可解释的决策支持系统铺平了道路。

Abstract: Pathological images play an essential role in cancer prognosis, while
survival analysis, which integrates computational techniques, can predict
critical clinical events such as patient mortality or disease recurrence from
whole-slide images (WSIs). Recent advancements in multiple instance learning
have significantly improved the efficiency of survival analysis. However,
existing methods often struggle to balance the modeling of long-range spatial
relationships with local contextual dependencies and typically lack inherent
interpretability, limiting their clinical utility. To address these challenges,
we propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel
framework that captures the characteristics of the tumor microenvironment and
models their spatial dependencies across the tissue. IPGPhormer uniquely
provides interpretability at both tissue and cellular levels without requiring
post-hoc manual annotations, enabling detailed analyses of individual WSIs and
cross-cohort assessments. Comprehensive evaluations on four public benchmark
datasets demonstrate that IPGPhormer outperforms state-of-the-art methods in
both predictive accuracy and interpretability. In summary, our method,
IPGPhormer, offers a promising tool for cancer prognosis assessment, paving the
way for more reliable and interpretable decision-support systems in pathology.
The code is publicly available at
https://anonymous.4open.science/r/IPGPhormer-6EEB.

</details>


### [67] [ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers](https://arxiv.org/abs/2508.12384)
*Hanwen Cao,Haobo Lu,Xiaosen Wang,Kun He*

Main category: cs.CV

TL;DR: 本文提出ViT-EnsembleAttack方法，通过对替代ViT模型进行对抗增帽和自动重新加权，显著提升了对抗示例的迁移性能力，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有集成攻击方法主要关注集成权重或集成路径的优化，而忽视了通过增强集成模型来提升攻击迁移性的探索。同时，集成Vision Transformer攻击方法得到的关注较少。

Method: 提出ViT-EnsembleAttack方法，使用三种策略对替代ViT模型进行对抗增帽：多头投票下接、注意力分数缩放和MLP特征混合。通过贝叶斯优化调整参数，并介入自动重新加权和步长扩大模块来提升迁移性。

Result: 大量实验表明，ViT-EnsembleAttack显著提升了集成基攻击在ViT上的对抗迁移性，性能远超现有方法。

Conclusion: 该方法通过对抗增帽替代模型和自动优化集成策略，有效提升了对抗示例的跨模型迁移能力，为ViT集成攻击领域提供了新的解决方案。

Abstract: Ensemble-based attacks have been proven to be effective in enhancing
adversarial transferability by aggregating the outputs of models with various
architectures. However, existing research primarily focuses on refining
ensemble weights or optimizing the ensemble path, overlooking the exploration
of ensemble models to enhance the transferability of adversarial attacks. To
address this gap, we propose applying adversarial augmentation to the surrogate
models, aiming to boost overall generalization of ensemble models and reduce
the risk of adversarial overfitting. Meanwhile, observing that ensemble Vision
Transformers (ViTs) gain less attention, we propose ViT-EnsembleAttack based on
the idea of model adversarial augmentation, the first ensemble-based attack
method tailored for ViTs to the best of our knowledge. Our approach generates
augmented models for each surrogate ViT using three strategies: Multi-head
dropping, Attention score scaling, and MLP feature mixing, with the associated
parameters optimized by Bayesian optimization. These adversarially augmented
models are ensembled to generate adversarial examples. Furthermore, we
introduce Automatic Reweighting and Step Size Enlargement modules to boost
transferability. Extensive experiments demonstrate that ViT-EnsembleAttack
significantly enhances the adversarial transferability of ensemble-based
attacks on ViTs, outperforming existing methods by a substantial margin. Code
is available at https://github.com/Trustworthy-AI-Group/TransferAttack.

</details>


### [68] [DeCoT: Decomposing Complex Instructions for Enhanced Text-to-Image Generation with Large Language Models](https://arxiv.org/abs/2508.12396)
*Xiaochuan Lin,Xiangyong Chen,Xuan Li,Yichen Su*

Main category: cs.CV

TL;DR: DeCoT是一个通过LLM分解复杂文本指令来提升T2I模型性能的框架，在LongBench-T2I基准测试中显著改善了图像生成质量


<details>
  <summary>Details</summary>
Motivation: 当前T2I模型在处理复杂长文本指令时存在困难，经常无法准确渲染细节、空间关系和特定约束，需要更好的方法来理解和执行复杂指令

Method: DeCoT框架包含两个核心阶段：1）复杂指令分解和语义增强 - LLM将原始指令分解为结构化语义单元并澄清歧义；2）多阶段提示集成和自适应生成 - 将这些单元转换为分层或优化的单一提示

Result: 在LongBench-T2I数据集上的实验表明，DeCoT显著提升了主流T2I模型的性能，特别是在"文本"和"构图"等挑战性方面。与Infinity-8B集成时平均得分3.52，优于基线3.44

Conclusion: DeCoT有效弥合了高级用户意图与T2I模型需求之间的差距，实现了更忠实和准确的图像生成，各组件都发挥了关键作用

Abstract: Despite remarkable advancements, current Text-to-Image (T2I) models struggle
with complex, long-form textual instructions, frequently failing to accurately
render intricate details, spatial relationships, or specific constraints. This
limitation is highlighted by benchmarks such as LongBench-T2I, which reveal
deficiencies in handling composition, specific text, and fine textures. To
address this, we propose DeCoT (Decomposition-CoT), a novel framework that
leverages Large Language Models (LLMs) to significantly enhance T2I models'
understanding and execution of complex instructions. DeCoT operates in two core
stages: first, Complex Instruction Decomposition and Semantic Enhancement,
where an LLM breaks down raw instructions into structured, actionable semantic
units and clarifies ambiguities; second, Multi-Stage Prompt Integration and
Adaptive Generation, which transforms these units into a hierarchical or
optimized single prompt tailored for existing T2I models. Extensive experiments
on the LongBench-T2I dataset demonstrate that DeCoT consistently and
substantially improves the performance of leading T2I models across all
evaluated dimensions, particularly in challenging aspects like "Text" and
"Composition". Quantitative results, validated by multiple MLLM evaluators
(Gemini-2.0-Flash and InternVL3-78B), show that DeCoT, when integrated with
Infinity-8B, achieves an average score of 3.52, outperforming the baseline
Infinity-8B (3.44). Ablation studies confirm the critical contribution of each
DeCoT component and the importance of sophisticated LLM prompting. Furthermore,
human evaluations corroborate these findings, indicating superior perceptual
quality and instruction fidelity. DeCoT effectively bridges the gap between
high-level user intent and T2I model requirements, leading to more faithful and
accurate image generation.

</details>


### [69] [Federated Cross-Modal Style-Aware Prompt Generation](https://arxiv.org/abs/2508.12399)
*Suraj Prasad,Navyansh Mahla,Sunny Gupta,Amit Sethi*

Main category: cs.CV

TL;DR: FedCSAP是一个联邦学习框架，利用CLIP的多尺度视觉特征和客户端特定风格统计来生成鲁棒的跨模态提示，提升分类准确性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统方法仅使用最终层特征，忽略了多尺度视觉线索和客户端数据的领域特定风格变化，限制了联邦学习中视觉语言模型的性能

Method: 从CLIP视觉编码器提取低、中、高层特征，结合客户端批处理统计的风格指标，生成上下文感知的提示令牌，在联邦学习框架下进行本地训练和全局聚合

Result: 在多个图像分类数据集上，FedCSAP在准确性和泛化能力方面优于现有的联邦提示学习方法

Conclusion: 通过整合多尺度视觉特征和风格感知机制，FedCSAP有效解决了联邦学习中的非IID数据分布和领域风格多样性问题，显著提升了模型性能

Abstract: Prompt learning has propelled vision-language models like CLIP to excel in
diverse tasks, making them ideal for federated learning due to computational
efficiency. However, conventional approaches that rely solely on final-layer
features miss out on rich multi-scale visual cues and domain-specific style
variations in decentralized client data. To bridge this gap, we introduce
FedCSAP (Federated Cross-Modal Style-Aware Prompt Generation). Our framework
harnesses low, mid, and high-level features from CLIP's vision encoder
alongside client-specific style indicators derived from batch-level statistics.
By merging intricate visual details with textual context, FedCSAP produces
robust, context-aware prompt tokens that are both distinct and non-redundant,
thereby boosting generalization across seen and unseen classes. Operating
within a federated learning paradigm, our approach ensures data privacy through
local training and global aggregation, adeptly handling non-IID class
distributions and diverse domain-specific styles. Comprehensive experiments on
multiple image classification datasets confirm that FedCSAP outperforms
existing federated prompt learning methods in both accuracy and overall
generalization.

</details>


### [70] [MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2508.12400)
*Amirul Rahman,Qiang Xu,Xueying Huang*

Main category: cs.CV

TL;DR: MPCAR是一种无需微调的推理时策略，通过多角度生成描述来增强大型视觉语言模型的上下文理解能力，在复杂视觉推理任务中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在需要深度上下文理解、多角度分析或细节识别的复杂视觉推理任务中表现有限，主要依赖单次图像编码和提示，难以充分捕捉细微视觉信息

Method: 三阶段方法：1) 从不同角度生成N个多样互补的描述或初步推理路径；2) 智能整合这些描述与原问题构建上下文增强提示；3) 使用增强提示指导最终推理和答案生成

Result: 在GQA、VQA-CP v2和ScienceQA等挑战性VQA数据集上持续超越基线方法，定量结果显示准确性显著提升，特别是在需要强上下文理解的任务上，人工评估也确认了答案连贯性和完整性的改善

Conclusion: 利用LVLM固有生成能力丰富输入上下文可有效释放其在复杂多模态任务中的潜在推理潜力，消融研究强调了多样提示模板和生成视角数量的重要性

Abstract: Despite significant advancements, Large Vision-Language Models (LVLMs)
continue to face challenges in complex visual reasoning tasks that demand deep
contextual understanding, multi-angle analysis, or meticulous detail
recognition. Existing approaches often rely on single-shot image encoding and
prompts, limiting their ability to fully capture nuanced visual information.
Inspired by the notion that strategically generated "additional" information
can serve as beneficial contextual augmentation, we propose Multi-Perspective
Contextual Augmentation for Reasoning (MPCAR), a novel inference-time strategy
designed to enhance LVLM performance. MPCAR operates in three stages: first, an
LVLM generates N diverse and complementary descriptions or preliminary
reasoning paths from various angles; second, these descriptions are
intelligently integrated with the original question to construct a
comprehensive context-augmented prompt; and finally, this enriched prompt
guides the ultimate LVLM for deep reasoning and final answer generation.
Crucially, MPCAR achieves these enhancements without requiring any fine-tuning
of the underlying LVLM's parameters. Extensive experiments on challenging
Visual Question Answering (VQA) datasets, including GQA, VQA-CP v2, and
ScienceQA (Image-VQA), demonstrate that MPCAR consistently outperforms
established baseline methods. Our quantitative results show significant
accuracy gains, particularly on tasks requiring robust contextual
understanding, while human evaluations confirm improved coherence and
completeness of the generated answers. Ablation studies further highlight the
importance of diverse prompt templates and the number of generated
perspectives. This work underscores the efficacy of leveraging LVLMs' inherent
generative capabilities to enrich input contexts, thereby unlocking their
latent reasoning potential for complex multimodal tasks.

</details>


### [71] [LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving](https://arxiv.org/abs/2508.12404)
*Nan Song,Bozhou Zhang,Xiatian Zhu,Jiankang Deng,Li Zhang*

Main category: cs.CV

TL;DR: LMAD是一个专为自动驾驶设计的视觉语言框架，通过引入初步场景交互和专家适配器，显著提升了现有VLM在驾驶推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要在车载多视角图像和场景推理文本上微调VLM，但缺乏自动驾驶所需的整体细致场景识别和强大空间感知能力，特别是在复杂情况下。

Method: 提出LMAD框架，模拟现代端到端驾驶范式，结合全面场景理解和任务专用结构，引入初步场景交互和专用专家适配器，与现有VLM完全兼容并可与规划导向驾驶系统无缝集成。

Result: 在DriveLM和nuScenes-QA数据集上的广泛实验表明，LMAD显著提升了现有VLM在驾驶推理任务中的性能。

Conclusion: LMAD为可解释自动驾驶设立了新标准，通过更好的VLM与自动驾驶场景对齐，解决了现有方法的局限性。

Abstract: Large vision-language models (VLMs) have shown promising capabilities in
scene understanding, enhancing the explainability of driving behaviors and
interactivity with users. Existing methods primarily fine-tune VLMs on on-board
multi-view images and scene reasoning text, but this approach often lacks the
holistic and nuanced scene recognition and powerful spatial awareness required
for autonomous driving, especially in complex situations. To address this gap,
we propose a novel vision-language framework tailored for autonomous driving,
called LMAD. Our framework emulates modern end-to-end driving paradigms by
incorporating comprehensive scene understanding and a task-specialized
structure with VLMs. In particular, we introduce preliminary scene interaction
and specialized expert adapters within the same driving task structure, which
better align VLMs with autonomous driving scenarios. Furthermore, our approach
is designed to be fully compatible with existing VLMs while seamlessly
integrating with planning-oriented driving systems. Extensive experiments on
the DriveLM and nuScenes-QA datasets demonstrate that LMAD significantly boosts
the performance of existing VLMs on driving reasoning tasks,setting a new
standard in explainable autonomous driving.

</details>


### [72] [S5: Scalable Semi-Supervised Semantic Segmentation in Remote Sensing](https://arxiv.org/abs/2508.12409)
*Liang Lv,Di Wang,Jing Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: 基于大规模遠感数据的半监督语义分割框架S5，通过数据选择策略和基础模型预训练，在土地覆盖分割和目标检测任务上达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 解决现有半监督语义分割方法依赖小规模数据集和模型的限制，充分利用大量未标注的地球观测数据

Method: 构建RS4P-1M大规模数据集，采用基于熵的过滤和多样性扩展的数据选择策略，预训练不同规模的遠感基础模型，并在微调中使用专家混合方法

Result: 在多个遠感测试集上达到最先进性能，显著提升了土地覆盖分割和目标检测任务的表现

Conclusion: 证明了通过扩展半监督学习来激活大规模未标注遠感数据的可行性，为遠感分析领域提供了更强大的实用能力

Abstract: Semi-supervised semantic segmentation (S4) has advanced remote sensing (RS)
analysis by leveraging unlabeled data through pseudo-labeling and consistency
learning. However, existing S4 studies often rely on small-scale datasets and
models, limiting their practical applicability. To address this, we propose S5,
the first scalable framework for semi-supervised semantic segmentation in RS,
which unlocks the potential of vast unlabeled Earth observation data typically
underutilized due to costly pixel-level annotations. Built upon existing
large-scale RS datasets, S5 introduces a data selection strategy that
integrates entropy-based filtering and diversity expansion, resulting in the
RS4P-1M dataset. Using this dataset, we systematically scales S4 methods by
pre-training RS foundation models (RSFMs) of varying sizes on this extensive
corpus, significantly boosting their performance on land cover segmentation and
object detection tasks. Furthermore, during fine-tuning, we incorporate a
Mixture-of-Experts (MoE)-based multi-dataset fine-tuning approach, which
enables efficient adaptation to multiple RS benchmarks with fewer parameters.
This approach improves the generalization and versatility of RSFMs across
diverse RS benchmarks. The resulting RSFMs achieve state-of-the-art performance
across all benchmarks, underscoring the viability of scaling semi-supervised
learning for RS applications. All datasets, code, and models will be released
at https://github.com/MiliLab/S5

</details>


### [73] [SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes](https://arxiv.org/abs/2508.12410)
*Jun Zeng,Yannan Huang,Elif Keles,Halil Ertugrul Aktas,Gorkem Durak,Nikhil Kumar Tomar,Quoc-Huy Trinh,Deepak Ranjan Nayak,Ulas Bagci,Debesh Jha*

Main category: cs.CV

TL;DR: 基于Mamba的SRMA-Mamba网络，通过空间解剖基础的Mamba扫描和空间反向注意力模块，实现了肝硫变病理结构的高效3D分割，性能超越现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法没有充分利用体积MRI数据中的空间解剖细节，影响了临床效果和可解释性。肝硫变的复杂解剖结构和多样病理变化为准确检测和特征化造成困难。

Method: 提出SRMA-Mamba网络，集成空间解剖基础的Mamba模块(SABMamba)，在肝硫变组织中进行选择性Mamba扫描，结合夸状面、颚状面和横断面的解剖信息构建全局空间上下文表征。还包含空间反向注意力模块(SRMA)，利用粗糕分割图和层次编码特征渐进式精炼硫变细节。

Result: 广泛实验证明SRMA-Mamba在3D病理性肝脏分割中超越了现有最优方法，展现出杰出的性能。

Conclusion: SRMA-Mamba通过空间解剖基础的Mamba扫描和空间反向注意力机制，有效地解决了肝硫变病理结构分割的挑战，为临床提供了高效、准确且可解释的解决方案。

Abstract: Liver Cirrhosis plays a critical role in the prognosis of chronic liver
disease. Early detection and timely intervention are critical in significantly
reducing mortality rates. However, the intricate anatomical architecture and
diverse pathological changes of liver tissue complicate the accurate detection
and characterization of lesions in clinical settings. Existing methods
underutilize the spatial anatomical details in volumetric MRI data, thereby
hindering their clinical effectiveness and explainability. To address this
challenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to
model the spatial relationships within the complex anatomical structures of MRI
volumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba),
SRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and
combines anatomical information from the sagittal, coronal, and axial planes to
construct a global spatial context representation, enabling efficient
volumetric segmentation of pathological liver structures. Furthermore, we
introduce the Spatial Reverse Attention module (SRMA), designed to
progressively refine cirrhotic details in the segmentation map, utilizing both
the coarse segmentation map and hierarchical encoding features. Extensive
experiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods,
delivering exceptional performance in 3D pathological liver segmentation. Our
code is available for public:
{\color{blue}{https://github.com/JunZengz/SRMA-Mamba}}.

</details>


### [74] [TiP4GEN: Text to Immersive Panorama 4D Scene Generation](https://arxiv.org/abs/2508.12415)
*Ke Xing,Hanwen Liang,Dejia Xu,Yuyang Yin,Konstantinos N. Plataniotis,Yao Zhao,Yunchao Wei*

Main category: cs.CV

TL;DR: TiP4GEN是一个先进的文本到动态全景场景生成框架，能够实现细粒度内容控制并合成运动丰富、几何一致的全景4D场景，解决了现有方法在360度沉浸式体验方面的不足。


<details>
  <summary>Details</summary>
Motivation: 随着VR/AR技术的快速发展，对高质量沉浸式动态场景的需求日益增长，但现有生成工作主要集中在静态场景或窄视角动态场景，无法提供真正的360度全视角沉浸体验。

Method: TiP4GEN集成了全景视频生成和动态场景重建。视频生成采用双分支生成模型（全景分支和透视分支），通过双向交叉注意力机制实现信息交换。场景重建基于3D高斯泼溅的几何对齐重建模型，通过度量深度图对齐时空点云，并使用估计位姿初始化场景相机。

Result: 大量实验证明了所提出设计的有效性，TiP4GEN在生成视觉吸引人且运动连贯的动态全景场景方面表现出优越性。

Conclusion: TiP4GEN框架成功解决了动态全景场景生成的挑战，能够创建几何一致和时间连贯的360度沉浸式虚拟环境，为VR/AR应用提供了高质量的动态场景生成解决方案。

Abstract: With the rapid advancement and widespread adoption of VR/AR technologies,
there is a growing demand for the creation of high-quality, immersive dynamic
scenes. However, existing generation works predominantly concentrate on the
creation of static scenes or narrow perspective-view dynamic scenes, falling
short of delivering a truly 360-degree immersive experience from any viewpoint.
In this paper, we introduce \textbf{TiP4GEN}, an advanced text-to-dynamic
panorama scene generation framework that enables fine-grained content control
and synthesizes motion-rich, geometry-consistent panoramic 4D scenes. TiP4GEN
integrates panorama video generation and dynamic scene reconstruction to create
360-degree immersive virtual environments. For video generation, we introduce a
\textbf{Dual-branch Generation Model} consisting of a panorama branch and a
perspective branch, responsible for global and local view generation,
respectively. A bidirectional cross-attention mechanism facilitates
comprehensive information exchange between the branches. For scene
reconstruction, we propose a \textbf{Geometry-aligned Reconstruction Model}
based on 3D Gaussian Splatting. By aligning spatial-temporal point clouds using
metric depth maps and initializing scene cameras with estimated poses, our
method ensures geometric consistency and temporal coherence for the
reconstructed scenes. Extensive experiments demonstrate the effectiveness of
our proposed designs and the superiority of TiP4GEN in generating visually
compelling and motion-coherent dynamic panoramic scenes. Our project page is at
https://ke-xing.github.io/TiP4GEN/.

</details>


### [75] [Illusions in Humans and AI: How Visual Perception Aligns and Diverges](https://arxiv.org/abs/2508.12422)
*Jianyi Yang,Junyi Ye,Ankan Dash,Guiling Wang*

Main category: cs.CV

TL;DR: 通过对比生物与人工智能视觉系统在视觉幻觉上的差异，揭示了AI视视觉的特有弱点和幻觉现象，为开发更健壮、可解释的AI视觉系统提供指导


<details>
  <summary>Details</summary>
Motivation: 理解人工智能视觉系统与人类视觉在幻觉响应上的差异，发现AI特有的视觉弱点，以开发更健壮、可信赖的视觉AI系统

Method: 系统性测试人工智能视觉模型对经典视觉幻觉（颜色、大小、形状、运动）的响应，对比人类视觉行为

Result: 发现AI会出现类似人类的幻觉效应，但也有唯AI所独有的幻觉现象（像素级敏感性、幻觉），揭示了人工智能视觉的特有弱点和安全风险

Conclusion: 通过视觉幻觉对比研究，可以为开发更健壮、可解释、与人类视觉对齐的AI视觉系统提供重要见解，同时避免媒介幻觉带来的信任和安全风险

Abstract: By comparing biological and artificial perception through the lens of
illusions, we highlight critical differences in how each system constructs
visual reality. Understanding these divergences can inform the development of
more robust, interpretable, and human-aligned artificial intelligence (AI)
vision systems. In particular, visual illusions expose how human perception is
based on contextual assumptions rather than raw sensory data. As artificial
vision systems increasingly perform human-like tasks, it is important to ask:
does AI experience illusions, too? Does it have unique illusions? This article
explores how AI responds to classic visual illusions that involve color, size,
shape, and motion. We find that some illusion-like effects can emerge in these
models, either through targeted training or as by-products of pattern
recognition. In contrast, we also identify illusions unique to AI, such as
pixel-level sensitivity and hallucinations, that lack human counterparts. By
systematically comparing human and AI responses to visual illusions, we uncover
alignment gaps and AI-specific perceptual vulnerabilities invisible to human
perception. These findings provide insights for future research on vision
systems that preserve human-beneficial perceptual biases while avoiding
distortions that undermine trust and safety.

</details>


### [76] [Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations](https://arxiv.org/abs/2508.12430)
*Yahsin Yeh,Yilun Wu,Bokai Ruan,Honghan Shuai*

Main category: cs.CV

TL;DR: 这篇论文揭示了视觉问答中自然语言解释系统的漏洞，通过攻击咄伪方法显示其不一致性问题，并提出基于外部知识的缓解方案。


<details>
  <summary>Details</summary>
Motivation: 现有VQA-NLE系统存在解释不一致咄结论缺乏真实理解的问题，需要更好地曝露黑盒模型的决策过程。

Method: 使用现有的问题批批动策略咄提出新的图像最小改动攻击策略，并为缓解这些问题而引入外部知识。

Result: 在两个标准测试集咄两个广泛使用的VQA-NLE模型上进行了评估，证明了攻击的有效性咄知识基础防御的潜力。

Conclusion: 当前VQA-NLE系统存在严重的安全性咄可靠性问题，知识基础的防御方案有助于提升模型稳健性。

Abstract: Natural language explanations in visual question answering (VQA-NLE) aim to
make black-box models more transparent by elucidating their decision-making
processes. However, we find that existing VQA-NLE systems can produce
inconsistent explanations and reach conclusions without genuinely understanding
the underlying context, exposing weaknesses in either their inference pipeline
or explanation-generation mechanism. To highlight these vulnerabilities, we not
only leverage an existing adversarial strategy to perturb questions but also
propose a novel strategy that minimally alters images to induce contradictory
or spurious outputs. We further introduce a mitigation method that leverages
external knowledge to alleviate these inconsistencies, thereby bolstering model
robustness. Extensive evaluations on two standard benchmarks and two widely
used VQA-NLE models underscore the effectiveness of our attacks and the
potential of knowledge-based defenses, ultimately revealing pressing security
and reliability concerns in current VQA-NLE systems.

</details>


### [77] [X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning](https://arxiv.org/abs/2508.12455)
*Chee Ng,Liliang Sun,Shaoqing Tang*

Main category: cs.CV

TL;DR: X-Ray-CoT是一个基于视觉语言大模型的框架，通过模拟放射科医生的思维链过程，实现胸部X光片的智能诊断和可解释报告生成，在保持竞争力的诊断准确率的同时提供高质量的解释性报告。


<details>
  <summary>Details</summary>
Motivation: 胸部X光片诊断需要丰富的临床经验且存在观察者间差异，现有深度学习模型虽然准确率高但缺乏可解释性，阻碍了在高风险医疗环境中的临床应用。

Method: 提出X-Ray-CoT框架，首先提取多模态特征和视觉概念，然后使用基于LLM的组件配合结构化思维链提示策略进行推理，生成详细的自然语言诊断报告。

Result: 在CORDA数据集上，疾病诊断的平衡准确率达到80.52%，F1分数为78.65%，略优于现有黑盒模型，并能生成高质量的可解释报告。

Conclusion: 该工作代表了在医学影像中构建可信赖和临床可操作AI系统的重要进展，消融研究证实了多模态融合和思维链推理对于构建稳健透明医疗AI的必要性。

Abstract: Chest X-ray imaging is crucial for diagnosing pulmonary and cardiac diseases,
yet its interpretation demands extensive clinical experience and suffers from
inter-observer variability. While deep learning models offer high diagnostic
accuracy, their black-box nature hinders clinical adoption in high-stakes
medical settings. To address this, we propose X-Ray-CoT (Chest X-Ray
Chain-of-Thought), a novel framework leveraging Vision-Language Large Models
(LVLMs) for intelligent chest X-ray diagnosis and interpretable report
generation. X-Ray-CoT simulates human radiologists' "chain-of-thought" by first
extracting multi-modal features and visual concepts, then employing an
LLM-based component with a structured Chain-of-Thought prompting strategy to
reason and produce detailed natural language diagnostic reports. Evaluated on
the CORDA dataset, X-Ray-CoT achieves competitive quantitative performance,
with a Balanced Accuracy of 80.52% and F1 score of 78.65% for disease
diagnosis, slightly surpassing existing black-box models. Crucially, it
uniquely generates high-quality, explainable reports, as validated by
preliminary human evaluations. Our ablation studies confirm the integral role
of each proposed component, highlighting the necessity of multi-modal fusion
and CoT reasoning for robust and transparent medical AI. This work represents a
significant step towards trustworthy and clinically actionable AI systems in
medical imaging.

</details>


### [78] [Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping](https://arxiv.org/abs/2508.12466)
*Xuhui Zhan,Tyler Derr*

Main category: cs.CV

TL;DR: Inverse-LLaVA提出了一种新的多模态学习方法，无需对齐预训练，通过将文本嵌入映射到视觉表示空间来实现模态融合，在推理任务上表现优异，计算需求减少45%。


<details>
  <summary>Details</summary>
Motivation: 挑战传统多模态学习需要昂贵对齐预训练的范式，探索更高效的多模态融合方法，避免大规模图像-文本对齐数据集的需求。

Method: 将文本嵌入映射到连续视觉表示空间，在transformer中间层进行融合，通过注意力机制中的选择性加法组件实现动态集成。

Result: 在9个多模态基准测试中显示性能权衡：推理密集型任务显著提升（MM-VET: +0.2%, VizWiz: +1.8%, ScienceQA: +0.2%, 认知推理: +27.2%），但感知任务下降（名人识别: -49.5%, OCR: -21.3%）。

Conclusion: 首次证明对齐预训练对有效多模态学习并非必要，特别是复杂推理任务；建立了减少45%计算需求的新范式，为高效多模态架构开辟了新方向。

Abstract: Traditional multimodal learning approaches require expensive alignment
pre-training to bridge vision and language modalities, typically projecting
visual features into discrete text token spaces. We challenge both fundamental
assumptions underlying this paradigm by proposing Inverse-LLaVA, a novel
approach that eliminates alignment pre-training entirely while inverting the
conventional mapping direction. Rather than projecting visual features to text
space, our method maps text embeddings into continuous visual representation
space and performs fusion within transformer intermediate layers. Through
selective additive components in attention mechanisms, we enable dynamic
integration of visual and textual representations without requiring massive
image-text alignment datasets. Comprehensive experiments across nine multimodal
benchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves
notable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,
VizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing
expected decreases in perception tasks requiring memorized visual-text
associations (celebrity recognition: -49.5%, OCR: -21.3%). These results
provide the first empirical evidence that alignment pre-training is not
necessary for effective multimodal learning, particularly for complex reasoning
tasks. Our work establishes the feasibility of a new paradigm that reduces
computational requirements by 45%, challenges conventional wisdom about
modality fusion, and opens new research directions for efficient multimodal
architectures that preserve modality-specific characteristics. Our project
website with code and additional resources is available at
https://inverse-llava.github.io.

</details>


### [79] [Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2508.12473)
*Eranga Bandara,Ross Gore,Sachin Shetty,Ravi Mukkamala,Christopher Rhea,Atmaram Yarlagadda,Shaifali Kaushik,L. H. M. P. De Silva,Andriy Maznychenko,Inna Sokolowska,Amin Hass,Kasun De Zoysa*

Main category: cs.CV

TL;DR: 使用细调视觉-语言模型联盟和理解大语言模型构建自动化H-反射电机图象解释诊断系统，提高神经肌诊断的准确性和标准化程度


<details>
  <summary>Details</summary>
Motivation: 传统H-反射EMG波形分析存在主观性和变异性问题，影响诊断的可靠性和标准化，需要自动化解决方案

Method: 细调多个VLM模型处理波形图像和临床数据，通过共识机制聚合诊断结果，再由专门理解LLM进行提炼和解释，构建端到端自动化系统

Result: 深度学习模型能够从EMG图像中提取关键电生理特征，预测疗程进展和运动员状态，实验结果显示系统具有高准确性、一致性和可解释性

Conclusion: 该深度学习模型联盟与理解模型的融合为神经肌诊断带来了重大进步，为下一代AI辅助诊断平台奠定了基础

Abstract: Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a
critical role in sports science, rehabilitation, and clinical neurology.
Traditional analysis of H-reflex EMG waveforms is subject to variability and
interpretation bias among clinicians and researchers, limiting reliability and
standardization. To address these challenges, we propose a Fine-Tuned
Vision-Language Model (VLM) Consortium and a reasoning Large-Language Model
(LLM)-enabled Decision Support System for automated H-reflex waveform
interpretation and diagnosis. Our approach leverages multiple VLMs, each
fine-tuned on curated datasets of H-reflex EMG waveform images annotated with
clinical observations, recovery timelines, and athlete metadata. These models
are capable of extracting key electrophysiological features and predicting
neuromuscular states, including fatigue, injury, and recovery, directly from
EMG images and contextual metadata. Diagnostic outputs from the VLM consortium
are aggregated using a consensus-based method and refined by a specialized
reasoning LLM, which ensures robust, transparent, and explainable decision
support for clinicians and sports scientists. The end-to-end platform
orchestrates seamless communication between the VLM ensemble and the reasoning
LLM, integrating prompt engineering strategies and automated reasoning
workflows using LLM Agents. Experimental results demonstrate that this hybrid
system delivers highly accurate, consistent, and interpretable H-reflex
assessments, significantly advancing the automation and standardization of
neuromuscular diagnostics. To our knowledge, this work represents the first
integration of a fine-tuned VLM consortium with a reasoning LLM for image-based
H-reflex analysis, laying the foundation for next-generation AI-assisted
neuromuscular assessment and athlete monitoring platforms.

</details>


### [80] [Skin Cancer Classification: Hybrid CNN-Transformer Models with KAN-Based Fusion](https://arxiv.org/abs/2508.12484)
*Shubhi Agarwal,Amulya Kumar Mahto*

Main category: cs.CV

TL;DR: 该研究提出了一种结合CNN-Transformer混合架构和卷积Kolmogorov-Arnold网络(CKAN)的皮肤癌分类方法，通过整合迁移学习和数据增强技术，在多个基准数据集上取得了优异的分类性能。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌分类是医学图像分析中的关键任务，准确区分恶性和非恶性病变对于早期诊断和治疗至关重要。传统方法在特征表示和模型泛化能力方面存在局限，需要开发更强大的混合架构来提高分类性能。

Method: 采用顺序和并行混合的CNN-Transformer模型，结合卷积Kolmogorov-Arnold网络(CKAN)。CNN提取局部空间特征，Transformer建模全局依赖关系，CKAN通过可学习激活函数实现非线性特征融合。使用迁移学习和大量数据增强技术。

Result: 在多个数据集上取得优异性能：HAM10000数据集上准确率92.81%、F1分数92.47%；PAD-UFES数据集上准确率97.83%、F1分数97.83%；BCN20000数据集上准确率91.17%、F1分数91.79%。

Conclusion: 混合CNN-Transformer架构能有效捕获空间和上下文特征，CKAN的集成通过可学习激活函数增强了特征融合能力。该研究强调了特征表示和模型设计在推进稳健准确的医学图像分类中的重要性。

Abstract: Skin cancer classification is a crucial task in medical image analysis, where
precise differentiation between malignant and non-malignant lesions is
essential for early diagnosis and treatment. In this study, we explore
Sequential and Parallel Hybrid CNN-Transformer models with Convolutional
Kolmogorov-Arnold Network (CKAN). Our approach integrates transfer learning and
extensive data augmentation, where CNNs extract local spatial features,
Transformers model global dependencies, and CKAN facilitates nonlinear feature
fusion for improved representation learning. To assess generalization, we
evaluate our models on multiple benchmark datasets (HAM10000,BCN20000 and
PAD-UFES) under varying data distributions and class imbalances. Experimental
results demonstrate that hybrid CNN-Transformer architectures effectively
capture both spatial and contextual features, leading to improved
classification performance. Additionally, the integration of CKAN enhances
feature fusion through learnable activation functions, yielding more
discriminative representations. Our proposed approach achieves competitive
performance in skin cancer classification, demonstrating 92.81% accuracy and
92.47% F1-score on the HAM10000 dataset, 97.83% accuracy and 97.83% F1-score on
the PAD-UFES dataset, and 91.17% accuracy with 91.79% F1- score on the BCN20000
dataset highlighting the effectiveness and generalizability of our model across
diverse datasets. This study highlights the significance of feature
representation and model design in advancing robust and accurate medical image
classification.

</details>


### [81] [Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients](https://arxiv.org/abs/2508.12506)
*E. Ulises Moya-Sánchez,Abraham Sánchez-Perez,Raúl Nanclares Da Veiga,Alejandro Zarate-Macías,Edgar Villareal,Alejandro Sánchez-Montes,Edtna Jauregui-Ulloa,Héctor Moreno,Ulises Cortés*

Main category: cs.CV

TL;DR: RAIS-DR是一个负责任的人工智能系统，用于糖尿病视网膜病变筛查，在准确性和公平性方面显著优于FDA批准的EyeArt系统。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是工作年龄人群视力丧失的主要原因，早期检测可降低95%的视力丧失风险。但由于视网膜专家短缺和及时检查的挑战，临床采用受到低质量数据和偏见的阻碍。

Method: 开发了RAIS-DR系统，在整个AI生命周期中整合伦理原则，包括高效的卷积模型进行预处理、质量评估和三个专门的DR分类模型。

Result: 在1,046名患者的本地数据集上评估，RAIS-DR相比EyeArt系统F1分数提高5-12%，准确率提高6-19%，特异性提高10-20%。公平性指标显示在不同人口统计亚组中表现公平。

Conclusion: RAIS-DR是一个强大且符合伦理的DR筛查解决方案，有潜力减少医疗保健差距，代码和权重已开源。

Abstract: Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age
individuals. Early detection of DR can reduce the risk of vision loss by up to
95%, but a shortage of retinologists and challenges in timely examination
complicate detection. Artificial Intelligence (AI) models using retinal fundus
photographs (RFPs) offer a promising solution. However, adoption in clinical
settings is hindered by low-quality data and biases that may lead AI systems to
learn unintended features. To address these challenges, we developed RAIS-DR, a
Responsible AI System for DR screening that incorporates ethical principles
across the AI lifecycle. RAIS-DR integrates efficient convolutional models for
preprocessing, quality assessment, and three specialized DR classification
models. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local
dataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated
significant improvements, with F1 scores increasing by 5-12%, accuracy by
6-19%, and specificity by 10-20%. Additionally, fairness metrics such as
Disparate Impact and Equal Opportunity Difference indicated equitable
performance across demographic subgroups, underscoring RAIS-DR's potential to
reduce healthcare disparities. These results highlight RAIS-DR as a robust and
ethically aligned solution for DR screening in clinical settings. The code,
weights of RAIS-DR are available at
https://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with
RAIL.

</details>


### [82] [LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models](https://arxiv.org/abs/2508.12512)
*Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath*

Main category: cs.CV

TL;DR: 本文提出LangVision-LoRA-NAS框架，通过神经架构搜索动态优化LoRA的秩配置，在提升视觉语言模型性能的同时降低微调成本。


<details>
  <summary>Details</summary>
Motivation: 当前LoRA方法使用固定秩进行微调，限制了在不同多模态任务中的灵活性和效率，需要一种能够动态调整秩配置的方法。

Method: 结合神经架构搜索(NAS)与LoRA技术，为特定多模态任务动态搜索最优的LoRA秩配置，平衡性能与计算效率。

Result: 在LLaMA-3.2-11B模型上的实验表明，该方法显著提升了模型性能并降低了微调成本。

Conclusion: LangVision-LoRA-NAS框架为视觉语言模型的高效微调提供了新的解决方案，通过动态秩优化实现了更好的性能与效率平衡。

Abstract: Vision Language Models (VLMs) integrate visual and text modalities to enable
multimodal understanding and generation. These models typically combine a
Vision Transformer (ViT) as an image encoder and a Large Language Model (LLM)
for text generation. LoRA (Low-Rank Adaptation) is an efficient fine-tuning
method to adapt pre-trained models to new tasks by introducing low-rank updates
to their weights. While LoRA has emerged as a powerful technique for
fine-tuning large models by introducing low-rank updates, current
implementations assume a fixed rank, potentially limiting flexibility and
efficiency across diverse tasks. This paper introduces
\textit{LangVision-LoRA-NAS}, a novel framework that integrates Neural
Architecture Search (NAS) with LoRA to optimize VLMs for variable-rank
adaptation. Our approach leverages NAS to dynamically search for the optimal
LoRA rank configuration tailored to specific multimodal tasks, balancing
performance and computational efficiency. Through extensive experiments using
the LLaMA-3.2-11B model on several datasets, LangVision-LoRA-NAS demonstrates
notable improvement in model performance while reducing fine-tuning costs. Our
Base and searched fine-tuned models on LLaMA-3.2-11B-Vision-Instruct can be
found
\href{https://huggingface.co/collections/krishnateja95/llama-32-11b-vision-instruct-langvision-lora-nas-6786cac480357a6a6fcc59ee}{\textcolor{blue}{here}}
and the code for LangVision-LoRA-NAS can be found
\href{https://github.com/krishnateja95/LangVision-NAS}{\textcolor{blue}{here}}.

</details>


### [83] [An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers](https://arxiv.org/abs/2508.12520)
*Felipe Carlos dos Santos,Eric Aislan Antonelo,Gustavo Claudio Karl Couto*

Main category: cs.CV

TL;DR: 使用跨视图Transformer将相机图像映射到布鸥视角地图，在都市自动驾驶场景中实现了路面、车道标记和规划轨迹的准确分析


<details>
  <summary>Details</summary>
Motivation: 布鸥视角地图提供了结构化的顶部视图抽象，对自动驾驶感知至关重要，需要研究如何从相机图像生成准确的BEV地图

Method: 使用Cross-View Transformers(CVT)，通过现实中的都市驾驶模拟器进行训练，映射到三个BEV通道（路面、车道标记、规划轨迹），测试了不同相机布局和损失函数（focal和L1）的效果

Result: 在仅使用一个城镇数据训练的情况下，四相机CVT配合L1损失在新城镇的测试中表现最为稳健，显示了良好的泛化能力

Conclusion: 跨视图Transformer在将相机输入映射到相对准确的BEV地图方面具有很大潜力，为自动驾驶感知系统提供了有效的解决方案

Abstract: Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is
crucial for autonomous-driving perception. In this work, we employ Cross-View
Transformers (CVT) for learning to map camera images to three BEV's channels -
road, lane markings, and planned trajectory - using a realistic simulator for
urban driving. Our study examines generalization to unseen towns, the effect of
different camera layouts, and two loss formulations (focal and L1). Using
training data from only a town, a four-camera CVT trained with the L1 loss
delivers the most robust test performance, evaluated in a new town. Overall,
our results underscore CVT's promise for mapping camera inputs to reasonably
accurate BEV maps.

</details>


### [84] [MuSACo: Multimodal Subject-Specific Selection and Adaptation for Expression Recognition with Co-Training](https://arxiv.org/abs/2508.12522)
*Muhammad Osama Zeeshan,Natacha Gillet,Alessandro Lameiras Koerich,Marco Pedersoli,Francois Bremond,Eric Granger*

Main category: cs.CV

TL;DR: MuSACo是一个基于协同训练的多模态个性化表情识别方法，通过选择相关源主体并利用多模态互补信息进行主体特异性适应，在BioVid和StressID数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MSDA方法往往忽视多模态信息或将多个源混合为单一域，限制了主体多样性且未能显式捕获主体特异性特征，需要解决这些限制来提升个性化表情识别性能。

Method: 基于协同训练的多模态主体特异性选择和适应方法，选择与目标相关的源主体，使用主导模态生成伪标签进行类感知学习，结合类无关损失从低置信度目标样本中学习，对齐各模态源特征并仅组合置信目标特征。

Result: 在BioVid和StressID多模态表情识别数据集上的实验结果表明，MuSACo能够超越UDA（混合）和最先进的MSDA方法。

Conclusion: MuSACo通过有效利用多模态互补信息和多源域适应，成功解决了个性化表情识别中的主体特异性特征捕获问题，在数字健康等情感计算应用中具有重要价值。

Abstract: Personalized expression recognition (ER) involves adapting a machine learning
model to subject-specific data for improved recognition of expressions with
considerable interpersonal variability. Subject-specific ER can benefit
significantly from multi-source domain adaptation (MSDA) methods, where each
domain corresponds to a specific subject, to improve model accuracy and
robustness. Despite promising results, state-of-the-art MSDA approaches often
overlook multimodal information or blend sources into a single domain, limiting
subject diversity and failing to explicitly capture unique subject-specific
characteristics. To address these limitations, we introduce MuSACo, a
multi-modal subject-specific selection and adaptation method for ER based on
co-training. It leverages complementary information across multiple modalities
and multiple source domains for subject-specific adaptation. This makes MuSACo
particularly relevant for affective computing applications in digital health,
such as patient-specific assessment for stress or pain, where subject-level
nuances are crucial. MuSACo selects source subjects relevant to the target and
generates pseudo-labels using the dominant modality for class-aware learning,
in conjunction with a class-agnostic loss to learn from less confident target
samples. Finally, source features from each modality are aligned, while only
confident target features are combined. Our experimental results on challenging
multimodal ER datasets: BioVid and StressID, show that MuSACo can outperform
UDA (blending) and state-of-the-art MSDA methods.

</details>


### [85] [REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language](https://arxiv.org/abs/2508.12543)
*Ipsita Praharaj,Yukta Butala,Yash Butala*

Main category: cs.CV

TL;DR: REVEAL框架利用大型视觉语言模型，通过整体场景评估和区域异常检测两种方法，实现了跨领域的图像伪造检测和定位。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展使得视觉伪造检测和解释变得更加困难，现有方法在跨领域泛化方面存在挑战，需要能够同时提供检测、定位和推理的鲁棒框架。

Method: 提出REVEAL框架，将伪造检测构建为提示驱动的视觉推理任务，采用两种互补方法：(1)整体场景级评估，基于物理、语义、透视和真实性的综合判断；(2)区域级异常检测，将图像分割成多个区域进行分析。

Result: 在多个领域数据集（Photoshop、DeepFake和AIGC编辑）上进行实验，与竞争基线进行比较，并分析了模型提供的推理能力。

Conclusion: 该框架通过视觉语言模型的语义对齐能力，实现了跨领域的图像伪造检测，提供了可解释的推理结果和精确定位能力。

Abstract: The rapid advancement of generative models has intensified the challenge of
detecting and interpreting visual forgeries, necessitating robust frameworks
for image forgery detection while providing reasoning as well as localization.
While existing works approach this problem using supervised training for
specific manipulation or anomaly detection in the embedding space,
generalization across domains remains a challenge. We frame this problem of
forgery detection as a prompt-driven visual reasoning task, leveraging the
semantic alignment capabilities of large vision-language models. We propose a
framework, `REVEAL` (Reasoning and Evaluation of Visual Evidence through
Aligned Language), that incorporates generalized guidelines. We propose two
tangential approaches - (1) Holistic Scene-level Evaluation that relies on the
physics, semantics, perspective, and realism of the image as a whole and (2)
Region-wise anomaly detection that splits the image into multiple regions and
analyzes each of them. We conduct experiments over datasets from different
domains (Photoshop, DeepFake and AIGC editing). We compare the Vision Language
Models against competitive baselines and analyze the reasoning provided by
them.

</details>


### [86] [Structure-preserving Feature Alignment for Old Photo Colorization](https://arxiv.org/abs/2508.12570)
*Yingxue Pang,Xin Jin,Jun Fu,Zhibo Chen*

Main category: cs.CV

TL;DR: 通过仅使用两张图片训练的CNN算法SFAC，解决老照片着色中缺乏真实标签和领域差距问题，通过结构保持和特征对齐机制实现超越域间色彩转移。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习着色方法依赖大规模数据集，但在老照片着色任务中遇到了缺乏真实标签和领域差距的挑战，需要一种不依赖大数据的方案。

Method: 提出SFAC算法，仅需两张图片训练。通过特征分布对齐损失建立语义对应关系，使得语义相关对象具有相似颜色。使用结构保持机制（特征层感知约束和像素层冰冻-更新金字塔）来减少结构扭曲。

Result: 广泛实验验证了方法在老照片着色任务上的有效性，通过定性和定量指标确认了其优势。

Conclusion: SFAC算法能够有效解决老照片着色中的领域差距问题，无需大规模数据训练，通过结构保持和特征对齐机制实现了超越领域的色彩转移效果。

Abstract: Deep learning techniques have made significant advancements in
reference-based colorization by training on large-scale datasets. However,
directly applying these methods to the task of colorizing old photos is
challenging due to the lack of ground truth and the notorious domain gap
between natural gray images and old photos. To address this issue, we propose a
novel CNN-based algorithm called SFAC, i.e., Structure-preserving Feature
Alignment Colorizer. SFAC is trained on only two images for old photo
colorization, eliminating the reliance on big data and allowing direct
processing of the old photo itself to overcome the domain gap problem. Our
primary objective is to establish semantic correspondence between the two
images, ensuring that semantically related objects have similar colors. We
achieve this through a feature distribution alignment loss that remains robust
to different metric choices. However, utilizing robust semantic correspondence
to transfer color from the reference to the old photo can result in inevitable
structure distortions. To mitigate this, we introduce a structure-preserving
mechanism that incorporates a perceptual constraint at the feature level and a
frozen-updated pyramid at the pixel level. Extensive experiments demonstrate
the effectiveness of our method for old photo colorization, as confirmed by
qualitative and quantitative metrics.

</details>


### [87] [Foundation Model for Skeleton-Based Human Action Understanding](https://arxiv.org/abs/2508.12586)
*Hongsong Wang,Wanjiang Weng,Junbo Wang,Fang Zhao,Guo-Sen Xie,Xin Geng,Liang Wang*

Main category: cs.CV

TL;DR: 提出了USDRL框架，一个用于骨架动作理解的统一基础模型，通过Transformer编码器、多粒度特征解相关和多视角一致性训练，在25个基准测试中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作理解方法缺乏处理多样化任务的扩展性和泛化能力，需要能够适应广泛动作理解任务的基础模型

Method: USDRL框架包含：1）基于Transformer的密集时空编码器（DSTE）学习时空特征；2）多粒度特征解相关（MG-FD）减少维度冗余；3）多视角一致性训练（MPCT）进行自监督学习

Result: 在9个骨架动作理解任务的25个基准测试中显著超越当前最先进方法，涵盖粗粒度预测、密集预测和迁移预测

Conclusion: 该工作拓宽了骨架动作理解的研究范围，鼓励更多关注密集预测任务，为骨架基础模型的发展提供了重要贡献

Abstract: Human action understanding serves as a foundational pillar in the field of
intelligent motion perception. Skeletons serve as a modality- and
device-agnostic representation for human modeling, and skeleton-based action
understanding has potential applications in humanoid robot control and
interaction. \RED{However, existing works often lack the scalability and
generalization required to handle diverse action understanding tasks. There is
no skeleton foundation model that can be adapted to a wide range of action
understanding tasks}. This paper presents a Unified Skeleton-based Dense
Representation Learning (USDRL) framework, which serves as a foundational model
for skeleton-based human action understanding. USDRL consists of a
Transformer-based Dense Spatio-Temporal Encoder (DSTE), Multi-Grained Feature
Decorrelation (MG-FD), and Multi-Perspective Consistency Training (MPCT). The
DSTE module adopts two parallel streams to learn temporal dynamic and spatial
structure features. The MG-FD module collaboratively performs feature
decorrelation across temporal, spatial, and instance domains to reduce
dimensional redundancy and enhance information extraction. The MPCT module
employs both multi-view and multi-modal self-supervised consistency training.
The former enhances the learning of high-level semantics and mitigates the
impact of low-level discrepancies, while the latter effectively facilitates the
learning of informative multimodal features. We perform extensive experiments
on 25 benchmarks across across 9 skeleton-based action understanding tasks,
covering coarse prediction, dense prediction, and transferred prediction. Our
approach significantly outperforms the current state-of-the-art methods. We
hope that this work would broaden the scope of research in skeleton-based
action understanding and encourage more attention to dense prediction tasks.

</details>


### [88] [Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models](https://arxiv.org/abs/2508.12587)
*Tan-Hanh Pham,Chris Ngo*

Main category: cs.CV

TL;DR: 多模态连续思维链(MCOUT)通过在聚合潜在空间进行连续向量推理，充分利用视觉和文本特征，在多模态理解任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型推理方法(如思维链提示)在多模态环境中效果不佳，难以动态对齐音频、视觉和文本信息。

Method: 提出MCOUT方法，将推理状态表示为连续隐藏向量，迭代精炼并与视觉、文本嵌入对齐。包括MCOUT-Base(重用语言模型隐藏状态)和MCOUT-Multi(多模态潜在注意力机制)两个变体。

Result: 在MMMU、ScienceQA、MMStar等测试集上显著提升性能，准确率最高提升8.23%，BLEU指标提升达8.27%，在多选题和开放式任务上都取得良好效果。

Conclusion: 潜在连续推理是提升大型多模态模型理解能力的有前景方向，提供了一种可扩展的类人思维多模态推理框架。

Abstract: Many reasoning techniques for large multimodal models adapt language model
approaches, such as Chain-of-Thought (CoT) prompting, which express reasoning
as word sequences. While effective for text, these methods are suboptimal for
multimodal contexts, struggling to align audio, visual, and textual information
dynamically. To explore an alternative paradigm, we propose the Multimodal
Chain of Continuous Thought (MCOUT), which enables reasoning directly in a
joint latent space rather than in natural language. In MCOUT, the reasoning
state is represented as a continuous hidden vector, iteratively refined and
aligned with visual and textual embeddings, inspired by human reflective
cognition. We develop two variants: MCOUT-Base, which reuses the language
model`s last hidden state as the continuous thought for iterative reasoning,
and MCOUT-Multi, which integrates multimodal latent attention to strengthen
cross-modal alignment between visual and textual features. Experiments on
benchmarks including MMMU, ScienceQA, and MMStar show that MCOUT consistently
improves multimodal reasoning, yielding up to 8.23% accuracy gains over strong
baselines and improving BLEU scores up to 8.27% across multiple-choice and
open-ended tasks. These findings highlight latent continuous reasoning as a
promising direction for advancing LMMs beyond language-bound CoT, offering a
scalable framework for human-like reflective multimodal inference. Code is
available at https://github.com/Hanhpt23/OmniMod.

</details>


### [89] [ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.12603)
*Can Cui,Yupeng Zhou,Juntong Peng,Sung-Yeon Park,Zichong Yang,Prashanth Sankaranarayanan,Jiaru Zhang,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: ViLaD是一个基于扩散模型的新型端到端自动驾驶框架，通过并行生成驾驶决策序列显著降低延迟，支持双向推理和渐进式生成，在nuScenes数据集上表现优于现有自回归VLM方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉语言模型的自回归架构存在推理延迟高、无法进行双向推理的问题，不适合动态的安全关键环境。

Method: 采用掩码扩散模型实现驾驶决策序列的并行生成，支持双向推理和渐进式易先生成策略。

Result: 在nuScenes数据集上，ViLaD在规划准确性和推理速度方面均优于最先进的自回归VLM基线，接近零失败率，并在真实自动驾驶车辆上验证了实用性。

Conclusion: ViLaD框架代表了端到端自动驾驶的范式转变，通过扩散模型解决了自回归架构的局限性，为实际应用提供了有效的解决方案。

Abstract: End-to-end autonomous driving systems built on Vision Language Models (VLMs)
have shown significant promise, yet their reliance on autoregressive
architectures introduces some limitations for real-world applications. The
sequential, token-by-token generation process of these models results in high
inference latency and cannot perform bidirectional reasoning, making them
unsuitable for dynamic, safety-critical environments. To overcome these
challenges, we introduce ViLaD, a novel Large Vision Language Diffusion (LVLD)
framework for end-to-end autonomous driving that represents a paradigm shift.
ViLaD leverages a masked diffusion model that enables parallel generation of
entire driving decision sequences, significantly reducing computational
latency. Moreover, its architecture supports bidirectional reasoning, allowing
the model to consider both past and future simultaneously, and supports
progressive easy-first generation to iteratively improve decision quality. We
conduct comprehensive experiments on the nuScenes dataset, where ViLaD
outperforms state-of-the-art autoregressive VLM baselines in both planning
accuracy and inference speed, while achieving a near-zero failure rate.
Furthermore, we demonstrate the framework's practical viability through a
real-world deployment on an autonomous vehicle for an interactive parking task,
confirming its effectiveness and soundness for practical applications.

</details>


### [90] [ViDA-UGC: Detailed Image Quality Analysis via Visual Distortion Assessment for UGC Images](https://arxiv.org/abs/2508.12605)
*Wenjie Liao,Jieyu Yuan,Yifang Xu,Chunle Guo,Zilong Zhang,Jihong Li,Jiachen Fu,Haotian Fan,Tao Li,Junhui Cui,Chongyi Li*

Main category: cs.CV

TL;DR: 这篇论文提出了ViDA-UGC数据集，专门用于用户生成内容图片的视觉失真评估，通过链式思维框架生成细粒度质量描述，显著提升了多模态大语言模型的图片质量分析能力。


<details>
  <summary>Details</summary>
Motivation: 当前的可解释性图片质量评估方法存在两个主要问题：一是将UGC和AIGC图片混淆使用相同的失真标准进行评估，二是缺乏详细的质量分析来监控图片质量和指导图片恢复。

Method: 构建了首个大规模的UGC图片视觉失真评估指令微调数据集ViDA-UGC，包含11K张图片的细粒度质量基准、详细质量感知和推理质量描述。通过失真导向的流水线和链式思维评估框架，引导GPT-4o生成质量描述。

Result: 实验结果显示，ViDA-UGC数据集和CoT框架能够一致地提升多个基础MLLM模型在ViDA-UGC-Bench和Q-Bench上的图片质量分析能力，甚至超越了GPT-4o的表现。

Conclusion: 该研究成功构建了首个大规模的UGC图片失真评估数据集，通过链式思维框架生成了高质量的质量描述，为可解释性图片质量评估领域提供了有力的数据支撑和方法论基础。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have introduced a
paradigm shift for Image Quality Assessment (IQA) from unexplainable image
quality scoring to explainable IQA, demonstrating practical applications like
quality control and optimization guidance. However, current explainable IQA
methods not only inadequately use the same distortion criteria to evaluate both
User-Generated Content (UGC) and AI-Generated Content (AIGC) images, but also
lack detailed quality analysis for monitoring image quality and guiding image
restoration. In this study, we establish the first large-scale Visual
Distortion Assessment Instruction Tuning Dataset for UGC images, termed
ViDA-UGC, which comprises 11K images with fine-grained quality grounding,
detailed quality perception, and reasoning quality description data. This
dataset is constructed through a distortion-oriented pipeline, which involves
human subject annotation and a Chain-of-Thought (CoT) assessment framework.
This framework guides GPT-4o to generate quality descriptions by identifying
and analyzing UGC distortions, which helps capturing rich low-level visual
features that inherently correlate with distortion patterns. Moreover, we
carefully select 476 images with corresponding 6,149 question answer pairs from
ViDA-UGC and invite a professional team to ensure the accuracy and quality of
GPT-generated information. The selected and revised data further contribute to
the first UGC distortion assessment benchmark, termed ViDA-UGC-Bench.
Experimental results demonstrate the effectiveness of the ViDA-UGC and CoT
framework for consistently enhancing various image quality analysis abilities
across multiple base MLLMs on ViDA-UGC-Bench and Q-Bench, even surpassing
GPT-4o.

</details>


### [91] [OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion](https://arxiv.org/abs/2508.12610)
*Chen Qian,Danyang Li,Xinran Yu,Zheng Yang,Qiang Ma*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的动戯捕捉模型OpenMoCap和一个包含现实标记遮挡模式的CMU-Occlu数据集，以解决大规模标记遮挡导致的系统性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 光学动戯捕捉技术在虚拟现实和电影制作领域应用广泛，但实际应用中大规模标记遮挡会严重影响系统性能。当前模型存在两个主要问题：缺乏反映现实遮挡模式的训练数据集，以及缺乏捕捉标记间长程依赖关系的训练策略。

Method: 首先使用光线追踪技术创建了CMU-Occlu数据集，现实地模拟实际标记遮挡模式。然后提出OpenMoCap模型，利用标记-关节链推理机制，实现标记与关节间深度约束的同时优化和构建。

Result: 大量对比实验表明，OpenMoCap在多种场景下都一贵地超过了其他竞争方法。CMU-Occlu数据集为未来稳健动戯解决研究打开了新的可能性。

Conclusion: OpenMoCap模型已集成到MoSen动戯捕捉系统中进行实际部署，代码已开源。该研究有效解决了大规模标记遮挡带来的挑战，提高了光学动戯捕捉在复杂环境下的稳健性。

Abstract: Optical motion capture is a foundational technology driving advancements in
cutting-edge fields such as virtual reality and film production. However,
system performance suffers severely under large-scale marker occlusions common
in real-world applications. An in-depth analysis identifies two primary
limitations of current models: (i) the lack of training datasets accurately
reflecting realistic marker occlusion patterns, and (ii) the absence of
training strategies designed to capture long-range dependencies among markers.
To tackle these challenges, we introduce the CMU-Occlu dataset, which
incorporates ray tracing techniques to realistically simulate practical marker
occlusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving
model designed specifically for robust motion capture in environments with
significant occlusions. Leveraging a marker-joint chain inference mechanism,
OpenMoCap enables simultaneous optimization and construction of deep
constraints between markers and joints. Extensive comparative experiments
demonstrate that OpenMoCap consistently outperforms competing methods across
diverse scenarios, while the CMU-Occlu dataset opens the door for future
studies in robust motion solving. The proposed OpenMoCap is integrated into the
MoSen MoCap system for practical deployment. The code is released at:
https://github.com/qianchen214/OpenMoCap.

</details>


### [92] [WIPES: Wavelet-based Visual Primitives](https://arxiv.org/abs/2508.12615)
*Wenhao Zhang,Hao Zhu,Delong Wu,Di Kang,Linchao Bao,Zhan Ma,Xun Cao*

Main category: cs.CV

TL;DR: WIPES是一个基于小波的通用视觉基元表示方法，通过小波的空间-频率局部化优势同时捕捉低频和高频信息，并开发了基于小波的可微分光栅化器实现快速渲染。


<details>
  <summary>Details</summary>
Motivation: 现有视觉表示方法依赖频率指导或复杂神经网络解码，导致频谱损失或渲染速度慢，需要一种能同时提供灵活频率调制和快速渲染速度的连续视觉表示。

Method: 基于小波的空间-频率局部化优势构建WIPES表示，开发小波基可微分光栅化器实现快速视觉渲染。

Result: 在2D图像表示、5D静态和6D动态新视角合成等视觉任务中，WIPES相比基于INR的方法提供更高渲染质量和更快推理速度，在渲染质量上优于基于高斯的方法。

Conclusion: WIPES作为一种视觉基元，能够有效解决现有方法的频谱损失和渲染速度问题，在多个视觉任务中表现出优越的性能。

Abstract: Pursuing a continuous visual representation that offers flexible frequency
modulation and fast rendering speed has recently garnered increasing attention
in the fields of 3D vision and graphics. However, existing representations
often rely on frequency guidance or complex neural network decoding, leading to
spectrum loss or slow rendering. To address these limitations, we propose
WIPES, a universal Wavelet-based vIsual PrimitivES for representing
multi-dimensional visual signals. Building on the spatial-frequency
localization advantages of wavelets, WIPES effectively captures both the
low-frequency "forest" and the high-frequency "trees." Additionally, we develop
a wavelet-based differentiable rasterizer to achieve fast visual rendering.
Experimental results on various visual tasks, including 2D image
representation, 5D static and 6D dynamic novel view synthesis, demonstrate that
WIPES, as a visual primitive, offers higher rendering quality and faster
inference than INR-based methods, and outperforms Gaussian-based
representations in rendering quality.

</details>


### [93] [Creative4U: MLLMs-based Advertising Creative Image Selector with Comparative Reasoning](https://arxiv.org/abs/2508.12628)
*Yukang Lin,Xiang Zhang,Shichang Jia,Bowen Wan,Chenghan Fu,Xudong Ren,Yueran Liu,Wanxian Guan,Pengji Wang,Jian Xu,Bo Zheng,Baolin Liu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于多模态大语言模型的可解释性广告创意图像评估和选择方法，构建了首个对比性创意数据集CreativePair，并开发了考虑用户兴趣的创意选择器Creative4U。


<details>
  <summary>Details</summary>
Motivation: 虽然AIGC技术让广告主能以低成本生产大量创意图像，但现有方法主要关注排名而非可解释性的创意选择，无法满足广告主选择高质量创意图像的需求。

Method: 提出了一种基于多模态大语言模型的可解释性创意评估方法，将创意图像的评估和选择集成到自然语言生成任务中。构建了CreativePair数据集（包含8k带注释的图像对），并通过Reason-to-Select RFT训练方法（包括CoT-SFT和GRPO强化学习）开发了Creative4U创意选择器。

Result: 线上和线下实验都证明了该方法的有效性，能够准确地评估和选择创意图像。

Conclusion: 该研究为创意图像评估和选择领域提供了首个可解释性的解决方案，通过多模态大语言模型和对比性理解方法，有助于提升电子商务平台的广告效果和用户体验。

Abstract: Creative image in advertising is the heart and soul of e-commerce platform.
An eye-catching creative image can enhance the shopping experience for users,
boosting income for advertisers and advertising revenue for platforms. With the
advent of AIGC technology, advertisers can produce large quantities of creative
images at minimal cost. However, they struggle to assess the creative quality
to select. Existing methods primarily focus on creative ranking, which fails to
address the need for explainable creative selection.
  In this work, we propose the first paradigm for explainable creative
assessment and selection. Powered by multimodal large language models (MLLMs),
our approach integrates the assessment and selection of creative images into a
natural language generation task. To facilitate this research, we construct
CreativePair, the first comparative reasoning-induced creative dataset
featuring 8k annotated image pairs, with each sample including a label
indicating which image is superior. Additionally, we introduce Creative4U
(pronounced Creative for You), a MLLMs-based creative selector that takes into
account users' interests. Through Reason-to-Select RFT, which includes
supervised fine-tuning with Chain-of-Thought (CoT-SFT) and Group Relative
Policy Optimization (GRPO) based reinforcement learning, Creative4U is able to
evaluate and select creative images accurately. Both offline and online
experiments demonstrate the effectiveness of our approach. Our code and dataset
will be made public to advance research and industrial applications.

</details>


### [94] [SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer](https://arxiv.org/abs/2508.12638)
*Chen Qian,Xinran Yu,Zewen Huang,Danyang Li,Qiang Ma,Fan Dang,Xuan Ding,Guangyong Shang,Zheng Yang*

Main category: cs.CV

TL;DR: 提出了一种新的云边协同视觉-语言模型框架SpotVLM，利用大模型的延迟输出作为历史上下文来指导小模型的实时推理


<details>
  <summary>Details</summary>
Motivation: 现有的云边协同方案无法适应云端延迟波动，且没有充分利用大模型延迟但准确的响应

Method: 设计了Context Transfer框架，包含上下文替换模块和视觉聚焦模块，用于精炼历史文本输入和提升视觉基准一致性

Result: 在四个数据集的三个实时视觉任务上进行了广泛实验，验证了框架的有效性

Conclusion: 该新框架为未来VLM系统更有效和延迟感知的协同策略奠定了基础

Abstract: Vision-Language Models (VLMs) are increasingly deployed in real-time
applications such as autonomous driving and human-computer interaction, which
demand fast and reliable responses based on accurate perception. To meet these
requirements, existing systems commonly employ cloud-edge collaborative
architectures, such as partitioned Large Vision-Language Models (LVLMs) or task
offloading strategies between Large and Small Vision-Language Models (SVLMs).
However, these methods fail to accommodate cloud latency fluctuations and
overlook the full potential of delayed but accurate LVLM responses. In this
work, we propose a novel cloud-edge collaborative paradigm for VLMs, termed
Context Transfer, which treats the delayed outputs of LVLMs as historical
context to provide real-time guidance for SVLMs inference. Based on this
paradigm, we design SpotVLM, which incorporates both context replacement and
visual focus modules to refine historical textual input and enhance visual
grounding consistency. Extensive experiments on three real-time vision tasks
across four datasets demonstrate the effectiveness of the proposed framework.
The new paradigm lays the groundwork for more effective and latency-aware
collaboration strategies in future VLM systems.

</details>


### [95] [Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow](https://arxiv.org/abs/2508.12640)
*Bastian Brandstötter,Erich Kobler*

Main category: cs.CV

TL;DR: 使用两阶段后验均值正流模型(PMRF)从非对比增强MRI生成体积对比增强脑部MRI，避免镍基对比剂的使用


<details>
  <summary>Details</summary>
Motivation: 对比增强T1加权MRI在神经脱粒细胞癌诊断中关键，但需要镍基对比剂，这会增加成本和扫描时间，带来环境问题和患者风险

Method: 两阶段流程：首先用片基3D U-Net预测像素后验均值(最小化MSE)，然后用时间条件化3D正流模型精炼，以结合现实素材和结构保真性

Result: 在360个测试数据上，最佳精炼输出达到轴位FID 12.46和KID 0.007(比后验均值降低68.7%)，保持低体积MSE 0.057(比后验均值高27%)

Conclusion: 方法能够实际恢复病变边缘和血管细节，有效平衡感知-失真交易，适合临床部署

Abstract: Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic
diagnosis but requires gadolinium-based agents, which add cost and scan time,
raise environmental concerns, and may pose risks to patients. In this work, we
propose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for
synthesizing volumetric CE brain MRI from non-contrast inputs. First, a
patch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE).
Then, this initial estimate is refined by a time-conditioned 3D rectified flow
to incorporate realistic textures without compromising structural fidelity. We
train this model on a multi-institutional collection of paired pre- and
post-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360
diverse volumes, our best refined outputs achieve an axial FID of $12.46$ and
KID of $0.007$ ($\sim 68.7\%$ lower FID than the posterior mean) while
maintaining low volumetric MSE of $0.057$ ($\sim 27\%$ higher than the
posterior mean). Qualitative comparisons confirm that our method restores
lesion margins and vascular details realistically, effectively navigating the
perception-distortion trade-off for clinical deployment.

</details>


### [96] [Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation](https://arxiv.org/abs/2508.12680)
*Yuheng Zha,Kun Zhou,Yujia Wu,Yushu Wang,Jie Feng,Zhi Xu,Shibo Hao,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

Main category: cs.CV

TL;DR: 通过多域数据集集成和彩集数据筛选策略，训练出在多个视觉推理预测任务上超越GPT-4o和Gemini-1.5 Flash的视觉语言模型Vision-G1


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的训练集中在数学和逻辑推理等范围有限的任务，导致模型在广泛领域的推理能力普遍不佳，且缺乏可验证的奖励数据和域间数据集的整合方法

Method: 从46个数据源中构建包含8个维度的全面RL准备视觉推理数据集，采用影响函数基于的数据选择和难度基于的筛选策略识别高质量训练样本，通过多轮强化学习和数据课程迭代改进模型能力

Result: Vision-G1模型在各种视觉推理测试集上达到了最先进水平，超过同规模VLMs甚至超过GPT-4o和Gemini-1.5 Flash等专有模型

Conclusion: 通过多域数据集成和优化的数据筛选策略，可以有效提升视觉语言模型的推理能力和通用性，为广泛领域的视觉推理问题提供了有效解决方案

Abstract: Despite their success, current training pipelines for reasoning VLMs focus on
a limited range of tasks, such as mathematical and logical reasoning. As a
result, these models face difficulties in generalizing their reasoning
capabilities to a wide range of domains, primarily due to the scarcity of
readily available and verifiable reward data beyond these narrowly defined
areas. Moreover, integrating data from multiple domains is challenging, as the
compatibility between domain-specific datasets remains uncertain. To address
these limitations, we build a comprehensive RL-ready visual reasoning dataset
from 46 data sources across 8 dimensions, covering a wide range of tasks such
as infographic, mathematical, spatial, cross-image, graphic user interface,
medical, common sense and general science. We propose an influence function
based data selection and difficulty based filtering strategy to identify
high-quality training samples from this dataset. Subsequently, we train the
VLM, referred to as Vision-G1, using multi-round RL with a data curriculum to
iteratively improve its visual reasoning capabilities. Our model achieves
state-of-the-art performance across various visual reasoning benchmarks,
outperforming similar-sized VLMs and even proprietary models like GPT-4o and
Gemini-1.5 Flash. The model, code and dataset are publicly available at
https://github.com/yuh-zha/Vision-G1.

</details>


### [97] [Learn Faster and Remember More: Balancing Exploration and Exploitation for Continual Test-time Adaptation](https://arxiv.org/abs/2508.12643)
*Pinci Yang,Peisong Wen,Ke Ma,Qianqian Xu*

Main category: cs.CV

TL;DR: 本文提出BEE方法，通过多级一致性正则化和互补锚点回放机制，在持续测试时适应中平衡探索新域和利用历史知识


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法存在两个主要问题：1）深层预测调整浅层特征效率低下，导致探索缓慢；2）单一模型在探索新域时会遗忘历史知识，无法有效利用相似域

Method: 采用均值教师框架，提出多级一致性正则化(MCR)损失对齐师生模型中间特征，加速当前域适应；使用互补锚点回放(CAR)机制重用历史检查点来恢复多样化域知识

Result: 在多个基准测试中显著优于最先进方法

Conclusion: BEE方法有效解决了CTTA中探索与利用的平衡问题，通过特征级对齐和知识回放机制实现了快速适应和知识保持

Abstract: Continual Test-Time Adaptation (CTTA) aims to adapt a source pre-trained
model to continually changing target domains during inference. As a fundamental
principle, an ideal CTTA method should rapidly adapt to new domains
(exploration) while retaining and exploiting knowledge from previously
encountered domains to handle similar domains in the future. Despite
significant advances, balancing exploration and exploitation in CTTA is still
challenging: 1) Existing methods focus on adjusting predictions based on
deep-layer outputs of neural networks. However, domain shifts typically affect
shallow features, which are inefficient to be adjusted from deep predictions,
leading to dilatory exploration; 2) A single model inevitably forgets knowledge
of previous domains during the exploration, making it incapable of exploiting
historical knowledge to handle similar future domains. To address these
challenges, this paper proposes a mean teacher framework that strikes an
appropriate Balance between Exploration and Exploitation (BEE) during the CTTA
process. For the former challenge, we introduce a Multi-level Consistency
Regularization (MCR) loss that aligns the intermediate features of the student
and teacher models, accelerating adaptation to the current domain. For the
latter challenge, we employ a Complementary Anchor Replay (CAR) mechanism to
reuse historical checkpoints (anchors), recovering complementary knowledge for
diverse domains. Experiments show that our method significantly outperforms
state-of-the-art methods on several benchmarks, demonstrating its effectiveness
for CTTA tasks.

</details>


### [98] [DyCrowd: Towards Dynamic Crowd Reconstruction from a Large-scene Video](https://arxiv.org/abs/2508.12644)
*Hao Wen,Hongbo Kang,Jian Ma,Jing Huang,Yuanwang Yang,Haozhe Lin,Yu-Kun Lai,Kun Li*

Main category: cs.CV

TL;DR: DyCrowd是首个从大场景视频中进行时空一致3D人群重建的框架，通过粗到细的群体引导运动优化策略和VAE运动先验，解决了遮挡和时序不一致问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法从静态图像重建3D人群缺乏时序一致性，无法有效处理遮挡问题，需要开发能够从视频中重建大规模动态人群的新方法。

Method: 提出粗到细的群体引导运动优化策略，结合VAE人体运动先验和分段级群体引导优化，利用异步运动一致性损失和群体行为来解决长期动态遮挡问题。

Result: 实验结果表明该方法在大场景动态人群重建任务中达到了最先进的性能，并贡献了VirtualCrowd虚拟基准数据集。

Conclusion: DyCrowd框架能够从大场景视频中高质量地重建数百人的姿态、位置和形状，解决了遮挡和时序一致性问题，为动态人群重建提供了有效解决方案。

Abstract: 3D reconstruction of dynamic crowds in large scenes has become increasingly
important for applications such as city surveillance and crowd analysis.
However, current works attempt to reconstruct 3D crowds from a static image,
causing a lack of temporal consistency and inability to alleviate the typical
impact caused by occlusions. In this paper, we propose DyCrowd, the first
framework for spatio-temporally consistent 3D reconstruction of hundreds of
individuals' poses, positions and shapes from a large-scene video. We design a
coarse-to-fine group-guided motion optimization strategy for occlusion-robust
crowd reconstruction in large scenes. To address temporal instability and
severe occlusions, we further incorporate a VAE (Variational Autoencoder)-based
human motion prior along with a segment-level group-guided optimization. The
core of our strategy leverages collective crowd behavior to address long-term
dynamic occlusions. By jointly optimizing the motion sequences of individuals
with similar motion segments and combining this with the proposed Asynchronous
Motion Consistency (AMC) loss, we enable high-quality unoccluded motion
segments to guide the motion recovery of occluded ones, ensuring robust and
plausible motion recovery even in the presence of temporal desynchronization
and rhythmic inconsistencies. Additionally, in order to fill the gap of no
existing well-annotated large-scene video dataset, we contribute a virtual
benchmark dataset, VirtualCrowd, for evaluating dynamic crowd reconstruction
from large-scene videos. Experimental results demonstrate that the proposed
method achieves state-of-the-art performance in the large-scene dynamic crowd
reconstruction task. The code and dataset will be available for research
purposes.

</details>


### [99] [Stable Diffusion-Based Approach for Human De-Occlusion](https://arxiv.org/abs/2508.12663)
*Seung Young Noh,Ju Yong Chang*

Main category: cs.CV

TL;DR: 一种两阶段消隘人体遮挡的方法，先通过滴水模型完整体形提示完成遮挡掩码，再使用Stable Diffusion在掩码指导下生成RGB外观，并且能提升下游任务性能


<details>
  <summary>Details</summary>
Motivation: 人类能通过先验知识推断遮挡部分，但现有深度学习模型在准确预测遮挡区域方面仍面临挑战，特别是在人体消隘任务中

Method: 两阶段方法：第一阶段使用基于滴水模型的人体先验知识来完成掩码，结合遮挡关节热力图提供空间线索；第二阶段使用重建的掩码作为条件输入，通过Stable Diffusion进行RGB生成，并使用VQA模型提取人体特征提升生成质量

Result: 该方法能够有效重建体形外观，甚至在严重遮挡情况下也能获得良好效果，在掩码和RGB完成任务上都较现有方法更优，并能提升2D姿势估计和3D人体重建等下游任务的性能

Conclusion: 该研究提出了一种高效的人体消隘方法，通过结合滴水模型和人体特征提取，能够准确预测遮挡区域，且生成的消隘图像能够提升下游任务的性能，代码将开源公布

Abstract: Humans can infer the missing parts of an occluded object by leveraging prior
knowledge and visible cues. However, enabling deep learning models to
accurately predict such occluded regions remains a challenging task.
De-occlusion addresses this problem by reconstructing both the mask and RGB
appearance. In this work, we focus on human de-occlusion, specifically
targeting the recovery of occluded body structures and appearances. Our
approach decomposes the task into two stages: mask completion and RGB
completion. The first stage leverages a diffusion-based human body prior to
provide a comprehensive representation of body structure, combined with
occluded joint heatmaps that offer explicit spatial cues about missing regions.
The reconstructed amodal mask then serves as a conditioning input for the
second stage, guiding the model on which areas require RGB reconstruction. To
further enhance RGB generation, we incorporate human-specific textual features
derived using a visual question answering (VQA) model and encoded via a CLIP
encoder. RGB completion is performed using Stable Diffusion, with decoder
fine-tuning applied to mitigate pixel-level degradation in visible regions -- a
known limitation of prior diffusion-based de-occlusion methods caused by latent
space transformations. Our method effectively reconstructs human appearances
even under severe occlusions and consistently outperforms existing methods in
both mask and RGB completion. Moreover, the de-occluded images generated by our
approach can improve the performance of downstream human-centric tasks, such as
2D pose estimation and 3D human reconstruction. The code will be made publicly
available.

</details>


### [100] [WP-CLIP: Leveraging CLIP to Predict Wölfflin's Principles in Visual Art](https://arxiv.org/abs/2508.12668)
*Abhijay Ghildyal,Li-Yun Wang,Feng Liu*

Main category: cs.CV

TL;DR: 这篇论文研究了如何使用CLIP视觉-语言模型预测Wölfflin五大艺术原则，通过细调模型实现了WP-CLIP系统，能够在生成式绘画和真实艺术数据集上进行艺术风格分析。


<details>
  <summary>Details</summary>
Motivation: 虽然Wölfflin五大原则提供了结构化的艺术风格分析方法，但目前缺少能够预测所有五个原则的计量指标。需要一种能够解释颜色、构图、主题选择等关键元素的计量方法来计算地评估绘画的视觉方面。

Method: 使用预训练的CLIP模型，在带标注的真实艺术图像数据集上进行细调，以预测每个Wölfflin原则的得分。构建了WP-CLIP模型。

Result: 在GAN生成的绘画和Pandora-18K艺术数据集上评估，模型能够在多样化的艺术风格中展现良好的泛化能力。

Conclusion: 视觉-语言模型在自动化艺术分析方面具有很大潜力，通过细调可以让大规模预训练模型理解和预测精细的艺术元素。

Abstract: W\"olfflin's five principles offer a structured approach to analyzing
stylistic variations for formal analysis. However, no existing metric
effectively predicts all five principles in visual art. Computationally
evaluating the visual aspects of a painting requires a metric that can
interpret key elements such as color, composition, and thematic choices. Recent
advancements in vision-language models (VLMs) have demonstrated their ability
to evaluate abstract image attributes, making them promising candidates for
this task. In this work, we investigate whether CLIP, pre-trained on
large-scale data, can understand and predict W\"olfflin's principles. Our
findings indicate that it does not inherently capture such nuanced stylistic
elements. To address this, we fine-tune CLIP on annotated datasets of real art
images to predict a score for each principle. We evaluate our model, WP-CLIP,
on GAN-generated paintings and the Pandora-18K art dataset, demonstrating its
ability to generalize across diverse artistic styles. Our results highlight the
potential of VLMs for automated art analysis.

</details>


### [101] [Refine-and-Contrast: Adaptive Instance-Aware BEV Representations for Multi-UAV Collaborative Object Detection](https://arxiv.org/abs/2508.12684)
*Zhongyao Li,Peirui Cheng,Liangjin Zhao,Chen Chen,Yundu Li,Zhechao Wang,Xue Yang,Xian Sun,Zhirui Wang*

Main category: cs.CV

TL;DR: AdaBEV是一个创新的多无人机协同3D检测框架，通过自适应实例感知的BEV表示学习，在保持低分辨率输入的同时实现了优异的精度-计算权衡。


<details>
  <summary>Details</summary>
Motivation: 多无人机协同3D检测虽然能通过融合多视角观测提供准确鲁棒的感知，但在资源受限的无人机平台上计算负担重。现有方法对所有BEV网格同等对待，效率不高。

Method: 提出refine-and-contrast范式：1) Box-Guided Refinement Module (BG-RM) - 仅精炼与前景实例相关的BEV网格，使用2D监督和空间细分；2) Instance-Background Contrastive Learning (IBCL) - 在BEV空间通过对比学习增强前景和背景特征的可区分性

Result: 在Air-Co-Pred数据集上的大量实验表明，AdaBEV在不同模型规模下都实现了优越的精度-计算权衡，在低分辨率下优于其他最先进方法，接近上限性能，同时保持低分辨率BEV输入和可忽略的开销

Conclusion: AdaBEV通过学习自适应实例感知的BEV表示，有效解决了多无人机协同3D检测中的计算效率问题，为资源受限平台上的高性能感知提供了可行解决方案

Abstract: Multi-UAV collaborative 3D detection enables accurate and robust perception
by fusing multi-view observations from aerial platforms, offering significant
advantages in coverage and occlusion handling, while posing new challenges for
computation on resource-constrained UAV platforms. In this paper, we present
AdaBEV, a novel framework that learns adaptive instance-aware BEV
representations through a refine-and-contrast paradigm. Unlike existing methods
that treat all BEV grids equally, AdaBEV introduces a Box-Guided Refinement
Module (BG-RM) and an Instance-Background Contrastive Learning (IBCL) to
enhance semantic awareness and feature discriminability. BG-RM refines only BEV
grids associated with foreground instances using 2D supervision and spatial
subdivision, while IBCL promotes stronger separation between foreground and
background features via contrastive learning in BEV space. Extensive
experiments on the Air-Co-Pred dataset demonstrate that AdaBEV achieves
superior accuracy-computation trade-offs across model scales, outperforming
other state-of-the-art methods at low resolutions and approaching upper bound
performance while maintaining low-resolution BEV inputs and negligible
overhead.

</details>


### [102] [TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions](https://arxiv.org/abs/2508.12690)
*Dongjae Jeon,Taeheon Kim,Seongwon Cho,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: TTA-DAME方法通过源域数据增强、域判别器和专门域检测器来处理驾驶场景中的天气域偏移，特别是在白天到夜间的剧烈变化，并通过多检测器集成提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决真实驾驶场景中频繁出现的天气域偏移问题，特别是在动态变化的环境中实现模型的自适应优化。

Method: 利用源域数据增强到目标域，引入域判别器和专门域检测器处理剧烈域偏移，训练多个检测器并通过非极大值抑制整合预测结果。

Result: 在SHIFT基准测试上显示出显著的性能提升，验证了方法的有效性。

Conclusion: TTA-DAME方法能有效处理驾驶场景中的动态域偏移问题，特别是在天气变化和昼夜转换等挑战性条件下表现出色。

Abstract: Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically
adapt and perform optimally on shifting target domains. This task is
particularly emphasized in real-world driving scenes, where weather domain
shifts occur frequently. To address such dynamic changes, our proposed method,
TTA-DAME, leverages source domain data augmentation into target domains.
Additionally, we introduce a domain discriminator and a specialized domain
detector to mitigate drastic domain shifts, especially from daytime to
nighttime conditions. To further improve adaptability, we train multiple
detectors and consolidate their predictions through Non-Maximum Suppression
(NMS). Our empirical validation demonstrates the effectiveness of our method,
showing significant performance enhancements on the SHIFT Benchmark.

</details>


### [103] [Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning](https://arxiv.org/abs/2508.12692)
*Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeong,Jonghyun Choi*

Main category: cs.CV

TL;DR: 本文提出了多级知识蒸馏和动态自监督损失两个组件，用于解决重复类增量学习问题，在CVPR CLVISION挑战赛中取得第二名。


<details>
  <summary>Details</summary>
Motivation: 传统的类增量学习假设每个任务都包含新类别，而重复类增量学习(CIR)中先前训练过的类别会在未来任务中重复出现，这种场景更加现实。CIR可以轻松从互联网等外部来源获取大量未标注数据。

Method: 1. 多级知识蒸馏(MLKD)：从多个先前模型跨多个视角（包括特征和logits）蒸馏知识，使模型能够保持各种先前的知识。2. 动态自监督损失(SSL)：利用未标注数据加速新类学习，同时通过动态加权保持对主要任务的训练重点。

Result: 提出的两个组件显著提高了CIR设置下的性能，在CVPR第5届CLVISION挑战赛中获得了第二名。

Conclusion: 通过多级知识蒸馏和动态自监督损失的结合，能够有效利用未标注数据，在重复类增量学习场景中实现高稳定性和高可塑性。

Abstract: Class-incremental with repetition (CIR), where previously trained classes
repeatedly introduced in future tasks, is a more realistic scenario than the
traditional class incremental setup, which assumes that each task contains
unseen classes. CIR assumes that we can easily access abundant unlabeled data
from external sources, such as the Internet. Therefore, we propose two
components that efficiently use the unlabeled data to ensure the high stability
and the plasticity of models trained in CIR setup. First, we introduce
multi-level knowledge distillation (MLKD) that distills knowledge from multiple
previous models across multiple perspectives, including features and logits, so
the model can maintain much various previous knowledge. Moreover, we implement
dynamic self-supervised loss (SSL) to utilize the unlabeled data that
accelerates the learning of new classes, while dynamic weighting of SSL keeps
the focus of training to the primary task. Both of our proposed components
significantly improve the performance in CIR setup, achieving 2nd place in the
CVPR 5th CLVISION Challenge.

</details>


### [104] [Neural Rendering for Sensor Adaptation in 3D Object Detection](https://arxiv.org/abs/2508.12695)
*Felix Embacher,David Holtz,Jonas Uhrig,Marius Cordts,Markus Enzweiler*

Main category: cs.CV

TL;DR: 这篇论文研究了自主驾驶车载不同相机传感器配置导致的跨传感器域差间问题，提出了CamShift数据集和基于神经渲染的数据驱动传感器适配方案，有效减轻了3D物体检测器的性能泄漏。


<details>
  <summary>Details</summary>
Motivation: 自主驾驶车的相机传感器配置因车辆类型不同而异，导致在一种传感器配置上训练的感知模型在其他配置上性能泄漏，这就是跨传感器域差间问题。

Method: 创建了CamShift数据集（受nuScenes启发在CARLA中制作）来模拟子紧凑型车辆和SUV之间的传感器差异。提出了一种基于神经渲染的数据驱动传感器适配管道，可以将整个数据集转换以匹配不同相机传感器配置。

Result: 证明了跨传感器性能显著泄漏，识别了模型结构对稳健性的依赖关系（BEVFormer等基于密集BEV表示的模型最稳健）。神经渲染适配方案大幅提升了所有研究的3D检测器性能。

Conclusion: 跨传感器域差间是自主驾驶车感知系统的重要挑战，通过选择适当的模型算法和数据适配技术可以有效缓解这一问题，减少重新收集数据的需求。

Abstract: Autonomous vehicles often have varying camera sensor setups, which is
inevitable due to restricted placement options for different vehicle types.
Training a perception model on one particular setup and evaluating it on a new,
different sensor setup reveals the so-called cross-sensor domain gap, typically
leading to a degradation in accuracy. In this paper, we investigate the impact
of the cross-sensor domain gap on state-of-the-art 3D object detectors. To this
end, we introduce CamShift, a dataset inspired by nuScenes and created in CARLA
to specifically simulate the domain gap between subcompact vehicles and sport
utility vehicles (SUVs). Using CamShift, we demonstrate significant
cross-sensor performance degradation, identify robustness dependencies on model
architecture, and propose a data-driven solution to mitigate the effect. On the
one hand, we show that model architectures based on a dense Bird's Eye View
(BEV) representation with backward projection, such as BEVFormer, are the most
robust against varying sensor configurations. On the other hand, we propose a
novel data-driven sensor adaptation pipeline based on neural rendering, which
can transform entire datasets to match different camera sensor setups. Applying
this approach improves performance across all investigated 3D object detectors,
mitigating the cross-sensor domain gap by a large margin and reducing the need
for new data collection by enabling efficient data reusability across vehicles
with different sensor setups. The CamShift dataset and the sensor adaptation
benchmark are available at https://dmholtz.github.io/camshift/.

</details>


### [105] [Has GPT-5 Achieved Spatial Intelligence? An Empirical Study](https://arxiv.org/abs/2508.13142)
*Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: GPT-5在空间智能方面展现出前所未有的强大能力，但仍未达到人类水平，特别是在最具挑战性的空间问题上，专有模型并不具备决定性优势。


<details>
  <summary>Details</summary>
Motivation: 多模态模型在空间理解和推理方面仍存在显著局限性，这是实现通用人工智能的关键能力。随着GPT-5的发布，需要评估当前最先进模型在空间智能方面的表现。

Method: 提出了统一现有基准的空间任务分类法，评估了最先进的专有和开源模型在8个关键基准上的表现，消耗了超过10亿个token，并进行了定性评估。

Result: GPT-5在空间智能方面表现出前所未有的强大能力，但在广泛任务中仍不及人类表现；识别出多模态模型面临的最具挑战性的空间智能问题；专有模型在最困难问题上没有决定性优势。

Conclusion: 尽管GPT-5在空间智能方面取得了显著进步，但多模态模型在空间理解和推理方面仍存在明显差距，特别是在对人类直观但对AI模型困难的情境中表现不佳。

Abstract: Multi-modal models have achieved remarkable progress in recent years.
Nevertheless, they continue to exhibit notable limitations in spatial
understanding and reasoning, which are fundamental capabilities to achieving
artificial general intelligence. With the recent release of GPT-5, allegedly
the most powerful AI model to date, it is timely to examine where the leading
models stand on the path toward spatial intelligence. First, we propose a
comprehensive taxonomy of spatial tasks that unifies existing benchmarks and
discuss the challenges in ensuring fair evaluation. We then evaluate
state-of-the-art proprietary and open-source models on eight key benchmarks, at
a cost exceeding one billion total tokens. Our empirical study reveals that (1)
GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)
still falls short of human performance across a broad spectrum of tasks.
Moreover, we (3) identify the more challenging spatial intelligence problems
for multi-modal models, and (4) proprietary models do not exhibit a decisive
advantage when facing the most difficult problems. In addition, we conduct a
qualitative evaluation across a diverse set of scenarios that are intuitive for
humans yet fail even the most advanced multi-modal models.

</details>


### [106] [Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection](https://arxiv.org/abs/2508.12711)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Yunyun Dong,Bingbing Song,Wei Zhou*

Main category: cs.CV

TL;DR: GenAI驱动的新闻多样性导致多级漂移，显著降低现有LVLM多模态虚假信息检测系统的性能，平均F1下降14.8%，推理稳定性恶化。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具带来的新闻内容多样性对多模态虚假信息检测构成新挑战，需要研究其对检测系统鲁棒性的影响。

Method: 引入DriftBench基准数据集（16,000个新闻实例，6种多样化类别），设计三个评估任务：真实性验证鲁棒性、对抗性证据污染敏感性、推理一致性分析。

Result: 6个最先进的LVLM检测器性能显著下降（平均F1下降14.8%），推理轨迹不稳定，对抗性证据注入下表现更差。

Conclusion: 现有MMD系统存在根本性脆弱性，在GenAI时代迫切需要更具弹性的方法。

Abstract: The proliferation of multimodal misinformation poses growing threats to
public discourse and societal trust. While Large Vision-Language Models (LVLMs)
have enabled recent progress in multimodal misinformation detection (MMD), the
rise of generative AI (GenAI) tools introduces a new challenge: GenAI-driven
news diversity, characterized by highly varied and complex content. We show
that this diversity induces multi-level drift, comprising (1) model-level
misperception drift, where stylistic variations disrupt a model's internal
reasoning, and (2) evidence-level drift, where expression diversity degrades
the quality or relevance of retrieved external evidence. These drifts
significantly degrade the robustness of current LVLM-based MMD systems. To
systematically study this problem, we introduce DriftBench, a large-scale
benchmark comprising 16,000 news instances across six categories of
diversification. We design three evaluation tasks: (1) robustness of truth
verification under multi-level drift; (2) susceptibility to adversarial
evidence contamination generated by GenAI; and (3) analysis of reasoning
consistency across diverse inputs. Experiments with six state-of-the-art
LVLM-based detectors show substantial performance drops (average F1 -14.8%) and
increasingly unstable reasoning traces, with even more severe failures under
adversarial evidence injection. Our findings uncover fundamental
vulnerabilities in existing MMD systems and suggest an urgent need for more
resilient approaches in the GenAI era.

</details>


### [107] [Real-Time Sign Language Gestures to Speech Transcription using Deep Learning](https://arxiv.org/abs/2508.12713)
*Brandone Fonya*

Main category: cs.CV

TL;DR: 基于CNN深度学习的手语实时翻译系统，通过摄像头捕捉手势并转换为文本和语音，提高听障人士的沟通能力


<details>
  <summary>Details</summary>
Motivation: 解决听障人士在日常环境中的沟通障碍，帮助他们更好地融入社会互动

Method: 使用卷积神经网络(CNN)在Sign Language MNIST数据集上训练，通过摄像头实时捕捉手势并进行分类识别，结合文本转语音技术

Result: 系统展现出高准确率和实时性能（存在一些延迟），证明了其作为辅助工具的实用性

Conclusion: 该系统为手语使用者提供了一个可访问、可靠且用户友好的工具，有效增强了他们在不同社交环境中的自主性和融入度

Abstract: Communication barriers pose significant challenges for individuals with
hearing and speech impairments, often limiting their ability to effectively
interact in everyday environments. This project introduces a real-time
assistive technology solution that leverages advanced deep learning techniques
to translate sign language gestures into textual and audible speech. By
employing convolution neural networks (CNN) trained on the Sign Language MNIST
dataset, the system accurately classifies hand gestures captured live via
webcam. Detected gestures are instantaneously translated into their
corresponding meanings and transcribed into spoken language using
text-to-speech synthesis, thus facilitating seamless communication.
Comprehensive experiments demonstrate high model accuracy and robust real-time
performance with some latency, highlighting the system's practical
applicability as an accessible, reliable, and user-friendly tool for enhancing
the autonomy and integration of sign language users in diverse social settings.

</details>


### [108] [Single-Reference Text-to-Image Manipulation with Dual Contrastive Denoising Score](https://arxiv.org/abs/2508.12718)
*Syed Muhmmad Israr,Feng Zhao*

Main category: cs.CV

TL;DR: 基于对比学习的双对比去噪分数框架，解决文本到图像生成模型在真实图像编辑中的提示语语义不准确和不期望匹配问题


<details>
  <summary>Details</summary>
Motivation: 现有的大规模文本到图像生成模型在真实图像编辑中遇到两个主要挑战：用户难以准确描述输入图像所有视觉细节的文本提示，以及模型在引入期望变化时常常会大幅改变输入内容并在不期望区域产生意外变化

Method: 提出Dual Contrastive Denoising Score框架，利用潜在去噪模型中自注意力层的中间表征的丰富空间信息，不依赖辅助网络。受无配对图像到图像转换中对比学习的启发，在框架内部引入简单的双对比损失

Result: 方法能够同时实现灵活的内容修改和输入输出图像之间的结构保持，以及零样本图像到图像转换。经过大量实验验证，方法在真实图像编辑上超过现有方法，同时保持了直接利用预训练文本到图像去噪模型而无需进一步训练的能力

Conclusion: 双对比去噪分数框架是一种简单但强大的解决方案，能够利用文本到图像去噪模型的丰富生成先验知识，有效解决了真实图像编辑中的关键挑战

Abstract: Large-scale text-to-image generative models have shown remarkable ability to
synthesize diverse and high-quality images. However, it is still challenging to
directly apply these models for editing real images for two reasons. First, it
is difficult for users to come up with a perfect text prompt that accurately
describes every visual detail in the input image. Second, while existing models
can introduce desirable changes in certain regions, they often dramatically
alter the input content and introduce unexpected changes in unwanted regions.
To address these challenges, we present Dual Contrastive Denoising Score, a
simple yet powerful framework that leverages the rich generative prior of
text-to-image diffusion models. Inspired by contrastive learning approaches for
unpaired image-to-image translation, we introduce a straightforward dual
contrastive loss within the proposed framework. Our approach utilizes the
extensive spatial information from the intermediate representations of the
self-attention layers in latent diffusion models without depending on auxiliary
networks. Our method achieves both flexible content modification and structure
preservation between input and output images, as well as zero-shot
image-to-image translation. Through extensive experiments, we show that our
approach outperforms existing methods in real image editing while maintaining
the capability to directly utilize pretrained text-to-image diffusion models
without further training.

</details>


### [109] [Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting](https://arxiv.org/abs/2508.12720)
*Kangjie Chen,Yingji Zhong,Zhihao Li,Jiaqi Lin,Youyu Chen,Minghan Qin,Haoqian Wang*

Main category: cs.CV

TL;DR: 3DGS在稀疏视图下会出现外观伪影，研究发现这是高斯之间的过度纠缠（co-adaptation）导致的。提出了CA指标量化纠缠程度，并提出了两种轻量级策略来缓解这个问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射在密集视图下表现优异，但在稀疏视图场景中，虽然训练视图渲染效果真实，但在新视图中会出现外观伪影。需要探究这些伪影的根本原因并提出解决方案。

Method: 提出了Co-Adaptation Score (CA)指标来量化高斯之间的纠缠程度。基于分析提出了两种轻量级策略：1）随机高斯丢弃；2）对不透明度注入乘法噪声。这些策略都是即插即用的。

Result: 分析发现高斯纠缠程度随着训练视图数量的增加而自然缓解。提出的两种策略在各种方法和基准测试中都验证了有效性。

Conclusion: 对co-adaptation效应的深入理解将有助于社区更全面地理解稀疏视图3DGS，提出的轻量级策略能有效缓解外观伪影问题。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated impressive performance in novel
view synthesis under dense-view settings. However, in sparse-view scenarios,
despite the realistic renderings in training views, 3DGS occasionally manifests
appearance artifacts in novel views. This paper investigates the appearance
artifacts in sparse-view 3DGS and uncovers a core limitation of current
approaches: the optimized Gaussians are overly-entangled with one another to
aggressively fit the training views, which leads to a neglect of the real
appearance distribution of the underlying scene and results in appearance
artifacts in novel views. The analysis is based on a proposed metric, termed
Co-Adaptation Score (CA), which quantifies the entanglement among Gaussians,
i.e., co-adaptation, by computing the pixel-wise variance across multiple
renderings of the same viewpoint, with different random subsets of Gaussians.
The analysis reveals that the degree of co-adaptation is naturally alleviated
as the number of training views increases. Based on the analysis, we propose
two lightweight strategies to explicitly mitigate the co-adaptation in
sparse-view 3DGS: (1) random gaussian dropout; (2) multiplicative noise
injection to the opacity. Both strategies are designed to be plug-and-play, and
their effectiveness is validated across various methods and benchmarks. We hope
that our insights into the co-adaptation effect will inspire the community to
achieve a more comprehensive understanding of sparse-view 3DGS.

</details>


### [110] [Frequency-Driven Inverse Kernel Prediction for Single Image Defocus Deblurring](https://arxiv.org/abs/2508.12736)
*Ying Zhang,Xiongxin Tang,Chongyi Li,Qiao Chen,Yuquan Wu*

Main category: cs.CV

TL;DR: 频域驱动的逆内核预测网络(FDIKP)，通过双分支逆内核预测策略和位置适配卷积，在单图散焦去模糊任务中取得更优的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依靠空间特征进行内核估计，但在严重模糊区域性能会降低，因为局部高频细节缺失。需要利用频域表示来增强内核建模的结构可识别性。

Method: 1. 设计双分支逆内核预测策略(DIKP)，利用频域的优势来提高内核估计准确性和稳定性
2. 提出位置适配卷积(PAC)，增强反卷积过程的适应能力
3. 提出双域尺度递归模块(DSRM)，融合反卷积结果并从粗到细逐步改善去模糊质量

Result: 经过大量实验验证，该方法在单图散焦去模糊任务上超越了现有方法。

Conclusion: 通过结合频域表示和空间特征，提出的FDIKP网络能够更有效地处理严重模糊区域，提高了内核估计的准确性和去模糊的质量。

Abstract: Single image defocus deblurring aims to recover an all-in-focus image from a
defocus counterpart, where accurately modeling spatially varying blur kernels
remains a key challenge. Most existing methods rely on spatial features for
kernel estimation, but their performance degrades in severely blurry regions
where local high-frequency details are missing. To address this, we propose a
Frequency-Driven Inverse Kernel Prediction network (FDIKP) that incorporates
frequency-domain representations to enhance structural identifiability in
kernel modeling. Given the superior discriminative capability of the frequency
domain for blur modeling, we design a Dual-Branch Inverse Kernel Prediction
(DIKP) strategy that improves the accuracy of kernel estimation while
maintaining stability. Moreover, considering the limited number of predicted
inverse kernels, we introduce a Position Adaptive Convolution (PAC) to enhance
the adaptability of the deconvolution process. Finally, we propose a
Dual-Domain Scale Recurrent Module (DSRM) to fuse deconvolution results and
progressively improve deblurring quality from coarse to fine. Extensive
experiments demonstrate that our method outperforms existing approaches. Code
will be made publicly available.

</details>


### [111] [DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification](https://arxiv.org/abs/2508.12745)
*Xizhan Gao,Wei Hu*

Main category: cs.CV

TL;DR: 提出DCSCR网络，结合传统图像集分类方法与深度模型，同时学习帧级和概念级特征表示，通过类特定协作表示度量学习解决少样本图像集分类问题。


<details>
  <summary>Details</summary>
Motivation: 现有传统方法忽略特征学习，深度方法在度量集合距离时无法自适应调整特征，导致少样本图像集分类性能有限。

Method: DCSCR包含全卷积深度特征提取器、全局特征学习模块和类特定协作表示度量学习模块，通过新的CSCR对比损失函数学习概念级特征表示和集合间距离相似性。

Result: 在多个知名少样本图像集分类数据集上的大量实验表明，该方法相比最先进的图像集分类算法具有更好的效果。

Conclusion: DCSCR成功结合了传统方法和深度模型的优势，能够同时学习多层次特征表示并自适应调整特征度量，有效提升了少样本图像集分类性能。

Abstract: Image set classification (ISC), which can be viewed as a task of comparing
similarities between sets consisting of unordered heterogeneous images with
variable quantities and qualities, has attracted growing research attention in
recent years. How to learn effective feature representations and how to explore
the similarities between different image sets are two key yet challenging
issues in this field. However, existing traditional ISC methods classify image
sets based on raw pixel features, ignoring the importance of feature learning.
Existing deep ISC methods can learn deep features, but they fail to adaptively
adjust the features when measuring set distances, resulting in limited
performance in few-shot ISC. To address the above issues, this paper combines
traditional ISC methods with deep models and proposes a novel few-shot ISC
approach called Deep Class-specific Collaborative Representation (DCSCR)
network to simultaneously learn the frame- and concept-level feature
representations of each image set and the distance similarities between
different sets. Specifically, DCSCR consists of a fully convolutional deep
feature extractor module, a global feature learning module, and a
class-specific collaborative representation-based metric learning module. The
deep feature extractor and global feature learning modules are used to learn
(local and global) frame-level feature representations, while the
class-specific collaborative representation-based metric learning module is
exploit to adaptively learn the concept-level feature representation of each
image set and thus obtain the distance similarities between different sets by
developing a new CSCR-based contrastive loss function. Extensive experiments on
several well-known few-shot ISC datasets demonstrate the effectiveness of the
proposed method compared with some state-of-the-art image set classification
algorithms.

</details>


### [112] [D2-Mamba: Dual-Scale Fusion and Dual-Path Scanning with SSMs for Shadow Removal](https://arxiv.org/abs/2508.12750)
*Linhao Li,Boya Jin,Zizhe Li,Lanqing Guo,Hao Cheng,Bo Li,Yongfeng Dong*

Main category: cs.CV

TL;DR: 提出一种基于Mamba的双角度融合网络，通过双路循环扫描和适应性扫描策略来提升阴影移除的效果。


<details>
  <summary>Details</summary>
Motivation: 阴影移除任务中，被阴影覆盖区域的修复变换与良好照明区域存在显著差异，常规的均匀修复策略效果不佳，需要更有效地利用非阴影区域的上下文信息进行指导。

Method: 设计了双组合融合Mamba块(DFMB)来增强多尺度特征表征，通过融合原始特征和低分辨率特征减少边界偏差。使用双路循环Mamba组(DPMG)通过水平扫描捕获全局特征，并采用面具感知的适应性扫描策略来改善结构连续性和细粒度区域建模。

Result: 在阴影移除标准测试集上，该方法显著超越了现有的最先进方法。

Conclusion: 通过Mamba结构的双角度融合和适应性扫描策略，能够有效地解决阴影移除中的区域特异性问题，实现了更优秀的图像恢复效果。

Abstract: Shadow removal aims to restore images that are partially degraded by shadows,
where the degradation is spatially localized and non-uniform. Unlike general
restoration tasks that assume global degradation, shadow removal can leverage
abundant information from non-shadow regions for guidance. However, the
transformation required to correct shadowed areas often differs significantly
from that of well-lit regions, making it challenging to apply uniform
correction strategies. This necessitates the effective integration of non-local
contextual cues and adaptive modeling of region-specific transformations. To
this end, we propose a novel Mamba-based network featuring dual-scale fusion
and dual-path scanning to selectively propagate contextual information based on
transformation similarity across regions. Specifically, the proposed Dual-Scale
Fusion Mamba Block (DFMB) enhances multi-scale feature representation by fusing
original features with low-resolution features, effectively reducing boundary
artifacts. The Dual-Path Mamba Group (DPMG) captures global features via
horizontal scanning and incorporates a mask-aware adaptive scanning strategy,
which improves structural continuity and fine-grained region modeling.
Experimental results demonstrate that our method significantly outperforms
existing state-of-the-art approaches on shadow removal benchmarks.

</details>


### [113] [CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke](https://arxiv.org/abs/2508.12755)
*Cristo J. van den Berg,Frank G. te Nijenhuis,Mirre J. Blaauboer,Daan T. W. van Erp,Carlijn M. Keppels,Matthijs van der Sluijs,Bob Roozenbeek,Wim van Zwam,Sandra Cornelissen,Danny Ruijters,Ruisheng Su,Theo van Walsum*

Main category: cs.CV

TL;DR: CLAIRE-DSA是一个基于深度学习的框架，用于在急性缺血性卒中机械取栓过程中对最小强度投影图像进行质量分类，显著提升下游分割任务的性能


<details>
  <summary>Details</summary>
Motivation: 计算机视觉模型在机械取栓手术中辅助应用时，图像质量差会严重影响性能表现，需要开发自动化工具进行图像质量控制和分类

Method: 使用预训练的ResNet骨干网络进行微调，训练独立的分类器来预测9个图像属性（如对比剂存在、投影角度、运动伪影严重程度等），基于1758张标注的荧光镜MinIP图像数据集

Result: 模型在所有标签上都表现出色，ROC-AUC达到0.91-0.98，精确度0.70-1.00。在分割任务中，通过过滤低质量图像，分割成功率从42%提升至69%（p<0.001）

Conclusion: CLAIRE-DSA作为自动化工具在急性缺血性卒中患者的DSA系列图像属性分类方面表现出强大潜力，支持临床和研究应用中的图像标注和质量控制

Abstract: Computer vision models can be used to assist during mechanical thrombectomy
(MT) for acute ischemic stroke (AIS), but poor image quality often degrades
performance. This work presents CLAIRE-DSA, a deep learning--based framework
designed to categorize key image properties in minimum intensity projections
(MinIPs) acquired during MT for AIS, supporting downstream quality control and
workflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models,
fine-tuned to predict nine image properties (e.g., presence of contrast,
projection angle, motion artefact severity). Separate classifiers were trained
on an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model
achieved excellent performance on all labels, with ROC-AUC ranging from $0.91$
to $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of
CLAIRE-DSA to identify suitable images was evaluated on a segmentation task by
filtering poor quality images and comparing segmentation performance on
filtered and unfiltered datasets. Segmentation success rate increased from
$42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an
automated tool for accurately classifying image properties in DSA series of
acute ischemic stroke patients, supporting image annotation and quality control
in clinical and research applications. Source code is available at
https://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa.

</details>


### [114] [Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors](https://arxiv.org/abs/2508.12766)
*Peihao Li,Yan Fang,Man Liu,Huihui Bai,Anhong Wang,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: 提出了ICAF框架解决CdZnTe半导体图像标注难题，通过组内一致性增强和伪标签校正网络，在仅使用2%标注数据的情况下达到70.6% mIoU


<details>
  <summary>Details</summary>
Motivation: CdZnTe半导体图像标注困难，缺陷边界对比度低，需要多视图交叉参考。现有半监督语义分割方法基于"一对一"关系，在多视图"多对一"场景下表现不佳，导致误差累积和确认偏差

Method: 提出组内一致性增强框架(ICAF)，包含伪标签校正网络(PCN)。PCN有两个模块：视图增强模块(VAM)通过多视图聚合动态合成边界感知视图；视图校正模块(VCM)进行信息交互，突出显著区域并减少噪声

Result: 在CdZnTe数据集上，使用DeepLabV3+和ResNet-101骨干网络，仅用2%的组标注数据就达到了70.6%的mIoU

Conclusion: ICAF框架有效解决了CdZnTe材料的多视图标注挑战，通过组内一致性约束和伪标签校正显著提升了半监督分割性能

Abstract: Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging
due to the low-contrast defect boundaries, necessitating annotators to
cross-reference multiple views. These views share a single ground truth (GT),
forming a unique ``many-to-one'' relationship. This characteristic renders
advanced semi-supervised semantic segmentation (SSS) methods suboptimal, as
they are generally limited by a ``one-to-one'' relationship, where each image
is independently associated with its GT. Such limitation may lead to error
accumulation in low-contrast regions, further exacerbating confirmation bias.
To address this issue, we revisit the SSS pipeline from a group-oriented
perspective and propose a human-inspired solution: the Intra-group Consistency
Augmentation Framework (ICAF). First, we experimentally validate the inherent
consistency constraints within CdZnTe groups, establishing a group-oriented
baseline using the Intra-group View Sampling (IVS). Building on this insight,
we introduce the Pseudo-label Correction Network (PCN) to enhance consistency
representation, which consists of two key modules. The View Augmentation Module
(VAM) improves boundary details by dynamically synthesizing a boundary-aware
view through the aggregation of multiple views. In the View Correction Module
(VCM), this synthesized view is paired with other views for information
interaction, effectively emphasizing salient regions while minimizing noise.
Extensive experiments demonstrate the effectiveness of our solution for CdZnTe
materials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation
model, we achieve a 70.6\% mIoU on the CdZnTe dataset using only 2
group-annotated data (5\textperthousand). The code is available at
\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}.

</details>


### [115] [SocialTrack: Multi-Object Tracking in Complex Urban Traffic Scenes Inspired by Social Behavior](https://arxiv.org/abs/2508.12777)
*Wenguang Tao,Xiaotian Wang,Tian Yan,Jie Yan,Guodong Li,Kun Bai*

Main category: cs.CV

TL;DR: SocialTrack是一个针对无人机视角下多目标跟踪的框架，通过多尺度特征增强检测器、速度自适应卡尔曼滤波、群体运动补偿策略和时空记忆预测，显著提升了复杂城市交通环境中小目标的跟踪精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决无人机视角下多目标跟踪面临的挑战，包括小目标尺度变化、遮挡、非线性交叉运动和运动模糊等问题，这些因素严重影响了跟踪的稳定性。

Method: 1. 专用小目标检测器采用多尺度特征增强机制
2. 速度自适应容积卡尔曼滤波(VACKF)引入速度动态建模机制
3. 群体运动补偿策略(GMCS)建模社会群体运动先验
4. 时空记忆预测(STMP)利用历史轨迹信息预测未来状态

Result: 在UAVDT和MOT17数据集上的大量实验表明，SocialTrack在多个关键指标上优于现有最先进方法，特别是在MOTA和IDF1等核心性能指标上有显著提升。

Conclusion: SocialTrack框架具有出色的鲁棒性和适应性，同时具有高度模块化和兼容性，可以与现有跟踪器无缝集成以进一步提升性能。

Abstract: As a key research direction in the field of multi-object tracking (MOT),
UAV-based multi-object tracking has significant application value in the
analysis and understanding of urban intelligent transportation systems.
However, in complex UAV perspectives, challenges such as small target scale
variations, occlusions, nonlinear crossing motions, and motion blur severely
hinder the stability of multi-object tracking. To address these challenges,
this paper proposes a novel multi-object tracking framework, SocialTrack, aimed
at enhancing the tracking accuracy and robustness of small targets in complex
urban traffic environments. The specialized small-target detector enhances the
detection performance by employing a multi-scale feature enhancement mechanism.
The Velocity Adaptive Cubature Kalman Filter (VACKF) improves the accuracy of
trajectory prediction by incorporating a velocity dynamic modeling mechanism.
The Group Motion Compensation Strategy (GMCS) models social group motion priors
to provide stable state update references for low-quality tracks, significantly
improving the target association accuracy in complex dynamic environments.
Furthermore, the Spatio-Temporal Memory Prediction (STMP) leverages historical
trajectory information to predict the future state of low-quality tracks,
effectively mitigating identity switching issues. Extensive experiments on the
UAVDT and MOT17 datasets demonstrate that SocialTrack outperforms existing
state-of-the-art (SOTA) methods across several key metrics. Significant
improvements in MOTA and IDF1, among other core performance indicators,
highlight its superior robustness and adaptability. Additionally, SocialTrack
is highly modular and compatible, allowing for seamless integration with
existing trackers to further enhance performance.

</details>


### [116] [Leveraging Diffusion Models for Stylization using Multiple Style Images](https://arxiv.org/abs/2508.12784)
*Dan Ruta,Abdelaziz Djelouah,Raphael Ortiz,Christopher Schroers*

Main category: cs.CV

TL;DR: 基于多样式图片的潜在液体模型风格转换方法，通过图片提示适配器和统计对齐技术，在去噪UNet的交叉注意力和自注意力层进行干预，实现了更准确的风格匹配和内容-风格解耦合效果


<details>
  <summary>Details</summary>
Motivation: 现有风格转换方法在准确匹配风格、支持多样式图片数量、避免内容-风格耦合方面仍遇到困难，需要提出更有效的解决方案

Method: 利用多个风格图片来更好地表征风格特征并防止内容泄漏，设计了结合图片提示适配器和去噪过程中特征统计对齐的方法，在交叉注意力和自注意力层进行干预，采用聚类技术从大量注意力特征中精炼小集代表性特征集

Result: 该方法在风格化任务中达到了状态前沿的结果

Conclusion: 通过多样式图片结合图片提示适配器和统计对齐技术，成功地解决了现有风格转换方法的关键问题，实现了更准确的风格控制和更好的内容-风格分离效果

Abstract: Recent advances in latent diffusion models have enabled exciting progress in
image style transfer. However, several key issues remain. For example, existing
methods still struggle to accurately match styles. They are often limited in
the number of style images that can be used. Furthermore, they tend to entangle
content and style in undesired ways. To address this, we propose leveraging
multiple style images which helps better represent style features and prevent
content leaking from the style images. We design a method that leverages both
image prompt adapters and statistical alignment of the features during the
denoising process. With this, our approach is designed such that it can
intervene both at the cross-attention and the self-attention layers of the
denoising UNet. For the statistical alignment, we employ clustering to distill
a small representative set of attention features from the large number of
attention values extracted from the style samples. As demonstrated in our
experimental section, the resulting method achieves state-of-the-art results
for stylization.

</details>


### [117] [Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision](https://arxiv.org/abs/2508.12794)
*Kyriaki,Kokka,Rahul Goel,Ali Abbas,Kerry A. Nice,Luca Martial,SM Labib,Rihuan Ke,Carola Bibiane Schönlieb,James Woodcock*

Main category: cs.CV

TL;DR: 利用街景图像和深度学习技术，通过检测Google Street View图片中的自行车和摩托车来估算全球各城市的两种交通方式的使用水平，并与传统调查数据得到了较好的相关性和预测准确性。


<details>
  <summary>Details</summary>
Motivation: 交通方式影响健康，但全球范围内关于自行车和摩托车行为的比较数据缺乏。街景图像结合计算机视觉技术可以高效获取旅行行为数据。

Method: 采集185个全球城市的数据，使用YOLOv4模型识别Google Street View图片中的自行车和摩托车（每个城市8000张图片），并使用beta回归模型预测城市级别的交通方式分享率。

Result: 摩托车检测数量与实际使用水平相关系数高达0.78，自行车为0.51。回归模型预测自行车和摩托车使用率的R²分别为0.614和0.612，中位绝对误差分别为1.3%和1.4%。

Conclusion: 通过计算机视觉技术分析街景图像可以有效捕捉交通行为数据，为传统数据源提供价值补充，特别是在数据缺乏的地区。

Abstract: Transportation influence health by shaping exposure to physical activity, air
pollution and injury risk.Comparative data on cycling and motorcycling
behaviours is scarce, particularly at a global scale.Street view imagery, such
as Google Street View (GSV), combined with computer vision, is a valuable
resource for efficiently capturing travel behaviour data.This study
demonstrates a novel approach using deep learning on street view images to
estimate cycling and motorcycling levels across diverse cities worldwide.We
utilized data from 185 global cities.The data on mode shares of cycling and
motorcycling estimated using travel surveys or censuses.We used GSV images to
detect cycles and motorcycles in sampled locations, using 8000 images per
city.The YOLOv4 model, fine-tuned using images from six cities, achieved a mean
average precision of 89% for detecting cycles and motorcycles in GSV images.A
global prediction model was developed using beta regression with city-level
mode shares as outcome, with log transformed explanatory variables of counts of
GSV-detected images with cycles and motorcycles, while controlling for
population density.We found strong correlations between GSV motorcycle counts
and motorcycle mode share (0.78) and moderate correlations between GSV cycle
counts and cycling mode share (0.51).Beta regression models predicted mode
shares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,
achieving median absolute errors (MDAE) of 1.3% and 1.4%,
respectively.Scatterplots demonstrated consistent prediction accuracy, though
cities like Utrecht and Cali were outliers.The model was applied to 60 cities
globally for which we didn't have recent mode share data.We provided estimates
for some cities in the Middle East, Latin America and East Asia.With computer
vision, GSV images capture travel modes and activity, providing insights
alongside traditional data sources.

</details>


### [118] [Morphological classification of eclipsing binary stars using computer vision methods](https://arxiv.org/abs/2508.12802)
*Štefan Parimucha,Maksim Gabdeev,Yanna Markus,Martin Vaňko,Pavol Gajdoš*

Main category: cs.CV

TL;DR: 使用预训练CNN和Vision Transformer模型，通过极坐标变换和hexbin可视化方法分类蔽双星光变曲，在主分类任务上达到高精度，但在斑点检测任务上表现较差


<details>
  <summary>Details</summary>
Motivation: 应对大规模天文调查中的蔽双星分类需求，提高分类效率和自动化水平

Method: 使用ResNet50和Vision Transformer预训练模型，极坐标变换合并hexbin可视化方法处理光变曲图像，采用两步层次分类策略

Result: 主分类任务在多个波段(Gaia G、I、TESS)上达到>96%的验证准确率，在OGLE、DEBCat等观测数据上表现90-100%的性能，但斑点检测任务表现异常差

Conclusion: 计算机视觉在大规模蔽双星形态分类中具有强大潜力，但在细微光度特征检测方面需要更深入研究

Abstract: We present an application of computer vision methods to classify the light
curves of eclipsing binaries (EB). We have used pre-trained models based on
convolutional neural networks ($\textit{ResNet50}$) and vision transformers
($\textit{vit\_base\_patch16\_224}$), which were fine-tuned on images created
from synthetic datasets. To improve model generalisation and reduce
overfitting, we developed a novel image representation by transforming
phase-folded light curves into polar coordinates combined with hexbin
visualisation. Our hierarchical approach in the first stage classifies systems
into detached and overcontact types, and in the second stage identifies the
presence or absence of spots. The binary classification models achieved high
accuracy ($>96\%$) on validation data across multiple passbands (Gaia~$G$, $I$,
and $TESS$) and demonstrated strong performance ($>94\%$, up to $100\%$ for
$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and
WUMaCat catalogues. While the primary binary classification was highly
successful, the secondary task of automated spot detection performed poorly,
revealing a significant limitation of our models for identifying subtle
photometric features. This study highlights the potential of computer vision
for EB morphological classification in large-scale surveys, but underscores the
need for further research into robust, automated spot detection.

</details>


### [119] [Next Visual Granularity Generation](https://arxiv.org/abs/2508.12811)
*Yikai Wang,Zhouxia Wang,Zhonghua Wu,Qingyi Tao,Kang Liao,Chen Change Loy*

Main category: cs.CV

TL;DR: 该论文提出了一种新的图像生成方法NVG，通过将图像分解为结构化的视觉粒度序列，从全局布局到细节逐步精细地生成图像。在ImageNet数据集上表现超过VAR系列模型，FID指标更优。


<details>
  <summary>Details</summary>
Motivation: 传统图像生成方法缺乏层次化的细粒度控制，需要一种能够从全局到局部逐步精细化的生成框架来实现更精确的图像生成控制。

Method: 提出Next Visual Granularity (NVG)生成框架，将图像分解为结构化序列，每个元素具有相同空间分辨率但不同的标记数量。从空白图像开始，逐步精细地生成从全局到细节的视觉粒度序列。

Result: 在ImageNet数据集上训练的NVG模型显示了明显的缩放行为。与VAR系列相比，NVG在FID指标上持续表现更优（3.30->3.03, 2.57->2.44, 2.09->2.06）。

Conclusion: NVG框架通过层次化的视觉粒度序列生成，提供了细粒度的生成控制能力，在图像生成质量方面取得了显著改进，具有强大的潜力和应用前景。

Abstract: We propose a novel approach to image generation by decomposing an image into
a structured sequence, where each element in the sequence shares the same
spatial resolution but differs in the number of unique tokens used, capturing
different level of visual granularity. Image generation is carried out through
our newly introduced Next Visual Granularity (NVG) generation framework, which
generates a visual granularity sequence beginning from an empty image and
progressively refines it, from global layout to fine details, in a structured
manner. This iterative process encodes a hierarchical, layered representation
that offers fine-grained control over the generation process across multiple
granularity levels. We train a series of NVG models for class-conditional image
generation on the ImageNet dataset and observe clear scaling behavior. Compared
to the VAR series, NVG consistently outperforms it in terms of FID scores (3.30
-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to
showcase the capability and potential of the NVG framework. Our code and models
will be released.

</details>


### [120] [SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop](https://arxiv.org/abs/2508.12813)
*Friedhelm Hamann,Emil Mededovic,Fabian Gülhan,Yuli Wu,Johannes Stegmaier,Jing He,Yiqing Wang,Kexin Zhang,Lingling Li,Licheng Jiao,Mengru Ma,Hongxiang Huang,Yuhao Yan,Hongwei Ren,Xiaopeng Lin,Yulong Huang,Bojun Cheng,Se Hyun Lee,Gyu Sung Ham,Kanghan Oh,Gi Hyun Lim,Boxuan Yang,Bowen Du,Guillermo Gallego*

Main category: cs.CV

TL;DR: CVPR 2025事件视觉研讨会中的时空实例分割挑战赛概述，涉及事件相机和灰度相机数据的像素级分割任务


<details>
  <summary>Details</summary>
Motivation: 推动事件相机与灰度相机融合的时空实例分割技术发展，为计算机视觉社区提供基准数据集和评估平台

Method: 组织挑战赛，提供时空对齐的事件相机和灰度相机数据集，评估参赛团队的像素级分割方法

Result: 公布了前5名团队的方法和结果，提供了详细的挑战赛结果和参与者代码资源

Conclusion: 该挑战赛成功推动了事件视觉领域的时空实例分割研究，为后续研究提供了宝贵的数据集和基准方法

Abstract: We present an overview of the Spatio-temporal Instance Segmentation (SIS)
challenge held in conjunction with the CVPR 2025 Event-based Vision Workshop.
The task is to predict accurate pixel-level segmentation masks of defined
object classes from spatio-temporally aligned event camera and grayscale camera
data. We provide an overview of the task, dataset, challenge details and
results. Furthermore, we describe the methods used by the top-5 ranking teams
in the challenge. More resources and code of the participants' methods are
available here:
https://github.com/tub-rip/MouseSIS/blob/main/docs/challenge_results.md

</details>


### [121] [DEEP-SEA: Deep-Learning Enhancement for Environmental Perception in Submerged Aquatics](https://arxiv.org/abs/2508.12824)
*Shuang Chen,Ronald Thenius,Farshad Arvin,Amir Atapour-Abarghouei*

Main category: cs.CV

TL;DR: DEEP-SEA是一个基于深度学习的海底图像恢复模型，通过双频增强自注意力空间和频率调制器，有效解决水下环境中的光散射、吸收和浑浊问题，提升图像清晰度和色彩准确性。


<details>
  <summary>Details</summary>
Motivation: 水下监测平台依赖视觉数据进行海洋生物多样性分析和生态评估，但水下环境的光散射、吸收和浑浊问题严重降低图像质量，影响准确观测。

Method: 提出DEEP-SEA模型，采用双频增强自注意力空间和频率调制器，自适应地在频域和空间域细化特征表示，同时保留空间结构信息。

Result: 在EUVP和LSUI数据集上的综合实验表明，该模型在恢复精细图像细节和结构一致性方面优于现有最先进方法。

Conclusion: DEEP-SEA通过有效缓解水下视觉退化问题，有潜力提高水下监测平台的可靠性，实现更准确的生态观测、物种识别和自主导航。

Abstract: Continuous and reliable underwater monitoring is essential for assessing
marine biodiversity, detecting ecological changes and supporting autonomous
exploration in aquatic environments. Underwater monitoring platforms rely on
mainly visual data for marine biodiversity analysis, ecological assessment and
autonomous exploration. However, underwater environments present significant
challenges due to light scattering, absorption and turbidity, which degrade
image clarity and distort colour information, which makes accurate observation
difficult. To address these challenges, we propose DEEP-SEA, a novel deep
learning-based underwater image restoration model to enhance both low- and
high-frequency information while preserving spatial structures. The proposed
Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator aims to
adaptively refine feature representations in frequency domains and
simultaneously spatial information for better structural preservation. Our
comprehensive experiments on EUVP and LSUI datasets demonstrate the superiority
over the state of the art in restoring fine-grained image detail and structural
consistency. By effectively mitigating underwater visual degradation, DEEP-SEA
has the potential to improve the reliability of underwater monitoring platforms
for more accurate ecological observation, species identification and autonomous
navigation.

</details>


### [122] [Multi-source Multimodal Progressive Domain Adaption for Audio-Visual Deception Detection](https://arxiv.org/abs/2508.12842)
*Ronghao Lin,Sijie Mai,Ying Zeng,Qiaolin He,Aolin Xiong,Haifeng Hu*

Main category: cs.CV

TL;DR: 提出多源多模态渐进域适应框架MMPDA，解决跨域欺骗检测中的域偏移问题，在MMDD挑战赛中取得Top-2成绩


<details>
  <summary>Details</summary>
Motivation: 针对源域和目标域之间的域偏移问题，需要将来自不同源域的视听知识有效迁移到目标域

Method: 采用多源多模态渐进域适应框架，通过在特征层和决策层逐步对齐源域和目标域来弥合域偏移

Result: 在竞赛第二阶段达到60.43%准确率和56.99% F1分数，F1分数比第一名高5.59%，准确率比第三名高6.75%

Conclusion: 该方法在多模态欺骗检测中有效解决了跨域适应问题，性能表现优异

Abstract: This paper presents the winning approach for the 1st MultiModal Deception
Detection (MMDD) Challenge at the 1st Workshop on Subtle Visual Computing
(SVC). Aiming at the domain shift issue across source and target domains, we
propose a Multi-source Multimodal Progressive Domain Adaptation (MMPDA)
framework that transfers the audio-visual knowledge from diverse source domains
to the target domain. By gradually aligning source and the target domain at
both feature and decision levels, our method bridges domain shifts across
diverse multimodal datasets. Extensive experiments demonstrate the
effectiveness of our approach securing Top-2 place. Our approach reaches 60.43%
on accuracy and 56.99\% on F1-score on competition stage 2, surpassing the 1st
place team by 5.59% on F1-score and the 3rd place teams by 6.75% on accuracy.
Our code is available at https://github.com/RH-Lin/MMPDA.

</details>


### [123] [Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models](https://arxiv.org/abs/2508.12861)
*Dexia Chen,Wentao Zhang,Qianjie Zhu,Ping Hu,Weibing Li,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: 通过多视角协作优化和一致性约束，CoMuCo方法提升了视觉-语言模型在跨域少样本任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有的VLM迅速迁移学习方法在自然图像数据集上表现良好，但在跨域任务（如医学影像等）中效果有限

Method: 提出CoMuCo策略，使用两个功能互补的专家模块提取多视角特征，结合先验知识的一致性约束和信息几何的共识机制

Result: 在新建立的跨域少样本测试集上，CoMuCo持续超过当前最佳方法

Conclusion: CoMuCo通过多视角协作和一致性约束，有效提升了VLM在跨域少样本任务中的适应能力，为跨域学习提供了新的解决方案

Abstract: Vision-language models (VLMs) pre-trained on natural image and language data,
such as CLIP, have exhibited significant potential in few-shot image
recognition tasks, leading to development of various efficient transfer
learning methods. These methods exploit inherent pre-learned knowledge in VLMs
and have achieved strong performance on standard image datasets. However, their
effectiveness is often limited when confronted with cross-domain tasks where
imaging domains differ from natural images. To address this limitation, we
propose Consistency-guided Multi-view Collaborative Optimization (CoMuCo), a
novel fine-tuning strategy for VLMs. This strategy employs two functionally
complementary expert modules to extract multi-view features, while
incorporating prior knowledge-based consistency constraints and information
geometry-based consensus mechanisms to enhance the robustness of feature
learning. Additionally, a new cross-domain few-shot benchmark is established to
help comprehensively evaluate methods on imaging domains distinct from natural
images. Extensive empirical evaluations on both existing and newly proposed
benchmarks suggest CoMuCo consistently outperforms current methods in few-shot
tasks. The code and benchmark will be released.

</details>


### [124] [Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning](https://arxiv.org/abs/2508.12877)
*Dexia Chen,Qianjie Zhu,Weibing Li,Yue Yu,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: MPS-Tuning是一种新的视觉语言模型微调方法，通过保持特征空间中语义流形的几何结构并增强类别可分性来提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型微调方法往往忽略数据分布的几何结构，可能导致整体语义表示的扭曲，需要一种能够保持流形结构的方法

Method: 将特征空间中的数据分布视为语义流形，通过对齐微调前后的Gram矩阵来保持宏观和微观拓扑结构，并优化图像和文本模态的配对相似性来增强类别可分性

Result: 大量实验表明MPS-Tuning显著提高了模型性能，同时有效保持了语义流形的结构

Conclusion: MPS-Tuning通过显式约束语义流形的内在几何结构并增强其类别可分性，为视觉语言模型的微调提供了一种有效的新方法

Abstract: Pretrained vision-language models (VLMs), such as CLIP, have shown remarkable
potential in few-shot image classification and led to numerous effective
transfer learning strategies. These methods leverage the pretrained knowledge
of VLMs to enable effective domain adaptation while mitigating overfitting
through parameter-efficient tuning or instance-based consistency constraints.
However, such regularizations often neglect the geometric structure of data
distribution, which may lead to distortion of the overall semantic
representation. To overcome this limitation, we propose a novel fine-tuning
method, Manifold-Preserving and Sculpting Tuning (MPS-Tuning). Regarding the
data distribution in feature space as a semantic manifold, MPS-Tuning
explicitly constrains the intrinsic geometry of this manifold while further
sculpting it to enhance class separability. Specifically, MPS-Tuning preserves
both macroscopic and microscopic topological structures of the original
manifold by aligning Gram matrices of features before and after fine-tuning.
Theoretically, this constraint is shown to approximate an upper bound of the
Gromov-Wasserstein distance. Furthermore, features from the image and text
modalities are paired, and pairwise similarities are optimized to enhance the
manifold's class discriminability. Extensive experiments demonstrate that
MPS-Tuning significantly improves model performance while effectively
preserving the structure of the semantic manifold. The code will be released.

</details>


### [125] [S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models](https://arxiv.org/abs/2508.12880)
*Chubin Chen,Jiashu Zhu,Xiaokun Feng,Nisha Huang,Meiqi Wu,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Xiu Li*

Main category: cs.CV

TL;DR: 通过对CFG方法的实证分析，发现它产生次优预测导致语义不一致和低质量输出。提出S^2-Guidance方法，利用随机块投弃构建随机子网络，有效改善生成质量。


<details>
  <summary>Details</summary>
Motivation: 现代涵散模型中广泛使用的分类器免指导(CFG)技术在实践中存在次优预测问题，导致语义不一致和低质量输出。

Method: 提出S^2-Guidance方法，通过在前向过程中使用随机块投弃来构建随机子网络，帮助模型避免潜在的低质量预测并向高质量输出导向。

Result: 在文本到图像和文本到视频生成任务上进行了广泛的定性和定量实验，结果显示S^2-Guidance尤其在生成质量方面表现优异，一贵超越CFG和其他先进指导策略。

Conclusion: S^2-Guidance通过利用模型自身的随机子网络来精炼次优预测，有效解决了CFG方法的限制，为涵散模型的指导技术提供了新的方向。

Abstract: Classifier-free Guidance (CFG) is a widely used technique in modern diffusion
models for enhancing sample quality and prompt adherence. However, through an
empirical analysis on Gaussian mixture modeling with a closed-form solution, we
observe a discrepancy between the suboptimal results produced by CFG and the
ground truth. The model's excessive reliance on these suboptimal predictions
often leads to semantic incoherence and low-quality outputs. To address this
issue, we first empirically demonstrate that the model's suboptimal predictions
can be effectively refined using sub-networks of the model itself. Building on
this insight, we propose S^2-Guidance, a novel method that leverages stochastic
block-dropping during the forward process to construct stochastic sub-networks,
effectively guiding the model away from potential low-quality predictions and
toward high-quality outputs. Extensive qualitative and quantitative experiments
on text-to-image and text-to-video generation tasks demonstrate that
S^2-Guidance delivers superior performance, consistently surpassing CFG and
other advanced guidance strategies. Our code will be released.

</details>


### [126] [ONG: One-Shot NMF-based Gradient Masking for Efficient Model Sparsification](https://arxiv.org/abs/2508.12891)
*Sankar Behera,Yamuna Prasad*

Main category: cs.CV

TL;DR: ONG是一种基于非负矩阵分解的一次性剪枝方法，通过梯度掩码机制在训练过程中严格保持目标稀疏度，在CIFAR数据集上实现了与现有方法相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络规模庞大导致部署困难，现有剪枝方法往往需要复杂的迭代过程、专用标准，或在训练中难以有效保持稀疏性。

Method: 使用非负矩阵分解(NMF)识别重要权重结构进行一次性剪枝，然后采用精确的梯度掩码机制确保只更新未剪枝权重，严格保持目标稀疏度。

Result: 在CIFAR-10和CIFAR-100数据集上使用ResNet架构进行测试，ONG在各种稀疏度水平下都能达到可比或更优的性能，同时保持剪枝后的结构完整性。

Conclusion: ONG提供了一种有效的稀疏化策略，能够一次性确定剪枝结构并在整个训练过程中严格保持目标稀疏度，为目标稀疏度提供了清晰的机制。

Abstract: Deep Neural Networks (DNNs) have achieved remarkable success but their large
size poses deployment challenges. While various pruning techniques exist, many
involve complex iterative processes, specialized criteria, or struggle to
maintain sparsity effectively during training. We introduce ONG (One-shot
NMF-based Gradient Masking), a novel sparsification strategy that identifies
salient weight structures using Non-negative Matrix Factorization (NMF) for
one-shot pruning at the outset of training. Subsequently, ONG employs a precise
gradient masking mechanism to ensure that only unpruned weights are updated,
strictly preserving the target sparsity throughout the training phase. We
integrate ONG into the BIMP comparative framework and evaluate it on CIFAR-10
and CIFAR-100 with ResNet56, ResNet34, and ResNet18 against established stable
sparsification methods. Our experiments demonstrate ONG's ability to achieve
comparable or superior performance at various sparsity levels while maintaining
structural integrity post-pruning and offering a clear mechanism for targeting
desired sparsities.

</details>


### [127] [CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis](https://arxiv.org/abs/2508.12900)
*Jiayi Wang,Hadrien Reynaud,Franciskus Xaverius Erick,Bernhard Kainz*

Main category: cs.CV

TL;DR: CTFlow是一个0.5B参数的潜在流匹配变换器模型，通过临床报告生成整个CT体积，在时间一致性、图像多样性和文本图像对齐方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 利用临床报告生成整个CT体积可以加速医学研究，通过数据增强、隐私保护合成和减少患者数据的监管限制，同时保留诊断信号。

Method: 使用FLUX的A-VAE定义潜在空间，CT-Clip文本编码器编码临床报告，采用自定义自回归方法生成一致的整个CT体积，先基于文本生成第一个切片序列，然后基于先前生成的切片序列和文本预测后续序列。

Result: 在FID、FVD、IS分数和CLIP分数评估中，CTFlow在时间一致性、图像多样性和文本图像对齐方面优于最先进的生成CT模型。

Conclusion: CTFlow展示了基于临床报告生成高质量、一致CT体积的能力，为医学图像生成和数据增强提供了有效解决方案。

Abstract: Generative modelling of entire CT volumes conditioned on clinical reports has
the potential to accelerate research through data augmentation,
privacy-preserving synthesis and reducing regulator-constraints on patient data
while preserving diagnostic signals. With the recent release of CT-RATE, a
large-scale collection of 3D CT volumes paired with their respective clinical
reports, training large text-conditioned CT volume generation models has become
achievable. In this work, we introduce CTFlow, a 0.5B latent flow matching
transformer model, conditioned on clinical reports. We leverage the A-VAE from
FLUX to define our latent space, and rely on the CT-Clip text encoder to encode
the clinical reports. To generate consistent whole CT volumes while keeping the
memory constraints tractable, we rely on a custom autoregressive approach,
where the model predicts the first sequence of slices of the volume from
text-only, and then relies on the previously generated sequence of slices and
the text, to predict the following sequence. We evaluate our results against
state-of-the-art generative CT model, and demonstrate the superiority of our
approach in terms of temporal coherence, image diversity and text-image
alignment, with FID, FVD, IS scores and CLIP score.

</details>


### [128] [CMF-IoU: Multi-Stage Cross-Modal Fusion 3D Object Detection with IoU Joint Prediction](https://arxiv.org/abs/2508.12917)
*Zhiwei Ning,Zhaojiang Liu,Xuanang Gao,Yifan Zuo,Jie Yang,Yuming Fang,Wei Liu*

Main category: cs.CV

TL;DR: CMF-IOU是一个多阶段跨模态融合的3D检测框架，通过深度补全网络将像素信息投影到3D空间生成伪点云，设计双边跨视图增强3D骨干网络，并结合迭代体素点感知细粒度池化模块，在KITTI、nuScenes和Waymo数据集上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态3D检测方法大多只进行单阶段或部分阶段融合，导致特征提取不足和性能欠佳。需要解决3D空间信息与2D语义信息的对齐挑战。

Method: 1) 通过深度补全网络将像素信息投影到3D空间生成伪点云；2) 设计双边跨视图增强3D骨干网络（S2D分支和ResVC分支）；3) 引入迭代体素点感知细粒度池化模块；4) 设计IoU联合预测分支和新的候选框生成技术

Result: 在KITTI、nuScenes和Waymo数据集上进行了广泛实验，证明了方法的优越性能

Conclusion: 提出的CMF-IOU框架通过多阶段跨模态融合有效解决了3D空间和2D语义信息的对齐问题，在多个基准数据集上取得了优异的结果

Abstract: Multi-modal methods based on camera and LiDAR sensors have garnered
significant attention in the field of 3D detection. However, many prevalent
works focus on single or partial stage fusion, leading to insufficient feature
extraction and suboptimal performance. In this paper, we introduce a
multi-stage cross-modal fusion 3D detection framework, termed CMF-IOU, to
effectively address the challenge of aligning 3D spatial and 2D semantic
information. Specifically, we first project the pixel information into 3D space
via a depth completion network to get the pseudo points, which unifies the
representation of the LiDAR and camera information. Then, a bilateral
cross-view enhancement 3D backbone is designed to encode LiDAR points and
pseudo points. The first sparse-to-distant (S2D) branch utilizes an
encoder-decoder structure to reinforce the representation of sparse LiDAR
points. The second residual view consistency (ResVC) branch is proposed to
mitigate the influence of inaccurate pseudo points via both the 3D and 2D
convolution processes. Subsequently, we introduce an iterative voxel-point
aware fine grained pooling module, which captures the spatial information from
LiDAR points and textural information from pseudo points in the proposal
refinement stage. To achieve more precise refinement during iteration, an
intersection over union (IoU) joint prediction branch integrated with a novel
proposals generation technique is designed to preserve the bounding boxes with
both high IoU and classification scores. Extensive experiments show the
superior performance of our method on the KITTI, nuScenes and Waymo datasets.

</details>


### [129] [7Bench: a Comprehensive Benchmark for Layout-guided Text-to-image Models](https://arxiv.org/abs/2508.12919)
*Elena Izzo,Luca Parolari,Davide Vezzaro,Lamberto Ballan*

Main category: cs.CV

TL;DR: 提出了7Bench基准测试，首个同时评估布局引导文本到图像生成中语义对齐和空间对齐的基准，包含7个挑战性场景，并提出了包含布局对齐分数的评估协议


<details>
  <summary>Details</summary>
Motivation: 现有基准只评估文本对齐而忽略了布局对齐，无法全面评估模型的空间保真度，这在合成数据生成等应用中至关重要

Method: 构建包含文本-布局对的7Bench基准，涵盖7个挑战性场景，提出结合布局对齐分数的评估协议来评估空间准确性

Result: 使用7Bench评估了多个最先进的扩散模型，揭示了它们在不同对齐任务中的优势和局限性

Conclusion: 7Bench填补了布局引导文本到图像生成评估的空白，为模型的空间保真度评估提供了重要工具

Abstract: Layout-guided text-to-image models offer greater control over the generation
process by explicitly conditioning image synthesis on the spatial arrangement
of elements. As a result, their adoption has increased in many computer vision
applications, ranging from content creation to synthetic data generation. A
critical challenge is achieving precise alignment between the image, textual
prompt, and layout, ensuring semantic fidelity and spatial accuracy. Although
recent benchmarks assess text alignment, layout alignment remains overlooked,
and no existing benchmark jointly evaluates both. This gap limits the ability
to evaluate a model's spatial fidelity, which is crucial when using
layout-guided generation for synthetic data, as errors can introduce noise and
degrade data quality. In this work, we introduce 7Bench, the first benchmark to
assess both semantic and spatial alignment in layout-guided text-to-image
generation. It features text-and-layout pairs spanning seven challenging
scenarios, investigating object generation, color fidelity, attribute
recognition, inter-object relationships, and spatial control. We propose an
evaluation protocol that builds on existing frameworks by incorporating the
layout alignment score to assess spatial accuracy. Using 7Bench, we evaluate
several state-of-the-art diffusion models, uncovering their respective
strengths and limitations across diverse alignment tasks. The benchmark is
available at https://github.com/Elizzo/7Bench.

</details>


### [130] [Towards High-Resolution Industrial Image Anomaly Detection](https://arxiv.org/abs/2508.12931)
*Ximiao Zhang,Min Xu,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: HiAD是一个针对高分辨率图像异常检测的通用框架，通过双分支架构和多分辨率特征融合策略，有效解决了传统方法在检测细微异常区域时的信息丢失问题，在多个高分辨率基准测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前异常检测方法主要针对低分辨率场景，传统下采样方法在高分辨率图像中会导致细微异常区域的检测遗漏。现有方法在检测精度和效率方面仍难以满足工业场景的实际需求。

Method: 提出HiAD框架，采用双分支架构集成不同尺度的异常线索，结合多分辨率特征融合策略处理高分辨率图像的细粒度纹理变化。使用检测器池和多种检测器分配策略，根据图像块特征自适应分配检测器，在保证性能的同时控制计算成本。

Result: 在专门构建的高分辨率异常检测基准测试（MVTec-HD、VisA-HD和RealIAD-HD）上进行了广泛实验，证明了HiAD的优越性能。

Conclusion: HiAD框架能够有效检测高分辨率图像中不同大小的异常区域，在有限计算资源下实现了检测精度和效率的平衡，为工业应用提供了实用的解决方案。

Abstract: Current anomaly detection methods primarily focus on low-resolution
scenarios. For high-resolution images, conventional downsampling often results
in missed detections of subtle anomalous regions due to the loss of
fine-grained discriminative information. Despite some progress, recent studies
have attempted to improve detection resolution by employing lightweight
networks or using simple image tiling and ensemble methods. However, these
approaches still struggle to meet the practical demands of industrial scenarios
in terms of detection accuracy and efficiency. To address the above issues, we
propose HiAD, a general framework for high-resolution anomaly detection. HiAD
is capable of detecting anomalous regions of varying sizes in high-resolution
images under limited computational resources. Specifically, HiAD employs a
dual-branch architecture that integrates anomaly cues across different scales
to comprehensively capture both subtle and large-scale anomalies. Furthermore,
it incorporates a multi-resolution feature fusion strategy to tackle the
challenges posed by fine-grained texture variations in high-resolution images.
To enhance both adaptability and efficiency, HiAD utilizes a detector pool in
conjunction with various detector assignment strategies, enabling detectors to
be adaptively assigned based on patch features, ensuring detection performance
while effectively controlling computational costs. We conduct extensive
experiments on our specifically constructed high-resolution anomaly detection
benchmarks, including MVTec-HD, VisA-HD, and the real-world benchmark
RealIAD-HD, demonstrating the superior performance of HiAD. The code is
available at https://github.com/cnulab/HiAD.

</details>


### [131] [SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory](https://arxiv.org/abs/2508.12932)
*Hongyang Chen,Shaoling Pu,Lingyu Zheng,Zhongwu Sun*

Main category: cs.CV

TL;DR: SEDEG是一个两阶段训练框架，通过提升编码器和解码器的泛化能力来缓解增量学习中的灾难性遗忘问题，特别是在小内存场景下表现优异


<details>
  <summary>Details</summary>
Motivation: 现有增量学习方法通常只关注编码器或解码器中的一个组件，限制了缓解灾难性遗忘的效果，特别是在小内存场景下表现更差

Method: 采用两阶段训练：首先通过特征增强训练集成编码器学习泛化表示，然后使用知识蒸馏策略压缩集成编码器并开发新的泛化编码器

Result: 在三个基准数据集上的广泛实验显示SEDEG具有优越性能，消融研究确认了其组件的有效性

Conclusion: SEDEG通过顺序提升编码器和解码器的泛化能力，有效缓解了增量学习中的灾难性遗忘问题，特别是在小内存场景下表现出色

Abstract: In incremental learning, enhancing the generality of knowledge is crucial for
adapting to dynamic data inputs. It can develop generalized representations or
more balanced decision boundaries, preventing the degradation of long-term
knowledge over time and thus mitigating catastrophic forgetting. Some emerging
incremental learning methods adopt an encoder-decoder architecture and have
achieved promising results. In the encoder-decoder achitecture, improving the
generalization capabilities of both the encoder and decoder is critical, as it
helps preserve previously learned knowledge while ensuring adaptability and
robustness to new, diverse data inputs. However, many existing continual
methods focus solely on enhancing one of the two components, which limits their
effectiveness in mitigating catastrophic forgetting. And these methods perform
even worse in small-memory scenarios, where only a limited number of historical
samples can be stored. To mitigate this limitation, we introduces SEDEG, a
two-stage training framework for vision transformers (ViT), focusing on
sequentially improving the generality of both Decoder and Encoder. Initially,
SEDEG trains an ensembled encoder through feature boosting to learn generalized
representations, which subsequently enhance the decoder's generality and
balance the classifier. The next stage involves using knowledge distillation
(KD) strategies to compress the ensembled encoder and develop a new, more
generalized encoder. This involves using a balanced KD approach and feature KD
for effective knowledge transfer. Extensive experiments on three benchmark
datasets show SEDEG's superior performance, and ablation studies confirm the
efficacy of its components. The code is available at
https://github.com/ShaolingPu/CIL.

</details>


### [132] [Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data](https://arxiv.org/abs/2508.12942)
*Kyriaki-Margarita Bintsi,Yaël Balbastre,Jingjing Wu,Julia F. Lehman,Suzanne N. Haber,Anastasia Yendiki*

Main category: cs.CV

TL;DR: 基于U-Net结构的全自动化框架，通过大补丁尺寸、前景感知采样和半监督预训练，实现了猴类追踪数据中纤维束分割的显著改进


<details>
  <summary>Details</summary>
Motivation: 解决历史学分析中手工注释纤维束的劳动密集问题，充分利用追踪数据来验证和优化液相碳水化磁共振成像追躊技术

Method: 采用U-Net网络结构，结合大补丁尺寸、前景感知采样策略和半监督预训练方法

Result: 稀疏纤维束检测提高超20%，假发现率降低40%，避免了终端被误标为束的常见错误，支持单独切片分析

Conclusion: 该框架能大规模自动分析解剖学追踪数据，为磁共振成像追躊技术提供更多真实地面真实数据

Abstract: Anatomic tracer studies are critical for validating and improving diffusion
MRI (dMRI) tractography. However, large-scale analysis of data from such
studies is hampered by the labor-intensive process of annotating fiber bundles
manually on histological slides. Existing automated methods often miss sparse
bundles or require complex post-processing across consecutive sections,
limiting their flexibility and generalizability. We present a streamlined,
fully automated framework for fiber bundle segmentation in macaque tracer data,
based on a U-Net architecture with large patch sizes, foreground aware
sampling, and semisupervised pre-training. Our approach eliminates common
errors such as mislabeling terminals as bundles, improves detection of sparse
bundles by over 20% and reduces the False Discovery Rate (FDR) by 40% compared
to the state-of-the-art, all while enabling analysis of standalone slices. This
new framework will facilitate the automated analysis of anatomic tracing data
at a large scale, generating more ground-truth data that can be used to
validate and optimize dMRI tractography methods.

</details>


### [133] [Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models](https://arxiv.org/abs/2508.12945)
*Jianshu Zeng,Yuxuan Liu,Yutong Feng,Chenxuan Miao,Zixiang Gao,Jiwang Qu,Jianzhang Zhang,Bin Wang,Kun Yuan*

Main category: cs.CV

TL;DR: Lumen是一个端到端的视频重光照框架，基于大规模视频生成模型，通过文本描述控制光照和背景，在保持前景一致性的同时实现和谐的视频重光照效果。


<details>
  <summary>Details</summary>
Motivation: 视频重光照是一个具有挑战性但有价值的任务，需要在替换视频背景的同时相应调整前景光照并实现和谐融合。现有方法缺乏高质量配对视频数据，且难以保持时间一致性和前景属性。

Method: 构建混合真实和合成视频的大规模数据集；使用3D渲染引擎生成合成视频对；采用HDR光照模拟补充真实视频；设计联合训练课程，注入域感知适配器解耦重光照和域外观分布学习。

Result: 实验结果表明Lumen能够有效编辑输入视频，生成具有一致光照和严格前景保持的电影级重光照视频，在综合基准测试中优于现有方法。

Conclusion: Lumen框架通过大规模混合数据集和域感知适配器设计，成功解决了视频重光照中的一致性和前景保持问题，为视频编辑提供了有效的解决方案。

Abstract: Video relighting is a challenging yet valuable task, aiming to replace the
background in videos while correspondingly adjusting the lighting in the
foreground with harmonious blending. During translation, it is essential to
preserve the original properties of the foreground, e.g., albedo, and propagate
consistent relighting among temporal frames. In this paper, we propose Lumen,
an end-to-end video relighting framework developed on large-scale video
generative models, receiving flexible textual description for instructing the
control of lighting and background. Considering the scarcity of high-qualified
paired videos with the same foreground in various lighting conditions, we
construct a large-scale dataset with a mixture of realistic and synthetic
videos. For the synthetic domain, benefiting from the abundant 3D assets in the
community, we leverage advanced 3D rendering engine to curate video pairs in
diverse environments. For the realistic domain, we adapt a HDR-based lighting
simulation to complement the lack of paired in-the-wild videos. Powered by the
aforementioned dataset, we design a joint training curriculum to effectively
unleash the strengths of each domain, i.e., the physical consistency in
synthetic videos, and the generalized domain distribution in realistic videos.
To implement this, we inject a domain-aware adapter into the model to decouple
the learning of relighting and domain appearance distribution. We construct a
comprehensive benchmark to evaluate Lumen together with existing methods, from
the perspectives of foreground preservation and video consistency assessment.
Experimental results demonstrate that Lumen effectively edit the input into
cinematic relighted videos with consistent lighting and strict foreground
preservation. Our project page: https://lumen-relight.github.io/

</details>


### [134] [MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation](https://arxiv.org/abs/2508.12948)
*Wei Wei,Shaojie Zhang,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: MaskSem是一种新颖的语义引导掩码方法，通过Grad-CAM基于相对运动来指导关节掩码，并使用混合高阶运动作为重建目标，提高了基于骨架的动作识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督骨架动作识别方法主要关注有限关节集和低阶运动模式，限制了模型对复杂运动模式的理解能力。

Method: 提出语义引导掩码方法MaskSem，利用基于相对运动的Grad-CAM指导关节掩码；使用混合高阶运动（低阶速度和高阶加速度）作为重建目标。

Result: 在NTU60、NTU120和PKU-MMD数据集上的实验表明，MaskSem结合普通transformer提高了骨架动作识别性能。

Conclusion: 该方法能更全面地描述动态运动过程，增强对运动模式的理解，更适合人机交互应用。

Abstract: Human action recognition is a crucial task for intelligent robotics,
particularly within the context of human-robot collaboration research. In
self-supervised skeleton-based action recognition, the mask-based
reconstruction paradigm learns the spatial structure and motion patterns of the
skeleton by masking joints and reconstructing the target from unlabeled data.
However, existing methods focus on a limited set of joints and low-order motion
patterns, limiting the model's ability to understand complex motion patterns.
To address this issue, we introduce MaskSem, a novel semantic-guided masking
method for learning 3D hybrid high-order motion representations. This novel
framework leverages Grad-CAM based on relative motion to guide the masking of
joints, which can be represented as the most semantically rich temporal
orgions. The semantic-guided masking process can encourage the model to explore
more discriminative features. Furthermore, we propose using hybrid high-order
motion as the reconstruction target, enabling the model to learn multi-order
motion patterns. Specifically, low-order motion velocity and high-order motion
acceleration are used together as the reconstruction target. This approach
offers a more comprehensive description of the dynamic motion process,
enhancing the model's understanding of motion patterns. Experiments on the
NTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla
transformer, improves skeleton-based action recognition, making it more
suitable for applications in human-robot interaction.

</details>


### [135] [Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination](https://arxiv.org/abs/2508.12957)
*Yizhou Liu,Jingwei Wei,Zizhi Chen,Minghao Han,Xukun Zhang,Keliang Liu,Lihua Zhang*

Main category: cs.CV

TL;DR: ARMed是一个针对开放式医学视觉问答的强化学习框架，通过结合领域知识和自适应语义奖励来提升医学推理质量，在多个基准测试中显著提升了准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习微调方法主要针对封闭式医学VQA，而开放式医学VQA更能反映临床实践但研究不足。基于模型的语义奖励存在奖励崩溃问题，即语义差异显著的回复获得相似分数。

Method: ARMed首先通过监督微调在思维链数据中融入领域知识，然后应用带有文本正确性和自适应语义奖励的强化学习来提升推理质量。

Result: 在六个医学VQA基准测试中，ARMed在域内任务上提升32.64%，在域外基准上提升11.65%，显著提升了准确性和泛化能力。

Conclusion: 研究强调了奖励可区分性在医学强化学习中的关键作用，以及语义引导奖励在实现稳健且具有临床意义的多模态推理方面的潜力。

Abstract: Reinforcement learning (RL) with rule-based rewards has demonstrated strong
potential in enhancing the reasoning and generalization capabilities of
vision-language models (VLMs) and large language models (LLMs), while reducing
computational overhead. However, its application in medical imaging remains
underexplored. Existing reinforcement fine-tuning (RFT) approaches in this
domain primarily target closed-ended visual question answering (VQA), limiting
their applicability to real-world clinical reasoning. In contrast, open-ended
medical VQA better reflects clinical practice but has received limited
attention. While some efforts have sought to unify both formats via
semantically guided RL, we observe that model-based semantic rewards often
suffer from reward collapse, where responses with significant semantic
differences receive similar scores. To address this, we propose ARMed (Adaptive
Reinforcement for Medical Reasoning), a novel RL framework for open-ended
medical VQA. ARMed first incorporates domain knowledge through supervised
fine-tuning (SFT) on chain-of-thought data, then applies reinforcement learning
with textual correctness and adaptive semantic rewards to enhance reasoning
quality. We evaluate ARMed on six challenging medical VQA benchmarks. Results
show that ARMed consistently boosts both accuracy and generalization, achieving
a 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain
benchmarks. These results highlight the critical role of reward
discriminability in medical RL and the promise of semantically guided rewards
for enabling robust and clinically meaningful multimodal reasoning.

</details>


### [136] [Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation](https://arxiv.org/abs/2508.12962)
*Dominic LaBella,Keshav Jha,Jared Robbins,Esther Yu*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D SegResNet架构的深度学习管道，用于CBCT图像中的多类别牙齿分割，在ToothFairy3挑战赛验证集上达到平均Dice系数0.87


<details>
  <summary>Details</summary>
Motivation: 自动化CBCT牙齿结构分割能够有效辅助病理识别（如牙髓或根尖周病变）和头颈癌患者的放射治疗规划，提高患者护理质量

Method: 使用MONAI Auto3DSeg框架和3D SegResNet架构，采用5折交叉验证训练，关键预处理包括图像重采样和强度裁剪，采用两阶段分割策略：第一阶段整体分割，第二阶段对下颌神经结构进行紧密裁剪分割

Result: 在ToothFairy3挑战赛样本外验证集上取得了平均Dice系数0.87的优异性能

Conclusion: 该方法展示了自动化牙齿分割在放射肿瘤学中改善患者护理的相关性和有效性，为临床诊断和治疗规划提供了高效辅助工具

Abstract: Cone-beam computed tomography (CBCT) has become an invaluable imaging
modality in dentistry, enabling 3D visualization of teeth and surrounding
structures for diagnosis and treatment planning. Automated segmentation of
dental structures in CBCT can efficiently assist in identifying pathology
(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning
in head and neck cancer patients. We describe the DLaBella29 team's approach
for the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning
pipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg
framework with a 3D SegResNet architecture, trained on a subset of the
ToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key
preprocessing steps included image resampling to 0.6 mm isotropic resolution
and intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE
on the 5-fold predictions to infer a Phase 1 segmentation and then conducted
tight cropping around the easily segmented Phase 1 mandible to perform Phase 2
segmentation on the smaller nerve structures. Our method achieved an average
Dice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This
paper details the clinical context, data preparation, model development,
results of our approach, and discusses the relevance of automated dental
segmentation for improving patient care in radiation oncology.

</details>


### [137] [GazeDETR: Gaze Detection using Disentangled Head and Gaze Representations](https://arxiv.org/abs/2508.12966)
*Ryan Anthony Jalova de Belen,Gelareh Mohammadi,Arcot Sowmya*

Main category: cs.CV

TL;DR: GazeDETR是一种新颖的端到端架构，使用两个解耦的解码器分别处理头部定位和视线预测任务，在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端视线目标检测模型使用单一解码器同时定位头部和预测视线，导致表示纠缠。需要解耦这两个任务以获得更好的性能。

Method: 提出GazeDETR架构，包含两个独立的解码器：一个用于头部定位（利用局部信息），另一个用于视线预测（结合局部和全局信息），使用连贯注意力场。

Result: 在GazeFollow、VideoAttentionTarget和ChildPlay数据集上达到最先进水平，显著优于现有端到端模型。

Conclusion: 解耦的架构设计能够为每个子任务学习独特的表示，有效提升视线通信行为的量化性能。

Abstract: Gaze communication plays a crucial role in daily social interactions.
Quantifying this behavior can help in human-computer interaction and digital
phenotyping. While end-to-end models exist for gaze target detection, they only
utilize a single decoder to simultaneously localize human heads and predict
their corresponding gaze (e.g., 2D points or heatmap) in a scene. This
multitask learning approach generates a unified and entangled representation
for human head localization and gaze location prediction. Herein, we propose
GazeDETR, a novel end-to-end architecture with two disentangled decoders that
individually learn unique representations and effectively utilize coherent
attentive fields for each subtask. More specifically, we demonstrate that its
human head predictor utilizes local information, while its gaze decoder
incorporates both local and global information. Our proposed architecture
achieves state-of-the-art results on the GazeFollow, VideoAttentionTarget and
ChildPlay datasets. It outperforms existing end-to-end models with a notable
margin.

</details>


### [138] [Compact Attention: Exploiting Structured Spatio-Temporal Sparsity for Fast Video Generation](https://arxiv.org/abs/2508.12969)
*Qirui Li,Guangcong Zheng,Qi Zhao,Jie Li,Bin Dong,Yiwu Yao,Xi Li*

Main category: cs.CV

TL;DR: 通过分析视频波散Transformer的注意力矩阵，发现具有结构化的异质稀疏模式，提出Compact Attention加速框架，通过适配到小组细、时间变化窗口和自动配置搜索，实现1.6~2.5倍的注意力计算加速而保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: 解决自注意力机制在辅助视频生成中的计算要求过高问题，尤其是在合成超长序列时。现有的因子化注意力和固定稀疏模式方法无法充分利用视频数据的内在时空冗余性。

Method: 提出Compact Attention加速框架，包括：1)适配到小组策略，通过动态到小组细近似多样化空间交互模式；2)时间变化窗口，根据帧距离调整稀疏程度；3)自动化配置搜索算法，在保留关键注意通道的同时优化稀疏模式。

Result: 在单GPU环境下实现了注意力计算1.6~2.5倍的加速，同时保持了与全注意力基线相当的视觉质量。

Conclusion: 该方法通过结构化稀疏利用提供了一种有理论基础的方法，用于开启高效的长形式视频生成。

Abstract: The computational demands of self-attention mechanisms pose a critical
challenge for transformer-based video generation, particularly in synthesizing
ultra-long sequences. Current approaches, such as factorized attention and
fixed sparse patterns, fail to fully exploit the inherent spatio-temporal
redundancies in video data. Through systematic analysis of video diffusion
transformers (DiT), we uncover a key insight: Attention matrices exhibit
structured, yet heterogeneous sparsity patterns, where specialized heads
dynamically attend to distinct spatiotemporal regions (e.g., local pattern,
cross-shaped pattern, or global pattern). Existing sparse attention methods
either impose rigid constraints or introduce significant overhead, limiting
their effectiveness. To address this, we propose Compact Attention, a
hardware-aware acceleration framework featuring three innovations: 1) Adaptive
tiling strategies that approximate diverse spatial interaction patterns via
dynamic tile grouping, 2) Temporally varying windows that adjust sparsity
levels based on frame proximity, and 3) An automated configuration search
algorithm that optimizes sparse patterns while preserving critical attention
pathways. Our method achieves 1.6~2.5x acceleration in attention computation on
single-GPU setups while maintaining comparable visual quality with
full-attention baselines. This work provides a principled approach to unlocking
efficient long-form video generation through structured sparsity exploitation.
Project Page: https://yo-ava.github.io/Compact-Attention.github.io/

</details>


### [139] [Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature](https://arxiv.org/abs/2508.12977)
*Rohan Asthana,Joschua Conrad,Maurits Ortmanns,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 这篇论文提出了一种无需标签数据的零成本代理方法，通过结合渗透性、普遍性和表达能力来预测神经网络的性能，在多个NAS测试集上表现优异且效率高。


<details>
  <summary>Details</summary>
Motivation: 现有的零成本代理方法多依赖标签数据，而这在实际应用中通常不可用。同时当前方法要么只关注收敛性和普遍性，要么只关注网络的表达能力，需要一种综合考虑这三者的方法。

Method: 等近代理通过结合神经网络层特征的奇异值分解(SVD)和网络输出的外在曲率来设计。具体表达为两个关键组件（特征条件数的逆和输出外在曲率）对数的简化调和平均值。该方法仅需一个无标签数据样本就能预测网络性能。

Result: 在多个相关性测试集包括NAS-Bench-101、NAS-Bench-201和TransNAS-Bench-101-micro上表现优异，同时在DARTS和AutoFormer搜索空间的NAS任务中也显示出良好性能，而且计算效率很高。

Conclusion: 该研究提出的零成本代理方法成功解决了对标签数据的依赖性问题，通过综合考虑渗透性、普遍性和表达能力，实现了在无标签数据情况下的准确性能预测，为实际应用提供了可行的解决方案。

Abstract: Zero-shot Neural Architecture Search (NAS) typically optimises the
architecture search process by exploiting the network or gradient properties at
initialisation through zero-cost proxies. The existing proxies often rely on
labelled data, which is usually unavailable in real-world settings.
Furthermore, the majority of the current methods focus either on optimising the
convergence and generalisation attributes or solely on the expressivity of the
network architectures. To address both limitations, we first demonstrate how
channel collinearity affects the convergence and generalisation properties of a
neural network. Then, by incorporating the convergence, generalisation and
expressivity in one approach, we propose a zero-cost proxy that omits the
requirement of labelled data for its computation. In particular, we leverage
the Singular Value Decomposition (SVD) of the neural network layer features and
the extrinsic curvature of the network output to design our proxy. %As a
result, the proposed proxy is formulated as the simplified harmonic mean of the
logarithms of two key components: the sum of the inverse of the feature
condition number and the extrinsic curvature of the network output. Our
approach enables accurate prediction of network performance on test data using
only a single label-free data sample. Our extensive evaluation includes a total
of six experiments, including the Convolutional Neural Network (CNN) search
space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The
proposed proxy demonstrates a superior performance on multiple correlation
benchmarks, including NAS-Bench-101, NAS-Bench-201, and
TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the
AutoFormer search space, all while being notably efficient. The code is
available at https://github.com/rohanasthana/Dextr.

</details>


### [140] [Omni Survey for Multimodality Analysis in Visual Object Tracking](https://arxiv.org/abs/2508.13000)
*Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Hui Li,Shaochuan Zhao,Tao Zhou,Chunyang Cheng,Xiaojun Wu,Josef Kittler*

Main category: cs.CV

TL;DR: 本文是一个多模态视觉目标跟踪(MMVOT)的全面调研报告，涵盖了数据收集、模态对齐、模型设计和评估等关键方面，包含6个MMVOT任务和338个参考文献。


<details>
  <summary>Details</summary>
Motivation: 智慧城市发展产生了大量多模态数据，需要综合监测城市基础设施和服务。多模态视觉目标跟踪作为关键任务，需要从多模态角度进行系统分析。

Method: 从四个关键方面分析MMVOT与单模态跟踪的差异：数据收集、模态对齐和标注、模型设计、评估。对现有方法按处理可见光(RGB)和其他模态(X)的不同方式进行分类。

Result: 完整调研了6个MMVOT任务，统计338个参考文献。首次分析现有MMVOT数据集中对象类别的分布，发现其呈现明显的长尾分布特征，且动物类别比RGB数据集显著缺乏。

Conclusion: 多模态跟踪并非总是比单模态跟踪更优的解决方案，需要明确其应用有益的具体情况。数据集的长尾分布特征和类别偏料问题需要重点关注。

Abstract: The development of smart cities has led to the generation of massive amounts
of multi-modal data in the context of a range of tasks that enable a
comprehensive monitoring of the smart city infrastructure and services. This
paper surveys one of the most critical tasks, multi-modal visual object
tracking (MMVOT), from the perspective of multimodality analysis. Generally,
MMVOT differs from single-modal tracking in four key aspects, data collection,
modality alignment and annotation, model designing, and evaluation.
Accordingly, we begin with an introduction to the relevant data modalities,
laying the groundwork for their integration. This naturally leads to a
discussion of challenges of multi-modal data collection, alignment, and
annotation. Subsequently, existing MMVOT methods are categorised, based on
different ways to deal with visible (RGB) and X modalities: programming the
auxiliary X branch with replicated or non-replicated experimental
configurations from the RGB branch. Here X can be thermal infrared (T), depth
(D), event (E), near infrared (NIR), language (L), or sonar (S). The final part
of the paper addresses evaluation and benchmarking. In summary, we undertake an
omni survey of all aspects of multi-modal visual object tracking (VOT),
covering six MMVOT tasks and featuring 338 references in total. In addition, we
discuss the fundamental rhetorical question: Is multi-modal tracking always
guaranteed to provide a superior solution to unimodal tracking with the help of
information fusion, and if not, in what circumstances its application is
beneficial. Furthermore, for the first time in this field, we analyse the
distributions of the object categories in the existing MMVOT datasets,
revealing their pronounced long-tail nature and a noticeable lack of animal
categories when compared with RGB datasets.

</details>


### [141] [Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning](https://arxiv.org/abs/2508.13005)
*Jiawen Xu,Odej Kao*

Main category: cs.CV

TL;DR: 本文通过实证研究发现，增强特征多样性可以显著提高开放集识别能力，同时也有利于持续学习中旧知识的保持和新知识的整合。


<details>
  <summary>Details</summary>
Motivation: 虽然已有许多方法通过启发式方式促进特征多样性来解决开放集识别和持续学习问题，但很少有研究直接探讨特征多样性在这些问题中的具体作用。

Method: 通过实证研究分析特征多样性对开放集识别和持续学习性能的影响，提供经验证据。

Result: 增强特征多样性确实能够改善开放集样本的识别，同时促进持续学习中旧数据的保持和新数据的整合。

Conclusion: 特征多样性在开放集识别和持续学习中发挥着重要作用，这一发现可为这两个领域的实践方法和理论理解提供新的研究方向。

Abstract: Open set recognition (OSR) and continual learning are two critical challenges
in machine learning, focusing respectively on detecting novel classes at
inference time and updating models to incorporate the new classes. While many
recent approaches have addressed these problems, particularly OSR, by
heuristically promoting feature diversity, few studies have directly examined
the role that feature diversity plays in tackling them. In this work, we
provide empirical evidence that enhancing feature diversity improves the
recognition of open set samples. Moreover, increased feature diversity also
facilitates both the retention of previously learned data and the integration
of new data in continual learning. We hope our findings can inspire further
research into both practical methods and theoretical understanding in these
domains.

</details>


### [142] [SlimComm: Doppler-Guided Sparse Queries for Bandwidth-Efficient Cooperative 3-D Perception](https://arxiv.org/abs/2508.13007)
*Melih Yazgan,Qiyuan Wu,Iramm Hamdard,Shiqi Li,J. Marius Zoellner*

Main category: cs.CV

TL;DR: SlimComm是一个通信高效的协作感知框架，通过整合4D雷达多普勒信息和查询驱动的稀疏方案，大幅降低带宽需求，同时保持感知精度。


<details>
  <summary>Details</summary>
Motivation: 协作感知虽然能克服遮挡和传感器范围限制，但传输密集的BEV特征图会严重占用车联网通信带宽，需要更高效的通信方案。

Method: 构建运动中心动态地图区分动静物体，生成参考查询（动态和高置信区域）和探索查询（遮挡区域），仅交换查询特定的BEV特征，通过多尺度门控可变形注意力进行融合。

Result: 带宽比全图共享降低90%，在不同交通密度和遮挡条件下达到或超越现有基线性能，并发布了包含点级多普勒雷达的OPV2V-R和Adver-City-R数据集。

Conclusion: SlimComm成功解决了协作感知中的带宽瓶颈问题，通过查询驱动的稀疏通信策略实现了高效的特征交换，为实际部署提供了可行的解决方案。

Abstract: Collaborative perception allows connected autonomous vehicles (CAVs) to
overcome occlusion and limited sensor range by sharing intermediate features.
Yet transmitting dense Bird's-Eye-View (BEV) feature maps can overwhelm the
bandwidth available for inter-vehicle communication. We present SlimComm, a
communication-efficient framework that integrates 4D radar Doppler with a
query-driven sparse scheme. SlimComm builds a motion-centric dynamic map to
distinguish moving from static objects and generates two query types: (i)
reference queries on dynamic and high-confidence regions, and (ii) exploratory
queries probing occluded areas via a two-stage offset. Only query-specific BEV
features are exchanged and fused through multi-scale gated deformable
attention, reducing payload while preserving accuracy. For evaluation, we
release OPV2V-R and Adver-City-R, CARLA-based datasets with per-point Doppler
radar. SlimComm achieves up to 90% lower bandwidth than full-map sharing while
matching or surpassing prior baselines across varied traffic densities and
occlusions. Dataset and code will be available at: https://url.fzi.de/SlimComm.

</details>


### [143] [Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model](https://arxiv.org/abs/2508.13009)
*Xianglong He,Chunli Peng,Zexiang Liu,Boyang Wang,Yifan Zhang,Qi Cui,Fei Kang,Biao Jiang,Mengyin An,Yangyang Ren,Baixin Xu,Hao-Xiang Guo,Kaixiong Gong,Cyrus Wu,Wei Li,Xuchen Song,Yang Liu,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-Game 2.0是一个实时交互式世界模型，通过少步自回归扩散生成高质量长视频，达到25FPS的超快速度


<details>
  <summary>Details</summary>
Motivation: 现有交互式世界模型依赖双向注意力和冗长推理步骤，限制了实时性能，难以模拟需要即时更新的真实世界动态

Method: 包含三个关键组件：(1)可扩展的数据生产流水线，从Unreal Engine和GTA5环境生成约1200小时带交互标注的视频数据；(2)动作注入模块，支持帧级鼠标键盘输入作为交互条件；(3)基于因果架构的少步蒸馏，实现实时流式视频生成

Result: 能够以25FPS的速度生成高质量分钟级视频，覆盖多样化场景

Conclusion: 该框架推进了交互式世界建模研究，并开源了模型权重和代码库

Abstract: Recent advances in interactive video generations have demonstrated diffusion
model's potential as world models by capturing complex physical dynamics and
interactive behaviors. However, existing interactive world models depend on
bidirectional attention and lengthy inference steps, severely limiting
real-time performance. Consequently, they are hard to simulate real-world
dynamics, where outcomes must update instantaneously based on historical
context and current actions. To address this, we present Matrix-Game 2.0, an
interactive world model generates long videos on-the-fly via few-step
auto-regressive diffusion. Our framework consists of three key components: (1)
A scalable data production pipeline for Unreal Engine and GTA5 environments to
effectively produce massive amounts (about 1200 hours) of video data with
diverse interaction annotations; (2) An action injection module that enables
frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step
distillation based on the casual architecture for real-time and streaming video
generation. Matrix Game 2.0 can generate high-quality minute-level videos
across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our
model weights and codebase to advance research in interactive world modeling.

</details>


### [144] [EgoTwin: Dreaming Body and View in First Person](https://arxiv.org/abs/2508.13013)
*Jingqiao Xiu,Fangzhou Hong,Yicong Li,Mengze Li,Wentao Wang,Sirui Han,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 提出了EgoTwin框架，用于联合生成第一人称视角视频和人体运动，解决了视角对齐和因果交互两个关键挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然外中心视角视频合成取得了很大进展，但第一人称视角视频生成仍然未被充分探索，需要同时建模第一人称视角内容和穿戴者身体运动引起的相机运动模式。

Method: 基于扩散transformer架构构建EgoTwin框架，引入以头部为中心的运动表示，并采用控制论启发的交互机制在注意力操作中显式捕捉视频与运动之间的因果交互。

Result: 构建了大规模的真实世界同步文本-视频-运动三元组数据集，设计了新的评估指标来评估视频-运动一致性，大量实验证明了EgoTwin框架的有效性。

Conclusion: EgoTwin成功解决了第一人称视频和人体运动联合生成的关键挑战，为这一新兴领域提供了有效的解决方案。

Abstract: While exocentric video synthesis has achieved great progress, egocentric
video generation remains largely underexplored, which requires modeling
first-person view content along with camera motion patterns induced by the
wearer's body movements. To bridge this gap, we introduce a novel task of joint
egocentric video and human motion generation, characterized by two key
challenges: 1) Viewpoint Alignment: the camera trajectory in the generated
video must accurately align with the head trajectory derived from human motion;
2) Causal Interplay: the synthesized human motion must causally align with the
observed visual dynamics across adjacent video frames. To address these
challenges, we propose EgoTwin, a joint video-motion generation framework built
on the diffusion transformer architecture. Specifically, EgoTwin introduces a
head-centric motion representation that anchors the human motion to the head
joint and incorporates a cybernetics-inspired interaction mechanism that
explicitly captures the causal interplay between video and motion within
attention operations. For comprehensive evaluation, we curate a large-scale
real-world dataset of synchronized text-video-motion triplets and design novel
metrics to assess video-motion consistency. Extensive experiments demonstrate
the effectiveness of the EgoTwin framework.

</details>


### [145] [HierAdaptMR: Cross-Center Cardiac MRI Reconstruction with Hierarchical Feature Adapters](https://arxiv.org/abs/2508.13026)
*Ruru Xu,Ilkay Oksuz*

Main category: cs.CV

TL;DR: HierAdaptMR是一个分层特征适应框架，通过参数高效的适配器解决多中心心脏MRI重建中的域偏移问题，在CMRxRecon2025数据集上表现出优秀的跨中心泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习心脏MRI重建在多个临床中心部署时面临显著的域偏移挑战，不同扫描仪配置和成像协议导致性能下降。

Method: 采用分层特征适应框架：协议级适配器处理序列特定特征，中心级适配器处理扫描仪相关变化，基于变分展开主干网络。通用适配器通过随机训练学习中心不变适应，实现完全未见中心的泛化。使用多尺度SSIM损失和频域增强进行优化。

Result: 在CMRxRecon2025数据集（5+中心、10+扫描仪、9种模态）上的综合评估显示，该方法在保持重建质量的同时实现了优越的跨中心泛化性能。

Conclusion: HierAdaptMR通过分层适配器有效解决了多中心心脏MRI重建的域偏移问题，为临床部署提供了实用的解决方案。

Abstract: Deep learning-based cardiac MRI reconstruction faces significant domain shift
challenges when deployed across multiple clinical centers with heterogeneous
scanner configurations and imaging protocols. We propose HierAdaptMR, a
hierarchical feature adaptation framework that addresses multi-level domain
variations through parameter-efficient adapters. Our method employs
Protocol-Level Adapters for sequence-specific characteristics and Center-Level
Adapters for scanner-dependent variations, built upon a variational unrolling
backbone. A Universal Adapter enables generalization to entirely unseen centers
through stochastic training that learns center-invariant adaptations. The
framework utilizes multi-scale SSIM loss with frequency domain enhancement and
contrast-adaptive weighting for robust optimization. Comprehensive evaluation
on the CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9
modalities demonstrates superior cross-center generalization while maintaining
reconstruction quality. code: https://github.com/Ruru-Xu/HierAdaptMR

</details>


### [146] [IntelliCap: Intelligent Guidance for Consistent View Sampling](https://arxiv.org/abs/2508.13043)
*Ayaka Yasunaga,Hideo Saito,Dieter Schmalstieg,Shohei Mori*

Main category: cs.CV

TL;DR: 一种基于视觉-语言模型的扫描指导技术，通过识别重要物体并生成球形代理来指导用户进行密集视角采集，提升新视角合成质量


<details>
  <summary>Details</summary>
Motivation: 高质量新视角合成需要均匀密集的视角采样，但人类操作员容易忽略这些要求，现有方法覆盖不充分或忽略视角依赖的材质特性

Method: 利用语义分割和类别识别扩出重要物体，通过视觉-语言模型进行排名，为高排名物体生成球形代理来指导用户扫描

Result: 在真实场景中表现超过传统视角采样策略

Conclusion: 该方法能够有效指导用户进行多尺度扫描，确保重要物体获得充分的图像覆盖，从而提升新视角合成的质量

Abstract: Novel view synthesis from images, for example, with 3D Gaussian splatting,
has made great progress. Rendering fidelity and speed are now ready even for
demanding virtual reality applications. However, the problem of assisting
humans in collecting the input images for these rendering algorithms has
received much less attention. High-quality view synthesis requires uniform and
dense view sampling. Unfortunately, these requirements are not easily addressed
by human camera operators, who are in a hurry, impatient, or lack understanding
of the scene structure and the photographic process. Existing approaches to
guide humans during image acquisition concentrate on single objects or neglect
view-dependent material characteristics. We propose a novel situated
visualization technique for scanning at multiple scales. During the scanning of
a scene, our method identifies important objects that need extended image
coverage to properly represent view-dependent appearance. To this end, we
leverage semantic segmentation and category identification, ranked by a
vision-language model. Spherical proxies are generated around highly ranked
objects to guide the user during scanning. Our results show superior
performance in real scenes compared to conventional view sampling strategies.

</details>


### [147] [Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping](https://arxiv.org/abs/2508.13065)
*Siddharth Khandelwal,Sridhar Kamath,Arjun Jain*

Main category: cs.CV

TL;DR: 这篇论文提出了Odo方法，通过第一个大规模人体形状编辑数据集和涵嵌式渗透模型，实现了高质量的人体形状编辑效果。


<details>
  <summary>Details</summary>
Motivation: 人体形状编辑目前存在数据集缺乏、传统方法导致体型不真实、纹理扭曲和背景不一致等问题，需要提供更好的解决方案。

Method: 构建了18,573张图片的大规模数据集，提出Odo渗透基础方法，结合冻结UNet保持外观细节和ControlNet通过SMPL深度地图指导形状变换。

Result: 方法在每个顶点重建误差上达到7.5mm，显著低于基线方法的13.6mm，生成了更真实的结果。

Conclusion: Odo方法通过新的数据集和渗透模型结构，在人体形状编辑任务上取得了显著成效，为该领域提供了可靠的解决方案。

Abstract: Human shape editing enables controllable transformation of a person's body
shape, such as thin, muscular, or overweight, while preserving pose, identity,
clothing, and background. Unlike human pose editing, which has advanced
rapidly, shape editing remains relatively underexplored. Current approaches
typically rely on 3D morphable models or image warping, often introducing
unrealistic body proportions, texture distortions, and background
inconsistencies due to alignment errors and deformations. A key limitation is
the lack of large-scale, publicly available datasets for training and
evaluating body shape manipulation methods. In this work, we introduce the
first large-scale dataset of 18,573 images across 1523 subjects, specifically
designed for controlled human shape editing. It features diverse variations in
body shape, including fat, muscular and thin, captured under consistent
identity, clothing, and background conditions. Using this dataset, we propose
Odo, an end-to-end diffusion-based method that enables realistic and intuitive
body reshaping guided by simple semantic attributes. Our approach combines a
frozen UNet that preserves fine-grained appearance and background details from
the input image with a ControlNet that guides shape transformation using target
SMPL depth maps. Extensive experiments demonstrate that our method outperforms
prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm,
significantly lower than the 13.6mm observed in baseline methods, while
producing realistic results that accurately match the desired target shapes.

</details>


### [148] [Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation](https://arxiv.org/abs/2508.13068)
*Tanjim Islam Riju,Shuchismita Anwar,Saman Sarker Joy,Farig Sadeque,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 一个两阶段多模态框架，通过视线指导的对比学习提升肺部X光疾病分类性能，并通过模块化报告生成管道生成医学报告，结果显示视线数据能同时提升分类性能咊报告的可解释性。


<details>
  <summary>Details</summary>
Motivation: 利用视线跟踪数据来提升肺部X光疾病分类的准确性，并生成更有解释性的医学报告，以改善医疗诊断过程。

Method: 第一阶段采用视线指导的对比学习架构，整合视觉特征、临床标签、盲框咊视线跟踪信号，使用多项视线注意力损失函数。第二阶段通过模块化报告生成管道，提取信心度加权的诊断关键词，并使用预先建立的解剖学词典进行医学区域映射。

Result: 视线数据的结合使F1分数从0.597提升到0.631（+5.70%），AUC从0.821提升到0.849（+3.41%），同时提高了精度咊召回率。报告生成质量在临床关键词召回率咊ROUGE重合指标上都有显著改善。

Conclusion: 视线数据的集成能够同时提升疾病分类的性能咊生成医学报告的可解释性，为医学图像分析提供了更有效的注意力监督机制。

Abstract: We propose a two-stage multimodal framework that enhances disease
classification and region-aware radiology report generation from chest X-rays,
leveraging the MIMIC-Eye dataset. In the first stage, we introduce a
gaze-guided contrastive learning architecture for disease classification. It
integrates visual features, clinical labels, bounding boxes, and radiologist
eye-tracking signals and is equipped with a novel multi-term gaze-attention
loss combining MSE, KL divergence, correlation, and center-of-mass alignment.
Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC
from 0.821 to 0.849 (+3.41%), while also improving precision and recall,
highlighting the effectiveness of gaze-informed attention supervision. In the
second stage, we present a modular report generation pipeline that extracts
confidence-weighted diagnostic keywords, maps them to anatomical regions using
a curated dictionary constructed from domain-specific priors, and generates
region-aligned sentences via structured prompts. This pipeline improves report
quality as measured by clinical keyword recall and ROUGE overlap. Our results
demonstrate that integrating gaze data improves both classification performance
and the interpretability of generated medical reports.

</details>


### [149] [ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset](https://arxiv.org/abs/2508.13078)
*Qingwen Zeng,Juan E. Tapia,Izan Garcia,Juan M. Espin,Christoph Busch*

Main category: cs.CV

TL;DR: 通过使用Stable Diffusion生成合成真实ID卡图像来解决身份证攻击检测系统中真实样本数量不足的问题，提升检测器的通用性能。


<details>
  <summary>Details</summary>
Motivation: 当前ID卡身份验证攻击检测系统面临真实样本数量稀缺和攻击手段多样化的挑战，现有算法多关注攻击样本生成而忽视了真实样本的限制。

Method: 使用Stable Diffusion生成器生成合成的真实ID卡图像，并在从头开始训练的系统和商业解决方案中评估这些新图像的效果。

Result: 身份验证攻击检测系统将生成的合成图像识别为真实样本，这对检测性能和数据限制问题产生了积极影响。

Conclusion: 使用生成式人工智能技术生成合成真实ID卡图像是一种有效的方法，可以解决真实样本数量不足的问题，提升身份验证系统的检测性能和通用性。

Abstract: Nowadays, the development of a Presentation Attack Detection (PAD) system for
ID cards presents a challenge due to the lack of images available to train a
robust PAD system and the increase in diversity of possible attack instrument
species. Today, most algorithms focus on generating attack samples and do not
take into account the limited number of bona fide images. This work is one of
the first to propose a method for mimicking bona fide images by generating
synthetic versions of them using Stable Diffusion, which may help improve the
generalisation capabilities of the detector. Furthermore, the new images
generated are evaluated in a system trained from scratch and in a commercial
solution. The PAD system yields an interesting result, as it identifies our
images as bona fide, which has a positive impact on detection performance and
data restrictions.

</details>


### [150] [Checkmate: interpretable and explainable RSVQA is the endgame](https://arxiv.org/abs/2508.13086)
*Lucrezia Tosato,Christel Tartini Chappuis,Syrielle Montariol,Flora Weissgerber,Sylvain Lobry,Devis Tuia*

Main category: cs.CV

TL;DR: 一种新的解释性遥感视觉问答模型Checkmate，基于新的棋盘数据集提高决策透明度和可信质性


<details>
  <summary>Details</summary>
Motivation: 解决当前RSVQA模型缺乏可解释性和可解释性的问题，以及数据集偏差导致的短路学习偏向

Method: 创建新的Chessboard数据集（3,123,253个问题，均衡答案分布），开发Checkmate模型能够识别图像中与决策最相关的像素单元

Result: 通过多种模型架构的广泛实验，证明该方法提高了RSVQA系统的透明度

Conclusion: 该研究为遥感视觉问答系统提供了更可信赖的决策支持，通过细粒度的视觉推理和可解释性机制实现了更高的透明性

Abstract: Remote Sensing Visual Question Answering (RSVQA) presents unique challenges
in ensuring that model decisions are both understandable and grounded in visual
content. Current models often suffer from a lack of interpretability and
explainability, as well as from biases in dataset distributions that lead to
shortcut learning. In this work, we tackle these issues by introducing a novel
RSVQA dataset, Chessboard, designed to minimize biases through 3'123'253
questions and a balanced answer distribution. Each answer is linked to one or
more cells within the image, enabling fine-grained visual reasoning.
  Building on this dataset, we develop an explainable and interpretable model
called Checkmate that identifies the image cells most relevant to its
decisions. Through extensive experiments across multiple model architectures,
we show that our approach improves transparency and supports more trustworthy
decision-making in RSVQA systems.

</details>


### [151] [DMS:Diffusion-Based Multi-Baseline Stereo Generation for Improving Self-Supervised Depth Estimation](https://arxiv.org/abs/2508.13091)
*Zihua Liu,Yizhou Li,Songyan Zhang,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: 提出DMS方法，利用扩散模型生成新视角图像来解决自监督立体匹配和深度估计中的遮挡问题，无需额外标注数据即可显著提升性能


<details>
  <summary>Details</summary>
Motivation: 自监督立体匹配和深度估计方法在遮挡区域和画面外区域存在对应像素缺失问题，导致光度重建模糊性，需要解决这一挑战

Method: 基于Stable Diffusion模型微调，通过方向提示生成沿极线方向的新视角图像（左-左视图、右-右视图和中间视图），补充遮挡像素以建立明确的光度对应关系

Result: 在多个基准数据集上达到最先进性能，异常值减少高达35%，仅需未标注的立体图像对进行训练和合成

Conclusion: DMS是一种模型无关的即插即用方法，能有效增强自监督立体匹配和单目深度估计，仅依赖无标注立体图像对

Abstract: While supervised stereo matching and monocular depth estimation have advanced
significantly with learning-based algorithms, self-supervised methods using
stereo images as supervision signals have received relatively less focus and
require further investigation. A primary challenge arises from ambiguity
introduced during photometric reconstruction, particularly due to missing
corresponding pixels in ill-posed regions of the target view, such as
occlusions and out-of-frame areas. To address this and establish explicit
photometric correspondences, we propose DMS, a model-agnostic approach that
utilizes geometric priors from diffusion models to synthesize novel views along
the epipolar direction, guided by directional prompts. Specifically, we
finetune a Stable Diffusion model to simulate perspectives at key positions:
left-left view shifted from the left camera, right-right view shifted from the
right camera, along with an additional novel view between the left and right
cameras. These synthesized views supplement occluded pixels, enabling explicit
photometric reconstruction. Our proposed DMS is a cost-free, ''plug-and-play''
method that seamlessly enhances self-supervised stereo matching and monocular
depth estimation, and relies solely on unlabeled stereo image pairs for both
training and synthesizing. Extensive experiments demonstrate the effectiveness
of our approach, with up to 35% outlier reduction and state-of-the-art
performance across multiple benchmark datasets.

</details>


### [152] [Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants](https://arxiv.org/abs/2508.13101)
*Miftahul Huda,Arsyiah Azahra,Putri Maulida Chairani,Dimas Rizky Ramadhani,Nabila Azhari,Ade Lailani*

Main category: cs.CV

TL;DR: 这篇论文研究了RT-DETR模型在海滩垃圾自动检测中的效果，发现RT-DETR-L模型在检测准确性和计算效率之间取得更好平衡，更适合实时部署。


<details>
  <summary>Details</summary>
Motivation: 海津污染是全球急需解决的环境问题，需要可扩展的自动化监测管理方案。研究旨在评估最新的对象检测模型在海滩垃圾检测中的效果。

Method: 采用现有海滩垃圾数据集，对RT-DETR-Large和RT-DETR-Extra-Large两个模型变体进行严格的对比分析，评估其在自动检测和计数方面的表现。

Result: RT-DETR-X模型达到略高的准确度（mAP@50: 0.816，mAP@50-95: 0.612），但RT-DETR-L模型在处理速度上显著更优（20.1ms vs 34.5ms）。RT-DETR-L模型在性能和效率方面更适合实时应用。

Conclusion: 这项研究为环境保护领域的Transformer基础检测器应用提供了价值见解，强调了模型复杂度与运营可行性之间的关键承偿。RT-DETR-L模型在实际部署中更具实用性。

Abstract: Coastal pollution is a pressing global environmental issue, necessitating
scalable and automated solutions for monitoring and management. This study
investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a
state-of-the-art, end-to-end object detection model, for the automated
detection and counting of beach litter. A rigorous comparative analysis is
conducted between two model variants, RT-DETR-Large (RT-DETR-L) and
RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of
coastal debris. The evaluation reveals that the RT-DETR-X model achieves
marginally superior accuracy, with a mean Average Precision at 50\% IoU
(mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L model's
0.810 and 0.606, respectively. However, this minor performance gain is realized
at a significant computational cost; the RT-DETR-L model demonstrates a
substantially faster inference time of 20.1 ms versus 34.5 ms for the
RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more
practical and efficient solution for real-time, in-field deployment due to its
superior balance of processing speed and detection accuracy. This research
provides valuable insights into the application of advanced Transformer-based
detectors for environmental conservation, highlighting the critical trade-offs
between model complexity and operational viability.

</details>


### [153] [Precise Action-to-Video Generation Through Visual Action Prompts](https://arxiv.org/abs/2508.13104)
*Yuang Wang,Chao Wen,Haoyu Guo,Sida Peng,Minghan Qin,Hujun Bao,Xiaowei Zhou,Ruizhen Hu*

Main category: cs.CV

TL;DR: 提出了视觉动作提示（visual action prompts）作为统一的动作表示方法，通过将动作渲染为视觉骨架来平衡动作精度和跨域动态可迁移性，解决了动作驱动视频生成中的精度-泛化权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的动作驱动视频生成方法面临精度与泛化性的权衡：文本、原始动作或粗糙掩码方法泛化性好但缺乏精度，而智能体中心动作信号精度高但跨域可迁移性差。需要一种既能保持几何精度又具有跨域适应性的动作表示方法。

Method: 提出将动作渲染为精确的视觉提示（视觉骨架）作为领域无关表示，构建从人-物交互和灵巧机器人操作数据中提取骨架的鲁棒流程，通过轻量级微调将视觉骨架集成到预训练视频生成模型中。

Result: 在EgoVid、RT-1和DROID数据集上的实验证明了该方法的有效性，能够实现对复杂交互的精确动作控制，同时保持跨域动态的学习能力。

Conclusion: 视觉动作提示提供了一种统一的动作表示，成功平衡了动作精度和动态可迁移性，为复杂高自由度交互的动作到视频生成提供了有效的解决方案。

Abstract: We present visual action prompts, a unified action representation for
action-to-video generation of complex high-DoF interactions while maintaining
transferable visual dynamics across domains. Action-driven video generation
faces a precision-generality trade-off: existing methods using text, primitive
actions, or coarse masks offer generality but lack precision, while
agent-centric action signals provide precision at the cost of cross-domain
transferability. To balance action precision and dynamic transferability, we
propose to "render" actions into precise visual prompts as domain-agnostic
representations that preserve both geometric precision and cross-domain
adaptability for complex actions; specifically, we choose visual skeletons for
their generality and accessibility. We propose robust pipelines to construct
skeletons from two interaction-rich data sources - human-object interactions
(HOI) and dexterous robotic manipulation - enabling cross-domain training of
action-driven generative models. By integrating visual skeletons into
pretrained video generation models via lightweight fine-tuning, we enable
precise action control of complex interaction while preserving the learning of
cross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the
effectiveness of our proposed approach. Project page:
https://zju3dv.github.io/VAP/.

</details>


### [154] [Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence](https://arxiv.org/abs/2508.13139)
*Ling-Hao Chen,Yuhong Zhang,Zixin Yin,Zhiyang Dou,Xin Chen,Jingbo Wang,Taku Komura,Lei Zhang*

Main category: cs.CV

TL;DR: Motion2Motion是一个无需训练的新框架，通过稀疏骨骼对应关系实现不同拓扑结构角色之间的动作迁移，仅需目标骨骼上的少量示例动作即可工作。


<details>
  <summary>Details</summary>
Motivation: 解决不同骨骼拓扑结构角色间动作迁移的挑战，当前技术难以处理骨骼拓扑不一致问题，且缺乏大规模配对动作数据集限制了数据驱动方法的发展。

Method: 提出训练免费的Motion2Motion框架，通过建立源骨骼和目标骨骼之间的稀疏骨骼对应关系，仅需一个或几个目标骨骼上的示例动作即可实现动作迁移。

Result: 在相似骨骼和跨物种骨骼迁移场景中都实现了高效可靠的性能，成功集成到下游应用和用户界面中，展示了工业应用潜力。

Conclusion: Motion2Motion为解决不同拓扑结构骨骼间的动作迁移问题提供了有效解决方案，具有实际应用价值和工业应用前景。

Abstract: This work studies the challenge of transfer animations between characters
whose skeletal topologies differ substantially. While many techniques have
advanced retargeting techniques in decades, transfer motions across diverse
topologies remains less-explored. The primary obstacle lies in the inherent
topological inconsistency between source and target skeletons, which restricts
the establishment of straightforward one-to-one bone correspondences. Besides,
the current lack of large-scale paired motion datasets spanning different
topological structures severely constrains the development of data-driven
approaches. To address these limitations, we introduce Motion2Motion, a novel,
training-free framework. Simply yet effectively, Motion2Motion works with only
one or a few example motions on the target skeleton, by accessing a sparse set
of bone correspondences between the source and target skeletons. Through
comprehensive qualitative and quantitative evaluations, we demonstrate that
Motion2Motion achieves efficient and reliable performance in both
similar-skeleton and cross-species skeleton transfer scenarios. The practical
utility of our approach is further evidenced by its successful integration in
downstream applications and user interfaces, highlighting its potential for
industrial applications. Code and data are available at
https://lhchen.top/Motion2Motion.

</details>


### [155] [IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion](https://arxiv.org/abs/2508.13153)
*Wenhao Hu,Zesheng Li,Haonan Zhou,Liu Liu,Xuexiang Wen,Zhizhong Su,Xi Li,Gaoang Wang*

Main category: cs.CV

TL;DR: IGFuse是一个新颖的3D场景重建框架，通过融合多视角扫描数据来重建交互式高斯场景，解决了传统方法中物体遮挡和传感器覆盖限制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景重建方法面临物体遮挡和传感器覆盖限制的挑战，多阶段流程容易出错且难以扩展，需要一种能够有效融合多扫描数据并揭示被遮挡区域的新方法。

Method: 构建分割感知的高斯场，通过双向光度和语义一致性约束跨扫描数据，引入伪中间场景状态进行统一对齐，采用协作共剪枝策略优化几何结构。

Result: 实验验证了框架对新场景配置的强泛化能力，能够实现高保真渲染和物体级场景操作，无需密集观测或复杂流程。

Conclusion: IGFuse为真实世界3D重建和实景到仿真转换提供了有效的解决方案，通过多扫描融合成功解决了遮挡问题并实现了交互式场景重建。

Abstract: Reconstructing complete and interactive 3D scenes remains a fundamental
challenge in computer vision and robotics, particularly due to persistent
object occlusions and limited sensor coverage. Multiview observations from a
single scene scan often fail to capture the full structural details. Existing
approaches typically rely on multi stage pipelines, such as segmentation,
background completion, and inpainting or require per-object dense scanning,
both of which are error-prone, and not easily scalable. We propose IGFuse, a
novel framework that reconstructs interactive Gaussian scene by fusing
observations from multiple scans, where natural object rearrangement between
captures reveal previously occluded regions. Our method constructs segmentation
aware Gaussian fields and enforces bi-directional photometric and semantic
consistency across scans. To handle spatial misalignments, we introduce a
pseudo-intermediate scene state for unified alignment, alongside collaborative
co-pruning strategies to refine geometry. IGFuse enables high fidelity
rendering and object level scene manipulation without dense observations or
complex pipelines. Extensive experiments validate the framework's strong
generalization to novel scene configurations, demonstrating its effectiveness
for real world 3D reconstruction and real-to-simulation transfer. Our project
page is available online.

</details>


### [156] [4DNeX: Feed-Forward 4D Generative Modeling Made Easy](https://arxiv.org/abs/2508.13154)
*Zhaoxi Chen,Tianqi Liu,Long Zhuo,Jiawei Ren,Zeng Tao,He Zhu,Fangzhou Hong,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 4DNeX是首个从单张图像生成4D（动态3D）场景的前馈框架，通过微调预训练视频扩散模型实现高效的端到端图像到4D生成，无需计算密集型优化或多帧视频输入。


<details>
  <summary>Details</summary>
Motivation: 解决现有4D生成方法依赖计算密集型优化或需要多帧视频输入的问题，提供更高效的图像到4D生成方案。

Method: 1)构建大规模4D数据集4DNeX-10M；2)引入统一的6D视频表示联合建模RGB和XYZ序列；3)提出适配策略将预训练视频扩散模型重新用于4D建模。

Result: 生成高质量动态点云，支持新颖视角视频合成，在效率和泛化性方面优于现有4D生成方法。

Conclusion: 4DNeX为图像到4D建模提供了可扩展解决方案，为生成式4D世界模型模拟动态场景演化奠定了基础。

Abstract: We present 4DNeX, the first feed-forward framework for generating 4D (i.e.,
dynamic 3D) scene representations from a single image. In contrast to existing
methods that rely on computationally intensive optimization or require
multi-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D
generation by fine-tuning a pretrained video diffusion model. Specifically, 1)
to alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale
dataset with high-quality 4D annotations generated using advanced
reconstruction approaches. 2) we introduce a unified 6D video representation
that jointly models RGB and XYZ sequences, facilitating structured learning of
both appearance and geometry. 3) we propose a set of simple yet effective
adaptation strategies to repurpose pretrained video diffusion models for 4D
modeling. 4DNeX produces high-quality dynamic point clouds that enable
novel-view video synthesis. Extensive experiments demonstrate that 4DNeX
outperforms existing 4D generation methods in efficiency and generalizability,
offering a scalable solution for image-to-4D modeling and laying the foundation
for generative 4D world models that simulate dynamic scene evolution.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [157] [Deep Language Geometry: Constructing a Metric Space from LLM Weights](https://arxiv.org/abs/2508.11676)
*Maksym Shamrai,Vladyslav Hamolia*

Main category: cs.CL

TL;DR: 提出了一种利用LLM内部权重激活构建语言度量空间的新框架，通过自适应剪枝算法自动生成高维向量表示，覆盖106种语言，结果与传统语系分类一致并揭示新的语言联系。


<details>
  <summary>Details</summary>
Motivation: 传统基于手工特征的语言分析方法有限，需要自动化的方法来捕捉语言内在特征和关系。

Method: 使用改进的剪枝算法计算LLM权重重要性分数，自动生成高维语言向量表示，构建语言度量空间。

Result: 在106种语言上验证，结果与传统语系分类高度一致，同时揭示了可能反映历史接触或语言演化的意外语言联系。

Conclusion: 该方法能有效捕捉语言内在特征，为语言分类和演化研究提供了新的自动化工具，代码和语言向量已开源。

Abstract: We introduce a novel framework that utilizes the internal weight activations
of modern Large Language Models (LLMs) to construct a metric space of
languages. Unlike traditional approaches based on hand-crafted linguistic
features, our method automatically derives high-dimensional vector
representations by computing weight importance scores via an adapted pruning
algorithm. Our approach captures intrinsic language characteristics that
reflect linguistic phenomena. We validate our approach across diverse datasets
and multilingual LLMs, covering 106 languages. The results align well with
established linguistic families while also revealing unexpected inter-language
connections that may indicate historical contact or language evolution. The
source code, computed language latent vectors, and visualization tool are made
publicly available at https://github.com/mshamrai/deep-language-geometry.

</details>


### [158] [Can we Evaluate RAGs with Synthetic Data?](https://arxiv.org/abs/2508.11758)
*Jonas van Elburg,Peter van der Putten,Maarten Marx*

Main category: cs.CL

TL;DR: 研究发现LLM生成的合成问答数据在评估检索器配置时能可靠替代人工标注基准，但在比较生成器架构时无法产生一致的RAG排名。


<details>
  <summary>Details</summary>
Motivation: 探索当人工标注基准不可用时，大语言模型生成的合成问答数据是否能有效替代人工标注基准来评估检索增强生成(RAG)系统。

Method: 通过两个实验进行评估：1）固定生成器，变化检索器参数；2）固定检索器参数，变化生成器架构。在四个数据集（两个开放域和两个专有数据集）上进行测试。

Result: 合成基准在评估不同检索器配置的RAG系统时表现可靠，与人工标注基准结果一致；但在比较不同生成器架构时无法产生一致的排名，可能由于任务不匹配和风格偏好导致。

Conclusion: 合成问答数据可以作为检索器配置评估的有效代理，但不适用于生成器架构的比较评估，需要解决任务匹配和风格偏差问题。

Abstract: We investigate whether synthetic question-answer (QA) data generated by large
language models (LLMs) can serve as an effective proxy for human-labeled
benchmarks when such data is unavailable. We assess the reliability of
synthetic benchmarks across two experiments: one varying retriever parameters
while keeping the generator fixed, and another varying the generator with fixed
retriever parameters. Across four datasets, of which two open-domain and two
proprietary, we find that synthetic benchmarks reliably rank the RAGs varying
in terms of retriever configuration, aligning well with human-labeled benchmark
baselines. However, they fail to produce consistent RAG rankings when comparing
generator architectures. The breakdown possibly arises from a combination of
task mismatch between the synthetic and human benchmarks, and stylistic bias
favoring certain generators.

</details>


### [159] [Limitation Learning: Catching Adverse Dialog with GAIL](https://arxiv.org/abs/2508.11767)
*Noah Kasmanoff,Rahul Zalkikar*

Main category: cs.CL

TL;DR: 应用模仿学习到对话任务中，通过专家演示训练策略和判别器，策略能基于提示生成对话，判别器可区分专家和合成对话，该方法可识别对话模型的负面行为


<details>
  <summary>Details</summary>
Motivation: 在缺乏奖励机制的情况下，利用模仿学习从专家演示中学习对话策略，同时训练判别器来检测对话模型的行为限制

Method: 采用模仿学习方法，基于专家对话演示训练生成策略和判别分类器，策略根据输入状态生成对话响应，判别器区分专家对话和合成对话

Result: 成功训练出有效的对话策略，但判别器结果显示对话模型存在局限性，该方法能够识别对话导向任务中常见数据模型的不良行为

Conclusion: 模仿学习技术可用于对话任务，不仅能生成有效策略，还能通过判别器识别和诊断对话模型的缺陷和负面行为

Abstract: Imitation learning is a proven method for creating a policy in the absence of
rewards, by leveraging expert demonstrations. In this work, we apply imitation
learning to conversation. In doing so, we recover a policy capable of talking
to a user given a prompt (input state), and a discriminator capable of
classifying between expert and synthetic conversation. While our policy is
effective, we recover results from our discriminator that indicate the
limitations of dialog models. We argue that this technique can be used to
identify adverse behavior of arbitrary data models common for dialog oriented
tasks.

</details>


### [160] [Investigating Transcription Normalization in the Faetar ASR Benchmark](https://arxiv.org/abs/2508.11771)
*Leo Peckham,Michael Ong,Naomi Nagy,Ewan Dunbar*

Main category: cs.CL

TL;DR: 该研究分析了Faetar自动语音识别基准中转写不一致性的作用，发现虽然存在不一致性但不是主要挑战，最终认为该任务仍极其困难。


<details>
  <summary>Details</summary>
Motivation: 调查低资源ASR基准中转写不一致性对任务难度的影响，以明确真正的挑战来源。

Method: 使用手工构建的小词典，分析转写不一致性；测试二元词语言模型和有限词典约束的解码效果。

Result: 转写不一致性存在但不是主要挑战；二元词语言模型无效；有限词典约束的解码有益。

Conclusion: Faetar ASR任务极其困难，转写不一致性不是主要问题，需要更有效的方法来应对这个挑战。

Abstract: We examine the role of transcription inconsistencies in the Faetar Automatic
Speech Recognition benchmark, a challenging low-resource ASR benchmark. With
the help of a small, hand-constructed lexicon, we conclude that find that,
while inconsistencies do exist in the transcriptions, they are not the main
challenge in the task. We also demonstrate that bigram word-based language
modelling is of no added benefit, but that constraining decoding to a finite
lexicon can be beneficial. The task remains extremely difficult.

</details>


### [161] [A Multi-Task Evaluation of LLMs' Processing of Academic Text Input](https://arxiv.org/abs/2508.11779)
*Tianyi Li,Yu Qin,Olivia R. Liu Sheng*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（如Google Gemini）在学术文本处理中的能力，发现其在学术同行评审中的表现有限，不建议无检查地使用LLMs构建同行评审。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在科学发现中的实际应用潜力，特别是在协助学术同行评审方面的能力，当前这一话题存在激烈争论。

Method: 采用四个任务评估LLMs：内容复现/比较/评分/反思，每个任务要求LLM扮演不同角色（预言家/判断仲裁者/知识仲裁者/合作者），使用一流信息系统期刊文章作为输入文本，结合多种文本指标进行严格性能评估。

Result: Gemini在学术文本摘要和释义方面表现可接受，但在文本排序方面扩展性较弱，评分时区分度差，反思虽然自洽但缺乏深度洞察。基于指标的内部（语言评估）、外部（与真实值比较）和人工评估结果一致，且对提示变化具有鲁棒性。

Conclusion: LLMs的文本处理能力不足以支持其在同行评审中的无检查使用，证据表明其表现存在妥协，不建议在构建同行评审时盲目依赖LLMs。

Abstract: How much large language models (LLMs) can aid scientific discovery, notably
in assisting academic peer review, is in heated debate. Between a literature
digest and a human-comparable research assistant lies their practical
application potential. We organize individual tasks that computer science
studies employ in separate terms into a guided and robust workflow to evaluate
LLMs' processing of academic text input. We employ four tasks in the
assessment: content reproduction/comparison/scoring/reflection, each demanding
a specific role of the LLM (oracle/judgmental arbiter/knowledgeable
arbiter/collaborator) in assisting scholarly works, and altogether testing LLMs
with questions that increasingly require intellectual capabilities towards a
solid understanding of scientific texts to yield desirable solutions. We
exemplify a rigorous performance evaluation with detailed instructions on the
prompts. Adopting first-rate Information Systems articles at three top journals
as the input texts and an abundant set of text metrics, we record a compromised
performance of the leading LLM - Google's Gemini: its summary and paraphrase of
academic text is acceptably reliable; using it to rank texts through pairwise
text comparison is faintly scalable; asking it to grade academic texts is prone
to poor discrimination; its qualitative reflection on the text is
self-consistent yet hardly insightful to inspire meaningful research. This
evidence against an endorsement of LLMs' text-processing capabilities is
consistent across metric-based internal (linguistic assessment), external
(comparing to the ground truth), and human evaluation, and is robust to the
variations of the prompt. Overall, we do not recommend an unchecked use of LLMs
in constructing peer reviews.

</details>


### [162] [LLM-Guided Planning and Summary-Based Scientific Text Simplification: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11816)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: 提出了一种基于大语言模型的两阶段科学文本简化方法，分别在句子级别和文档级别进行简化，通过结构化规划和摘要指导来提升简化的一致性和上下文忠实度。


<details>
  <summary>Details</summary>
Motivation: 解决科学文本简化任务中保持上下文一致性和忠实度的问题，通过结构化方法提升简化质量。

Method: 使用大语言模型进行两阶段简化：句子级别先生成结构化规划再按规划简化；文档级别先生成摘要再用摘要指导简化过程。

Result: 开发了一个能够产生更连贯和上下文忠实简化结果的框架。

Conclusion: 基于大语言模型的两阶段结构化方法能有效提升科学文本简化的质量和一致性。

Abstract: In this paper, we present our approach for the CLEF 2025 SimpleText Task 1,
which addresses both sentence-level and document-level scientific text
simplification. For sentence-level simplification, our methodology employs
large language models (LLMs) to first generate a structured plan, followed by
plan-driven simplification of individual sentences. At the document level, we
leverage LLMs to produce concise summaries and subsequently guide the
simplification process using these summaries. This two-stage, LLM-based
framework enables more coherent and contextually faithful simplifications of
scientific text.

</details>


### [163] [Hallucination Detection and Mitigation in Scientific Text Simplification using Ensemble Approaches: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11823)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: 提出了一个集成多种方法的框架来检测科学文本简化中的创造性生成和信息失真，包括BERT分类器、语义相似度、自然语言推理和LLM推理，并通过元分类器整合这些信号


<details>
  <summary>Details</summary>
Motivation: 解决CLEF 2025 SimpleText任务2中科学文本简化过程中的创造性生成和信息失真检测问题，提高检测的鲁棒性

Method: 构建集成框架，结合BERT分类器、语义相似度测量、自然语言推理模型和LLM推理，使用元分类器整合多种信号；对于基于原文的生成，采用LLM后编辑系统来基于原始输入文本修订简化内容

Result: 该方法整合了多种检测信号，通过元分类器增强了虚假信息和失真检测的鲁棒性

Conclusion: 提出的集成框架能够有效检测科学文本简化中的创造性生成和信息失真问题，为科学传播中的文本简化质量评估提供了有效解决方案

Abstract: In this paper, we describe our methodology for the CLEF 2025 SimpleText Task
2, which focuses on detecting and evaluating creative generation and
information distortion in scientific text simplification. Our solution
integrates multiple strategies: we construct an ensemble framework that
leverages BERT-based classifier, semantic similarity measure, natural language
inference model, and large language model (LLM) reasoning. These diverse
signals are combined using meta-classifiers to enhance the robustness of
spurious and distortion detection. Additionally, for grounded generation, we
employ an LLM-based post-editing system that revises simplifications based on
the original input texts.

</details>


### [164] [A Survey of Idiom Datasets for Psycholinguistic and Computational Research](https://arxiv.org/abs/2508.11828)
*Michael Flor,Xinyi Liu,Anna Feldman*

Main category: cs.CL

TL;DR: 这篇调查性论文综述了语言学和计算语言学领域中用于研究习语的53个数据集，分析了它们在内容、形式和用途方面的特点。


<details>
  <summary>Details</summary>
Motivation: 习语作为一种固定的修辞表达，其含义无法从单词推断，这给计算处理和人类实验研究带来了挑战。需要系统性地评估现有的习语研究数据集。

Method: 调查分析53个习语数据集，包括心理语言学资源（含熟悉度、透明度等评分）和计算语言学数据集（支持习语检测、重写等任务），分析其注释实践、覆盖范围和任务建模方式。

Result: 识别出了注释实践、覆盖范围和任务建模方面的趋势。虽然最近的研究扩大了语言覆盖和任务多样性，但心理语言学和计算语言学在习语研究方面仍然缺乏联系。

Conclusion: 该调查揭示了习语研究数据集的当前状况，指出了两个领域之间的分隔问题，为未来的交叉研究提供了见解。

Abstract: Idioms are figurative expressions whose meanings often cannot be inferred
from their individual words, making them difficult to process computationally
and posing challenges for human experimental studies. This survey reviews
datasets developed in psycholinguistics and computational linguistics for
studying idioms, focusing on their content, form, and intended use.
Psycholinguistic resources typically contain normed ratings along dimensions
such as familiarity, transparency, and compositionality, while computational
datasets support tasks like idiomaticity detection/classification,
paraphrasing, and cross-lingual modeling. We present trends in annotation
practices, coverage, and task framing across 53 datasets. Although recent
efforts expanded language coverage and task diversity, there seems to be no
relation yet between psycholinguistic and computational research on idioms.

</details>


### [165] [Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI Agents with Hormones and Emotions](https://arxiv.org/abs/2508.11829)
*Leigh Levinson,Christopher J. Agostino*

Main category: cs.CL

TL;DR: 该研究提出将模拟的月经和昼夜节律周期通过系统提示嵌入大型语言模型，以生物节律作为自然相关性过滤器来解决AI的框架问题，发现模型性能随激素水平变化并揭示语言模型中的社会偏见


<details>
  <summary>Details</summary>
Motivation: 解决AI系统面临的框架问题——从指数级大的可能性空间中确定上下文相关信息，受生物节律（特别是激素周期）作为自然相关性过滤器的启发

Method: 开发一个框架，通过周期性函数模拟关键激素（雌激素、睾酮、皮质醇）生成系统提示，将模拟的月经和昼夜节律周期嵌入大型语言模型

Result: 语言分析显示情感和风格变化与生物阶段相关：悲伤在月经期达到峰值，快乐在排卵期占主导；昼夜模式显示早晨乐观转向夜间内省。在SQuAD、MMLU、Hellaswag和AI2-ARC基准测试中表现出与生物预期一致的微妙但一致的性能变化，在中等而非极端激素范围内达到最佳功能

Conclusion: 该方法为上下文AI提供了新颖方法，同时揭示了语言模型中关于性别和生物学的社会偏见是如何被嵌入的

Abstract: Despite significant advances, AI systems struggle with the frame problem:
determining what information is contextually relevant from an exponentially
large possibility space. We hypothesize that biological rhythms, particularly
hormonal cycles, serve as natural relevance filters that could address this
fundamental challenge. We develop a framework that embeds simulated menstrual
and circadian cycles into Large Language Models through system prompts
generated from periodic functions modeling key hormones including estrogen,
testosterone, and cortisol. Across multiple state-of-the-art models, linguistic
analysis reveals emotional and stylistic variations that track biological
phases; sadness peaks during menstruation while happiness dominates ovulation
and circadian patterns show morning optimism transitioning to nocturnal
introspection. Benchmarking on SQuAD, MMLU, Hellaswag, and AI2-ARC demonstrates
subtle but consistent performance variations aligning with biological
expectations, including optimal function in moderate rather than extreme
hormonal ranges. This methodology provides a novel approach to contextual AI
while revealing how societal biases regarding gender and biology are embedded
within language models.

</details>


### [166] [When Does Language Transfer Help? Sequential Fine-Tuning for Cross-Lingual Euphemism Detection](https://arxiv.org/abs/2508.11831)
*Julia Sammartino,Libby Barak,Jing Peng,Anna Feldman*

Main category: cs.CL

TL;DR: 跨语言顺序微调可有效提升委婉语检测性能，特别是对低资源语言如约鲁巴语和土耳其语，XLM-R效果更好但易受预训练差距影响，mBERT更稳定但性能较低


<details>
  <summary>Details</summary>
Motivation: 委婉语具有文化差异性和模糊性，对语言模型特别是低资源环境下的处理构成挑战，需要研究跨语言迁移方法

Method: 使用XLM-R和mBERT模型，比较顺序微调、单语微调和同步微调三种策略，分析语言配对、类型学特征和预训练覆盖率的影响

Result: 顺序微调使用高资源L1语言可显著提升L2语言性能，XLM-R获得更大提升但对预训练差距更敏感且存在灾难性遗忘，mBERT结果更稳定但性能较低

Conclusion: 顺序微调是提升多语言模型委婉语检测性能的简单有效策略，特别适用于涉及低资源语言的情况

Abstract: Euphemisms are culturally variable and often ambiguous, posing challenges for
language models, especially in low-resource settings. This paper investigates
how cross-lingual transfer via sequential fine-tuning affects euphemism
detection across five languages: English, Spanish, Chinese, Turkish, and
Yoruba. We compare sequential fine-tuning with monolingual and simultaneous
fine-tuning using XLM-R and mBERT, analyzing how performance is shaped by
language pairings, typological features, and pretraining coverage. Results show
that sequential fine-tuning with a high-resource L1 improves L2 performance,
especially for low-resource languages like Yoruba and Turkish. XLM-R achieves
larger gains but is more sensitive to pretraining gaps and catastrophic
forgetting, while mBERT yields more stable, though lower, results. These
findings highlight sequential fine-tuning as a simple yet effective strategy
for improving euphemism detection in multilingual models, particularly when
low-resource languages are involved.

</details>


### [167] [SupraTok: Cross-Boundary Tokenization for Enhanced Language Model Performance](https://arxiv.org/abs/2508.11857)
*Andrei-Valentin Tănase,Elena Pelican*

Main category: cs.CL

TL;DR: SupraTok是一种新颖的分词架构，通过跨边界模式学习、熵驱动数据筛选和多阶段课程学习三大创新，实现了比主流分词器更高的效率（31%提升）和竞争性的多语言性能，在GPT-2规模模型上带来8.4-9.5%的基准测试提升。


<details>
  <summary>Details</summary>
Motivation: 当前分词技术作为NLP基础瓶颈被忽视，策略相对静态，尽管模型架构取得了显著进展。需要重新思考子词分割以提升语义保持和压缩效率。

Method: 基于Byte-Pair Encoding扩展，学习"superword"令牌（连贯的多词表达），包含：1）跨边界模式学习发现多词语义单元；2）熵驱动数据优化训练语料质量；3）多阶段课程学习确保稳定收敛。

Result: 英语分词效率提升31%（5.91 vs 4.51字符/令牌），优于OpenAI o200k和Google Gemma 3分词器；在38种语言保持竞争性能；GPT-2规模模型在HellaSWAG和MMLU基准分别提升8.4%和9.5%。

Conclusion: 高效分词可以作为架构创新的补充路径来提升语言模型性能，虽然当前结果在较小规模上表现良好，但需要在大规模模型上进一步验证。

Abstract: Tokenization remains a fundamental yet underexplored bottleneck in natural
language processing, with strategies largely static despite remarkable progress
in model architectures. We present SupraTok, a novel tokenization architecture
that reimagines subword segmentation through three innovations: cross-boundary
pattern learning that discovers multi-word semantic units, entropy-driven data
curation that optimizes training corpus quality, and multi-phase curriculum
learning for stable convergence. Our approach extends Byte-Pair Encoding by
learning "superword" tokens, coherent multi-word expressions that preserve
semantic unity while maximizing compression efficiency. SupraTok achieves 31%
improvement in English tokenization efficiency (5.91 versus 4.51 characters per
token) compared to OpenAI's o200k tokenizer and 30% improvement over Google's
Gemma 3 tokenizer (256k vocabulary), while maintaining competitive performance
across 38 languages. When integrated with a GPT-2 scale model (124M parameters)
trained on 10 billion tokens from the FineWeb-Edu dataset, SupraTok yields 8.4%
improvement on HellaSWAG and 9.5% on MMLU benchmarks without architectural
modifications. While these results are promising at this scale, further
validation at larger model scales is needed. These findings suggest that
efficient tokenization can complement architectural innovations as a path to
improved language model performance.

</details>


### [168] [In-Context Examples Matter: Improving Emotion Recognition in Conversation with Instruction Tuning](https://arxiv.org/abs/2508.11889)
*Hui Ma,Bo Zhang,Jinpeng Hu,Zenglin Shi*

Main category: cs.CL

TL;DR: 提出了InitERC，一个简单有效的一阶段上下文指令调优框架，用于对话情感识别，通过上下文学习实现说话者-上下文-情感的对齐


<details>
  <summary>Details</summary>
Motivation: 现有的多阶段指令调优方法无法联合捕捉说话者特征和对话上下文之间的动态交互，导致说话者身份、上下文线索和情感状态在统一框架内对齐效果不佳

Method: 提出InitERC框架，包含四个组件：演示池构建、上下文示例选择、提示模板设计和上下文指令调优，通过单阶段上下文指令调优让大语言模型从上下文示例中学习说话者-上下文-情感对齐

Result: 在三个广泛使用的数据集上进行大量实验，证明InitERC相比最先进的基线方法取得了显著改进

Conclusion: InitERC通过单阶段上下文指令调优有效解决了说话者-上下文-情感对齐问题，为对话情感识别提供了简单而有效的解决方案

Abstract: Emotion recognition in conversation (ERC) aims to identify the emotion of
each utterance in a conversation, playing a vital role in empathetic artificial
intelligence. With the growing of large language models (LLMs), instruction
tuning has emerged as a critical paradigm for ERC. Existing studies mainly
focus on multi-stage instruction tuning, which first endows LLMs with speaker
characteristics, and then conducts context-aware instruction tuning to
comprehend emotional states. However, these methods inherently constrains the
capacity to jointly capture the dynamic interaction between speaker
characteristics and conversational context, resulting in weak alignment among
speaker identity, contextual cues, and emotion states within a unified
framework. In this paper, we propose InitERC, a simple yet effective one-stage
in-context instruction tuning framework for ERC. InitERC adapts LLMs to learn
speaker-context-emotion alignment from context examples via in-context
instruction tuning. Specifically, InitERC comprises four components, i.e.,
demonstration pool construction, in-context example selection, prompt template
design, and in-context instruction tuning. To explore the impact of in-context
examples, we conduct a comprehensive study on three key factors: retrieval
strategy, example ordering, and the number of examples. Extensive experiments
on three widely used datasets demonstrate that our proposed InitERC achieves
substantial improvements over the state-of-the-art baselines.

</details>


### [169] [CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures](https://arxiv.org/abs/2508.11915)
*Punya Syon Pandey,Yongjin Yang,Jiarui Liu,Zhijing Jin*

Main category: cs.CL

TL;DR: 提出了CORE评分指标来量化多智能体系统中语言使用的有效性，通过整合聚类熵、词汇重复和语义相似性来评估对话质量，发现在合作设置中语言重复更多但词汇扩展更大，而竞争环境中词汇更受限。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体之间的博弈互动虽然展现出许多涌现能力，但语言多样性的量化不足，需要开发一个能够衡量多智能体系统语言使用有效性的评估指标。

Method: 提出CORE评分指标，整合聚类熵、词汇重复和语义相似性三个维度。在竞争、合作和中立三种博弈设置下进行成对LLM对话实验，并基于Zipf定律和Heaps定律分析词汇频率分布和词汇增长模式。

Result: 合作设置表现出更陡峭的Zipf分布和更高的Heaps指数，表明更多重复但词汇扩展更大；竞争互动显示较低的Zipf和Heaps指数，反映较少重复和更受限的词汇。

Conclusion: 社会激励因素显著影响语言适应模式，CORE可作为衡量多智能体LLM系统语言鲁棒性的有效诊断工具，为理解语言在社交环境中的演化提供了新见解。

Abstract: Game-theoretic interactions between agents with Large Language Models (LLMs)
have revealed many emergent capabilities, yet the linguistic diversity of these
interactions has not been sufficiently quantified. In this paper, we present
the Conversational Robustness Evaluation Score: CORE, a metric to quantify the
effectiveness of language use within multi-agent systems across different
game-theoretic interactions. CORE integrates measures of cluster entropy,
lexical repetition, and semantic similarity, providing a direct lens of dialog
quality. We apply CORE to pairwise LLM dialogs across competitive, cooperative,
and neutral settings, further grounding our analysis in Zipf's and Heaps' Laws
to characterize word frequency distributions and vocabulary growth. Our
findings show that cooperative settings exhibit both steeper Zipf distributions
and higher Heap exponents, indicating more repetition alongside greater
vocabulary expansion. In contrast, competitive interactions display lower Zipf
and Heaps exponents, reflecting less repetition and more constrained
vocabularies. These results provide new insights into how social incentives
influence language adaptation, and highlight CORE as a robust diagnostic for
measuring linguistic robustness in multi-agent LLM systems. Our code is
available at https://github.com/psyonp/core.

</details>


### [170] [LLMs Struggle with NLI for Perfect Aspect: A Cross-Linguistic Study in Chinese and Japanese](https://arxiv.org/abs/2508.11927)
*Jie Lu,Du Jin,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 中日语言缺乏完美体的独立语法标记，这给自然语言推理带来挑战。研究构建了语言学动机的模板基于NLI数据集，发现即使先进的大语言模型也难以处理微妙的时态和参考时间转移。


<details>
  <summary>Details</summary>
Motivation: 因为中文和日语缺乏像英语那样的独立完美体语法标记（如had, has, will have），这给自然语言推理特别是时态推理带来了重大挑战。研究者想要探索现有模型在这些语言中处理完美体时态的能力。

Method: 采用语言学动机的模板方法，构建了一个基于模板的NLI数据集，每种语言包含1,350对比对。该数据集专门注重于完美体的时态表达。

Result: 实验结果显示，即使是先进的大语言模型也在时态推理上遇到困难，特别是在检测微妙的时态变化和参考时间转移方面表现差强。

Conclusion: 这些发现显著地揭示了现有模型的限制，并强调了在时态语义学领域进行跨语言评估的必要性。研究为这一领域提供了公开的数据集资源。

Abstract: Unlike English, which uses distinct forms (e.g., had, has, will have) to mark
the perfect aspect across tenses, Chinese and Japanese lack separate
grammatical forms for tense within the perfect aspect, which complicates
Natural Language Inference (NLI). Focusing on the perfect aspect in these
languages, we construct a linguistically motivated, template-based NLI dataset
(1,350 pairs per language). Experiments reveal that even advanced LLMs struggle
with temporal inference, particularly in detecting subtle tense and
reference-time shifts. These findings highlight model limitations and
underscore the need for cross-linguistic evaluation in temporal semantics. Our
dataset is available at https://github.com/Lujie2001/CrossNLI.

</details>


### [171] [CAMF: Collaborative Adversarial Multi-agent Framework for Machine Generated Text Detection](https://arxiv.org/abs/2508.11933)
*Yue Wang,Liesheng Wei,Yuxiang Wang*

Main category: cs.CL

TL;DR: 一种新的协作对抗多段框架CAMF，通过多个LLM基于代理的协同工作，在零样本机器生成文本检测中显著超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的零样本机器生成文本检测方法存在显著缺陷：分析浅层、关注属性有限，缺乏对语言维度一致性的研究。

Method: 设计了协作对抗多段框架CAMF，使用多个LLM基于代理进行三阶段协同过程：多维语言特征提取、对抗性一致性探测、综合判断聚合。

Result: 经验评估显示CAMF在零样本MGT检测方面显著超过最先进技术。

Conclusion: CAMF框架通过深入分析跨维度文本不一致性，能够有效检测非人类起源的机器生成文本，为防范假信息和维护学术完整性提供了新的解决方案。

Abstract: Detecting machine-generated text (MGT) from contemporary Large Language
Models (LLMs) is increasingly crucial amid risks like disinformation and
threats to academic integrity. Existing zero-shot detection paradigms, despite
their practicality, often exhibit significant deficiencies. Key challenges
include: (1) superficial analyses focused on limited textual attributes, and
(2) a lack of investigation into consistency across linguistic dimensions such
as style, semantics, and logic. To address these challenges, we introduce the
\textbf{C}ollaborative \textbf{A}dversarial \textbf{M}ulti-agent
\textbf{F}ramework (\textbf{CAMF}), a novel architecture using multiple
LLM-based agents. CAMF employs specialized agents in a synergistic three-phase
process: \emph{Multi-dimensional Linguistic Feature Extraction},
\emph{Adversarial Consistency Probing}, and \emph{Synthesized Judgment
Aggregation}. This structured collaborative-adversarial process enables a deep
analysis of subtle, cross-dimensional textual incongruities indicative of
non-human origin. Empirical evaluations demonstrate CAMF's significant
superiority over state-of-the-art zero-shot MGT detection techniques.

</details>


### [172] [Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases](https://arxiv.org/abs/2508.12031)
*Shaozhe Yin,Jinyu Guo,Kai Shuang,Xia Liu,Ruize Ou*

Main category: cs.CL

TL;DR: 基于指令的对比学习持续关系提取方法，通过分析错误案例来进行双任务微调，有效减少恐怖忘却


<details>
  <summary>Details</summary>
Motivation: 现有的持续关系提取方法没有充分利用能够更有效反映模型认知偏见的错误案例

Method: 将每个任务的训练和记忆数据按初始响应正确性分为两部分，通过双任务微调工作，利用LLM的指令调整能力进行对比学习调整

Result: 在TACRED和FewRel数据集上达到了新的最高水平，显著提升了持续关系提取性能

Conclusion: 专门利用错误案例对于减少恐怖忘却具有重要意义，指令基于对比学习的方法更适合大语言模型

Abstract: Continual Relation Extraction (CRE) aims to continually learn new emerging
relations while avoiding catastrophic forgetting. Existing CRE methods mainly
use memory replay and contrastive learning to mitigate catastrophic forgetting.
However, these methods do not attach importance to the error cases that can
reveal the model's cognitive biases more effectively. To address this issue, we
propose an instruction-based continual contrastive tuning approach for Large
Language Models (LLMs) in CRE. Different from existing CRE methods that
typically handle the training and memory data in a unified manner, this
approach splits the training and memory data of each task into two parts
respectively based on the correctness of the initial responses and treats them
differently through dual-task fine-tuning. In addition, leveraging the
advantages of LLM's instruction-following ability, we propose a novel
instruction-based contrastive tuning strategy for LLM to continuously correct
current cognitive biases with the guidance of previous data in an
instruction-tuning manner, which mitigates the gap between old and new
relations in a more suitable way for LLMs. We experimentally evaluate our model
on TACRED and FewRel, and the results show that our model achieves new
state-of-the-art CRE performance with significant improvements, demonstrating
the importance of specializing in exploiting error cases.

</details>


### [173] [Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation](https://arxiv.org/abs/2508.12040)
*Jinyi Han,Tingyun Li,Shisong Chen,Jie Shi,Xinyi Wang,Guanglei Yue,Jiaqing Liang,Xin Lin,Liqian Wen,Zulong Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: FineCE是一种新颖的细粒度置信度估计方法，通过监督学习训练模型来预测文本生成过程中的连续置信度分数，解决了LLMs过度自信的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型缺乏自我意识，经常对错误预测给出高置信度分数，现有方法无法提供生成过程中的细粒度连续置信度估计。

Method: 开发数据构建管道捕获LLM响应的概率分布，训练监督模型预测置信度分数，提出后向置信度集成策略和三种最优估计位置识别策略。

Result: 在多个基准数据集上的广泛实验表明，FineCE始终优于现有的经典置信度估计方法。

Conclusion: FineCE通过细粒度置信度估计显著提高了LLM生成输出的可信度和可靠性，代码和基线已开源。

Abstract: While large language models (LLMs) have demonstrated remarkable performance
across diverse tasks, they fundamentally lack self-awareness and frequently
exhibit overconfidence, assigning high confidence scores to incorrect
predictions. Accurate confidence estimation is therefore critical for enhancing
the trustworthiness and reliability of LLM-generated outputs. However, existing
approaches suffer from coarse-grained scoring mechanisms that fail to provide
fine-grained, continuous confidence estimates throughout the generation
process. To address these limitations, we introduce FineCE, a novel confidence
estimation method that delivers accurate, fine-grained confidence scores during
text generation. Specifically, we first develop a comprehensive pipeline for
constructing training data that effectively captures the underlying
probabilistic distribution of LLM responses, and then train a model to predict
confidence scores for arbitrary text sequences in a supervised manner.
Furthermore, we propose a Backward Confidence Integration (BCI) strategy that
leverages information from the subsequent text to enhance confidence estimation
for the current sequence during inference. We also introduce three strategies
for identifying optimal positions to perform confidence estimation within the
generation process. Extensive experiments on multiple benchmark datasets
demonstrate that FineCE consistently outperforms existing classical confidence
estimation methods. Our code and all baselines used in the paper are available
on GitHub.

</details>


### [174] [J6: Jacobian-Driven Role Attribution for Multi-Objective Prompt Optimization in LLMs](https://arxiv.org/abs/2508.12086)
*Yao Wu*

Main category: cs.CL

TL;DR: J6方法通过雅可比矩阵分解为六个可解释组件，为多目标LLM提示优化提供结构化梯度分析框架，解决事实性和置信度平衡问题


<details>
  <summary>Details</summary>
Motivation: 现有多目标优化方法依赖标量梯度聚合，忽略了目标与参数间的几何结构关系，难以处理复杂交互

Method: 提出J6结构化雅可比方法，将梯度交互矩阵分解为6个可解释组件，支持硬决策和软策略的动态更新框架

Result: 该方法提供了参数归因、任务干扰和几何对齐适应的洞察，形成了冲突感知的提示优化机制

Conclusion: J6为多目标神经调优引入了结构化雅可比推理的新途径，提供了原则性和可扩展的优化机制

Abstract: In large language model (LLM) adaptation, balancing multiple optimization
objectives such as improving factuality (heat) and increasing confidence (via
low entropy) poses a fundamental challenge, especially when prompt parameters
(e.g., hidden-layer insertions h and embedding modifications w) interact in
non-trivial ways. Existing multi-objective optimization strategies often rely
on scalar gradient aggregation, ignoring the deeper geometric structure between
objectives and parameters. We propose J6, a structured Jacobian-based method
that decomposes the gradient interaction matrix into six interpretable
components. This decomposition enables both hard decision-making (e.g.,
choosing the dominant update direction via argmax) and soft strategies (e.g.,
attention-style weighting via softmax over J6), forming a dynamic update
framework that adapts to local conflict and synergy. Moreover, the
interpretable structure of J6 provides insight into parameter attribution, task
interference, and geometry-aligned adaptation. Our work introduces a principled
and extensible mechanism for conflict-aware prompt optimization, and opens a
new avenue for incorporating structured Jacobian reasoning into multi-objective
neural tuning.

</details>


### [175] [STEM: Efficient Relative Capability Evaluation of LLMs through Structured Transition Samples](https://arxiv.org/abs/2508.12096)
*Haiquan Hu,Jiazhi Jiang,Shiyou Xu,Ruhan Zeng,Tian Wang*

Main category: cs.CL

TL;DR: STEM是一个轻量级、可解释的评估框架，通过分析同架构不同参数规模LLM之间的性能转换来识别关键样本，从而高效估计未知模型的能力位置。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力快速提升，传统基准测试存在过拟合问题且计算成本高昂，难以有效区分模型间的真实能力差异。

Method: 提出STEM方法，通过识别重要转换样本(STS)来分析同架构不同规模模型间的性能转换模式，构建STS池来估计未知模型的能力排名。

Result: 在六个多样化基准测试上验证，STEM能够可靠捕捉性能趋势，与真实模型能力排名一致。

Conclusion: STEM是一种实用且可扩展的细粒度、架构无关的LLM评估方法，为高效模型评估提供了新思路。

Abstract: Evaluating large language models (LLMs) has become increasingly challenging
as model capabilities advance rapidly. While recent models often achieve higher
scores on standard benchmarks, these improvements do not consistently reflect
enhanced real-world reasoning capabilities. Moreover, widespread overfitting to
public benchmarks and the high computational cost of full evaluations have made
it both expensive and less effective to distinguish meaningful differences
between models. To address these challenges, we propose the \textbf{S}tructured
\textbf{T}ransition \textbf{E}valuation \textbf{M}ethod (STEM), a lightweight
and interpretable evaluation framework for efficiently estimating the relative
capabilities of LLMs. STEM identifies \textit{significant transition samples}
(STS) by analyzing consistent performance transitions among LLMs of the same
architecture but varying parameter scales. These samples enable STEM to
effectively estimate the capability position of an unknown model. Qwen3 model
family is applied to construct the STS pool on six diverse and representative
benchmarks. To assess generalizability. Experimental results indicate that STEM
reliably captures performance trends, aligns with ground-truth rankings of
model capability. These findings highlight STEM as a practical and scalable
method for fine-grained, architecture-agnostic evaluation of LLMs.

</details>


### [176] [Exploring Efficiency Frontiers of Thinking Budget in Medical Reasoning: Scaling Laws between Computational Resources and Reasoning Quality](https://arxiv.org/abs/2508.12140)
*Ziqian Bi,Lu Chen,Junhao Song,Hongying Luo,Enze Ge,Junmin Huang,Tianyang Wang,Keyu Chen,Chia Xin Liang,Zihan Wei,Huafeng Liu,Chunjie Tian,Jibin Guan,Joe Yeong,Yongzhi Xu,Peng Wang,Junfeng Hao*

Main category: cs.CL

TL;DR: 本研究首次系统评估了医学推理任务中的思考预算机制，揭示了计算资源与推理质量之间的基本缩放规律，发现了三个效率区间和模型规模与思考预算的互补关系。


<details>
  <summary>Details</summary>
Motivation: 随着医疗AI系统在临床环境中的部署需求增长，需要理解计算资源（思考预算）如何影响医学推理质量，以优化资源分配并确保临床应用的透明度和效率。

Method: 系统评估了两个主要模型家族（Qwen3和DeepSeek-R1，参数规模从1.5B到235B）在15个医学数据集上的表现，通过控制思考预算（从零到无限制token）进行实验。

Result: 建立了对数缩放关系，识别出三个效率区间：高效率（0-256 token）、平衡（256-512 token）和高精度（512+ token）。小模型从扩展思考中获益更大（15-20%提升），而大模型仅提升5-10%。不同医学专科需要不同深度的推理过程。

Conclusion: 思考预算控制是优化医疗AI系统的关键机制，能够实现与临床需求对齐的动态资源分配，同时保持医疗部署所需的透明度，该概念在不同架构间具有普适性。

Abstract: This study presents the first comprehensive evaluation of thinking budget
mechanisms in medical reasoning tasks, revealing fundamental scaling laws
between computational resources and reasoning quality. We systematically
evaluated two major model families, Qwen3 (1.7B to 235B parameters) and
DeepSeek-R1 (1.5B to 70B parameters), across 15 medical datasets spanning
diverse specialties and difficulty levels. Through controlled experiments with
thinking budgets ranging from zero to unlimited tokens, we establish
logarithmic scaling relationships where accuracy improvements follow a
predictable pattern with both thinking budget and model size. Our findings
identify three distinct efficiency regimes: high-efficiency (0 to 256 tokens)
suitable for real-time applications, balanced (256 to 512 tokens) offering
optimal cost-performance tradeoffs for routine clinical support, and
high-accuracy (above 512 tokens) justified only for critical diagnostic tasks.
Notably, smaller models demonstrate disproportionately larger benefits from
extended thinking, with 15 to 20% improvements compared to 5 to 10% for larger
models, suggesting a complementary relationship where thinking budget provides
greater relative benefits for capacity-constrained models. Domain-specific
patterns emerge clearly, with neurology and gastroenterology requiring
significantly deeper reasoning processes than cardiovascular or respiratory
medicine. The consistency between Qwen3 native thinking budget API and our
proposed truncation method for DeepSeek-R1 validates the generalizability of
thinking budget concepts across architectures. These results establish thinking
budget control as a critical mechanism for optimizing medical AI systems,
enabling dynamic resource allocation aligned with clinical needs while
maintaining the transparency essential for healthcare deployment.

</details>


### [177] [LLM-as-a-Judge for Privacy Evaluation? Exploring the Alignment of Human and LLM Perceptions of Privacy in Textual Data](https://arxiv.org/abs/2508.12158)
*Stephen Meisenbacher,Alexandra Klymenko,Florian Matthes*

Main category: cs.CL

TL;DR: LLM作为隐私评估器在文本隐私敏感性评估中表现出色，能够准确建模人类隐私视角，为解决隐私保护NLP中的评估难题提供了新思路


<details>
  <summary>Details</summary>
Motivation: 隐私保护NLP领域面临隐私评估的挑战，传统方法难以准确评估文本隐私敏感性。受LLM在其他NLP子领域成功应用的启发，研究探索使用LLM作为隐私评估器的可行性

Method: 采用LLM-as-a-Judge范式，通过涉及10个数据集、13个LLM模型和677名人类调查参与者的大规模研究，比较LLM评估与人类隐私感知的一致性

Result: 研究发现隐私确实难以量化评估（人类间一致性较低），但LLM能够准确建模全局人类隐私视角，在隐私评估任务中表现出色

Conclusion: LLM作为隐私评估器具有可行性，为解决隐私保护的核心挑战提供了创新技术方案，但需要进一步分析其优势和局限性

Abstract: Despite advances in the field of privacy-preserving Natural Language
Processing (NLP), a significant challenge remains the accurate evaluation of
privacy. As a potential solution, using LLMs as a privacy evaluator presents a
promising approach $\unicode{x2013}$ a strategy inspired by its success in
other subfields of NLP. In particular, the so-called $\textit{LLM-as-a-Judge}$
paradigm has achieved impressive results on a variety of natural language
evaluation tasks, demonstrating high agreement rates with human annotators.
Recognizing that privacy is both subjective and difficult to define, we
investigate whether LLM-as-a-Judge can also be leveraged to evaluate the
privacy sensitivity of textual data. Furthermore, we measure how closely LLM
evaluations align with human perceptions of privacy in text. Resulting from a
study involving 10 datasets, 13 LLMs, and 677 human survey participants, we
confirm that privacy is indeed a difficult concept to measure empirically,
exhibited by generally low inter-human agreement rates. Nevertheless, we find
that LLMs can accurately model a global human privacy perspective, and through
an analysis of human and LLM reasoning patterns, we discuss the merits and
limitations of LLM-as-a-Judge for privacy evaluation in textual data. Our
findings pave the way for exploring the feasibility of LLMs as privacy
evaluators, addressing a core challenge in solving pressing privacy issues with
innovative technical solutions.

</details>


### [178] [Arabic Multimodal Machine Learning: Datasets, Applications, Approaches, and Challenges](https://arxiv.org/abs/2508.12227)
*Abdelhamid Haouhat,Slimane Bellaouar,Attia Nehar,Hadda Cherroun,Ahmed Abdelali*

Main category: cs.CL

TL;DR: 阿拉伯多模态机器学习综述研究，通过新的分类法对数据集、应用、方法和挑战进行系统分析，为领域发展提供指导。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯多模态机器学习已经发展到一定成熟阶段，需要进行系统性的综述性研究来整理现状、发现研究空白和提出未来方向。

Method: 采用新的分类法（taxonomy），将阿拉伯多模态机器学习研究分为四个核心话题：数据集、应用领域、方法接口和面临挑战，并对现有研究进行系统分析。

Result: 提供了阿拉伯多模态机器学习领域的结构化概览，明确了当前研究状况，识别出了未被涉及的研究区域和关键的研究缺口。

Conclusion: 该综述为研究人员提供了完整的领域图谱，能够帮助他们在明确的研究机遇和挑战基础上推动阿拉伯多模态机器学习领域的进一步发展。

Abstract: Multimodal Machine Learning (MML) aims to integrate and analyze information
from diverse modalities, such as text, audio, and visuals, enabling machines to
address complex tasks like sentiment analysis, emotion recognition, and
multimedia retrieval. Recently, Arabic MML has reached a certain level of
maturity in its foundational development, making it time to conduct a
comprehensive survey. This paper explores Arabic MML by categorizing efforts
through a novel taxonomy and analyzing existing research. Our taxonomy
organizes these efforts into four key topics: datasets, applications,
approaches, and challenges. By providing a structured overview, this survey
offers insights into the current state of Arabic MML, highlighting areas that
have not been investigated and critical research gaps. Researchers will be
empowered to build upon the identified opportunities and address challenges to
advance the field.

</details>


### [179] [SEA-BED: Southeast Asia Embedding Benchmark](https://arxiv.org/abs/2508.12243)
*Wuttikorn Ponwitayarat,Raymond Ng,Jann Railey Montalan,Thura Aung,Jian Gang Ngui,Yosephine Susanto,William Tjhi,Panuthep Tasawong,Erik Cambria,Ekapol Chuangsuwanich,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: 首个大规模东南亚语言嵌入模型测试案例SEA-BED，包含169个数据集、9项任务和10种语言，71%由人工构建，揭示了东南亚语言的独特挑战和性能问题。


<details>
  <summary>Details</summary>
Motivation: 东南亚地区近一7亿人口但缺乏区域特定的嵌入模型测试标准，现有多语言测试集多为机器翻译，缺失原生语言特性。

Method: 构建SEA-BED测试案例，包含169个数据集、9项NLP任务和10种东南亚语言，其中71%由人工构建。评测17个嵌入模型，分析任务难度、语言性能差异、跨测试集比较以及人工与机器翻译的影响。

Result: 发现模型在东南亚语言上表现不稳定，排名发生显著变化，尤其是低资源语言如缅甸语等对人工构建数据集依赖性强。

Conclusion: 人工构建的原生语言数据集对东南亚语言嵌入模型评估至关重要，SEA-BED填补了该地区测试标准的空白，揭示了全球模型在这些语言上的特殊挑战。

Abstract: Sentence embeddings are essential for NLP tasks such as semantic search,
re-ranking, and textual similarity. Although multilingual benchmarks like MMTEB
broaden coverage, Southeast Asia (SEA) datasets are scarce and often
machine-translated, missing native linguistic properties. With nearly 700
million speakers, the SEA region lacks a region-specific embedding benchmark.
We introduce SEA-BED, the first large-scale SEA embedding benchmark with 169
datasets across 9 tasks and 10 languages, where 71% are formulated by humans,
not machine generation or translation. We address three research questions: (1)
which SEA languages and tasks are challenging, (2) whether SEA languages show
unique performance gaps globally, and (3) how human vs. machine translations
affect evaluation. We evaluate 17 embedding models across six studies,
analyzing task and language challenges, cross-benchmark comparisons, and
translation trade-offs. Results show sharp ranking shifts, inconsistent model
performance among SEA languages, and the importance of human-curated datasets
for low-resource languages like Burmese.

</details>


### [180] [What do Speech Foundation Models Learn? Analysis and Applications](https://arxiv.org/abs/2508.12255)
*Ankita Pasad*

Main category: cs.CL

TL;DR: 这篇论文提出了语音基础模型的轻量分析框架，并创建了语音语言理解评测数据集，以深入研究SFM所含的知识表征和在SLU任务上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 虽然语音基础模型在各种下游任务上表现突出，但对其所含知识的理解较为缺乏，同时在需要深度理解的语音语言理解任务上的表现也不明确。

Method: 开发了使用统计工具和无需训练任务的轻量分析框架，对比研究多个SFM模型。同时创建了语音命名实体识别和定位任务，并开发了基于SFM的端到端模型方法。

Result: 研究发现分析结果对下游任务性能有具体启示，端到端模型在语音命名实体识别和定位任务上超过了传统的流水线方法。

Conclusion: 该论文为SFM研究提供了分析工具和数据集资源，提升了对语音基础模型知识表征的理解，为未来模型设计和应用提供了重要指导。

Abstract: Speech foundation models (SFMs) are designed to serve as general-purpose
representations for a wide range of speech-processing tasks. The last five
years have seen an influx of increasingly successful self-supervised and
supervised pre-trained models with impressive performance on various downstream
tasks.
  Although the zoo of SFMs continues to grow, our understanding of the
knowledge they acquire lags behind. This thesis presents a lightweight analysis
framework using statistical tools and training-free tasks to investigate the
acoustic and linguistic knowledge encoded in SFM layers. We conduct a
comparative study across multiple SFMs and statistical tools. Our study also
shows that the analytical insights have concrete implications for downstream
task performance.
  The effectiveness of an SFM is ultimately determined by its performance on
speech applications. Yet it remains unclear whether the benefits extend to
spoken language understanding (SLU) tasks that require a deeper understanding
than widely studied ones, such as speech recognition. The limited exploration
of SLU is primarily due to a lack of relevant datasets. To alleviate that, this
thesis contributes tasks, specifically spoken named entity recognition (NER)
and named entity localization (NEL), to the Spoken Language Understanding
Evaluation benchmark. We develop SFM-based approaches for NER and NEL, and find
that end-to-end (E2E) models leveraging SFMs can surpass traditional cascaded
(speech recognition followed by a text model) approaches. Further, we evaluate
E2E SLU models across SFMs and adaptation strategies to assess the impact on
task performance.
  Collectively, this thesis tackles previously unanswered questions about SFMs,
providing tools and datasets to further our understanding and to enable the
community to make informed design choices for future model development and
adoption.

</details>


### [181] [Structuring the Unstructured: A Systematic Review of Text-to-Structure Generation for Agentic AI with a Universal Evaluation Framework](https://arxiv.org/abs/2508.12257)
*Zheye Deng,Chunkit Chan,Tianshi Zheng,Wei Fan,Weiqi Wang,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文对文本到结构化转换技术进行了系统性综述，包括方法、数据集和评估指标，并提出了通用评估框架，为下一代AI系统奠定基础


<details>
  <summary>Details</summary>
Motivation: AI系统向代理操作和上下文感知检索发展，需要将非结构化文本转换为表格、知识图谱和图表等结构化格式，但目前缺乏对方法、数据集和指标的综合研究

Method: 采用系统性文献综述方法，分析文本到结构转换技术，评估现有数据集和评估标准，并提出通用评估框架

Result: 全面梳理了文本到结构化转换的技术现状、挑战和评估方法，建立了该领域的研究基础

Conclusion: 文本到结构化转换是下一代AI系统的基础设施，本文提出的评估框架和系统性综述为该领域的未来发展指明了方向

Abstract: The evolution of AI systems toward agentic operation and context-aware
retrieval necessitates transforming unstructured text into structured formats
like tables, knowledge graphs, and charts. While such conversions enable
critical applications from summarization to data mining, current research lacks
a comprehensive synthesis of methodologies, datasets, and metrics. This
systematic review examines text-to-structure techniques and the encountered
challenges, evaluates current datasets and assessment criteria, and outlines
potential directions for future research. We also introduce a universal
evaluation framework for structured outputs, establishing text-to-structure as
foundational infrastructure for next-generation AI systems.

</details>


### [182] [Fast, Slow, and Tool-augmented Thinking for LLMs: A Review](https://arxiv.org/abs/2508.12265)
*Xinda Jia,Jinpeng Li,Zezhong Wang,Jingjing Li,Xingshan Zeng,Yasheng Wang,Weinan Zhang,Yong Yu,Weiwen Liu*

Main category: cs.CL

TL;DR: 该论文提出了一个基于认知心理学的新颖LLM推理策略分类法，包含快/慢边界和内部/外部边界两个维度，系统性地调研了自适应推理方法并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现实世界任务需要LLMs能够根据问题需求自适应地选择推理策略，从快速直觉响应到深思熟虑的逐步推理，但目前缺乏系统的分类框架。

Method: 基于认知心理学提出双维度分类法：快/慢边界（直觉vs审慎过程）和内部/外部边界（参数内推理vs工具增强推理），并系统性地调研和分类现有自适应推理方法。

Result: 建立了一个全面的LLM推理策略分类框架，将现有工作系统性地归类到不同的推理策略类别中，为理解和比较不同方法提供了统一的标准。

Conclusion: 该分类法为LLM自适应推理研究提供了理论基础，指出了实现更自适应、高效和可靠LLMs的开放挑战和未来发展方向。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
reasoning across diverse domains. However, effective reasoning in real-world
tasks requires adapting the reasoning strategy to the demands of the problem,
ranging from fast, intuitive responses to deliberate, step-by-step reasoning
and tool-augmented thinking. Drawing inspiration from cognitive psychology, we
propose a novel taxonomy of LLM reasoning strategies along two knowledge
boundaries: a fast/slow boundary separating intuitive from deliberative
processes, and an internal/external boundary distinguishing reasoning grounded
in the model's parameters from reasoning augmented by external tools. We
systematically survey recent work on adaptive reasoning in LLMs and categorize
methods based on key decision factors. We conclude by highlighting open
challenges and future directions toward more adaptive, efficient, and reliable
LLMs.

</details>


### [183] [The Self-Execution Benchmark: Measuring LLMs' Attempts to Overcome Their Lack of Self-Execution](https://arxiv.org/abs/2508.12277)
*Elon Ezra,Ariel Weizman,Amos Azaria*

Main category: cs.CL

TL;DR: 这篇论文提出了自我执行测试案，用于评估大语言模型预测自身响应的能力，发现模型在这方面表现差强且模型规模不一定能提升性能


<details>
  <summary>Details</summary>
Motivation: 传统评测重点在知识和推理能力，本文探索LLM是否能预测自身响应的特性，以了解模型对自身行为的认知

Method: 提出自我执行测试案（Self-Execution Benchmark），测量模型预测输出特性的能力，包括问题难度预测、拒绝回答预测、联想倾向预测等

Result: 模型在这个测试上表现普遍较差，模型规模或能力提升并不能一致提高性能

Conclusion: 这些结果显示了大语言模型在表征和推理自身行为方面存在根本的限制

Abstract: Large language models (LLMs) are commonly evaluated on tasks that test their
knowledge or reasoning abilities. In this paper, we explore a different type of
evaluation: whether an LLM can predict aspects of its own responses. Since LLMs
lack the ability to execute themselves, we introduce the Self-Execution
Benchmark, which measures a model's ability to anticipate properties of its
output, such as whether a question will be difficult for it, whether it will
refuse to answer, or what kinds of associations it is likely to produce. Our
experiments show that models generally perform poorly on this benchmark, and
that increased model size or capability does not consistently lead to better
performance. These results suggest a fundamental limitation in how LLMs
represent and reason about their own behavior.

</details>


### [184] [Legal$Δ$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain](https://arxiv.org/abs/2508.12281)
*Xin Dai,Buqiang Xu,Zhenghao Liu,Yukun Yan,Huiyuan Xie,Xiaoyuan Yi,Shuo Wang,Ge Yu*

Main category: cs.CL

TL;DR: LegalΔ是一个强化学习框架，通过思维链引导的信息增益来增强法律推理能力，在多个法律推理任务中表现出优于基线模型的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有法律大语言模型在生成可靠和可解释的推理过程方面存在困难，往往直接给出答案而缺乏明确的多步推理，限制了在需要严格论证的复杂法律场景中的有效性。

Method: 采用双阶段方法：1) 从强大的大型推理模型DeepSeek-R1中提炼潜在推理能力；2) 通过差异比较和评估结构连贯性与法律领域特异性的多维奖励机制来优化推理质量。使用双模式输入（直接答案模式和推理增强模式）并最大化两者间的信息增益。

Result: 在多个法律推理任务上的实验结果表明，LegalΔ在准确性和可解释性方面均优于强基线模型，能够持续产生更稳健和可信的法律判断，且不依赖标注的偏好数据。

Conclusion: LegalΔ框架成功解决了法律AI中推理过程不可靠和不可解释的问题，通过强化学习和信息增益机制有效提升了法律推理的质量和可信度。

Abstract: Legal Artificial Intelligence (LegalAI) has achieved notable advances in
automating judicial decision-making with the support of Large Language Models
(LLMs). However, existing legal LLMs still struggle to generate reliable and
interpretable reasoning processes. They often default to fast-thinking behavior
by producing direct answers without explicit multi-step reasoning, limiting
their effectiveness in complex legal scenarios that demand rigorous
justification. To address this challenge, we propose Legal$\Delta$, a
reinforcement learning framework designed to enhance legal reasoning through
chain-of-thought guided information gain. During training, Legal$\Delta$
employs a dual-mode input setup-comprising direct answer and
reasoning-augmented modes-and maximizes the information gain between them. This
encourages the model to acquire meaningful reasoning patterns rather than
generating superficial or redundant explanations. Legal$\Delta$ follows a
two-stage approach: (1) distilling latent reasoning capabilities from a
powerful Large Reasoning Model (LRM), DeepSeek-R1, and (2) refining reasoning
quality via differential comparisons, combined with a multidimensional reward
mechanism that assesses both structural coherence and legal-domain specificity.
Experimental results on multiple legal reasoning tasks demonstrate that
Legal$\Delta$ outperforms strong baselines in both accuracy and
interpretability. It consistently produces more robust and trustworthy legal
judgments without relying on labeled preference data. All code and data will be
released at https://github.com/NEUIR/LegalDelta.

</details>


### [185] [A Question Answering Dataset for Temporal-Sensitive Retrieval-Augmented Generation](https://arxiv.org/abs/2508.12282)
*Ziyang Chen,Erxue Min,Xiang Zhao,Yunxin Li,Xin Jia,Jinzhi Liao,Jichao Li,Shuaiqiang Wang,Baotian Hu,Dawei Yin*

Main category: cs.CL

TL;DR: ChronoQA是一个专门用于评估RAG系统时间推理能力的大规模中文问答基准数据集，包含5,176个高质量问题，覆盖多种时间类型和表达方式。


<details>
  <summary>Details</summary>
Motivation: 现有的问答数据集在时间推理方面存在不足，特别是在中文环境下缺乏专门评估时间敏感检索增强问答系统的基准数据集。

Method: 从2019-2024年的30万篇新闻文章中构建数据集，包含绝对、聚合和相对时间类型的问题，支持单文档和多文档场景，并通过规则、LLM和人工多阶段验证确保数据质量。

Result: 创建了一个包含5,176个高质量问题的基准数据集，具有全面的结构标注，支持广泛的时间任务评估。

Conclusion: ChronoQA为时间敏感的检索增强问答系统提供了一个动态、可靠且可扩展的评估基准，有助于推动该领域的发展。

Abstract: We introduce ChronoQA, a large-scale benchmark dataset for Chinese question
answering, specifically designed to evaluate temporal reasoning in
Retrieval-Augmented Generation (RAG) systems. ChronoQA is constructed from over
300,000 news articles published between 2019 and 2024, and contains 5,176
high-quality questions covering absolute, aggregate, and relative temporal
types with both explicit and implicit time expressions. The dataset supports
both single- and multi-document scenarios, reflecting the real-world
requirements for temporal alignment and logical consistency. ChronoQA features
comprehensive structural annotations and has undergone multi-stage validation,
including rule-based, LLM-based, and human evaluation, to ensure data quality.
By providing a dynamic, reliable, and scalable resource, ChronoQA enables
structured evaluation across a wide range of temporal tasks, and serves as a
robust benchmark for advancing time-sensitive retrieval-augmented question
answering systems.

</details>


### [186] [Incorporating Legal Logic into Deep Learning: An Intelligent Approach to Probation Prediction](https://arxiv.org/abs/2508.12286)
*Qinghua Wang,Xu Zhang,Lingyan Yang,Rui Shao,Bonan Wang,Fang Wang,Cunquan Qu*

Main category: cs.CL

TL;DR: 通过将法律逻辑整合到深度学习模型中，提出了一种新的罚金预测方法，解决了现有智能司法辅助系统缺乏专门罚金预测方法的问题。


<details>
  <summary>Details</summary>
Motivation: 现有智能司法辅助系统缺乏专门的罚金预测方法，且大部分研究仅依赖数据驱动方法而忽视了司法决策的法律逻辑基础。罚金适格性需要对犯罪情况和悔罪表现进行全面分析。

Method: 提出了一种新的三阶段方法：1）构建包含事实描述和罚金法律要素的专门数据集；2）设计基于罚金法律逻辑和《双轨制惩罚理论》的多任务双理论罚金预测模型（MT-DT）；3）通过实验验证模型效果。

Result: 实验结果显示MT-DT模型在罚金数据集上表现超过基线模型，并通过对基础法律逻辑的分析进一步验证了提出方法的有效性。

Conclusion: 该研究成功将法律逻辑整合到深度学习模型中，为智能司法辅助系统提供了一种更有效的罚金预测方法，并强调了法律逻辑在司法决策中的重要性。

Abstract: Probation is a crucial institution in modern criminal law, embodying the
principles of fairness and justice while contributing to the harmonious
development of society. Despite its importance, the current Intelligent
Judicial Assistant System (IJAS) lacks dedicated methods for probation
prediction, and research on the underlying factors influencing probation
eligibility remains limited. In addition, probation eligibility requires a
comprehensive analysis of both criminal circumstances and remorse. Much of the
existing research in IJAS relies primarily on data-driven methodologies, which
often overlooks the legal logic underpinning judicial decision-making. To
address this gap, we propose a novel approach that integrates legal logic into
deep learning models for probation prediction, implemented in three distinct
stages. First, we construct a specialized probation dataset that includes fact
descriptions and probation legal elements (PLEs). Second, we design a distinct
probation prediction model named the Multi-Task Dual-Theory Probation
Prediction Model (MT-DT), which is grounded in the legal logic of probation and
the \textit{Dual-Track Theory of Punishment}. Finally, our experiments on the
probation dataset demonstrate that the MT-DT model outperforms baseline models,
and an analysis of the underlying legal logic further validates the
effectiveness of the proposed approach.

</details>


### [187] [CarelessWhisper: Turning Whisper into a Causal Streaming Model](https://arxiv.org/abs/2508.12301)
*Tomer Krichli,Bhiksha Raj,Joseph Keshet*

Main category: cs.CL

TL;DR: 通过LoRA细调和弱对齐数据集将编码器-解码器变换器模型转换为低延迟流式ASR模型，在小于300ms的分块大小下表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 当前的SOTA ASR模型如Whisper和Canary主要用于离线转写，无法直接用于流式（实时）转写，需要一种方法将编码器-解码器变换器模型转换为低延迟流式模型

Method: 使用低级适配（LoRA）和弱对齐数据集对编码器和解码器进行细调，将非因果性编码器改造为因果性编码器，并提出更新的推理机制支持贪婪和析析解码

Result: 在小于300毫秒的低延迟分块大小下，细调后的模型在大多数情况下表现超过现有非细调流式方法，且复杂度更低，同时还能生成更好的对齐效果以提取单词级时间戳

Conclusion: 通过LoRA细调和弱对齐数据集可以有效将编码器-解码器变换器模型转换为低延迟流式ASR模型，为流式ASR研究提供了新的方法和工具支持

Abstract: Automatic Speech Recognition (ASR) has seen remarkable progress, with models
like OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA)
performance in offline transcription. However, these models are not designed
for streaming (online or real-time) transcription, due to limitations in their
architecture and training methodology. We propose a method to turn the
transformer encoder-decoder model into a low-latency streaming model that is
careless about future context. We present an analysis explaining why it is not
straightforward to convert an encoder-decoder transformer to a low-latency
streaming model. Our proposed method modifies the existing (non-causal) encoder
to a causal encoder by fine-tuning both the encoder and decoder using Low-Rank
Adaptation (LoRA) and a weakly aligned dataset. We then propose an updated
inference mechanism that utilizes the fine-tune causal encoder and decoder to
yield greedy and beam-search decoding, and is shown to be locally optimal.
Experiments on low-latency chunk sizes (less than 300 msec) show that our
fine-tuned model outperforms existing non-fine-tuned streaming approaches in
most cases, while using a lower complexity. Additionally, we observe that our
training process yields better alignment, enabling a simple method for
extracting word-level timestamps. We release our training and inference code,
along with the fine-tuned models, to support further research and development
in streaming ASR.

</details>


### [188] [Consensus or Conflict? Fine-Grained Evaluation of Conflicting Answers in Question-Answering](https://arxiv.org/abs/2508.12355)
*Eviatar Nachshoni,Arie Cattan,Shmuel Amar,Ori Shapira,Ido Dagan*

Main category: cs.CL

TL;DR: 通过利用事实检查数据集构建NATCONFQA标准数据集，用于评估大语言模型在多答案问答任务中的冲突处理能力，发现现有模型在处理各种冲突类型时表现脏弱且采用错误策略。


<details>
  <summary>Details</summary>
Motivation: 多答案问答(MAQA)任务中存在冲突答案的情况，但现有标准数据集构建成本高、依赖合成数据或自动标注，需要一个更现实、细粒度冲突标注的标准数据集来推动该领域的研究。

Method: 提出一种成本效益高的方法，利用事实检查数据集构建NATCONFQA标准数据集，该数据集包含详细的冲突标签。对8个高端大语言模型进行评测，分析它们在处理各种冲突类型时的表现和策略。

Result: 评测结果显示现有大语言模型在处理冲突答案时表现脏弱，对各种冲突类型的处理能力不足，且采用了错误的解决策略。

Conclusion: 该研究提供了一个现实主义的冲突感知MAQA标准数据集，曝露了大语言模型在处理多答案冲突时的根本缺陷，为该领域的进一步研究提供了重要基础和方向。

Abstract: Large Language Models (LLMs) have demonstrated strong performance in question
answering (QA) tasks. However, Multi-Answer Question Answering (MAQA), where a
question may have several valid answers, remains challenging. Traditional QA
settings often assume consistency across evidences, but MAQA can involve
conflicting answers. Constructing datasets that reflect such conflicts is
costly and labor-intensive, while existing benchmarks often rely on synthetic
data, restrict the task to yes/no questions, or apply unverified automated
annotation. To advance research in this area, we extend the conflict-aware MAQA
setting to require models not only to identify all valid answers, but also to
detect specific conflicting answer pairs, if any. To support this task, we
introduce a novel cost-effective methodology for leveraging fact-checking
datasets to construct NATCONFQA, a new benchmark for realistic, conflict-aware
MAQA, enriched with detailed conflict labels, for all answer pairs. We evaluate
eight high-end LLMs on NATCONFQA, revealing their fragility in handling various
types of conflicts and the flawed strategies they employ to resolve them.

</details>


### [189] [ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models](https://arxiv.org/abs/2508.12387)
*Yuanfeng Xu,Zehui Dai,Jian Liang,Jiapeng Guan,Guangrun Wang,Liang Lin,Xiaohui Lv*

Main category: cs.CL

TL;DR: ReaLM是一个强化学习框架，通过多路径过程验证、渐进式自主诱导和引导式思维链蒸馏，提升小语言模型的推理能力、自主性和泛化性，在垂直领域任务中表现显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 小语言模型(SLMs)相比大语言模型成本更低，但在复杂推理中存在能力有限、易出错和答案不一致的问题。现有方法通常以牺牲推理能力、自主性或泛化性为代价来提升性能。

Method: 提出ReaLM框架：1) MRPV多路径过程验证对比正负推理路径提取关键模式；2) EAAI渐进式自主诱导逐步减少外部信号依赖；3) 引导式思维链蒸馏将领域规则和专家知识编码到模型参数中。

Result: 在垂直领域和通用推理任务上的大量实验表明，ReaLM在推理能力、自主性和泛化性三个方面都显著提升了小语言模型的性能。

Conclusion: ReaLM通过创新的强化学习框架有效解决了小语言模型在复杂推理中的核心挑战，为垂直领域的实际应用提供了可行的解决方案。

Abstract: Small Language Models (SLMs) are a cost-effective alternative to Large
Language Models (LLMs), but often struggle with complex reasoning due to their
limited capacity and a tendency to produce mistakes or inconsistent answers
during multi-step reasoning. Existing efforts have improved SLM performance,
but typically at the cost of one or more of three key aspects: (1) reasoning
capability, due to biased supervision that filters out negative reasoning paths
and limits learning from errors; (2) autonomy, due to over-reliance on
externally generated reasoning signals; and (3) generalization, which suffers
when models overfit to teacher-specific patterns. In this paper, we introduce
ReaLM, a reinforcement learning framework for robust and self-sufficient
reasoning in vertical domains. To enhance reasoning capability, we propose
Multi-Route Process Verification (MRPV), which contrasts both positive and
negative reasoning paths to extract decisive patterns. To reduce reliance on
external guidance and improve autonomy, we introduce Enabling Autonomy via
Asymptotic Induction (EAAI), a training strategy that gradually fades external
signals. To improve generalization, we apply guided chain-of-thought
distillation to encode domain-specific rules and expert knowledge into SLM
parameters, making them part of what the model has learned. Extensive
experiments on both vertical and general reasoning tasks demonstrate that ReaLM
significantly improves SLM performance across aspects (1)-(3) above.

</details>


### [190] [MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph](https://arxiv.org/abs/2508.12393)
*Duzhen Zhang,Zixiao Wang,Zhong-Zhi Li,Yahan Yu,Shuncheng Jia,Jiahua Dong,Haotian Xu,Xing Wu,Yingying Zhang,Tielin Zhang,Jie Yang,Xiuying Chen,Le Song*

Main category: cs.CL

TL;DR: 提出了MedKGent框架，使用LLM代理从PubMed摘要构建时序演化的医学知识图谱，通过置信度评分和增量整合实现高质量知识提取，在多个医学问答基准上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱构建方法要么依赖监督流水线泛化性有限，要么简单聚合LLM输出，忽略了生物医学知识的时序动态性和上下文不确定性

Method: 使用Qwen2.5-32B-Instruct模型驱动的两个专门代理：提取代理通过采样估计置信度识别知识三元组，构建代理基于置信度和时间戳增量整合时序演化图谱

Result: 构建了包含156,275个实体和2,971,384个关系三元组的KG，准确率接近90%，在7个医学问答基准上使用5个领先LLM进行RAG均显著优于基线

Conclusion: MedKGent框架成功解决了医学知识图谱构建中的时序动态性问题，通过置信度感知的因果推理在药物重定位等应用中展现出实用价值

Abstract: The rapid expansion of medical literature presents growing challenges for
structuring and integrating domain knowledge at scale. Knowledge Graphs (KGs)
offer a promising solution by enabling efficient retrieval, automated
reasoning, and knowledge discovery. However, current KG construction methods
often rely on supervised pipelines with limited generalizability or naively
aggregate outputs from Large Language Models (LLMs), treating biomedical
corpora as static and ignoring the temporal dynamics and contextual uncertainty
of evolving knowledge. To address these limitations, we introduce MedKGent, a
LLM agent framework for constructing temporally evolving medical KGs.
Leveraging over 10 million PubMed abstracts published between 1975 and 2023, we
simulate the emergence of biomedical knowledge via a fine-grained daily time
series. MedKGent incrementally builds the KG in a day-by-day manner using two
specialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor
Agent identifies knowledge triples and assigns confidence scores via
sampling-based estimation, which are used to filter low-confidence extractions
and inform downstream processing. The Constructor Agent incrementally
integrates the retained triples into a temporally evolving graph, guided by
confidence scores and timestamps to reinforce recurring knowledge and resolve
conflicts. The resulting KG contains 156,275 entities and 2,971,384 relational
triples. Quality assessments by two SOTA LLMs and three domain experts
demonstrate an accuracy approaching 90\%, with strong inter-rater agreement. To
evaluate downstream utility, we conduct RAG across seven medical question
answering benchmarks using five leading LLMs, consistently observing
significant improvements over non-augmented baselines. Case studies further
demonstrate the KG's value in literature-based drug repurposing via
confidence-aware causal inference.

</details>


### [191] [Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing](https://arxiv.org/abs/2508.12405)
*Zilong Bai,Zihan Xu,Cong Sun,Chengxi Zang,H. Timothy Bunnell,Catherine Sinfield,Jacqueline Rutter,Aaron Thomas Martinez,L. Charles Bailey,Mark Weiner,Thomas R. Campion,Thomas Carton,Christopher B. Forrest,Rainu Kaushal,Fei Wang,Yifan Peng*

Main category: cs.CL

TL;DR: 开发了一种混合自然语言处理流水线，通过规则基命名实体识别和BERT基础断言检测模块，准确高效地从临床笔记中提取COVID-19后遗症状，为PASC诊断提供有效工具。


<details>
  <summary>Details</summary>
Motivation: PASC诊断面临挑战，因为其症状多样且随时间变化，需要准确高效的自动化方法来处理大量临床数据。

Method: 开发了混合NLP流水线，结合规则基命名实体识别和BERT基础断言检测模块，使用专业医生开发的PASC词典，分析来自11个健康系统的47,654份临床笔记。

Result: 在内部验证中获得0.82的平均F1分数，外部验证中为0.76，每份笔记处理时间仅需2.448秒，相关性检验显示高度显著相关（ρ>0.83，P<0.0001）。

Conclusion: 该NLP流水线显示出高效和准确性，为改善PASC诊断提供了强大的工具潜力，适用于大规模人群预估研究。

Abstract: Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC)
remains challenging due to its myriad symptoms that evolve over long- and
variable-time intervals. To address this issue, we developed a hybrid natural
language processing pipeline that integrates rule-based named entity
recognition with BERT-based assertion detection modules for PASC-symptom
extraction and assertion detection from clinical notes. We developed a
comprehensive PASC lexicon with clinical specialists. From 11 health systems of
the RECOVER initiative network across the U.S., we curated 160 intake progress
notes for model development and evaluation, and collected 47,654 progress notes
for a population-level prevalence study. We achieved an average F1 score of
0.82 in one-site internal validation and 0.76 in 10-site external validation
for assertion detection. Our pipeline processed each note at $2.448\pm 0.812$
seconds on average. Spearman correlation tests showed $\rho >0.83$ for positive
mentions and $\rho >0.72$ for negative ones, both with $P <0.0001$. These
demonstrate the effectiveness and efficiency of our models and their potential
for improving PASC diagnosis.

</details>


### [192] [ZigzagAttention: Efficient Long-Context Inference with Exclusive Retrieval and Streaming Heads](https://arxiv.org/abs/2508.12407)
*Zhuorui Liu,Chen Zhang,Dawei Song*

Main category: cs.CL

TL;DR: ZigzagAttention通过将检索头和流式头分离到不同层来优化LLM的KV缓存内存占用，减少延迟同时保持性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型处理长上下文时KV缓存消耗巨大，现有方法通过区分检索头和流式头来减少内存占用，但会导致额外的张量访问和索引延迟

Method: 设计新的标准强制将检索头和流式头分别聚集在不同的层中，避免同一层中混合两种头部类型导致的额外计算延迟

Result: ZigzagAttention方法在减少延迟的同时仅带来可忽略的性能下降，在基准测试中表现竞争力强

Conclusion: 通过层级的头部类型分离策略可以有效优化KV缓存的内存效率，同时避免额外的计算开销，为长上下文处理提供了实用的部署解决方案

Abstract: With the rapid development of large language models (LLMs), handling long
context has become one of the vital abilities in LLMs. Such long-context
ability is accompanied by difficulties in deployment, especially due to the
increased consumption of KV cache. There is certain work aiming to optimize the
memory footprint of KV cache, inspired by the observation that attention heads
can be categorized into retrieval heads that are of great significance and
streaming heads that are of less significance. Typically, identifying the
streaming heads and and waiving the KV cache in the streaming heads would
largely reduce the overhead without hurting the performance that much. However,
since employing both retrieval and streaming heads in one layer decomposes one
large round of attention computation into two small ones, it may unexpectedly
bring extra latency on accessing and indexing tensors. Based on this intuition,
we impose an important improvement to the identification process of retrieval
and streaming heads, in which we design a criterion that enforces exclusively
retrieval or streaming heads gathered in one unique layer. In this way, we
further eliminate the extra latency and only incur negligible performance
degradation. Our method named \textsc{ZigzagAttention} is competitive among
considered baselines owing to reduced latency and comparable performance.

</details>


### [193] [The Cultural Gene of Large Language Models: A Study on the Impact of Cross-Corpus Training on Model Values and Biases](https://arxiv.org/abs/2508.12411)
*Emanuel Z. Fenech-Borg,Tilen P. Meznaric-Kos,Milica D. Lekovic-Bojovic,Arni J. Hentze-Djurhuus*

Main category: cs.CL

TL;DR: 这篇论文提出了"文化基因"概念，通过文化探针数据集测量了LLM的系统性价值偏向，发现GPT-4呈现西方个人主义特征，而ERNIE Bot呈现东方集体主义特征，两者在文化倾向上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在全球部署，但其基础文化和伦理偏向仍未得到充分探索，需要研究LLM如何继承训练语料库的系统性价值观。

Method: 提出"文化基因"概念，构建包含200个提示的文化探针数据集(CPD)，重点考察个人主义-96c6体主义(IDV)和权力距离(PDI)两个经典跨文化维度，使用标准化零样本提示比较GPT-4和ERNIE Bot。

Result: 人工标注显示两者在两个维度上都存在显著和一致的分差：GPT-4呈现个人主义和低权力距离倾向(IDV约1.21；PDI约-1.05)，ERNIE Bot呈现集体主义和高权力距离倾向(IDV约-0.89；PDI约0.76)，差异统计显著(p < 0.001)。文化对齐指数显示GPT-4更接近美国，ERNIE Bot更接近中国。

Conclusion: 结果支持LLM作为其文化语料库的统计镜像的观点，强调需要文化意识的评估和部署，以避免算法文化霸权。

Abstract: Large language models (LLMs) are deployed globally, yet their underlying
cultural and ethical assumptions remain underexplored. We propose the notion of
a "cultural gene" -- a systematic value orientation that LLMs inherit from
their training corpora -- and introduce a Cultural Probe Dataset (CPD) of 200
prompts targeting two classic cross-cultural dimensions:
Individualism-Collectivism (IDV) and Power Distance (PDI). Using standardized
zero-shot prompts, we compare a Western-centric model (GPT-4) and an
Eastern-centric model (ERNIE Bot). Human annotation shows significant and
consistent divergence across both dimensions. GPT-4 exhibits individualistic
and low-power-distance tendencies (IDV score approx 1.21; PDI score approx
-1.05), while ERNIE Bot shows collectivistic and higher-power-distance
tendencies (IDV approx -0.89; PDI approx 0.76); differences are statistically
significant (p < 0.001). We further compute a Cultural Alignment Index (CAI)
against Hofstede's national scores and find GPT-4 aligns more closely with the
USA (e.g., IDV CAI approx 0.91; PDI CAI approx 0.88) whereas ERNIE Bot aligns
more closely with China (IDV CAI approx 0.85; PDI CAI approx 0.81). Qualitative
analyses of dilemma resolution and authority-related judgments illustrate how
these orientations surface in reasoning. Our results support the view that LLMs
function as statistical mirrors of their cultural corpora and motivate
culturally aware evaluation and deployment to avoid algorithmic cultural
hegemony.

</details>


### [194] [Uncovering Emergent Physics Representations Learned In-Context by Large Language Models](https://arxiv.org/abs/2508.12448)
*Yeongwoo Song,Jaeyong Bae,Dong-Kyum Kim,Hawoong Jeong*

Main category: cs.CL

TL;DR: 大语言模型通过上下文学习能够理解物理概念，特别是在动力学预测任务中表现出与能量等物理变量相关的特征编码。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在上下文学习中的机制，物理任务提供了实验可控、基于基本原理的现实但易处理的测试环境。

Method: 使用动力学预测任务作为代理，分析模型在长上下文中的表现，并通过稀疏自编码器(SAEs)分析殊异流激活动来提取特征。

Result: 长上下文提高了动力学预测性能，SAEs提取的特征与能量等关键物理变量相关联，证明LLMs在上下文学习中编码了有意义的物理概念。

Conclusion: 该研究为理解LLMs如何进行上下文学习提供了新的案例研究，扩展了对模型内部机制的认知。

Abstract: Large language models (LLMs) exhibit impressive in-context learning (ICL)
abilities, enabling them to solve wide range of tasks via textual prompts
alone. As these capabilities advance, the range of applicable domains continues
to expand significantly. However, identifying the precise mechanisms or
internal structures within LLMs that allow successful ICL across diverse,
distinct classes of tasks remains elusive. Physics-based tasks offer a
promising testbed for probing this challenge. Unlike synthetic sequences such
as basic arithmetic or symbolic equations, physical systems provide
experimentally controllable, real-world data based on structured dynamics
grounded in fundamental principles. This makes them particularly suitable for
studying the emergent reasoning behaviors of LLMs in a realistic yet tractable
setting. Here, we mechanistically investigate the ICL ability of LLMs,
especially focusing on their ability to reason about physics. Using a dynamics
forecasting task in physical systems as a proxy, we evaluate whether LLMs can
learn physics in context. We first show that the performance of dynamics
forecasting in context improves with longer input contexts. To uncover how such
capability emerges in LLMs, we analyze the model's residual stream activations
using sparse autoencoders (SAEs). Our experiments reveal that the features
captured by SAEs correlate with key physical variables, such as energy. These
findings demonstrate that meaningful physical concepts are encoded within LLMs
during in-context learning. In sum, our work provides a novel case study that
broadens our understanding of how LLMs learn in context.

</details>


### [195] [M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following](https://arxiv.org/abs/2508.12458)
*Ruirui Gao,Emily Johnson,Bowen Tan,Yanfei Qian*

Main category: cs.CL

TL;DR: M3PO是一种新颖的多模态偏好优化方法，通过智能选择LVLM生成的高价值偏好样本对，结合多模态对齐分数和模型自一致性，有效提升视觉指令跟随能力。


<details>
  <summary>Details</summary>
Motivation: 传统监督微调和偏好优化方法难以有效利用模型自身生成空间来识别高信息量的困难负样本，且人工标注成本高昂、不一致。

Method: 提出M3P-Score机制，整合多模态对齐分数(MAS)和模型自置信度，从LVLM生成候选中选择最有学习价值的偏好样本对，用于高效的DPO微调。

Result: 在多个多模态指令跟随基准测试(MME-Bench、POPE、IFT、人类偏好评分)上，M3PO consistently优于SFT、模拟RLHF、普通DPO和RM-DPO等强基线方法。

Conclusion: M3PO提供了一种数据高效的偏好优化方法，能够显著提升大型视觉语言模型在复杂多模态指令跟随任务中的性能。

Abstract: Large Vision-Language Models (LVLMs) hold immense potential for complex
multimodal instruction following, yet their development is often hindered by
the high cost and inconsistency of human annotation required for effective
fine-tuning and preference alignment. Traditional supervised fine-tuning (SFT)
and existing preference optimization methods like RLHF and DPO frequently
struggle to efficiently leverage the model's own generation space to identify
highly informative "hard negative" samples. To address these challenges, we
propose Multimodal-Model-Guided Preference Optimization (M3PO), a novel and
data-efficient method designed to enhance LVLMs' capabilities in visual
instruction following. M3PO intelligently selects the most "learning-valuable"
preference sample pairs from a diverse pool of LVLM-generated candidates. This
selection is driven by a sophisticated mechanism that integrates two crucial
signals: a Multimodal Alignment Score (MAS) to assess external quality and the
model's Self-Consistency / Confidence (log-probability) to gauge internal
belief. These are combined into a novel M3P-Score, which specifically
identifies preferred responses and challenging dispreferred responses that the
model might confidently generate despite being incorrect. These high-quality
preference pairs are then used for efficient Direct Preference Optimization
(DPO) fine-tuning on base LVLMs like LLaVA-1.5 (7B/13B) using LoRA. Our
extensive experiments demonstrate that M3PO consistently outperforms strong
baselines, including SFT, simulated RLHF, vanilla DPO, and RM-DPO, across a
comprehensive suite of multimodal instruction following benchmarks (MME-Bench,
POPE, IFT, Human Pref. Score).

</details>


### [196] [LoraxBench: A Multitask, Multilingual Benchmark Suite for 20 Indonesian Languages](https://arxiv.org/abs/2508.12459)
*Alham Fikri Aji,Trevor Cohn*

Main category: cs.CL

TL;DR: LoraxBench是一个针对印度尼西亚低资源语言的基准测试，涵盖6个任务和20种语言，发现多语言模型在印尼语和其他低资源语言间存在性能差距，且语域变化显著影响模型表现。


<details>
  <summary>Details</summary>
Motivation: 印度尼西亚作为世界人口大国，拥有700种语言，但在NLP领域进展滞后，需要专门针对其低资源语言的评估基准。

Method: 构建LoraxBench基准，包含阅读理解、开放域问答、语言推理、因果推理、翻译和文化问答6个任务，覆盖20种语言，并对3种语言添加两种正式度语域。评估多种多语言和区域专注的LLM。

Result: 基准测试具有挑战性，印尼语与其他低资源语言性能存在明显差距；区域特定模型与通用多语言模型相比没有明显优势；语域变化（如不常见的礼貌语域）显著影响模型性能。

Conclusion: 需要更多针对印尼低资源语言的NLP研究，语域多样性是影响模型性能的重要因素，区域特定模型在当前阶段并未显示出明显优势。

Abstract: As one of the world's most populous countries, with 700 languages spoken,
Indonesia is behind in terms of NLP progress. We introduce LoraxBench, a
benchmark that focuses on low-resource languages of Indonesia and covers 6
diverse tasks: reading comprehension, open-domain QA, language inference,
causal reasoning, translation, and cultural QA. Our dataset covers 20
languages, with the addition of two formality registers for three languages. We
evaluate a diverse set of multilingual and region-focused LLMs and found that
this benchmark is challenging. We note a visible discrepancy between
performance in Indonesian and other languages, especially the low-resource
ones. There is no clear lead when using a region-specific model as opposed to
the general multilingual model. Lastly, we show that a change in register
affects model performance, especially with registers not commonly found in
social media, such as high-level politeness `Krama' Javanese.

</details>


### [197] [Is GPT-OSS Good? A Comprehensive Evaluation of OpenAI's Latest Open Source Models](https://arxiv.org/abs/2508.12461)
*Ziqian Bi,Keyu Chen,Chiung-Yi Tseng,Danyang Zhang,Tianyang Wang,Hongying Luo,Lu Chen,Junming Huang,Jibin Guan,Junfeng Hao,Junhao Song*

Main category: cs.CL

TL;DR: OpenAI发布GPT-OSS开源模型（20B和120B参数），在多项基准测试中发现较小模型反而表现更好，表明稀疏架构的扩展可能不会带来成比例的性能提升。


<details>
  <summary>Details</summary>
Motivation: 评估OpenAI自2019年GPT-2以来首次发布的开源大语言模型性能，比较不同参数规模的稀疏架构模型在实际任务中的表现。

Method: 使用10个基准测试（包括通用知识、数学推理、代码生成、多语言理解和对话能力）对比6个开源大模型（14.7B-235B参数），采用标准化推理设置和McNemar检验进行统计验证。

Result: 20B参数模型在多个基准测试（如HumanEval和MMLU）上表现优于120B参数模型，且内存和能耗更低；两个模型在代码生成方面表现相对较强，但在多语言任务中表现较弱。

Conclusion: 稀疏架构的扩展可能不会带来成比例的性能收益，需要进一步研究优化策略，为未来开源部署提供更高效的模型选择依据。

Abstract: In August 2025, OpenAI released GPT-OSS models, its first open weight large
language models since GPT-2 in 2019, comprising two mixture of experts
architectures with 120B and 20B parameters. We evaluated both variants against
six contemporary open source large language models ranging from 14.7B to 235B
parameters, representing both dense and sparse designs, across ten benchmarks
covering general knowledge, mathematical reasoning, code generation,
multilingual understanding, and conversational ability. All models were tested
in unquantised form under standardised inference settings, with statistical
validation using McNemars test and effect size analysis. Results show that
gpt-oss-20B consistently outperforms gpt-oss-120B on several benchmarks, such
as HumanEval and MMLU, despite requiring substantially less memory and energy
per response. Both models demonstrate mid-tier overall performance within the
current open source landscape, with relative strength in code generation and
notable weaknesses in multilingual tasks. These findings provide empirical
evidence that scaling in sparse architectures may not yield proportional
performance gains, underscoring the need for further investigation into
optimisation strategies and informing more efficient model selection for future
open source deployments.

</details>


### [198] [The Structural Sources of Verb Meaning Revisited: Large Language Models Display Syntactic Bootstrapping](https://arxiv.org/abs/2508.12482)
*Xiaomeng Zhu,R. Thomas McCoy,Robert Frank*

Main category: cs.CL

TL;DR: 语法启动学习在大语言模型中的实证研究，通过测试语法信息消除对动词表征的影响，证实语法结构对动词学习的关键作用


<details>
  <summary>Details</summary>
Motivation: 检验大语言模型是否也体现了人类儿童在语言学习中的"语法启动学习"现象，即通过语法环境来学习动词意义

Method: 训练RoBERTa和GPT-2模型，使用经过语法信息消除处理的数据集，比较语法消除和共现信息消除对模型表现的影响

Result: 模型的动词表征在语法线索移除时退化更严重，心理动词比物理动词受影响更大，名词表征则更受共现信息影响

Conclusion: 证实了语法启动学习在动词学习中的重要作用，并为通过操控大语言模型学习环境来测试发育假设提供了可行方法

Abstract: Syntactic bootstrapping (Gleitman, 1990) is the hypothesis that children use
the syntactic environments in which a verb occurs to learn its meaning. In this
paper, we examine whether large language models exhibit a similar behavior. We
do this by training RoBERTa and GPT-2 on perturbed datasets where syntactic
information is ablated. Our results show that models' verb representation
degrades more when syntactic cues are removed than when co-occurrence
information is removed. Furthermore, the representation of mental verbs, for
which syntactic bootstrapping has been shown to be particularly crucial in
human verb learning, is more negatively impacted in such training regimes than
physical verbs. In contrast, models' representation of nouns is affected more
when co-occurrences are distorted than when syntax is distorted. In addition to
reinforcing the important role of syntactic bootstrapping in verb learning, our
results demonstrated the viability of testing developmental hypotheses on a
larger scale through manipulating the learning environments of large language
models.

</details>


### [199] [Mitigating Hallucinations in Large Language Models via Causal Reasoning](https://arxiv.org/abs/2508.12495)
*Yuangang Li,Yiqing Shen,Yi Nian,Jiechao Gao,Ziyi Wang,Chenxiao Yu,Shawn Li,Jie Wang,Xiyang Hu,Yue Zhao*

Main category: cs.CL

TL;DR: 基于因果图的超应小小调框架CDCR-SFT，通过显式建模因果结构提升LLM的因果推理能力并降低幻觉


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理方法如CoT在语言token层面运作，缺乏对基础因果关系的模型能力，无法表达条件独立性或满足因果识别假设

Method: 提出CDCR-SFT框架，训练LLM显式构建变量级的有向无环图(DAG)并在其上进行推理，同时构建包含25,368个样本的CausalDR数据集

Result: 在4个LLM和8个任务上的实验显示，CDCR-SFT在CLADDER任务上达到了195.33%的最高准确率(超过人类94.8%)，并在HaluEval上将幻觉降低了10%

Conclusion: 显式的因果结构建模能够有效减少LLM输出中的逻辑不一致性，为提升LLM的因果推理能力提供了有效途径

Abstract: Large language models (LLMs) exhibit logically inconsistent hallucinations
that appear coherent yet violate reasoning principles, with recent research
suggesting an inverse relationship between causal reasoning capabilities and
such hallucinations. However, existing reasoning approaches in LLMs, such as
Chain-of-Thought (CoT) and its graph-based variants, operate at the linguistic
token level rather than modeling the underlying causal relationships between
variables, lacking the ability to represent conditional independencies or
satisfy causal identification assumptions. To bridge this gap, we introduce
causal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning
framework that trains LLMs to explicitly construct variable-level directed
acyclic graph (DAG) and then perform reasoning over it. Moreover, we present a
dataset comprising 25,368 samples (CausalDR), where each sample includes an
input question, explicit causal DAG, graph-based reasoning trace, and validated
answer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves
the causal reasoning capability with the state-of-the-art 95.33% accuracy on
CLADDER (surpassing human performance of 94.8% for the first time) and reduces
the hallucination on HaluEval with 10% improvements. It demonstrates that
explicit causal structure modeling in LLMs can effectively mitigate logical
inconsistencies in LLM outputs. Code is available at
https://github.com/MrLYG/CDCR-SFT.

</details>


### [200] [CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection](https://arxiv.org/abs/2508.12535)
*Seonglae Cho,Zekun Wu,Adriano Koshiyama*

Main category: cs.CL

TL;DR: CorrSteer是一种基于相关性选择稀疏自编码器特征的方法，仅使用推理时激活来自动化特征选择和转向，在多个任务上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 解决传统稀疏自编码器在下游转向任务中需要对比数据集或大量激活存储的限制，避免伪相关性

Method: 通过将样本正确性与推理时生成的token的SAE激活进行相关性分析来选择特征，使用平均激活获得转向系数

Result: 在Gemma 2 2B和LLaMA 3.1 8B上，MMLU性能提升4.1%，HarmBench提升22.9%，仅需4000个样本

Conclusion: 基于相关性选择的方法为自动化SAE转向提供了一种有效且可扩展的解决方案

Abstract: Sparse Autoencoders (SAEs) can extract interpretable features from large
language models (LLMs) without supervision. However, their effectiveness in
downstream steering tasks is limited by the requirement for contrastive
datasets or large activation storage. To address these limitations, we propose
CorrSteer, which selects features by correlating sample correctness with SAE
activations from generated tokens at inference time. This approach uses only
inference-time activations to extract more relevant features, thereby avoiding
spurious correlations. It also obtains steering coefficients from average
activations, automating the entire pipeline. Our method shows improved task
performance on QA, bias mitigation, jailbreaking prevention, and reasoning
benchmarks on Gemma 2 2B and LLaMA 3.1 8B, notably achieving a +4.1%
improvement in MMLU performance and a +22.9% improvement in HarmBench with only
4000 samples. Selected features demonstrate semantically meaningful patterns
aligned with each task's requirements, revealing the underlying capabilities
that drive performance. Our work establishes correlationbased selection as an
effective and scalable approach for automated SAE steering across language
model applications.

</details>


### [201] [Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning](https://arxiv.org/abs/2508.12591)
*Yu-Hsuan Fang,Tien-Hong Lo,Yao-Ting Sung,Berlin Chen*

Main category: cs.CL

TL;DR: 本文首次系统性研究多模态大语言模型在自动说话评估中的应用，提出了专门的语音优先多模态训练方法，显著提升了评估性能。


<details>
  <summary>Details</summary>
Motivation: 传统自动说话评估系统存在模态限制：文本方法缺乏声学信息，音频方法缺少语义上下文。多模态大语言模型为全面评估提供了新机遇。

Method: 提出语音优先多模态训练（SFMT）方法，利用课程学习原理，先建立健壮的语音模型基础，再进行跨模态协同融合。

Result: 在标准数据集上将全面评估性能从PCC 0.783提升到0.846。在表达方面的评估中，语音优先训练方法比传统方法绝对准确率提高4%。

Conclusion: 多模态大语言模型在自动说话评估中表现优异，特别是通过专门的训练策略能够有效解决表达方面的挑战，为该领域开启了新途径。

Abstract: Traditional Automated Speaking Assessment (ASA) systems exhibit inherent
modality limitations: text-based approaches lack acoustic information while
audio-based methods miss semantic context. Multimodal Large Language Models
(MLLM) offer unprecedented opportunities for comprehensive ASA by
simultaneously processing audio and text within unified frameworks. This paper
presents a very first systematic study of MLLM for comprehensive ASA,
demonstrating the superior performance of MLLM across the aspects of content
and language use . However, assessment on the delivery aspect reveals unique
challenges, which is deemed to require specialized training strategies. We thus
propose Speech-First Multimodal Training (SFMT), leveraging a curriculum
learning principle to establish more robust modeling foundations of speech
before cross-modal synergetic fusion. A series of experiments on a benchmark
dataset show MLLM-based systems can elevate the holistic assessment performance
from a PCC value of 0.783 to 0.846. In particular, SFMT excels in the
evaluation of the delivery aspect, achieving an absolute accuracy improvement
of 4% over conventional training approaches, which also paves a new avenue for
ASA.

</details>


### [202] [Semantic Anchoring in Agentic Memory: Leveraging Linguistic Structures for Persistent Conversational Context](https://arxiv.org/abs/2508.12630)
*Maitreyi Chatterjee,Devansh Agarwal*

Main category: cs.CL

TL;DR: 提出Semantic Anchoring混合记忆架构，通过结合句法依赖、篇章关系和指代消解等显式语言线索来增强RAG系统的长期对话记忆能力，相比基线提升18%的事实回忆和篇章连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统将对话历史存储为稠密向量，虽然能捕捉语义相似性，但忽略了更精细的语言结构（如句法依赖、篇章关系、指代链接），限制了在长期多轮对话中的记忆持久性。

Method: 提出混合代理记忆架构Semantic Anchoring，在向量存储基础上增加显式语言线索：依赖解析、篇章关系标注和指代消解，创建结构化记忆条目。

Result: 在适应的长期对话数据集上实验显示，相比强RAG基线，语义锚定将事实回忆和篇章连贯性提升高达18%。通过消融研究、人工评估和错误分析验证了鲁棒性和可解释性。

Conclusion: Semantic Anchoring通过整合显式语言结构信息，显著提升了LLM在长期对话中的记忆能力和上下文理解，为改进多轮对话系统提供了有效方法。

Abstract: Large Language Models (LLMs) have demonstrated impressive fluency and task
competence in conversational settings. However, their effectiveness in
multi-session and long-term interactions is hindered by limited memory
persistence. Typical retrieval-augmented generation (RAG) systems store
dialogue history as dense vectors, which capture semantic similarity but
neglect finer linguistic structures such as syntactic dependencies, discourse
relations, and coreference links. We propose Semantic Anchoring, a hybrid
agentic memory architecture that enriches vector-based storage with explicit
linguistic cues to improve recall of nuanced, context-rich exchanges. Our
approach combines dependency parsing, discourse relation tagging, and
coreference resolution to create structured memory entries. Experiments on
adapted long-term dialogue datasets show that semantic anchoring improves
factual recall and discourse coherence by up to 18% over strong RAG baselines.
We further conduct ablation studies, human evaluations, and error analysis to
assess robustness and interpretability.

</details>


### [203] [Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing](https://arxiv.org/abs/2508.12631)
*Yiqun Zhang,Hao Li,Jianhao Chen,Hangfan Zhang,Peng Ye,Lei Bai,Shuyue Hu*

Main category: cs.CL

TL;DR: Avengers-Pro是一个测试时路由框架，通过动态将查询分配给不同容量和效率的LLM集合，在6个基准测试中超越最强单模型7%准确率，同时降低27-63%成本


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型性能与效率平衡的挑战，GPT-5虽然提出了测试时路由但仅限于两个模型，需要更统一的解决方案来处理所有性能-效率权衡

Method: 嵌入和聚类输入查询，然后基于性能-效率分数将每个查询路由到最合适的模型，集成不同容量和效率的LLM

Result: 在6个基准测试和8个领先模型上实现SOTA：超越最强单模型GPT-5-medium 7%准确率，以27%更低成本匹配其性能，以63%更低成本达到其90%性能

Conclusion: Avengers-Pro实现了帕累托前沿，在任何给定成本下提供最高准确率，在任何给定准确率下提供最低成本，为性能-效率权衡提供了统一解决方案

Abstract: Balancing performance and efficiency is a central challenge in large language
model (LLM) advancement. GPT-5 addresses this with test-time routing,
dynamically assigning queries to either an efficient or a high-capacity model
during inference. In this work, we present Avengers-Pro, a test-time routing
framework that ensembles LLMs of varying capacities and efficiencies, providing
a unified solution for all performance-efficiency tradeoffs. The Avengers-Pro
embeds and clusters incoming queries, then routes each to the most suitable
model based on a performance-efficiency score. Across 6 challenging benchmarks
and 8 leading models -- including GPT-5-medium, Gemini-2.5-pro, and
Claude-opus-4.1 -- Avengers-Pro achieves state-of-the-art results: by varying a
performance-efficiency trade-off parameter, it can surpass the strongest single
model (GPT-5-medium) by +7% in average accuracy. Moreover, it can match the
average accuracy of the strongest single model at 27% lower cost, and reach
~90% of that performance at 63% lower cost. Last but not least, it achieves a
Pareto frontier, consistently yielding the highest accuracy for any given cost,
and the lowest cost for any given accuracy, among all single models. Code is
available at https://github.com/ZhangYiqun018/AvengersPro.

</details>


### [204] [Prompt-Induced Linguistic Fingerprints for LLM-Generated Fake News Detection](https://arxiv.org/abs/2508.12632)
*Chi Wang,Min Gao,Zongwei Wang,Junwei Yin,Kai Shu,Chenghua Lin*

Main category: cs.CL

TL;DR: 提出LIFE方法，通过重构词级概率分布来检测LLM生成的假新闻，利用提示诱导的语言指纹实现最先进的检测性能


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，假新闻生成变得容易，现有方法主要关注文本内容本身，但虚假痕迹难以发现，需要更可靠的检测方法

Method: 通过分布差异分析发现提示诱导的语言指纹，提出LIFE方法重构词级概率分布，并利用关键片段技术放大语言差异

Result: LIFE在LLM生成的假新闻检测上达到最先进性能，在人工编写的假新闻上也保持高性能

Conclusion: LIFE方法通过挖掘提示诱导的语言指纹，能够有效检测LLM生成的假新闻，为解决假新闻检测问题提供了新思路

Abstract: With the rapid development of large language models, the generation of fake
news has become increasingly effortless, posing a growing societal threat and
underscoring the urgent need for reliable detection methods. Early efforts to
identify LLM-generated fake news have predominantly focused on the textual
content itself; however, because much of that content may appear coherent and
factually consistent, the subtle traces of falsification are often difficult to
uncover. Through distributional divergence analysis, we uncover prompt-induced
linguistic fingerprints: statistically distinct probability shifts between
LLM-generated real and fake news when maliciously prompted. Based on this
insight, we propose a novel method named Linguistic Fingerprints Extraction
(LIFE). By reconstructing word-level probability distributions, LIFE can find
discriminative patterns that facilitate the detection of LLM-generated fake
news. To further amplify these fingerprint patterns, we also leverage
key-fragment techniques that accentuate subtle linguistic differences, thereby
improving detection reliability. Our experiments show that LIFE achieves
state-of-the-art performance in LLM-generated fake news and maintains high
performance in human-written fake news. The code and data are available at
https://anonymous.4open.science/r/LIFE-E86A.

</details>


### [205] [Breaking Language Barriers: Equitable Performance in Multilingual Language Models](https://arxiv.org/abs/2508.12662)
*Tanay Nagar,Grigorii Khvatskii,Anna Sokol,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: 通过使用控制语言混合方法生成的合成代码切换文本进行精调，提升LLM在低资源语言上的常识推理性能，同时保持或提卉高资源语言的表现。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在低资源语言(LRLs)上常识推理任务表现较差的问题，确保不同语言社区获得公平的LLM输出质量。

Method: 使用控制语言混合方法生成合成代码切换文本，对LLM进行精调训练。创建了基于CommonSenseQA的新的合成代码切换数据集，包含三种不同语言比例配置。

Result: 经验证明，在合成代码切换数据集上精调LLM能够导致LRL模型性能的显著提升，同时保持或提卉HRL的性能。

Conclusion: 通过合成代码切换文本进行精调是有效缩小LLM在不同语言间性能差距的方法，为提升多语言平等性能提供了新的解决方案。

Abstract: Cutting-edge LLMs have emerged as powerful tools for multilingual
communication and understanding. However, LLMs perform worse in Common Sense
Reasoning (CSR) tasks when prompted in low-resource languages (LRLs) like Hindi
or Swahili compared to high-resource languages (HRLs) like English. Equalizing
this inconsistent access to quality LLM outputs is crucial to ensure fairness
for speakers of LRLs and across diverse linguistic communities. In this paper,
we propose an approach to bridge this gap in LLM performance. Our approach
involves fine-tuning an LLM on synthetic code-switched text generated using
controlled language-mixing methods. We empirically demonstrate that fine-tuning
LLMs on synthetic code-switched datasets leads to substantial improvements in
LRL model performance while preserving or enhancing performance in HRLs.
Additionally, we present a new dataset of synthetic code-switched text derived
from the CommonSenseQA dataset, featuring three distinct language ratio
configurations.

</details>


### [206] [Leveraging Large Language Models for Predictive Analysis of Human Misery](https://arxiv.org/abs/2508.12669)
*Bishanka Seal,Rahul Seetharaman,Aman Bansal,Abhilash Nandy*

Main category: cs.CL

TL;DR: 使用大型语言模型预测人类感知的痛苦分数，通过多种提示策略和创新的游戏化评估框架来测试模型的情感推理能力


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在情感预测任务中的表现，特别是从自然语言描述中预测人类感知的痛苦程度，探索超越传统静态评估的动态情感推理能力

Method: 采用回归问题框架，评估零样本、固定上下文少样本和基于BERT句子嵌入的检索式提示策略。引入"痛苦游戏秀"游戏化评估框架，包含顺序比较、二元分类、标量估计和反馈驱动推理等多个环节

Result: 少样本方法 consistently 优于零样本基线，证明了上下文示例在情感预测中的价值。游戏化评估显示了LLMs在动态情感推理任务中的潜力

Conclusion: LLMs在情感预测任务中表现出色，特别是通过少样本学习和游戏化评估框架，展示了在动态情感推理方面的广阔应用前景

Abstract: This study investigates the use of Large Language Models (LLMs) for
predicting human-perceived misery scores from natural language descriptions of
real-world scenarios. The task is framed as a regression problem, where the
model assigns a scalar value from 0 to 100 to each input statement. We evaluate
multiple prompting strategies, including zero-shot, fixed-context few-shot, and
retrieval-based prompting using BERT sentence embeddings. Few-shot approaches
consistently outperform zero-shot baselines, underscoring the value of
contextual examples in affective prediction. To move beyond static evaluation,
we introduce the "Misery Game Show", a novel gamified framework inspired by a
television format. It tests LLMs through structured rounds involving ordinal
comparison, binary classification, scalar estimation, and feedback-driven
reasoning. This setup enables us to assess not only predictive accuracy but
also the model's ability to adapt based on corrective feedback. The gamified
evaluation highlights the broader potential of LLMs in dynamic emotional
reasoning tasks beyond standard regression. Code and data link:
https://github.com/abhi1nandy2/Misery_Data_Exps_GitHub

</details>


### [207] [ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction](https://arxiv.org/abs/2508.12685)
*Xingshan Zeng,Weiwen Liu,Lingzhi Wang,Liangyou Li,Fei Mi,Yasheng Wang,Lifeng Shang,Xin Jiang,Qun Liu*

Main category: cs.CL

TL;DR: 提出了ToolACE-MT框架，通过非自回归迭代生成方法高效构建高质量多轮代理对话数据，避免传统自回归方法的成本问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于模拟的数据生成方法依赖多个LLM代理之间的昂贵自回归交互，限制了代理任务在现实世界中的性能表现。

Method: 采用三阶段框架：粗粒度初始化构建对话骨架，迭代细化通过掩码填充操作引入现实复杂性，离线验证通过规则和模型检查确保正确性。

Result: 实验证明ToolACE-MT能够实现高效、有效且可泛化的代理数据生成。

Conclusion: 为工具增强LLM场景中的高质量数据构建提供了新范式。

Abstract: Agentic task-solving with Large Language Models (LLMs) requires multi-turn,
multi-step interactions, often involving complex function calls and dynamic
user-agent exchanges. Existing simulation-based data generation methods for
such scenarios rely heavily on costly autoregressive interactions between
multiple LLM agents, thereby limiting real-world performance of agentic tasks.
In this paper, we propose a novel Non-Autoregressive Iterative Generation
framework, called ToolACE-MT, for constructing high-quality multi-turn agentic
dialogues. ToolACE-MT generates full conversational trajectories through three
stages: coarse-grained initialization, iterative refinement, and offline
verification. The initialization phase builds a structurally complete yet
semantically coarse dialogue skeleton; the iterative refinement phase
introduces realistic complexities and continued refinement via mask-and-fill
operations; and the offline verification phase ensures correctness and
coherence via rule- and model-based checks. Experiments demonstrate that
ToolACE-MT enables efficient, effective and generalizable agentic data
generation, offering a new paradigm for high-quality data construction in
tool-augmented LLM scenarios.

</details>


### [208] [DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726)
*Weize Liu,Yongchi Zhao,Yijia Luo,Mingyu Xu,Jiaheng Liu,Yanan Li,Xiguo Hu,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 这篇论文提出了DESIGNER数据合成流水线，通过设计逻辑概念从多学科原始文档生成了大规模、高难度的理解问题数据集，显著提升了大语言模型的多步理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的理解数据集要么缺乏学科广度，要么缺乏结构深度，无法激发模型的稳健理解行为。需要创建更具挑战性和多样性的多学科理解数据集。

Method: 提出DESIGNER数据合成流水线，使用设计逻辑概念模仿人类教育者的问题创造过程。从各学科现有问题中逆向工程抽象出12万个设计逻辑，然后将这些逻辑与学科源材料匹配生成理解问题。

Result: 生成了两个大规模数据集：DLR-Book（304万问题）和DLR-Web（166万问题），涵盖75个学科。问题难度和多样性显著超过基准数据集。在Qwen3-8B-Base和Qwen3-4B-Base模型上进行SFT实验，结果显示该数据集在同规模下显著超过现有多学科数据集。

Conclusion: DESIGNER方法能够生成高质量的多学科理解数据，有效提升大语言模型的多步理解能力，甚至能让基础模型超越官方模型的多学科理解性能。

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language tasks but still struggle with complex, multi-step reasoning,
particularly across diverse disciplines. Existing reasoning datasets often
either lack disciplinary breadth or the structural depth necessary to elicit
robust reasoning behaviors. We propose DESIGNER: a DESIGN-logic-guidEd
Reasoning data synthesis pipeline that leverages naturally available, extensive
raw documents (book corpus and web corpus) to generate multidisciplinary
challenging questions. A core innovation of our approach is the introduction of
a Design Logic concept, which mimics the question-creation process of human
educators. We use LLMs to reverse-engineer and abstract over 120,000 design
logics from existing questions across various disciplines. By matching these
design logics with disciplinary source materials, we are able to create
reasoning questions that far surpass the difficulty and diversity of existing
datasets. Based on this pipeline, we synthesized two large-scale reasoning
datasets that span 75 disciplines: Design-Logic-Reasoning-Book (DLR-Book),
containing 3.04 million challenging questions synthesized from the book corpus,
and Design-Logic-Reasoning-Web (DLR-Web), with 1.66 million challenging
questions from the web corpus. Our data analysis demonstrates that the
questions synthesized by our method exhibit substantially greater difficulty
and diversity than those in the baseline datasets. We validate the
effectiveness of these datasets by conducting SFT experiments on the
Qwen3-8B-Base and Qwen3-4B-Base models. The results show that our dataset
significantly outperforms existing multidisciplinary datasets of the same
volume. Training with the full datasets further enables the models to surpass
the multidisciplinary reasoning performance of the official Qwen3-8B and
Qwen3-4B models.

</details>


### [209] [LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models](https://arxiv.org/abs/2508.12733)
*Zhiyuan Ning,Tianle Gu,Jiaxin Song,Shixin Hong,Lingyu Li,Huacan Liu,Jie Li,Yixu Wang,Meng Lingyu,Yan Teng,Yingchun Wang*

Main category: cs.CL

TL;DR: LinguaSafe是一个包含12种语言、45k条目的多语言安全基准测试，通过翻译、转创和本地化数据构建，提供多维度的安全评估框架，填补了LLM在多语言安全评估方面的空白。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多语言安全评估缺乏全面性和多样性数据，限制了多语言安全对齐的发展，需要构建更全面的多语言安全基准。

Method: 结合翻译、转创和本地化数据源，构建包含12种语言45k条目的数据集，设计包含直接/间接安全评估和过度敏感性评估的多维度框架。

Result: 不同领域和语言的安全性和有用性评估结果差异显著，即使是资源水平相似的语言也存在明显差异。

Conclusion: 多语言安全评估对实现平衡的安全对齐至关重要，LinguaSafe为LLM多语言安全研究提供了全面的评估工具和数据集。

Abstract: The widespread adoption and increasing prominence of large language models
(LLMs) in global technologies necessitate a rigorous focus on ensuring their
safety across a diverse range of linguistic and cultural contexts. The lack of
a comprehensive evaluation and diverse data in existing multilingual safety
evaluations for LLMs limits their effectiveness, hindering the development of
robust multilingual safety alignment. To address this critical gap, we
introduce LinguaSafe, a comprehensive multilingual safety benchmark crafted
with meticulous attention to linguistic authenticity. The LinguaSafe dataset
comprises 45k entries in 12 languages, ranging from Hungarian to Malay. Curated
using a combination of translated, transcreated, and natively-sourced data, our
dataset addresses the critical need for multilingual safety evaluations of
LLMs, filling the void in the safety evaluation of LLMs across diverse
under-represented languages from Hungarian to Malay. LinguaSafe presents a
multidimensional and fine-grained evaluation framework, with direct and
indirect safety assessments, including further evaluations for oversensitivity.
The results of safety and helpfulness evaluations vary significantly across
different domains and different languages, even in languages with similar
resource levels. Our benchmark provides a comprehensive suite of metrics for
in-depth safety evaluation, underscoring the critical importance of thoroughly
assessing multilingual safety in LLMs to achieve more balanced safety
alignment. Our dataset and code are released to the public to facilitate
further research in the field of multilingual LLM safety.

</details>


### [210] [CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description](https://arxiv.org/abs/2508.12769)
*Shaoming Duan,Zirui Wang,Chuanyi Liu,Zhibin Zhu,Yuhao Zhang,Peiyi Han,Liang Yan,Zewu Penge*

Main category: cs.CL

TL;DR: CRED-SQL是一个针对大规模数据库的Text-to-SQL框架，通过聚类检索和执行描述语言解决语义不匹配问题，在两个大型跨域基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 大规模数据库中自然语言问题与SQL查询之间的语义不匹配问题严重，特别是在语义相似的属性存在时，这会阻碍模式链接并在SQL生成过程中产生语义漂移，降低模型准确性

Method: 提出CRED-SQL框架，包含聚类检索和执行描述语言(EDL)。首先进行基于聚类的大规模模式检索来定位最相关的表和列，然后引入EDL作为中间自然语言表示，将任务分解为Text-to-EDL和EDL-to-SQL两个阶段

Result: 在两个大规模跨域基准测试SpiderUnion和BirdUnion上的广泛实验表明，CRED-SQL达到了新的最先进(SOTA)性能

Conclusion: CRED-SQL通过集成聚类检索和执行描述语言，有效解决了大规模数据库中的语义不匹配问题，验证了其有效性和可扩展性

Abstract: Recent advances in large language models (LLMs) have significantly improved
the accuracy of Text-to-SQL systems. However, a critical challenge remains: the
semantic mismatch between natural language questions (NLQs) and their
corresponding SQL queries. This issue is exacerbated in large-scale databases,
where semantically similar attributes hinder schema linking and semantic drift
during SQL generation, ultimately reducing model accuracy. To address these
challenges, we introduce CRED-SQL, a framework designed for large-scale
databases that integrates Cluster Retrieval and Execution Description. CRED-SQL
first performs cluster-based large-scale schema retrieval to pinpoint the
tables and columns most relevant to a given NLQ, alleviating schema mismatch.
It then introduces an intermediate natural language representation-Execution
Description Language (EDL)-to bridge the gap between NLQs and SQL. This
reformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL,
leveraging LLMs' strong general reasoning capabilities while reducing semantic
deviation. Extensive experiments on two large-scale, cross-domain
benchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new
state-of-the-art (SOTA) performance, validating its effectiveness and
scalability. Our code is available at https://github.com/smduan/CRED-SQL.git

</details>


### [211] [From SALAMANDRA to SALAMANDRATA: BSC Submission for WMT25 General Machine Translation Shared Task](https://arxiv.org/abs/2508.12774)
*Javier Garcia Gilabert,Xixian Liao,Severino Da Dalt,Ella Bohman,Audrey Mash,Francesca De Luca Fornaciari,Irene Baucells,Joan Llop,Miguel Claramunt Argote,Carlos Escolano,Maite Melero*

Main category: cs.CL

TL;DR: SALAMANDRATA模型家族是SALAMANDRA LLMs的改进版本，专门针对38种欧洲语言的翻译任务进行训练，提供2B和7B两个参数规模版本，采用连续预训练和监督微调两阶段训练方法，并在WMT25机器翻译任务中应用质量感知解码策略。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对多语言翻译任务的高性能模型，特别是针对38种欧洲语言的翻译需求，提升机器翻译的质量和覆盖范围。

Method: 采用两阶段训练方法：1）在平行数据上进行连续预训练；2）在高质量指令上进行监督微调。针对WMT25任务额外进行词汇表适配和专门优化。解码时使用最小贝叶斯风险解码和基于COMET的调优重排序策略。

Result: 开发了SALAMANDRATA 2B和7B两个版本的模型，以及更新的SALAMANDRATA-V2模型，所有模型均在Hugging Face平台上公开发布。

Conclusion: SALAMANDRATA模型家族为多语言机器翻译任务提供了有效的解决方案，通过专门的训练方法和质量感知解码策略，在翻译性能上取得了显著提升，为研究社区提供了有价值的资源。

Abstract: In this paper, we present the SALAMANDRATA family of models, an improved
iteration of SALAMANDRA LLMs (Gonzalez-Agirre et al., 2025) specifically
trained to achieve strong performance in translation-related tasks for 38
European languages. SALAMANDRATA comes in two scales: 2B and 7B parameters. For
both versions, we applied the same training recipe with a first step of
continual pre-training on parallel data, and a second step of supervised
fine-tuning on high-quality instructions. The BSC submission to the WMT25
General Machine Translation shared task is based on the 7B variant of
SALAMANDRATA. We first adapted the model vocabulary to support the additional
non-European languages included in the task. This was followed by a second
phase of continual pre-training and supervised fine-tuning, carefully designed
to optimize performance across all translation directions for this year's
shared task. For decoding, we employed two quality-aware strategies: Minimum
Bayes Risk Decoding and Tuned Re-ranking using COMET and COMET-KIWI
respectively. We publicly release both the 2B and 7B versions of SALAMANDRATA,
along with the newer SALAMANDRATA-V2 model, on Hugging Face1

</details>


### [212] [HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks](https://arxiv.org/abs/2508.12778)
*Zhe Chen,Yusheng Liao,Shuyang Jiang,Zhiyuan Zhu,Haolin Li,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: MedAtlas和HeteroRAG框架通过整合多模态医疗报告和文本语料库，解决了医疗大视觉语言模型的事实不准确问题，显著提升了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 医疗大视觉语言模型存在事实不准确和输出不可靠的问题，在真实诊断中存在风险。现有的多模态检索增强生成系统无法有效处理异构数据源的检索。

Method: 构建MedAtlas多模态报告库，提出HeteroRAG框架：使用模态特定CLIP进行报告检索，多语料查询生成器动态构建查询，通过异构知识偏好调优实现跨模态多源知识对齐。

Result: 在12个数据集和3种模态上的实验表明，HeteroRAG在大多数医疗视觉语言基准测试中达到最先进性能，显著提高了Med-LVLMs的事实准确性和可靠性。

Conclusion: 该研究通过异构知识源增强Med-LVLMs，有效解决了医疗诊断中的事实准确性问题，为临床决策提供了更可靠的支持。

Abstract: Medical large vision-language Models (Med-LVLMs) have shown promise in
clinical applications but suffer from factual inaccuracies and unreliable
outputs, posing risks in real-world diagnostics. While retrieval-augmented
generation has emerged as a potential solution, current medical multimodal RAG
systems are unable to perform effective retrieval across heterogeneous sources.
The irrelevance of retrieved reports affects the factuality of analysis, while
insufficient knowledge affects the credibility of clinical decision-making. To
bridge the gap, we construct MedAtlas, which includes extensive multimodal
report repositories and diverse text corpora. Based on it, we present
HeteroRAG, a novel framework that enhances Med-LVLMs through heterogeneous
knowledge sources. The framework introduces Modality-specific CLIPs for
effective report retrieval and a Multi-corpora Query Generator for dynamically
constructing queries for diverse corpora. Incorporating knowledge from such
multifaceted sources, Med-LVLM is then trained with Heterogeneous Knowledge
Preference Tuning to achieve cross-modality and multi-source knowledge
alignment. Extensive experiments across 12 datasets and 3 modalities
demonstrate that the proposed HeteroRAG achieves state-of-the-art performance
in most medical vision language benchmarks, significantly improving factual
accuracy and reliability of Med-LVLMs.

</details>


### [213] [Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward](https://arxiv.org/abs/2508.12800)
*Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Changhua Meng*

Main category: cs.CL

TL;DR: 提出了Atomic Thought思维范式和Atom-Searcher强化学习框架，通过细粒度推理单元和过程奖励解决传统RAG和基于结果的RL在深度研究任务中的局限性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂任务中受限于静态知识，RAG方法在多跳推理和策略搜索方面存在局限，而基于结果的强化学习存在梯度冲突和奖励稀疏问题

Method: 1) Atomic Thought：将推理分解为细粒度功能单元，由推理奖励模型提供原子思维奖励；2) Atom-Searcher：整合Atomic Thought和ATR的RL框架，采用课程式奖励调度

Result: 在7个基准测试中均优于最先进方法，具有可扩展计算、更好的可解释性和类人推理模式等优势

Conclusion: Atomic Thought和Atom-Searcher框架有效解决了深度研究任务中的推理和监督问题，提供了更高效和可解释的解决方案

Abstract: Large language models (LLMs) exhibit remarkable problem-solving abilities,
but struggle with complex tasks due to static internal knowledge.
Retrieval-Augmented Generation (RAG) enhances access to external information,
yet remains limited in multi-hop reasoning and strategic search due to rigid
workflows. Recent advancements in agentic deep research empower LLMs to
autonomously reason, search, and synthesize information. However, current
approaches relying on outcome-based reinforcement learning (RL) face critical
issues such as conflicting gradients and reward sparsity, limiting performance
gains and training efficiency. To address these, we first propose Atomic
Thought, a novel LLM thinking paradigm that decomposes reasoning into
fine-grained functional units. These units are supervised by Reasoning Reward
Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained
guidance. Building on this, we propose Atom-Searcher, a novel RL framework for
agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher
uses a curriculum-inspired reward schedule, prioritizing process-level ATR
early and transitioning to outcome rewards, accelerating convergence on
effective reasoning paths. Experiments on seven benchmarks show consistent
improvements over the state-of-the-art. Key advantages include: (1)
Atom-Searcher scales computation at test-time. (2) Atomic Thought provides
supervision anchors for RRMs, bridging deep research tasks and RRMs. (3)
Atom-Searcher exhibits more interpretable, human-like reasoning patterns.

</details>


### [214] [When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models](https://arxiv.org/abs/2508.12803)
*Ahmed Elshabrawy,Hour Kaing,Haiyue Song,Alham Fikri Aji,Hideki Tanaka,Masao Utiyama,Raj Dabre*

Main category: cs.CL

TL;DR: 这篇论文通过实验证明，高资源标准语言的表征空间占据会对相关低资源方言的生成式建模产生负面影响，并提出了一种在线变分探针框架来解耦这种关联。


<details>
  <summary>Details</summary>
Motivation: 挖掘高资源标准语言（如现代标准阿拉伯语）与关联低资源方言表征之间的潜在负面作用，并提供原因性证据证明过度表征缘绕会限制相关语言变体的生成能力。

Method: 提出了一种在线变分探针框架，连续估计标准语言的子空间，并通过投影基础的解耦方法来减少这种依赖。以阿拉伯语25种方言的平行语料为案例进行研究。

Result: 在25种方言上，此干预方法将生成质量提高了最高+4.9 chrF++分数，平均+2.0，虽然在标准语言性能上存在一定的交换损失。

Conclusion: 高资源语言的子空间占据会限制相关语言变体的生成能力，该研究统一了几何和信息论探针技术，为多语言多域大语言模型的表征分配控制提供了实用工具。

Abstract: Alignment with high-resource standard languages is often assumed to aid the
modeling of related low-resource varieties. We challenge this assumption by
demonstrating that excessive representational entanglement with a dominant
variety, such as Modern Standard Arabic (MSA) in relation to Arabic dialects,
can actively hinder generative modeling. We present the first comprehensive
causal study of this phenomenon by analyzing and directly intervening in the
internal representation geometry of large language models (LLMs). Our key
contribution is an online variational probing framework that continuously
estimates the subspace of the standard variety during fine-tuning, enabling
projection-based decoupling from this space. While our study uses Arabic as a
case due to its unusually rich parallel resources across 25 dialects, the
broader motivation is methodological: dialectal MT serves as a controlled proxy
for generative tasks where comparable multi-variety corpora are unavailable.
Across 25 dialects, our intervention improves generation quality by up to +4.9
chrF++ and +2.0 on average compared to standard fine-tuning, despite a measured
tradeoff in standard-language performance. These results provide causal
evidence that subspace dominance by high-resource varieties can restrict
generative capacity for related varieties. More generally, we unify geometric
and information-theoretic probing with subspace-level causal interventions,
offering practical tools for improving generative modeling in closely related
language families and, more broadly, for controlling representational
allocation in multilingual and multi-domain LLMs. Code will be released.

</details>


### [215] [ding-01 :ARG0: An AMR Corpus for Spontaneous French Dialogue](https://arxiv.org/abs/2508.12819)
*Jeongwoo Kang,Maria Boritchev,Maximin Coavoux*

Main category: cs.CL

TL;DR: 构建法语对话语义语料库，扩展AMR框架适应自发语言特征，并训练AMR解析器作为注解工具


<details>
  <summary>Details</summary>
Motivation: 为了开发法语对话的语义资源，对自发语言进行深度语义注解，补充现有AMR框架在处理自发语言方面的不足

Method: 使用DinG语料库的法语自发对话进行AMR注解，扩展AMR框架以更好表示自发语言动态和法语特有句法结构，制定详细注解指南，训练AMR解析器

Result: 构建了免费开放的法语语义语料库(CC-SA-BY许可)，开发了支持一致注解的AMR解析器模型，可作为半自动化注解工具

Conclusion: 该工作为法语对话语义资源开发做出了贡献，通过扩展AMR框架和开发半自动化注解工具，推动了法语语义处理的发展

Abstract: We present our work to build a French semantic corpus by annotating French
dialogue in Abstract Meaning Representation (AMR). Specifically, we annotate
the DinG corpus, consisting of transcripts of spontaneous French dialogues
recorded during the board game Catan. As AMR has insufficient coverage of the
dynamics of spontaneous speech, we extend the framework to better represent
spontaneous speech and sentence structures specific to French. Additionally, to
support consistent annotation, we provide an annotation guideline detailing
these extensions. We publish our corpus under a free license (CC-SA-BY). We
also train and evaluate an AMR parser on our data. This model can be used as an
assistance annotation tool to provide initial annotations that can be refined
by human annotators. Our work contributes to the development of semantic
resources for French dialogue.

</details>


### [216] [Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection](https://arxiv.org/abs/2508.12828)
*Raneem Alharthi,Rajwa Alharthi,Aiqi Jiang,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 本研究探讨了利用上下文信息（父推文）来提升社交媒体回复中辱骂性语言检测的效果，发现结合内容特征能显著改善分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的辱骂性语言检测研究主要关注单个社交媒体帖子，忽略了从周围帖子中获得的额外上下文信息。本研究旨在探索利用父推文上下文是否有助于检测回复中的辱骂内容。

Method: 研究了一系列基于内容和账户的特征，比较了仅使用回复推文特征的方法。在包含对话交换（父推文-回复推文对）的数据集上测试了四种不同的分类模型。

Result: 实验表明，结合上下文特征相比仅使用回复推文特征有显著改进。内容特征（发布内容）比账户特征（发布者身份）对分类性能贡献更大，且组合多种特征效果最佳。

Conclusion: 研究证实了利用上下文信息的重要性，为在涉及对话的现实环境中开发情境化辱骂性语言检测模型提供了见解。

Abstract: Abusive language detection has become an increasingly important task as a
means to tackle this type of harmful content in social media. There has been a
substantial body of research developing models for determining if a social
media post is abusive or not; however, this research has primarily focused on
exploiting social media posts individually, overlooking additional context that
can be derived from surrounding posts. In this study, we look at conversational
exchanges, where a user replies to an earlier post by another user (the parent
tweet). We ask: does leveraging context from the parent tweet help determine if
a reply post is abusive or not, and what are the features that contribute the
most? We study a range of content-based and account-based features derived from
the context, and compare this to the more widely studied approach of only
looking at the features from the reply tweet. For a more generalizable study,
we test four different classification models on a dataset made of
conversational exchanges (parent-reply tweet pairs) with replies labeled as
abusive or not. Our experiments show that incorporating contextual features
leads to substantial improvements compared to the use of features derived from
the reply tweet only, confirming the importance of leveraging context. We
observe that, among the features under study, it is especially the
content-based features (what is being posted) that contribute to the
classification performance rather than account-based features (who is posting
it). While using content-based features, it is best to combine a range of
different features to ensure improved performance over being more selective and
using fewer features. Our study provides insights into the development of
contextualized abusive language detection models in realistic settings
involving conversations.

</details>


### [217] [It takes a village to write a book: Mapping anonymous contributions in Stephen Langton's Quaestiones Theologiae](https://arxiv.org/abs/2508.12830)
*Jan Maliszewski*

Main category: cs.CL

TL;DR: 这篇论文提出了一种用于分析中世纪教育文献的计算方法，通过形式语言学技术检测口讲教学记录文档的编辑层次，以验证关于这些文档形成过程的假设。


<details>
  <summary>Details</summary>
Motivation: 虽然间接证据表明在早期经院哲学时代，基于口头教学记录的文学创作并不穷见，但很少有源泄评论这种实践。需要新方法来分析这些古典文档的编辑过程。

Method: 采用形式语言学作者归属技术，对Stephen Langton的神学问题集进行分析。实施HTR（手写文本识别）流程，基于最常见单词、词性标注和伪后缀进行形式语言学分析。比较手工编辑和自动提取数据的性能，测试基于transformer的OCR和自动转录对齐技术。

Result: 这是一个提出的研究设计，尚未得出具体结果。如果成功，将会提供一个易于重用的模板。

Conclusion: 这项研究为计算教育传统研究带来两个方法论改进：直接比较手工编辑和自动提取数据的性能，以及验证基于transformer的OCR和自动转录对齐技术在教育拉丁语语料库中的有效性。

Abstract: While the indirect evidence suggests that already in the early scholastic
period the literary production based on records of oral teaching (so-called
reportationes) was not uncommon, there are very few sources commenting on the
practice. This paper details the design of a study applying stylometric
techniques of authorship attribution to a collection developed from
reportationes -- Stephen Langton's Quaestiones Theologiae -- aiming to uncover
layers of editorial work and thus validate some hypotheses regarding the
collection's formation. Following Camps, Cl\'erice, and Pinche (2021), I
discuss the implementation of an HTR pipeline and stylometric analysis based on
the most frequent words, POS tags, and pseudo-affixes. The proposed study will
offer two methodological gains relevant to computational research on the
scholastic tradition: it will directly compare performance on manually composed
and automatically extracted data, and it will test the validity of
transformer-based OCR and automated transcription alignment for workflows
applied to scholastic Latin corpora. If successful, this study will provide an
easily reusable template for the exploratory analysis of collaborative literary
production stemming from medieval universities.

</details>


### [218] [Word Meanings in Transformer Language Models](https://arxiv.org/abs/2508.12863)
*Jumbly Grindrod,Peter Grindrod*

Main category: cs.CL

TL;DR: 这篇论文研究了Transformer语言模型中词汇含义的表征方式，通过对RoBERTa-base模型的进一步分析发现其token嵌入空间中编码了丰富的语义信息，反驳了某些语义消过论假设。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer语言模型是否采用类似词汇库的方式表征词汇含义，即每个词是否有包含语义信息的入口。

Method: 提取RoBERTa-base模型的token嵌入空间，使用k-means聚类算法将其分为200个聚类，然后通过两个研究：手动检查聚类的语义敏感性，以及测试聚类对五种心理语言学指标的敏感性。

Result: 发现token嵌入空间中编码了广泛多样的语义信息，聚类显示出对语义信息的敏感性。

Conclusion: 这些发现有力地反驳了某些"语义消过论"假设，证明Transformer LLM在处理语义信息时并非消除语义表征。

Abstract: We investigate how word meanings are represented in the transformer language
models. Specifically, we focus on whether transformer models employ something
analogous to a lexical store - where each word has an entry that contains
semantic information. To do this, we extracted the token embedding space of
RoBERTa-base and k-means clustered it into 200 clusters. In our first study, we
then manually inspected the resultant clusters to consider whether they are
sensitive to semantic information. In our second study, we tested whether the
clusters are sensitive to five psycholinguistic measures: valence,
concreteness, iconicity, taboo, and age of acquisition. Overall, our findings
were very positive - there is a wide variety of semantic information encoded
within the token embedding space. This serves to rule out certain "meaning
eliminativist" hypotheses about how transformer LLMs process semantic
information.

</details>


### [219] [An LLM Agent-Based Complex Semantic Table Annotation Approach](https://arxiv.org/abs/2508.12868)
*Yilin Geng,Shujing Wang,Chuan Wang,Keqing He,Yanfei Lv,Ying Wang,Zaiwen Feng,Xiaoying Bai*

Main category: cs.CL

TL;DR: 基于LLM的代理方法通过动态选择注释策略和删除冗余注释，在复杂表格语义注释任务中实现了更高准确性和更低成本


<details>
  <summary>Details</summary>
Motivation: 复杂表格存在列名或单元格值语义丢失、严格的本体论层次要求、同词异义、拼写错误等挑战，影响注释准确性

Method: 基于ReAct框架设计5个外部工具和精心设计的提示，让STA代理能够根据表格特征动态选择适合的注释策略

Result: 在Tough Tables和BiodivTab数据集上超越现有方法，通过Levenshtein距离减少冗余注释，实现时间成本降低70%、LLM令牌使用量降低60%

Conclusion: 该方法为表格语义注释任务提供了高效、成本效益好的解决方案，能够有效处理复杂表格的各种挑战

Abstract: The Semantic Table Annotation (STA) task, which includes Column Type
Annotation (CTA) and Cell Entity Annotation (CEA), maps table contents to
ontology entities and plays important roles in various semantic applications.
However, complex tables often pose challenges such as semantic loss of column
names or cell values, strict ontological hierarchy requirements, homonyms,
spelling errors, and abbreviations, which hinder annotation accuracy. To
address these issues, this paper proposes an LLM-based agent approach for CTA
and CEA. We design and implement five external tools with tailored prompts
based on the ReAct framework, enabling the STA agent to dynamically select
suitable annotation strategies depending on table characteristics. Experiments
are conducted on the Tough Tables and BiodivTab datasets from the SemTab
challenge, which contain the aforementioned challenges. Our method outperforms
existing approaches across various metrics. Furthermore, by leveraging
Levenshtein distance to reduce redundant annotations, we achieve a 70%
reduction in time costs and a 60% reduction in LLM token usage, providing an
efficient and cost-effective solution for STA.

</details>


### [220] [A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models](https://arxiv.org/abs/2508.12903)
*Jinyi Han,Xinyi Wang,Haiquan Zhao,Tingyun li,Zishang Jiang,Sihang Jiang,Jiaqing Liang,Xin Lin,Weikang Zhou,Zeye Sun,Fei Yu,Yanghua Xiao*

Main category: cs.CL

TL;DR: PASR是一种主动自优化方法，让LLM在生成过程中动态决定何时、如何优化输出，相比传统固定迭代方法显著提升效率（减少41.6% token消耗）和准确性（提升8.2%）


<details>
  <summary>Details</summary>
Motivation: 现有自优化方法采用固定迭代次数的被动优化，难以根据生成上下文动态确定最佳优化时机和内容，而人类在思考过程中会动态优化思路

Method: 提出PASR方法，基于模型内部状态和演化上下文主动决定是否、何时以及如何优化，而不是重新生成整个响应

Result: 在10个多样化任务上的实验表明，PASR显著提升问题解决性能，在Qwen3-8B上相比标准生成减少41.6% token消耗，同时提升8.2%准确率

Conclusion: PASR通过主动在生成过程中进行动态优化，有效解决了传统自优化方法的局限性，在效率和准确性方面都取得了显著提升

Abstract: Recent advances in self-refinement have demonstrated significant potential
for improving the outputs of large language models (LLMs) through iterative
refinement. However, most existing self-refinement methods rely on a reactive
process with a fixed number of iterations, making it difficult to determine the
optimal timing and content of refinement based on the evolving generation
context. Inspired by the way humans dynamically refine their thoughts during
execution, we propose ProActive Self-Refinement (PASR), a novel method that
enables LLMs to refine their outputs during the generation process. Unlike
methods that regenerate entire responses, PASR proactively decides whether,
when, and how to refine based on the model's internal state and evolving
context. We conduct extensive experiments on a diverse set of 10 tasks to
evaluate the effectiveness of PASR. Experimental results show that PASR
significantly enhances problem-solving performance. In particular, on Qwen3-8B,
PASR reduces average token consumption by 41.6 percent compared to standard
generation, while also achieving an 8.2 percent improvement in accuracy. Our
code and all baselines used in the paper are available in the GitHub.

</details>


### [221] [Analyzing Information Sharing and Coordination in Multi-Agent Planning](https://arxiv.org/abs/2508.12981)
*Tianyue Ou,Saujas Vaduguru,Daniel Fried*

Main category: cs.CL

TL;DR: 多游戏规划任务中，LLM基于多代理系统通过笔记本共享和组织器协调，完成率提升25%。


<details>
  <summary>Details</summary>
Motivation: 长期限多约束规划任务对于大语言模型多代理系统构成挑战，需要处理详细信息和复杂的相互依赖约束。

Method: 构建LLM基于多代理系统进行旅行规划，引入笔记本机制促进信息共享，以及组织器代理来改善在自由形式对话中的协调。

Result: 笔记本减少幽灵详情错误18%，组织器在重点子领域进一步减少13.5%的错误。结合两种机制在TravelPlanner基准上达到25%的最终通过率，相比单代理基准线提升17.5%。

Conclusion: 结构化信息共享和反思性组织是LLM多代理系统在长期限规划任务中的关键组件，显示了这种系统的潜力。

Abstract: Multi-agent systems (MASs) have pushed the boundaries of large language model
(LLM) agents in domains such as web research and software engineering. However,
long-horizon, multi-constraint planning tasks involve conditioning on detailed
information and satisfying complex interdependent constraints, which can pose a
challenge for these systems. In this study, we construct an LLM-based MAS for a
travel planning task which is representative of these challenges. We evaluate
the impact of a notebook to facilitate information sharing, and evaluate an
orchestrator agent to improve coordination in free form conversation between
agents. We find that the notebook reduces errors due to hallucinated details by
18%, while an orchestrator directs the MAS to focus on and further reduce
errors by up to 13.5% within focused sub-areas. Combining both mechanisms
achieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute
improvement over the single-agent baseline's 7.5% pass rate. These results
highlight the potential of structured information sharing and reflective
orchestration as key components in MASs for long horizon planning with LLMs.

</details>


### [222] [WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents](https://arxiv.org/abs/2508.13024)
*Ralph Peeters,Aaron Steiner,Luca Schwarz,Julian Yuya Caspary,Christian Bizer*

Main category: cs.CL

TL;DR: WebMall是一个多商店在线购物基准测试，用于评估网络代理在比较购物中的效果和效率，包含4个模拟商店和91个跨商店任务，测试结果显示最佳配置在基础任务上达到75%完成率。


<details>
  <summary>Details</summary>
Motivation: 现有的电子商务基准测试（如WebShop或ShoppingBench）缺乏跨多商店的比较购物任务，且产品报价不够异构化，需要更长的交互轨迹来模拟真实购物行为。

Method: 构建包含4个模拟在线商店的基准测试，使用Common Crawl获取的真实产品报价，设计91个跨商店任务（包括基础任务和高级任务），评估8个基线代理的不同配置。

Result: 最佳配置在基础任务集上达到75%完成率和87% F1分数，在高级任务集上达到53%完成率和63% F1分数，使用GPT 4.1和Claude Sonnet 4模型。

Conclusion: WebMall基准测试公开发布，促进了网络代理研究，特别是在电子商务场景中的导航、推理和效率方面的进展，展示了多商店比较购物任务的挑战性。

Abstract: LLM-based web agents have the potential to automate long-running web tasks,
such as finding offers for specific products in multiple online shops and
subsequently ordering the cheapest products that meet the users needs. This
paper introduces WebMall, a multi-shop online shopping benchmark for evaluating
the effectiveness and efficiency of web agents for comparison-shopping. WebMall
consists of four simulated online shops populated with authentic product offers
sourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These
tasks include basic tasks such as finding specific products in multiple shops,
performing price comparisons, adding items to the shopping cart, and completing
checkout. Advanced tasks involve searching for products based on vague
requirements, identifying suitable substitutes, and finding compatible
products. Compared to existing e-commerce benchmarks, such as WebShop or
ShoppingBench, WebMall introduces comparison-shopping tasks across multiple
shops. Furthermore, the product offers are more heterogeneous, as they
originate from hundreds of distinct real-world shops. The tasks in WebMall
require longer interaction trajectories than those in WebShop, while remaining
representative of real-world shopping behaviors. We evaluate eight baseline
agents on WebMall, varying in observation modality, memory utilization, and
underlying large language model (GPT 4.1 and Claude Sonnet 4). The
best-performing configurations achieve completion rates of 75% and 53%, and F1
scores of 87% and 63%, on the basic and advanced task sets, respectively.
WebMall is publicly released to facilitate research on web agents and to
promote advancements in navigation, reasoning, and efficiency within e-commerce
scenarios.

</details>


### [223] [Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis](https://arxiv.org/abs/2508.13028)
*Zhu Li,Yuqing Zhang,Xiyuan Gao,Devraj Raghuvanshi,Nagendra Kumar,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 提出了一种结合双模态讽刺检测模型反馈损失和两阶段微调的方法，用于合成具有讽刺情感的语音，解决了讽刺语音数据稀缺和韵律微妙性的挑战。


<details>
  <summary>Details</summary>
Motivation: 讽刺语音合成对于增强娱乐和人机交互等应用中的自然交互至关重要，但由于讽刺的微妙韵律特征和标注数据的有限性，这一任务具有挑战性。

Method: 1) 将双模态讽刺检测模型的反馈损失整合到TTS训练过程中；2) 采用两阶段微调：先在包含多种语音风格的数据集上微调，再在专门的讽刺语音数据集上进一步精调。

Result: 客观和主观评估表明，所提方法提高了合成语音的质量、自然度和讽刺感知能力。

Conclusion: 该方法有效解决了讽刺语音合成的挑战，通过反馈损失和两阶段微调策略显著提升了合成语音的讽刺表达效果。

Abstract: Sarcastic speech synthesis, which involves generating speech that effectively
conveys sarcasm, is essential for enhancing natural interactions in
applications such as entertainment and human-computer interaction. However,
synthesizing sarcastic speech remains a challenge due to the nuanced prosody
that characterizes sarcasm, as well as the limited availability of annotated
sarcastic speech data. To address these challenges, this study introduces a
novel approach that integrates feedback loss from a bi-modal sarcasm detection
model into the TTS training process, enhancing the model's ability to capture
and convey sarcasm. In addition, by leveraging transfer learning, a speech
synthesis model pre-trained on read speech undergoes a two-stage fine-tuning
process. First, it is fine-tuned on a diverse dataset encompassing various
speech styles, including sarcastic speech. In the second stage, the model is
further refined using a dataset focused specifically on sarcastic speech,
enhancing its ability to generate sarcasm-aware speech. Objective and
subjective evaluations demonstrate that our proposed methods improve the
quality, naturalness, and sarcasm-awareness of synthesized speech.

</details>


### [224] [Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction](https://arxiv.org/abs/2508.13037)
*Xinhe Li,Jiajun Liu,Peng Wang*

Main category: cs.CL

TL;DR: LoRID方法通过多LoRA交互实现数学推理蒸馏，结合系统1直觉推理和系统2知识强化，让小语言模型在数学推理任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决小语言模型数学推理能力差的问题，受人类系统1（直觉）和系统2（知识+实践）双重思维模式启发，提出更有效的知识蒸馏方法。

Method: 使用多LoRA模块：直觉推理器直接生成思维链，知识生成器输出相关知识，深度推理器利用知识进行推理，并通过一致性检查实现迭代优化。

Result: 在GSM8K数据集上超越第二名方法2.3%-16.1%的准确率，在五个基础模型上都取得最先进性能。

Conclusion: LoRID通过模拟人类双重思维模式，有效提升了小语言模型的数学推理能力，为小模型的知识蒸馏提供了新思路。

Abstract: Recent studies have demonstrated that Large Language Models (LLMs) have
strong mathematical reasoning abilities but rely on hundreds of billions of
parameters. To tackle the challenge of poor reasoning in Small Language Models
(SLMs), existing methods typically leverage LLMs to generate massive amounts of
data for cramming training. In psychology, they are akin to System 1 thinking,
which resolves reasoning problems rapidly based on experience and intuition.
However, human learning also requires System 2 thinking, where knowledge is
first acquired and then reinforced through practice. Inspired by such two
distinct modes of thinking, we propose a novel method based on the multi-LoRA
Interaction for mathematical reasoning Distillation (LoRID). First, we input
the question and reasoning of each sample into an LLM to create
knowledge-enhanced datasets. Subsequently, we train a LoRA block on the student
model as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts
for problem-solving. Then, to imitate System 2 thinking, we train the Knowledge
Generator (KG) and Deep Reasoner (DR), respectively. The former outputs only
knowledge after receiving problems, while the latter uses that knowledge to
perform reasoning. Finally, to address the randomness in the generation of IR
and DR, we evaluate whether their outputs are consistent, and the inference
process needs to be iterated if not. This step can enhance the mathematical
reasoning ability of SLMs through mutual feedback. Experimental results show
that LoRID achieves state-of-the-art performance, especially on the GSM8K
dataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%,
12.3%, and 1.8% accuracy across the five base models, respectively.

</details>


### [225] [Büyük Dil Modelleri için TR-MMLU Benchmarkı: Performans Değerlendirmesi, Zorluklar ve İyileştirme Fırsatları](https://arxiv.org/abs/2508.13044)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Banu Diri,Savaş Yıldırım,Öner Aytaş*

Main category: cs.CL

TL;DR: 提出了土耳其语MMLU基准(TR-MMLU)，包含6200个选择题，用于评估大语言模型在土耳其语上的能力。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型评估主要针对英语等资源丰富语言，土耳其语等资源有限语言缺乏全面的评估基准。

Method: 基于土耳其教育体系精心构建包含62个领域的6200个选择题数据集，建立标准化评估框架。

Result: 在TR-MMLU上评估了最先进的大语言模型，揭示了模型设计需要改进的方面。

Conclusion: TR-MMLU为土耳其NLP研究设立了新标准，将推动该领域的未来发展。

Abstract: Language models have made significant advancements in understanding and
generating human language, achieving remarkable success in various
applications. However, evaluating these models remains a challenge,
particularly for resource-limited languages like Turkish. To address this
issue, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive
evaluation framework designed to assess the linguistic and conceptual
capabilities of large language models (LLMs) in Turkish. TR-MMLU is based on a
meticulously curated dataset comprising 6,200 multiple-choice questions across
62 sections within the Turkish education system. This benchmark provides a
standard framework for Turkish NLP research, enabling detailed analyses of
LLMs' capabilities in processing Turkish text. In this study, we evaluated
state-of-the-art LLMs on TR-MMLU, highlighting areas for improvement in model
design. TR-MMLU sets a new standard for advancing Turkish NLP research and
inspiring future innovations.

</details>


### [226] [Doğal Dil İşlemede Tokenizasyon Standartları ve Ölçümü: Türkçe Üzerinden Büyük Dil Modellerinin Karşılaştırmalı Analizi](https://arxiv.org/abs/2508.13058)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Sercan Karakaş,Banu Diri,Savaş Yıldırım*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的评估框架，用于分析对于形态丰富和低资源语言（如土耳其语）的标记化方法，发现语言特定标记百分比比标记纯度更能预测下游性能，并强调需要针对语言特点进行定制化标记化。


<details>
  <summary>Details</summary>
Motivation: 标记化是NLP中的基础预处理步骤，对大语言模型的语言学和语义理解能力有重要影响。当前的标记化方法在形态丰富和低资源语言上面临特殊挑战，需要专门的评估标准。

Method: 使用土耳其语MMLU（TR-MMLU）数据集（包含6,200道多选题），通过评估词汇大小、标记数量、处理时间、语言特定标记百分比（%TR）和标记纯度（%Pure）等新指标来分析标记化器的性能。

Result: 分析显示语言特定标记百分比与下游性能（如MMLU分数）的相关性更强，而标记纯度的相关性较弱。简单增加模型参数并不能必然提升语言性能。

Conclusion: 研究建立了一个健壮而实用的标记化标准框架，特别适用于形态复杂语言。强调了针对语言特点进行定制化标记化的重要性，而不是依赖简单的模型扩展。

Abstract: Tokenization is a fundamental preprocessing step in Natural Language
Processing (NLP), significantly impacting the capability of large language
models (LLMs) to capture linguistic and semantic nuances. This study introduces
a novel evaluation framework addressing tokenization challenges specific to
morphologically-rich and low-resource languages such as Turkish. Utilizing the
Turkish MMLU (TR-MMLU) dataset, comprising 6,200 multiple-choice questions from
the Turkish education system, we assessed tokenizers based on vocabulary size,
token count, processing time, language-specific token percentages (\%TR), and
token purity (\%Pure). These newly proposed metrics measure how effectively
tokenizers preserve linguistic structures. Our analysis reveals that
language-specific token percentages exhibit a stronger correlation with
downstream performance (e.g., MMLU scores) than token purity. Furthermore,
increasing model parameters alone does not necessarily enhance linguistic
performance, underscoring the importance of tailored, language-specific
tokenization methods. The proposed framework establishes robust and practical
tokenization standards for morphologically complex languages.

</details>


### [227] [Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database](https://arxiv.org/abs/2508.13060)
*John Alderete,Macarious Kin Fung Hui,Aanchan Mohan*

Main category: cs.CL

TL;DR: SFUSED语音错误数据库可用于评估语音识别模型性能，通过分析WhisperX在5300个标注错误上的转录准确率，证明了该数据库作为ASR系统诊断工具的有效性。


<details>
  <summary>Details</summary>
Motivation: 开发一个公开的语音错误数据库，用于语言学和心理语言学研究，并展示其如何用于测试和评估语音识别模型。

Method: 使用SFUSED数据库中系统标注的自发英语语音错误，包含多个分类维度（语言层级、上下文敏感性、词退化、词修正、词级和音节级错误定位），评估WhisperX模型在5300个文档化错误上的转录准确率。

Result: 分析证明了SFUSED数据库作为ASR系统性能诊断工具的有效性，能够系统评估语音识别模型在不同类型错误上的表现。

Conclusion: SFUSED语音错误数据库提供了一个有价值的工具，可用于全面评估语音识别模型的性能，特别是在处理各种类型语音错误方面的能力。

Abstract: The Simon Fraser University Speech Error Database (SFUSED) is a public data
collection developed for linguistic and psycholinguistic research. Here we
demonstrate how its design and annotations can be used to test and evaluate
speech recognition models. The database comprises systematically annotated
speech errors from spontaneous English speech, with each error tagged for
intended and actual error productions. The annotation schema incorporates
multiple classificatory dimensions that are of some value to model assessment,
including linguistic hierarchical level, contextual sensitivity, degraded
words, word corrections, and both word-level and syllable-level error
positioning. To assess the value of these classificatory variables, we
evaluated the transcription accuracy of WhisperX across 5,300 documented word
and phonological errors. This analysis demonstrates the atabase's effectiveness
as a diagnostic tool for ASR system performance.

</details>


### [228] [Reinforced Context Order Recovery for Adaptive Reasoning and Planning](https://arxiv.org/abs/2508.13070)
*Long Ma,Fangwei Zhong,Yizhou Wang*

Main category: cs.CL

TL;DR: 提出了ReCOR强化学习框架，通过自适应选择token生成顺序来改进因果和扩散语言模型，在推理和规划任务上表现优于基线方法


<details>
  <summary>Details</summary>
Motivation: 当前因果和扩散模型使用固定或随机token生成顺序，与逻辑顺序不符，在处理需要自适应token顺序的问题时存在困难

Method: 基于强化学习的ReCOR框架，通过token预测统计进行自监督，估计未填充token的预测难度并自适应选择下一个token

Result: 在具有挑战性的推理和规划数据集上表现出优越性能，有时甚至优于使用真实顺序监督的oracle模型

Conclusion: ReCOR框架能够有效提取数据依赖的自适应token生成顺序，显著提升模型在复杂任务上的表现

Abstract: Modern causal language models, followed by rapid developments in discrete
diffusion models, can now produce a wide variety of interesting and useful
content. However, these families of models are predominantly trained to output
tokens with a fixed (left-to-right) or random order, which may deviate from the
logical order in which tokens are generated originally. In this paper, we
observe that current causal and diffusion models encounter difficulties in
problems that require adaptive token generation orders to solve tractably,
which we characterize with the $\mathcal{V}$-information framework. Motivated
by this, we propose Reinforced Context Order Recovery (ReCOR), a
reinforcement-learning-based framework to extract adaptive, data-dependent
token generation orders from text data without annotations. Self-supervised by
token prediction statistics, ReCOR estimates the hardness of predicting every
unfilled token and adaptively selects the next token during both training and
inference. Experiments on challenging reasoning and planning datasets
demonstrate the superior performance of ReCOR compared with baselines,
sometimes outperforming oracle models supervised with the ground-truth order.

</details>


### [229] [DocHPLT: A Massively Multilingual Document-Level Translation Dataset](https://arxiv.org/abs/2508.13079)
*Dayyán O'Brien,Bhavitvya Malik,Ona de Gibert,Pinzhen Chen,Barry Haddow,Jörg Tiedemann*

Main category: cs.CL

TL;DR: 创建了DocHPLT，这是目前最大的公开文档级翻译数据集，包含50种语言与英语的1.24亿对齐文档对，共42.6亿句子，为长上下文建模提供基础设施。


<details>
  <summary>Details</summary>
Motivation: 现有文档级机器翻译资源仅适用于少数高资源语言，需要为全球社区提供训练和评估文档级翻译及长上下文建模的基础设施。

Method: 修改现有的网络提取流程以保持源文档的完整性，保留所有内容包括未对齐部分，而不是基于句子级数据拼接文档的重建方法。

Result: LLMs在DocHPLT上微调后显著优于现成的指令调优基线，特别是对低资源语言有显著改进。初步实验确定了文档级翻译的最佳训练上下文策略。

Conclusion: DocHPLT数据集在宽松许可下开源，为推进多语言文档级翻译提供了必要的基础设施，特别有助于低资源语言的发展。

Abstract: Existing document-level machine translation resources are only available for
a handful of languages, mostly high-resourced ones. To facilitate the training
and evaluation of document-level translation and, more broadly, long-context
modeling for global communities, we create DocHPLT, the largest publicly
available document-level translation dataset to date. It contains 124 million
aligned document pairs across 50 languages paired with English, comprising 4.26
billion sentences, with further possibility to provide 2500 bonus pairs not
involving English. Unlike previous reconstruction-based approaches that piece
together documents from sentence-level data, we modify an existing web
extraction pipeline to preserve complete document integrity from the source,
retaining all content including unaligned portions. After our preliminary
experiments identify the optimal training context strategy for document-level
translation, we demonstrate that LLMs fine-tuned on DocHPLT substantially
outperform off-the-shelf instruction-tuned baselines, with particularly
dramatic improvements for under-resourced languages. We open-source the dataset
under a permissive license, providing essential infrastructure for advancing
multilingual document-level translation.

</details>


### [230] [All for law and law for all: Adaptive RAG Pipeline for Legal Research](https://arxiv.org/abs/2508.13107)
*Figarri Keisha,Prince Singh,Pallavi,Dion Fernandes,Aravindh Manivannan,Ilham Wicaksono,Faisal Ahmad*

Main category: cs.CL

TL;DR: 通过上下文感知查询翻译、开源提取策略和综合评估框架三项改进，构建了一个效果显著优于专有方案的成本效益高的法律领域RAG系统


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在法律领域中的幻觉问题，通过引用来源基础输出内容，提高答案的准确性和可靠性

Method: 给出了一个端到端的RAG流水线，包括：1）上下文感知查询翻译器；2）使用SBERT和GTE嵌入的开源提取策略；3）结合RAGAS、BERTScore-F1和ROUGE-Recall的综合评估框架

Result: 开源流水线在提取质量上可以拟或超过专有方案，Recall@K提高30-95%，Precision@K提高约2.5倍（K>4），自定义法律基础提示能产生更准确和上下文相关的答案

Conclusion: 该研究证明了任务感知的组件级调优能够建造出具有法律基础、可复现性和成本效益高的RAG系统，为法律研究辅助提供了有效解决方案

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding
large language model outputs in cited sources, a capability that is especially
critical in the legal domain. We present an end-to-end RAG pipeline that
revisits and extends the LegalBenchRAG baseline with three targeted
enhancements: (i) a context-aware query translator that disentangles document
references from natural-language questions and adapts retrieval depth and
response style based on expertise and specificity, (ii) open-source retrieval
strategies using SBERT and GTE embeddings that achieve substantial performance
gains (improving Recall@K by 30-95\% and Precision@K by $\sim$2.5$\times$ for
$K>4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and
generation framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to
assess semantic alignment and faithfulness across models and prompt designs.
Our results show that carefully designed open-source pipelines can rival or
outperform proprietary approaches in retrieval quality, while a custom
legal-grounded prompt consistently produces more faithful and contextually
relevant answers than baseline prompting. Taken together, these contributions
demonstrate the potential of task-aware, component-level tuning to deliver
legally grounded, reproducible, and cost-effective RAG systems for legal
research assistance.

</details>


### [231] [AutoBnB-RAG: Enhancing Multi-Agent Incident Response with Retrieval-Augmented Generation](https://arxiv.org/abs/2508.13118)
*Zefang Liu,Arman Anwar*

Main category: cs.CL

TL;DR: AutoBnB-RAG是一个基于检索增强生成的多智能体事件响应框架，通过整合外部知识提升网络安全决策质量


<details>
  <summary>Details</summary>
Motivation: 传统LLM在事件响应中缺乏外部知识访问能力，限制了推理效果，需要检索机制来增强决策能力

Method: 扩展AutoBnB框架，集成RAG技术，在Backdoors & Breaches游戏环境中实现多智能体协作调查，引入两种检索设置（技术文档和事件报告）和八种团队结构

Result: 检索增强显著提高了决策质量和成功率，能够重建复杂的多阶段网络攻击

Conclusion: 将检索机制集成到基于LLM的多智能体系统中对网络安全决策具有重要价值

Abstract: Incident response (IR) requires fast, coordinated, and well-informed
decision-making to contain and mitigate cyber threats. While large language
models (LLMs) have shown promise as autonomous agents in simulated IR settings,
their reasoning is often limited by a lack of access to external knowledge. In
this work, we present AutoBnB-RAG, an extension of the AutoBnB framework that
incorporates retrieval-augmented generation (RAG) into multi-agent incident
response simulations. Built on the Backdoors & Breaches (B&B) tabletop game
environment, AutoBnB-RAG enables agents to issue retrieval queries and
incorporate external evidence during collaborative investigations. We introduce
two retrieval settings: one grounded in curated technical documentation
(RAG-Wiki), and another using narrative-style incident reports (RAG-News). We
evaluate performance across eight team structures, including newly introduced
argumentative configurations designed to promote critical reasoning. To
validate practical utility, we also simulate real-world cyber incidents based
on public breach reports, demonstrating AutoBnB-RAG's ability to reconstruct
complex multi-stage attacks. Our results show that retrieval augmentation
improves decision quality and success rates across diverse organizational
models. This work demonstrates the value of integrating retrieval mechanisms
into LLM-based multi-agent systems for cybersecurity decision-making.

</details>


### [232] [Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries](https://arxiv.org/abs/2508.13124)
*Kawin Mayilvaghanan,Siddhant Gupta,Ayush Kumar*

Main category: cs.CL

TL;DR: 提出了一个叫BlindSpot的框架，用于识别和量化联系中心播放摘要中的操作偏见，发现所有LLM都存在系统性偏见


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在联系中心生成了数百万个播放摘要，但不清楚它们是否系统性地偏向某些话语方面，引入偏见

Method: 建立了包含15个操作偏见维度的分类法，利用LLM作为零样本分类器来测量话语和摘要之间的分布差异

Result: 对2500个真实播放进行实验，发现所有测试的20个不同规模和家族的LLM都存在系统性偏见

Conclusion: 操作偏见是联系中心摘要中的普遍问题，需要重视并开发相应的测量工具

Abstract: Abstractive summarization is a core application in contact centers, where
Large Language Models (LLMs) generate millions of summaries of call transcripts
daily. Despite their apparent quality, it remains unclear whether LLMs
systematically under- or over-attend to specific aspects of the transcript,
potentially introducing biases in the generated summary. While prior work has
examined social and positional biases, the specific forms of bias pertinent to
contact center operations - which we term Operational Bias - have remained
unexplored. To address this gap, we introduce BlindSpot, a framework built upon
a taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)
for the identification and quantification of these biases. BlindSpot leverages
an LLM as a zero-shot classifier to derive categorical distributions for each
bias dimension in a pair of transcript and its summary. The bias is then
quantified using two metrics: Fidelity Gap (the JS Divergence between
distributions) and Coverage (the percentage of source labels omitted). Using
BlindSpot, we conducted an empirical study with 2500 real call transcripts and
their summaries generated by 20 LLMs of varying scales and families (e.g., GPT,
Llama, Claude). Our analysis reveals that biases are systemic and present
across all evaluated models, regardless of size or family.

</details>


### [233] [MuDRiC: Multi-Dialect Reasoning for Arabic Commonsense Validation](https://arxiv.org/abs/2508.13130)
*Kareem Elozeiri,Mervat Abassy,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 这篇论文提出了MuDRiC数据集和基于GCN的新方法，用于阿拉伯语多方言的常识验证任务，补充了现有资源主要集中在现代标准阿拉伯语的空白


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语常识验证任务在多方言方面很少被研究，现有资源主要集中在现代标准阿拉伯语(MSA)，而密切地方言在口语中却很普遍

Method: 提出了MuDRiC多方言阿拉伯语常识数据集，并且采用图卷积网络(GCN)来建模语义关系，改善常识验证性能

Result: 实验结果显示该方法在阿拉伯语常识验证任务中取得了更优的性能

Conclusion: 这项工作通过提供基础数据集和新方法，为处理阿拉伯语复杂变体的自然语言理解做出了贡献，是首个阿拉伯语多方言常识推理数据集

Abstract: Commonsense validation evaluates whether a sentence aligns with everyday
human understanding, a critical capability for developing robust natural
language understanding systems. While substantial progress has been made in
English, the task remains underexplored in Arabic, particularly given its rich
linguistic diversity. Existing Arabic resources have primarily focused on
Modern Standard Arabic (MSA), leaving regional dialects underrepresented
despite their prevalence in spoken contexts. To bridge this gap, we present two
key contributions: (i) we introduce MuDRiC, an extended Arabic commonsense
dataset incorporating multiple dialects, and (ii) a novel method adapting Graph
Convolutional Networks (GCNs) to Arabic commonsense reasoning, which enhances
semantic relationship modeling for improved commonsense validation. Our
experimental results demonstrate that this approach achieves superior
performance in Arabic commonsense validation. Our work enhances Arabic natural
language understanding by providing both a foundational dataset and a novel
method for handling its complex variations. To the best of our knowledge, we
release the first Arabic multi-dialect commonsense reasoning dataset.

</details>


### [234] [Improving Detection of Watermarked Language Models](https://arxiv.org/abs/2508.13131)
*Dara Bahri,John Wieting*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Watermarking has recently emerged as an effective strategy for detecting the
generations of large language models (LLMs). The strength of a watermark
typically depends strongly on the entropy afforded by the language model and
the set of input prompts. However, entropy can be quite limited in practice,
especially for models that are post-trained, for example via instruction tuning
or reinforcement learning from human feedback (RLHF), which makes detection
based on watermarking alone challenging. In this work, we investigate whether
detection can be improved by combining watermark detectors with non-watermark
ones. We explore a number of hybrid schemes that combine the two, observing
performance gains over either class of detector under a wide range of
experimental conditions.

</details>


### [235] [OptimalThinkingBench: Evaluating Over and Underthinking in LLMs](https://arxiv.org/abs/2508.13141)
*Pranjal Aggarwal,Seungone Kim,Jack Lanchantin,Sean Welleck,Jason Weston,Ilia Kulikov,Swarnadeep Saha*

Main category: cs.CL

TL;DR: OptimalThinkingBench是一个统一基准测试，用于评估LLMs的过度思考（overthinking）和思考不足（underthinking）问题，旨在促进开发在性能与效率间取得平衡的最优思考模型。


<details>
  <summary>Details</summary>
Motivation: 现有的思考型LLMs在处理复杂任务时计算成本高且在简单问题上过度思考，而非思考型LLMs虽然更快更便宜但在困难推理问题上思考不足。这导致需要用户自行选择合适模型，因此需要统一的评估基准来推动最优思考模型的发展。

Method: 构建包含两个子基准的统一评测框架：OverthinkingBench（72个领域的简单查询）和UnderthinkingBench（11个挑战性推理任务），使用新颖的思考调整准确率指标，对33种不同思考和非思考模型进行广泛评估。

Result: 评估显示没有模型能在该基准上实现最优思考。思考型模型经常在简单查询上过度思考数百个token却无性能提升，而大型非思考型模型经常思考不足，表现甚至不如更小的思考型模型。尝试的优化方法往往在一个子基准上改进却在另一个上退步。

Conclusion: 当前LLMs普遍存在过度思考或思考不足的问题，需要开发更好的统一最优思考模型来平衡性能与效率。

Abstract: Thinking LLMs solve complex tasks at the expense of increased compute and
overthinking on simpler problems, while non-thinking LLMs are faster and
cheaper but underthink on harder reasoning problems. This has led to the
development of separate thinking and non-thinking LLM variants, leaving the
onus of selecting the optimal model for each query on the end user. In this
work, we introduce OptimalThinkingBench, a unified benchmark that jointly
evaluates overthinking and underthinking in LLMs and also encourages the
development of optimally-thinking models that balance performance and
efficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench,
featuring simple queries in 72 domains, and UnderthinkingBench, containing 11
challenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we
perform extensive evaluation of 33 different thinking and non-thinking models
and show that no model is able to optimally think on our benchmark. Thinking
models often overthink for hundreds of tokens on the simplest user queries
without improving performance. In contrast, large non-thinking models
underthink, often falling short of much smaller thinking models. We further
explore several methods to encourage optimal thinking, but find that these
approaches often improve on one sub-benchmark at the expense of the other,
highlighting the need for better unified and optimal models in the future.

</details>


### [236] [Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation](https://arxiv.org/abs/2508.13144)
*David Heineman,Valentin Hofmann,Ian Magnusson,Yuling Gu,Noah A. Smith,Hannaneh Hajishirzi,Kyle Lo,Jesse Dodge*

Main category: cs.CL

TL;DR: 这篇论文分析了评测基准的信号和噪声特性，提出了提高评估质量的三种干预方法，包括改进指标、筛选噪声子任务和平均中间检查点输出，以获得更可靠的评估结果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型开发成本昂贵，需要通过小规模实验做决策。当前的评测基准存在可靠性问题，影响模型选择的准确性。

Method: 提出两个关键指标：信号（区分模型能力的能力）和噪声（对训练步长随机变化的敏感性）。使用30个基准和375个开源语言模型，构建了900K评估结果的数据集。

Result: 高信噪比的基准在小规模实验中更可靠，低噪声基准有更低的缩放律预测误差。使用更好的指标（如困惑度代替准确率）、筛选噪声子任务和平均中间检查点都能显著提升评估质量。

Conclusion: 建议在创建或选择评测基准时优先考虑高信号低噪声的基准，通过改进指标、筛选子任务和平均检查点等方法可以有效提升评估的可靠性。

Abstract: Developing large language models is expensive and involves making decisions
with small experiments, typically by evaluating on large, multi-task evaluation
suites. In this work, we analyze specific properties which make a benchmark
more reliable for such decisions, and interventions to design higher-quality
evaluation benchmarks. We introduce two key metrics that show differences in
current benchmarks: signal, a benchmark's ability to separate better models
from worse models, and noise, a benchmark's sensitivity to random variability
between training steps. We demonstrate that benchmarks with a better
signal-to-noise ratio are more reliable when making decisions at small scale,
and those with less noise have lower scaling law prediction error. These
results suggest that improving signal or noise will lead to more useful
benchmarks, so we introduce three interventions designed to directly affect
signal or noise. For example, we propose that switching to a metric that has
better signal and noise (e.g., perplexity rather than accuracy) leads to better
reliability and improved scaling law error. We also find that filtering noisy
subtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable
multi-task evaluations. We also find that averaging the output of a model's
intermediate checkpoints to reduce noise leads to consistent improvements. We
conclude by recommending that those creating new benchmarks, or selecting which
existing benchmarks to use, aim for high signal and low noise. We use 30
benchmarks for these experiments, and 375 open-weight language models from 60M
to 32B parameters, resulting in a new, publicly available dataset of 900K
evaluation benchmark results, totaling 200M instances.

</details>


### [237] [RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns](https://arxiv.org/abs/2508.13152)
*Xin Chen,Junchao Wu,Shu Yang,Runzhe Zhan,Zeyu Wu,Ziyang Luo,Di Wang,Min Yang,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: RepreGuard是一种基于LLM内部表示的检测方法，通过提取区分性激活特征来有效识别AI生成文本，在分布内和分布外场景中均优于现有方法，平均AUROC达到94.92%。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在分布外场景下的鲁棒性不足，作者假设LLM内部表示包含更全面和原始的特征，能更有效捕捉AI生成文本与人类文本的统计模式差异。

Method: 使用代理模型收集文本表示，提取能更好识别AI生成文本的区分性激活特征，通过计算文本表示在该特征方向上的投影分数并与预计算阈值比较进行分类。

Result: 在分布内和分布外场景中，RepreGuard平均AUROC达到94.92%，优于所有基线方法，同时对不同文本大小和主流攻击具有鲁棒性。

Conclusion: LLM内部表示确实包含更有效的特征用于检测AI生成文本，RepreGuard方法在多种场景下都表现出优异的检测性能和鲁棒性。

Abstract: Detecting content generated by large language models (LLMs) is crucial for
preventing misuse and building trustworthy AI systems. Although existing
detection methods perform well, their robustness in out-of-distribution (OOD)
scenarios is still lacking. In this paper, we hypothesize that, compared to
features used by existing detection methods, the internal representations of
LLMs contain more comprehensive and raw features that can more effectively
capture and distinguish the statistical pattern differences between
LLM-generated texts (LGT) and human-written texts (HWT). We validated this
hypothesis across different LLMs and observed significant differences in neural
activation patterns when processing these two types of texts. Based on this, we
propose RepreGuard, an efficient statistics-based detection method.
Specifically, we first employ a surrogate model to collect representation of
LGT and HWT, and extract the distinct activation feature that can better
identify LGT. We can classify the text by calculating the projection score of
the text representations along this feature direction and comparing with a
precomputed threshold. Experimental results show that RepreGuard outperforms
all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD
scenarios, while also demonstrating robust resilience to various text sizes and
mainstream attacks. Data and code are publicly available at:
https://github.com/NLP2CT/RepreGuard

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [238] [Reduced-order modeling of Hamiltonian dynamics based on symplectic neural networks](https://arxiv.org/abs/2508.11911)
*Yongsheng Chen,Wei Guo,Qi Tang,Xinghui Zhong*

Main category: math.NA

TL;DR: 提出一种新的数据驱动的守富ROM框架，通过统一的神经网络架构同时实现潜在空间发现和动力学学习，确保减序模型的准确性和长期稳定性


<details>
  <summary>Details</summary>
Motivation: 解决高维守富系统减序模型中的结构保持问题，提高ROM的保真度和长期稳定性

Method: 使用Henon神经网络构建编码器-解码器，通过SGS反射器层实现了完全守富的相空间映射，并用HenonNet实现潜在动力学演进

Result: 在标准守富系统上的数值实验表明，该方法能够准确重建轨道，在训练范围外供稳健预测，并准确保持守富量

Conclusion: 该统一的神经网络守富ROM框架有效且具有广泛的应用潜力，适用于科学和工程领域的复杂动力系统

Abstract: We introduce a novel data-driven symplectic induced-order modeling (ROM)
framework for high-dimensional Hamiltonian systems that unifies latent-space
discovery and dynamics learning within a single, end-to-end neural
architecture. The encoder-decoder is built from Henon neural networks
(HenonNets) and may be augmented with linear SGS-reflector layers. This yields
an exact symplectic map between full and latent phase spaces. Latent dynamics
are advanced by a symplectic flow map implemented as a HenonNet. This unified
neural architecture ensures exact preservation of the underlying symplectic
structure at the reduced-order level, significantly enhancing the fidelity and
long-term stability of the resulting ROM. We validate our method through
comprehensive numerical experiments on canonical Hamiltonian systems. The
results demonstrate the method's capability for accurate trajectory
reconstruction, robust predictive performance beyond the training horizon, and
accurate Hamiltonian preservation. These promising outcomes underscore the
effectiveness and potential applicability of our symplectic ROM framework for
complex dynamical systems across a broad range of scientific and engineering
disciplines.

</details>


### [239] [Implicit-Explicit Scheme with Multiscale Vanka Two-Grid Solver for Heterogeneous Unsaturated Poroelasticity](https://arxiv.org/abs/2508.12197)
*Maria Vasilyeva,Ben S. Southworth,Yunhui He,Min Wang*

Main category: math.NA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider a coupled nonlinear system of equations that describe unsaturated
flow in heterogeneous poroelastic media. For the numerical solution, we use a
finite element approximation in space and present an efficient multiscale
two-grid solver for solving the coupled system of equations. The proposed
two-grid solver contains two main parts: (i) accurate coarse grid approximation
based on local spectral spaces and (ii) coupled smoothing iterations based on
an overlapping multiscale Vanka method. A Vanka smoother and local spectral
coarse grids come with significant computational cost in the setup phase. To
avoid constructing a new solver for each time step and/or nonlinear iteration,
we utilize an implicit-explicit integration scheme in time, where we partition
the nonlinear operator as a sum of linear and nonlinear parts. In particular,
we construct an implicit linear approximation of the stiff components that
remains fixed across all time, while treating the remaining nonlinear residual
explicitly. This allows us to construct a robust two-grid solver offline and
utilize it for fast and efficient online time integration. A linear stability
analysis of the proposed novel coupled scheme is presented based on the
representation of the system as a two-step scheme. We show that the careful
decomposition of linear and nonlinear parts guarantees a linearly stable
scheme. A numerical study is presented for a two-dimensional nonlinear coupled
test problem of unsaturated flow in heterogeneous poroelastic media. We
demonstrate the robustness of the two-grid solver, particularly the efficacy of
block smoothing compared with simple pointwise smoothing, and illustrate the
accuracy and stability of implicit-explicit time integration.

</details>


### [240] [Structure-preserving parametric finite element methods for two-phase Stokes flow based on Lagrange multiplier approaches](https://arxiv.org/abs/2508.12326)
*Harald Garcke,Dennis Trautwein,Ganghui Zhang*

Main category: math.NA

TL;DR: 一种新的参数化有限元方法用于近似两相Stokes流，通过拉格朗日乘子方法确保在全离散级别上保持能量衰减和体积保持的物理性质。


<details>
  <summary>Details</summary>
Motivation: 为了达到在数值方法中精确保持两相Stokes流的关键物理性质（能量衰减和体积保持），需要开发新的数值推演方法。

Method: 提出了基于经典Stokes方程和新型界面条件的拉格朗日乘子方法，采用Crank-Nicolson和二阶向后微分公式等高阶时间离散方法，通过牛顿法和解耦技术高效求解非线性方程。

Result: 大量数值实验证明，该方法能够在保持两种物理性质的同时，达到预期的时间精度。

Conclusion: 新的拉格朗日乘子方法成功地在全离散级别上保持了两相Stokes流的能量衰减和体积保持性质，为相场流动模拟提供了可靠的数值工具。

Abstract: We present a novel formulation for parametric finite element methods to
approximate two-phase Stokes flow. The new formulation is based on the
classical Stokes equation in the bulk and a novel choice of interface
conditions with additional Lagrange multipliers. This new Lagrange multiplier
approach ensures that the numerical methods exactly preserve two physical
structures of two-phase Stokes flow at the fully discrete level: (i) the
energy-decaying and (ii) the volume-preserving properties. Moreover, different
types of higher-order time discretization methods are employed, including the
Crank--Nicolson method and the second-order backward differentiation formula
approach. The resulting schemes are nonlinear and can be efficiently solved by
using the Newton method with a decoupling technique. Extensive numerical
experiments demonstrate that our methods achieve the desired temporal accuracy
while preserving the two physical structures of the two-phase Stokes system.

</details>


### [241] [Adaptive time-domain boundary element methods for the wave equation with Neumann boundary conditions](https://arxiv.org/abs/2508.12332)
*Alessandra Aimi,Giulia Di Credico,Heiko Gimperlein,Chiara Guardasoni*

Main category: math.NA

TL;DR: 本文研究了具有Neumann边界条件的时域波动方程的自适应网格细化方法，基于超奇异边界积分方程形式，提出了空间自适应和时间自适应的时空边界元法，并通过数值实验验证了性能。


<details>
  <summary>Details</summary>
Motivation: 针对时域波动方程的数值求解，需要开发有效的自适应网格细化技术来提高计算效率和精度，特别是在处理Neumann边界条件时。

Method: 采用超奇异边界积分方程形式，提出了基于残差型后验误差估计的空间自适应和时间自适应时空边界元方法。

Result: 数值实验结果表明，所提出的自适应方法在时域波动方程求解中表现出良好的性能。

Conclusion: 基于残差型后验误差估计的自适应时空边界元法为时域波动方程的数值求解提供了一种有效的计算框架。

Abstract: This article investigates adaptive mesh refinement procedures for the
time-domain wave equation with Neumann boundary conditions, formulated as an
equivalent hypersingular boundary integral equation. Space-adaptive and
time-adaptive versions of a space-time boundary element method are presented,
based on a reliable a posteriori error estimate of residual type. Numerical
experiments illustrate the performance of the proposed approach.

</details>


### [242] [Convergence analysis of Left-Right splitting surface scattering method](https://arxiv.org/abs/2508.12342)
*Paul E Parbone,Mark Spivack,Orsola Rath Spivack*

Main category: math.NA

TL;DR: 研究左右分裂法在粗糙表面波散射中的收敛性，分析快速收敛机制和发散原因，提出通过特征向量相减和Shanks变换改进收敛的策略。


<details>
  <summary>Details</summary>
Motivation: 左右分裂法在低掠射角下通常快速收敛，但收敛性无法保证且可能出现半收敛现象，需要深入理解其收敛机制和失败原因。

Method: 通过减去连续主导特征向量来研究发散机制，应用Shanks变换的广义化来改进算子级数的收敛性，并分析发散特征向量的精确解。

Result: 揭示了方法在大入射角下快速收敛的原因，证明了精确解是良性的且可以从发散级数中推导出来，Shanks变换能有效改善收敛性。

Conclusion: 提出的特征向量分析和Shanks变换方法不仅解释了收敛机制，还提供了克服发散的有效策略，这些方法可推广到3D和复合问题。

Abstract: We study the convergence of the Left-Right splitting method (equivalent in
key respects to the Method of Multiple Ordered Interactions and
Forward-Backward method) for wave scattering by rough surfaces. This is an
operator series method primarily designed for low grazing incidence and found
in many cases to converge rapidly, often within one or two terms even for large
incident angles. However, convergence is not guaranteed and semi-convergence
may be observed.
  Our aims are two-fold: (1) To obtain theoretical and physical insight into
the regimes in which rapid convergence occurs and the mechanisms by which it
fails, by examining and modifying eigenvalues of the operator; (2) provide a
strategy for increasing the speed of convergence or more crucially for
overcoming divergence, and providing a stopping criterion. The first is
addressed by subtracting successive dominant eigenvectors from the incident
field, to examine the impact on divergence and on the incident spectrum. For
the second, we apply a generalisation of Shanks' transformation to the operator
series; this effectively improves convergence and (unlike eigenvalue
subtraction) readily generalises to 3D and composite problems. These results
also explain why the method converges so rapidly for much larger incident
angles. Finally we ask and give an analytical solution to a key question: For a
divergent eigenvector of the iterating operator, what is the exact solution and
can it be deduced from the divergent series? We show that the exact solution is
well-behaved and can be found from the series in a way which is related to the
Shanks transformation.

</details>


### [243] [Anderson Acceleration For Perturbed Newton Methods](https://arxiv.org/abs/2508.12513)
*Matt Dallas*

Main category: math.NA

TL;DR: 这篇论文提出了一种应用于扰动牛顿法(pNMs)的Anderson加速(AA)收敛理论，包括经典牛顿法和Levenberg-Marquardt法，通过γ-safeguarding保护机制实现了改进的局部线性收敛速度。


<details>
  <summary>Details</summary>
Motivation: 为了提高扰动牛顿法的收敛速度，将Anderson加速技术与保护机制结合，以获得比标准方法更好的收敛性能。

Method: 采用Anderson加速技术结合γ-safeguarding保护机制，应用于扰动牛顿法，包括经典牛顿法和Levenberg-Marquardt法。证明在2-regular问题下在星形收敛域中实现局部线性收敛。

Result: 理论证明了加速方法在局部星形域中的线性收敛性，并且收敛速度明显优于标准扰动牛顿法。保护机制能够检测超线性收敛并调整加速步长。

Conclusion: 该研究为Anderson加速的扰动牛顿法提供了严格的收敛理论基础，特别是对于Levenberg-Marquardt法的加速结果，并通过保护机制确保了算法的稳定性和效率。

Abstract: We present a convergence theory For Anderson acceleration (AA) applied to
perturbed Newton methods (pNMs) For computing roots of nonlinear problems. Two
important special cases are the classical Newton method and the
Levenberg-Marquardt method. We prove that if a problem is 2-regular, then
Anderson accelerated pNMs coupled with a safeguarding scheme, known as
$\gamma$-safeguarding, converge locally linearly in a starlike domain of
convergence, but with an improved rate of convergence compared to standard
perturbed Newton methods. Since Levenberg-Marquardt methods are a special case
of pNMs, we obtain a novel acceleration and local convergence result For
Anderson accelerated Levenberg-Marquardt. We further show that the safeguarding
technique can detect if the underlying perturbed Newton method is converging
superlinearly, and respond by tuning the Anderson step down. We demonstrate the
methods on several benchmark problems in the literature.

</details>


### [244] [Comparison of three random field sampling methods for high-resolution Bayesian inversion with application to a plane stress problem](https://arxiv.org/abs/2508.12876)
*Pieter Vanmechelen,Geert Lombaert,Giovanni Samaey*

Main category: math.NA

TL;DR: 本文比较了三种随机场采样策略在贝叶斯逆问题中的效果，发现LAS方法数值效率略优于其他方法


<details>
  <summary>Details</summary>
Motivation: 在高维度空间反演问题中，需要有效的随机场采样策略来描述连续参数的后验分布，并进行不确定性量化

Method: 使用多级马尔可夫链蒙特卡洛算法，比较三种随机场采样方法：Karhunen-Loeve展开、小波展开和局部平均分解(LAS)方法，应用于2D平面应力模型的材料参数重构

Result: 三种方法都能提供类似的后验估计，但局部平均分解方法在数值效率方面略优于其他两种方法

Conclusion: 局部平均分解方法是高分辨率有限元网格上高维度反演问题的有效选择，能够在保持后验估计质量的同时提高计算效率

Abstract: Bayesian inversion aims to provide uncertainty quantification of posterior
estimates conditional on observations. When the inferred parameter is a
continuous spatial function, one common strategy is to model it as a random
field. Several random field sampling strategies exist. In this article, we
investigate three different approaches in terms of numerical efficiency and
influence on the posterior distribution. These approaches are based on (i)
Karhunen-Loeve and (ii) wavelet expansions, and (iii) local average
subdivision. We use the multilevel Markov chain Monte Carlo algorithm to
construct posterior estimates with all approaches. This enables a focus on
high-dimensional problems discretised on high-resolution finite element grids.
As an application, we consider the reconstruction of material parameters in a
2D plane stress model, conditional on static displacement observations. Through
these numerical experiments, we deduce that the methods provide comparable
posterior estimates and that the local average subdivision method attains
slightly better numerical efficiency than the other two approaches.

</details>


### [245] [$\boldsymbol{H}(\textbf{curl})$-reconstruction of piecewise polynomial fields with application to $hp$-a posteriori nonconforming error analysis for Maxwell's equations](https://arxiv.org/abs/2508.12904)
*Zhaonan Dong,Alexandre Ern*

Main category: math.NA

TL;DR: 提出了一种新的H(curl)重构算子，用于形状规则单纯形网格上的分段多项式场，主要关注齐次切向边界条件，证明了重构场与原场在断裂旋度范数和L2范数下的误差界，并讨论了在Maxwell方程非协调误差分析中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了在形状规则单纯形网格上对分段多项式场进行有效的H(curl)重构，特别是在处理齐次切向边界条件时，需要开发一种能够提供最优误差界的重构方法，以支持Maxwell方程等应用的非协调误差分析。

Method: 使用由帽子基函数诱导的单位分解结合局部Helmholtz分解，在网格顶点补丁上设计非多项式重构。通过断裂旋度保持散度的Poincaré不等式等辅助结果来建立误差界。

Result: 证明了重构H0(curl)场与原分段多项式场在断裂旋度范数和L2范数下的差异可以通过原场的适当跳跃范数来界定，误差界在h上是最优的，在p上对断裂旋度范数有1/2阶次优，对L2范数有3/2阶次优。

Conclusion: 所提出的H(curl)重构算子为分段多项式场提供了有效的重构方法，具有最优的误差界特性，特别是在Maxwell方程的非协调误差分析中具有重要应用价值，并可扩展到混合边界条件和更一般的网格类型。

Abstract: We devise and analyse a novel $\boldsymbol{H}(\textbf{curl})$-reconstruction
operator for piecewise polynomial fields on shape-regular simplicial meshes.
The (non-polynomial) reconstruction is devised over the mesh vertex patches
using the partition of unity induced by hat basis functions in combination with
local Helmholtz decompositions. Our main focus is on homogeneous tangential
boundary conditions. We prove that the difference between the reconstructed
$\boldsymbol{H}_0(\textbf{curl})$-field and the original, piecewise polynomial
field, measured in the broken curl norm and in the $\boldsymbol{L}^2$-norm, can
be bounded in terms of suitable jump norms of the original field. The bounds
are always $h$-optimal, and $p$-suboptimal by $\frac12$-order for the broken
curl norm and by $\frac32$-order for the $\boldsymbol{L}^2$-norm. An auxiliary
result of independent interest is a novel broken-curl, divergence-preserving
Poincar\'{e} inequality on vertex patches. Moreover, the
$\boldsymbol{L}^2$-norm estimate can be improved to $\frac12$-order
suboptimality under a (reasonable) assumption on the uniform elliptic
regularity pickup for a Poisson problem with Neumann conditions over the vertex
patches. We also discuss extensions of the
$\boldsymbol{H}_0(\textbf{curl})$-reconstruction operator to the prescription
of mixed boundary conditions, to agglomerated polytopal meshes, and to convex
domains. Finally, we showcase an important application of the
$\boldsymbol{H}(\textbf{curl})$-reconstruction operator to the $hp$-a
posteriori nonconforming error analysis of Maxwell's equations. We focus on the
(symmetric) interior penalty discontinuous Galerkin (dG) approximation of some
simplified forms of Maxwell's equations.

</details>


### [246] [Basis construction for polynomial spline spaces over arbitrary T-meshe](https://arxiv.org/abs/2508.12950)
*Shicong Zhong,Falai Chen,Bingru Huang*

Main category: math.NA

TL;DR: 首个构建任意T-网格上多项式条件拟合空间基函数的方法，通过边伸展转换为可对角化T-网格，构建线性无关完整的PT-条件基函数


<details>
  <summary>Details</summary>
Motivation: 解决任意T-网格上多项式条件拟合空间基函数构建问题，充分利用T-网格的灵活性而避免线性相关性问题

Method: 通过边伸展将任意T-网格转换为可对角化T-网格，根据维数公式的三个组件（交叉切割、射线、T边）构建基函数，使用扩展边消除技术去除冗余边

Result: 构建出线性无关、完整的PT-条件基函数，支持任意T-网格类型，比LR B-条件和HB-条件更灵活且避免线性相关性问题

Conclusion: 该方法为任意T-网格提供了简洁有效的基函数构建方案，扩展了条件拟合在复杂网格上的应用能力，具有重要的理论价值和应用潜力

Abstract: This paper presents the first method for constructing bases for polynomial
spline spaces over an arbitrary T-meshes (PT-splines for short). We construct
spline basis functions for an arbitrary T-mesh by first converting the T-mesh
into a diagonalizable one via edge extension, ensuring a stable dimension of
the spline space. Basis functions over the diagoalizable T-mesh are constructed
according to the three components in the dimension formula corresponding to
cross-cuts, rays, and T $l$-edges in the diagonalizable T-mesh, and each
component is assigned some local tensor product B-splines as the basis
functions. We prove this set of functions constitutes a basis for the
diagonalizable T-mesh. To remove redundant edges from extension, we introduce a
technique, termed Extended Edge Elimination (EEE) to construct a basis for an
arbitrary T-mesh while reducing structural constraints and unnecessary
refinements. The resulting PT-spline basis ensures linear independence and
completeness, supported by a dedicated construction algorithm. A comparison
with LR B-splines, which may lack linear independence and are limited to
LR-meshes, highlights the PT-spline's versatility across any T-mesh. Examples
are also provided to demonstrate that dimensional instability in spline spaces
is related with basis function degradation and that PT-splines are advantageous
over HB-splines for certain hierarchical T-meshes.

</details>


### [247] [Preconditioning of a hybridizable discontinuous Galerkin method for Biot's consolidation model](https://arxiv.org/abs/2508.12991)
*Esteban Henríquez,Jeonghun J. Lee,Sander Rhebergen*

Main category: math.NA

TL;DR: 提出了一个针对Biot固结模型四场公式HDG离散化的参数鲁棒预处理器，并通过数值实验验证了其参数鲁棒性


<details>
  <summary>Details</summary>
Motivation: Biot固结模型的数值模拟需要处理多个物理场和多尺度参数，传统预处理器往往缺乏参数鲁棒性，特别是在HDG离散化后静态凝聚的情况下

Method: 首先为完整离散化开发参数鲁棒预处理器，然后应用先前工作中提出的框架证明简化形式的预处理器对简化HDG离散化同样具有参数鲁棒性

Result: 通过二维和三维数值实验验证了预处理器的参数鲁棒性，表明该方法在不同参数条件下都能保持良好性能

Conclusion: 成功开发了适用于HDG离散化Biot固结模型的参数鲁棒预处理器，为多物理场多尺度问题的数值求解提供了有效工具

Abstract: We present a parameter-robust preconditioner for a hybridizable discontinuous
Galerkin (HDG) discretization of a four-field formulation of Biot's
consolidation model. We first determine a parameter-robust preconditioner for
the full discretization. HDG methods, however, allow for static condensation.
We therefore apply the framework presented in our previous work
[arXiv:2503.05918, 2025] to show that a reduced form of the preconditioner is
also parameter-robust for the reduced HDG discretization. We verify the
parameter-robustness of the preconditioner through numerical examples in both
two and three dimensions.

</details>


### [248] [Some semi-decoupled algorithms with optimal convergence for a four-field linear thermo-poroelastic model](https://arxiv.org/abs/2508.13109)
*Ziliang Li,Mingchao Cai,Jingzhi Li,Qiang Liu*

Main category: math.NA

TL;DR: 提出三种半解耦算法，高效求解四场热温羟弹性模型，包括两种序列算法和一种并行算法，无需稳定化技术和迭代过程


<details>
  <summary>Details</summary>
Motivation: 解决四场热温羟弹性模型计算效率低的问题，提高大规模多物理场相互作用问题的求解效率

Method: 首先在初始时间步用单体法求解所有变量，之后分解为混合线性弹性子问题和压力-温度反应-正度子问题，有序列和并行两种求解策略

Result: 算法具有无条件稳定性、最优收敛速率和广泛的参数适应性，数值实验验证了理论结果

Conclusion: 提出的半解耦算法能够高效求解复杂的多物理场相互作用问题，为大规模模拟提供了可靠的数值解决方案

Abstract: We propose three semi-decoupled algorithms for efficiently solving a
four-field thermo-poroelastic model. The first two algorithms adopt a
sequential strategy: at the initial time step, all variables are computed
simultaneously using a monolithic solver; thereafter, the system is split into
a mixed linear elasticity subproblem and a coupled pressure-temperature
reaction-diffusion subproblem. The two variants differ in the order in which
these subproblems are solved. To further improve computational efficiency, we
introduce a parallel semi-decoupled algorithm. In this approach, the four-field
system is solved monolithically only at the first time step, and the two
subproblems are then solved in parallel at subsequent time levels. All three
algorithms are free from stabilization techniques and do not require iterative
procedures at each time step. Rigorous analysis confirms their unconditional
stability, optimal convergence rates, and robustness under a wide range of
physical parameter settings. These theoretical results are further validated by
numerical experiments.

</details>


### [249] [A time-adaptive optimization approach for reconstructing immune response in a mathematical model of acute HIV infection using clinical data](https://arxiv.org/abs/2508.13123)
*L. Beilina,I. Gainova,G. Bocharov*

Main category: math.NA

TL;DR: 提出了一种时间自适应优化方法，用于确定急性HIV感染数学模型中的时间依赖性免疫响应函数，使用四名未治疗患者的临床数据。该方法通过Tikhonov正则化和拉格朗日方法推导最优性条件，并开发了时间自适应网格细化算法。


<details>
  <summary>Details</summary>
Motivation: 需要准确重建急性HIV感染期间的时间依赖性免疫响应函数，以更好地理解HIV感染的动态过程和治疗策略。传统均匀时间网格方法在重建精度上存在局限。

Method: 将问题表述为ODE免疫响应系统的参数识别问题，采用Tikhonov正则化方法和拉格朗日方法推导最优性条件。开发了时间自适应优化算法，包含三种后验误差估计和局部时间自适应网格细化技术。

Result: 数值实验表明，与标准共轭梯度法在均匀时间网格上的应用相比，提出的局部时间自适应网格细化方法显著改善了免疫响应函数的重建效果。

Conclusion: 时间自适应优化方法能够有效重建急性HIV感染期间的免疫响应函数，为HIV感染的数学建模和治疗策略提供了更精确的工具。

Abstract: The paper proposes a time-adaptive optimization approach for determining the
time-dependent immune response function in a mathematical model of acute HIV
infection, using clinical data from four untreated patients. We formulate the
problem as a parameter identification problem for an immune response system of
ODE which includes novel component integrated into the third equation of the
classical three-equation HIV model.
  Tikhonov's regularization method, Lagrangian approach, from which we derive
the optimality conditions, and a numerical scheme to solve the forward
  and adjoint problems, as well as parameter identification problem, are
presented.
  Three different a posteriori error estimates are derived and based on these
estimates, a time adaptive optimization algorithm is formulated. Numerical
experiments demonstrate the effectiveness of the proposed adaptive method in
reconstructing the immune response function during the acute phase of HIV
infection, using patient-specific clinical data. Computational results show
improvement of
  reconstruction of immune response function using the local
  time-adaptive mesh refinement method compared to the standard conjugate
gradient method applied on a uniform time mesh.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [250] [Sparse Attention across Multiple-context KV Cache](https://arxiv.org/abs/2508.11661)
*Ziyi Cao,Qingyi Si,Jingbin Zhang,Bingquan Liu*

Main category: cs.LG

TL;DR: SamKV是首个针对多上下文KV缓存进行注意力稀疏化的方法，通过考虑其他上下文的互补信息进行稀疏化并局部重计算，在RAG场景中将序列长度压缩至15%而不损失精度


<details>
  <summary>Details</summary>
Motivation: 在检索增强生成(RAG)场景中，多上下文KV缓存缺乏交叉注意力机制，现有方法无法有效处理，且需要保留全部KV缓存导致内存开销巨大

Method: SamKV方法在进行上下文稀疏化时考虑其他上下文的互补信息，然后对稀疏化信息进行局部重计算

Result: 实验表明该方法将序列长度压缩至15%，相比完全重计算基线无精度损失，在多上下文RAG场景中显著提升吞吐量

Conclusion: SamKV成功解决了多上下文KV缓存的高效处理问题，为RAG场景中的长序列推理提供了有效的解决方案

Abstract: Large language models face significant cost challenges in long-sequence
inference. To address this, reusing historical Key-Value (KV) Cache for
improved inference efficiency has become a mainstream approach. Recent advances
further enhance throughput by sparse attention mechanisms to select the most
relevant KV Cache, thereby reducing sequence length. However, such techniques
are limited to single-context scenarios, where historical KV Cache is computed
sequentially with causal-attention dependencies. In retrieval-augmented
generation (RAG) scenarios, where retrieved documents as context are unknown
beforehand, each document's KV Cache is computed and stored independently
(termed multiple-context KV Cache), lacking cross-attention between contexts.
This renders existing methods ineffective. Although prior work partially
recomputes multiple-context KV Cache to mitigate accuracy loss from missing
cross-attention, it requires retaining all KV Cache throughout, failing to
reduce memory overhead. This paper presents SamKV, the first exploration of
attention sparsification for multiple-context KV Cache. Specifically, SamKV
takes into account the complementary information of other contexts when
sparsifying one context, and then locally recomputes the sparsified
information. Experiments demonstrate that our method compresses sequence length
to 15% without accuracy degradation compared with full-recompuation baselines,
significantly boosting throughput in multi-context RAG scenarios.

</details>


### [251] [Assessing Representation Stability for Transformer Models](https://arxiv.org/abs/2508.11667)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.LG

TL;DR: 提出Representation Stability (RS)框架，通过测量掩码重要词时嵌入表示的变化来检测对抗文本攻击，无需重新训练模型，在多个数据集和攻击类型上达到88%以上检测准确率。


<details>
  <summary>Details</summary>
Motivation: 对抗文本攻击对transformer模型构成持续威胁，现有防御方法通常针对特定攻击或需要昂贵的模型重新训练，需要一种模型无关的通用检测方案。

Method: RS框架首先使用重要性启发式方法对单词进行排名，然后测量掩码前k个关键词时的嵌入敏感性，最后使用BiLSTM检测器处理得到的模式。使用NDCG评估扰动识别质量。

Result: 在三个数据集、三种攻击类型和两个受害者模型上，RS达到超过88%的检测准确率，计算成本较低。基于梯度的排名方法在扰动识别质量上优于注意力和随机选择方法。

Conclusion: RS框架能够很好地泛化到未见过的数据集、攻击和模型，无需重新训练，为对抗文本检测提供了实用的解决方案。

Abstract: Adversarial text attacks remain a persistent threat to transformer models,
yet existing defenses are typically attack-specific or require costly model
retraining. We introduce Representation Stability (RS), a model-agnostic
detection framework that identifies adversarial examples by measuring how
embedding representations change when important words are masked. RS first
ranks words using importance heuristics, then measures embedding sensitivity to
masking top-k critical words, and processes the resulting patterns with a
BiLSTM detector. Experiments show that adversarially perturbed words exhibit
disproportionately high masking sensitivity compared to naturally important
words. Across three datasets, three attack types, and two victim models, RS
achieves over 88% detection accuracy and demonstrates competitive performance
compared to existing state-of-the-art methods, often at lower computational
cost. Using Normalized Discounted Cumulative Gain (NDCG) to measure
perturbation identification quality, we reveal that gradient-based ranking
outperforms attention and random selection approaches, with identification
quality correlating with detection performance for word-level attacks. RS also
generalizes well to unseen datasets, attacks, and models without retraining,
providing a practical solution for adversarial text detection.

</details>


### [252] [Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset](https://arxiv.org/abs/2508.11669)
*Wentao Li,Yonghu He,Kun Gao,Qing Liu,Yali Zheng*

Main category: cs.LG

TL;DR: 这篇论文提出了一种轻量级的KDCL_sInvResUNet模型，通过协同学习方案在嵌入式设备上实现了实时无创动脉血压监测，计算负载仅0.02 GFLOPS，推理时间8.49毫秒，精度与大型模型相当。


<details>
  <summary>Details</summary>
Motivation: 虽然现有深度学习模型能够从非侵入性生理信号重建动脉血压波形，但缺乏适合嵌入式系统部署的轻量级模型，需要解决模型性能与计算负载之间的平衡问题。

Method: 提出了轻量级sInvResUNet模型和KDCL_sInvResUNet协同学习方案，模型仅包0.89百万参数，通过大规模异质性围手术期数据集（包2,154名患者的1,257,141个数据段）进行主体独立验证。

Result: 模型在广泛血压范围（SBP 41-257 mmHg，DBP 31-234 mmHg）下达到均值绝对误差10.06 mmHg和相关系数0.88的性能，但在不同人口学和心血管条件下显示出显著的性能变化。

Conclusion: 该研究为现实围手术术后环境中实时无感知动脉血压监测奠定了基础，显示了轻量级模型在嵌入式部署中的潜力，但同时指出了深度学习模型在广泛人群中普遍化能力的局限性。

Abstract: Noninvasive arterial blood pressure (ABP) monitoring is essential for patient
management in critical care and perioperative settings, providing continuous
assessment of cardiovascular hemodynamics with minimal risks. Numerous deep
learning models have developed to reconstruct ABP waveform from noninvasively
acquired physiological signals such as electrocardiogram and
photoplethysmogram. However, limited research has addressed the issue of model
performance and computational load for deployment on embedded systems. The
study introduces a lightweight sInvResUNet, along with a collaborative learning
scheme named KDCL_sInvResUNet. With only 0.89 million parameters and a
computational load of 0.02 GFLOPS, real-time ABP estimation was successfully
achieved on embedded devices with an inference time of just 8.49 milliseconds
for a 10-second output. We performed subject-independent validation in a
large-scale and heterogeneous perioperative dataset containing 1,257,141 data
segments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and
31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better
performance compared to large models, with a mean absolute error of 10.06 mmHg
and mean Pearson correlation of 0.88 in tracking ABP changes. Despite these
promising results, all deep learning models showed significant performance
variations across different demographic and cardiovascular conditions,
highlighting their limited ability to generalize across such a broad and
diverse population. This study lays a foundation work for real-time,
unobtrusive ABP monitoring in real-world perioperative settings, providing
baseline for future advancements in this area.

</details>


### [253] [Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning](https://arxiv.org/abs/2508.11673)
*Haojie Zhang,Yixiong Liang,Hulin Kuang,Lihui Cen,Zhe Qu,Yigang Cen,Min Zeng,Shichao Kan*

Main category: cs.LG

TL;DR: 提出了MSLoRA-CR方法，通过模态特定的LoRA模块和对比正则化来解决多模态生物医学图像增量学习中的知识保留和跨模态知识迁移问题


<details>
  <summary>Details</summary>
Motivation: 生物医学领域需要处理多种模态和任务，但为每个模态单独训练模型会增加推理成本，需要统一的增量学习模型

Method: 基于大型视觉语言模型，冻结预训练参数，为每个模态增量添加特定的LoRA模块，并引入对比正则化来增强模态内知识共享和模态间知识区分

Result: 在生物医学图像增量学习实验中，MSLoRA-CR相比为每个模态单独训练模型和通用增量学习方法表现更好，整体性能提升1.88%，同时保持计算效率

Conclusion: MSLoRA-CR方法有效解决了多模态生物医学图像增量学习的挑战，在性能和效率方面都表现出色

Abstract: Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for
handling diverse tasks and modalities in the biomedical domain, as training
separate models for each modality or task significantly increases inference
costs. Existing incremental learning methods focus on task expansion within a
single modality, whereas MBIIL seeks to train a unified model incrementally
across modalities. The MBIIL faces two challenges: I) How to preserve
previously learned knowledge during incremental updates? II) How to effectively
leverage knowledge acquired from existing modalities to support new modalities?
To address these challenges, we propose MSLoRA-CR, a method that fine-tunes
Modality-Specific LoRA modules while incorporating Contrastive Regularization
to enhance intra-modality knowledge sharing and promote inter-modality
knowledge differentiation. Our approach builds upon a large vision-language
model (LVLM), keeping the pretrained model frozen while incrementally adapting
new LoRA modules for each modality or task. Experiments on the incremental
learning of biomedical images demonstrate that MSLoRA-CR outperforms both the
state-of-the-art (SOTA) approach of training separate models for each modality
and the general incremental learning method (incrementally fine-tuning LoRA).
Specifically, MSLoRA-CR achieves a 1.88% improvement in overall performance
compared to unconstrained incremental learning methods while maintaining
computational efficiency. Our code is publicly available at
https://github.com/VentusAislant/MSLoRA_CR.

</details>


### [254] [Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems](https://arxiv.org/abs/2508.11679)
*Shaodi Feng,Zhuoyi Lin,Jianan Zhou,Cong Zhang,Jingwen Li,Kuan-Wen Chen,Senthilnath Jayavelu,Yew-Soon Ong*

Main category: cs.LG

TL;DR: 这篇论文提出了一种终身学习框架，通过Transformer网络和上下文调度器，增量式训练神经网络汽车路线解决器，以处理不同场景下的VRP问题，达到了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 当前神经路线解决器通常只能处理单一上下文的VRP问题（如欧几里得距离、固定问题规模），影响了它们在不同场景下的直接应用能力。

Method: 使用Transformer网络作为核心，提出了上下文间自注意力机制来转移知识，并通过动态上下文调度器进行跨上下文经验回放，以增量式学习方式训练解决器。

Result: 在合成数据和标准测试集上（问题规模达18k），该方法在大部分VRP问题上超过了其他神经解决器，达到最佳性能。

Conclusion: 该终身学习框架能够有效地发现处理不同上下文VRP问题的策略，显著提升了神经解决器的通用性和性能。

Abstract: Deep learning has been extensively explored to solve vehicle routing problems
(VRPs), which yields a range of data-driven neural solvers with promising
outcomes. However, most neural solvers are trained to tackle VRP instances in a
relatively monotonous context, e.g., simplifying VRPs by using Euclidean
distance between nodes and adhering to a single problem size, which harms their
off-the-shelf application in different scenarios. To enhance their versatility,
this paper presents a novel lifelong learning framework that incrementally
trains a neural solver to manage VRPs in distinct contexts. Specifically, we
propose a lifelong learner (LL), exploiting a Transformer network as the
backbone, to solve a series of VRPs. The inter-context self-attention mechanism
is proposed within LL to transfer the knowledge obtained from solving preceding
VRPs into the succeeding ones. On top of that, we develop a dynamic context
scheduler (DCS), employing the cross-context experience replay to further
facilitate LL looking back on the attained policies of solving preceding VRPs.
Extensive results on synthetic and benchmark instances (problem sizes up to
18k) show that our LL is capable of discovering effective policies for tackling
generic VRPs in varying contexts, which outperforms other neural solvers and
achieves the best performance for most VRPs.

</details>


### [255] [Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics](https://arxiv.org/abs/2508.11680)
*Aditya Akella,Jonathan Farah*

Main category: cs.LG

TL;DR: 时间序列基础模型TimesFM在美国人口预测中表现优于传统方法，在86.67%的测试案例中获得最低均方误差，尤其在历史数据稀缩的少数群体预测中显示优势。


<details>
  <summary>Details</summary>
Motivation: 人口变化影响政策制定和规划，需要准确的人口预测来支持城市规划、医疗卫生和经济政策等领域的决策。

Method: 使用美国普查局和美联储FRED数据，对比时间序列基础模型TimesFM与传统方法（LSTM、ARIMA、线性回归）在6个人口结构多样的州的表现。

Result: TimesFM在86.67%的测试案例中获得最低均方误差，尤其在历史数据稀缩的少数群体预测中表现特别突出。

Conclusion: 预训练的基础模型能够提升人口分析效果，支持主动政策干预，而无需大量任务特定的微调。

Abstract: Demographic shifts, influenced by globalization, economic conditions,
geopolitical events, and environmental factors, pose significant challenges for
policymakers and researchers. Accurate demographic forecasting is essential for
informed decision-making in areas such as urban planning, healthcare, and
economic policy. This study explores the application of time series foundation
models to predict demographic changes in the United States using datasets from
the U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate
the performance of the Time Series Foundation Model (TimesFM) against
traditional baselines including Long Short-Term Memory (LSTM) networks,
Autoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our
experiments across six demographically diverse states demonstrate that TimesFM
achieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with
particularly strong performance on minority populations with sparse historical
data. These findings highlight the potential of pre-trained foundation models
to enhance demographic analysis and inform proactive policy interventions
without requiring extensive task-specific fine-tuning.

</details>


### [256] [From Heuristics to Data: Quantifying Site Planning Layout Indicators with Deep Learning and Multi-Modal Data](https://arxiv.org/abs/2508.11723)
*Qian Cao,Jielin Chen,Junchao Zhao,Rudi Stouffs*

Main category: cs.LG

TL;DR: 基于多源数据的基地规划布局指标系统(SPLI)，通过五大维度系统量化城市空间布局，提高功能分类准确性和自动化分析能力


<details>
  <summary>Details</summary>
Motivation: 传统基地规划依赖经验判断和单一数据源，无法系统量化多功能布局，需要数据驱动的结构化分析框架

Method: 整合OSM、POI、建筑形态、土地利用和卫星影像等多源数据，构建五大维度指标系统：层级建筑功能分类、空间组织形态、功能多样性、基础服务可达性、土地利用强度，使用RGNN和GNN深度学习处理数据缺失

Result: SPLI系统显著提高了功能分类的准确性，为自动化的数据驱动城市空间分析提供了标准化基础

Conclusion: 该研究提出的SPLI框架能够有效解决传统基地规划中的系统量化问题，为城市空间布局的数据驱动分析开启了新方向

Abstract: The spatial layout of urban sites shapes land-use efficiency and spatial
organization. Traditional site planning often relies on experiential judgment
and single-source data, limiting systematic quantification of multifunctional
layouts. We propose a Site Planning Layout Indicator (SPLI) system, a
data-driven framework integrating empirical knowledge with heterogeneous
multi-source data to produce structured urban spatial information. The SPLI
supports multimodal spatial data systems for analytics, inference, and
retrieval by combining OpenStreetMap (OSM), Points of Interest (POI), building
morphology, land use, and satellite imagery. It extends conventional metrics
through five dimensions: (1) Hierarchical Building Function Classification,
refining empirical systems into clear hierarchies; (2) Spatial Organization,
quantifying seven layout patterns (e.g., symmetrical, concentric,
axial-oriented); (3) Functional Diversity, transforming qualitative assessments
into measurable indicators using Functional Ratio (FR) and Simpson Index (SI);
(4) Accessibility to Essential Services, integrating facility distribution and
transport networks for comprehensive accessibility metrics; and (5) Land Use
Intensity, using Floor Area Ratio (FAR) and Building Coverage Ratio (BCR) to
assess utilization efficiency. Data gaps are addressed through deep learning,
including Relational Graph Neural Networks (RGNN) and Graph Neural Networks
(GNN). Experiments show the SPLI improves functional classification accuracy
and provides a standardized basis for automated, data-driven urban spatial
analytics.

</details>


### [257] [Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks](https://arxiv.org/abs/2508.11727)
*Songyao Jin,Biwei Huang*

Main category: cs.LG

TL;DR: 该论文提出了一个识别多元霍克斯过程中潜在子过程和因果影响的方法，通过离散时间模型表示连续时间事件序列，建立了可识别性的充要条件，并开发了一个两阶段迭代算法来恢复因果结构。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统往往只有部分被观测，存在潜在子过程对现有方法构成重大挑战，现有方法主要关注已观测子过程间的因果结构发现。

Method: 将连续时间事件序列表示为离散时间模型，建立识别潜在子过程和因果影响的充要条件，提出两阶段迭代算法：交替推断已发现子过程间的因果关系和发现新的潜在子过程。

Result: 在合成和真实数据集上的实验表明，该方法能有效恢复存在潜在子过程时的因果结构。

Conclusion: 该方法为解决多元霍克斯过程中潜在子过程的识别问题提供了有效解决方案，通过离散化表示和路径条件保证了可识别性。

Abstract: Multivariate Hawkes process provides a powerful framework for modeling
temporal dependencies and event-driven interactions in complex systems. While
existing methods primarily focus on uncovering causal structures among observed
subprocesses, real-world systems are often only partially observed, with latent
subprocesses posing significant challenges. In this paper, we show that
continuous-time event sequences can be represented by a discrete-time model as
the time interval shrinks, and we leverage this insight to establish necessary
and sufficient conditions for identifying latent subprocesses and the causal
influences. Accordingly, we propose a two-phase iterative algorithm that
alternates between inferring causal relationships among discovered subprocesses
and uncovering new latent subprocesses, guided by path-based conditions that
guarantee identifiability. Experiments on both synthetic and real-world
datasets show that our method effectively recovers causal structures despite
the presence of latent subprocesses.

</details>


### [258] [BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification](https://arxiv.org/abs/2508.11732)
*Xiangxiang Cui,Min Zhao,Dongmei Zhi,Shile Qi,Vince D Calhoun,Jing Sui*

Main category: cs.LG

TL;DR: 提出一种受脑组织启发的特征融合框架BRIEF，通过改进神经网络连接搜索和Transformer融合模块，自动优化网络结构并显著提升精神疾病分类性能


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在fMRI分类中存在网络结构确定依赖经验、特征融合方式简单（主要为拼接）缺乏相互学习等限制

Method: 1）提取4种fMRI时间表征：时间序列、静态/动态功能连接、多尺度分散熵极构建56个编码器 2）在每个编码器中使用改进Q学习动态优化神经网络连接搜索（NCS） 3）通过Transformer融合所有特征向量，利用稳定/时变连接和多尺度依赖关系 4）嵌入注意力模块提高可解释性

Result: 在精神分裂症（SZ，n=1100）和自闭谱系障碍（ASD，n=1550）识别任务中，与21个最新模型相比，BRIEF显著提升2.2%至12.1%，达到AUC为91.5%±0.6%（SZ）和78.4%±0.5%（ASD）

Conclusion: 这是首次尝试将受脑组织启发的强化学习策略应用于fMRI基于精神疾病分类，显示了在识别精确的神经影像生物标记物方面的重要潜力

Abstract: Existing deep learning models for functional MRI-based classification have
limitations in network architecture determination (relying on experience) and
feature space fusion (mostly simple concatenation, lacking mutual learning).
Inspired by the human brain's mechanism of updating neural connections through
learning and decision-making, we proposed a novel BRain-Inspired feature Fusion
(BRIEF) framework, which is able to optimize network architecture automatically
by incorporating an improved neural network connection search (NCS) strategy
and a Transformer-based multi-feature fusion module. Specifically, we first
extracted 4 types of fMRI temporal representations, i.e., time series (TCs),
static/dynamic functional connection (FNC/dFNC), and multi-scale dispersion
entropy (MsDE), to construct four encoders. Within each encoder, we employed a
modified Q-learning to dynamically optimize the NCS to extract high-level
feature vectors, where the NCS is formulated as a Markov Decision Process.
Then, all feature vectors were fused via a Transformer, leveraging both
stable/time-varying connections and multi-scale dependencies across different
brain regions to achieve the final classification. Additionally, an attention
module was embedded to improve interpretability. The classification performance
of our proposed BRIEF was compared with 21 state-of-the-art models by
discriminating two mental disorders from healthy controls: schizophrenia (SZ,
n=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated
significant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching
an AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is
the first attempt to incorporate a brain-inspired, reinforcement learning
strategy to optimize fMRI-based mental disorder classification, showing
significant potential for identifying precise neuroimaging biomarkers.

</details>


### [259] [Scalable Geospatial Data Generation Using AlphaEarth Foundations Model](https://arxiv.org/abs/2508.11739)
*Luc Houriez,Sebastian Pilarski,Behzad Vahedi,Ali Ahmadalipour,Teo Honda Scully,Nicholas Aflitto,David Andre,Caroline Jaffe,Martha Wedner,Rich Mazzola,Josh Jeffery,Ben Messinger,Sage McGinley-Smith,Sarah Russell*

Main category: cs.LG

TL;DR: 利用Google DeepMind的AlphaEarth Foundations (AEF) 全球地理空间表示，通过基础模型（如随机森林和逻辑回归）将地理标记数据集扩展到原始区域之外，在植被类型分类任务中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 高质量的地理标记数据集通常只覆盖特定地理区域，无法满足全球范围的应用需求。需要一种方法来扩展这些数据集的地理覆盖范围。

Method: 利用AEF作为信息密集的全球地理空间表示，采用随机森林和逻辑回归等基础模型，将美国LANDFIRE的植被类型数据集扩展到加拿大地区。

Result: 在EvtPhys（13个类别）上，模型预测与地面实况相符，在美国和加拿大的验证集上分别达到81%和73%的分类准确率。

Conclusion: 即使使用基础模型，结合AEF全球表示也能有效扩展地理标记数据集的地理覆盖范围，为全球地理空间分析提供了可行方案。

Abstract: High-quality labeled geospatial datasets are essential for extracting
insights and understanding our planet. Unfortunately, these datasets often do
not span the entire globe and are limited to certain geographic regions where
data was collected. Google DeepMind's recently released AlphaEarth Foundations
(AEF) provides an information-dense global geospatial representation designed
to serve as a useful input across a wide gamut of tasks. In this article we
propose and evaluate a methodology which leverages AEF to extend geospatial
labeled datasets beyond their initial geographic regions. We show that even
basic models like random forests or logistic regression can be used to
accomplish this task. We investigate a case study of extending LANDFIRE's
Existing Vegetation Type (EVT) dataset beyond the USA into Canada at two levels
of granularity: EvtPhys (13 classes) and EvtGp (80 classes). Qualitatively, for
EvtPhys, model predictions align with ground truth. Trained models achieve 81%
and 73% classification accuracy on EvtPhys validation sets in the USA and
Canada, despite discussed limitations.

</details>


### [260] [Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data](https://arxiv.org/abs/2508.11794)
*Hemanth Macharla,Mayukha Pal*

Main category: cs.LG

TL;DR: Fed-Meta-Align是一个四阶段联邦学习框架，通过序列化元初始化和平行联邦学习解决IoT设备非IID数据下的故障分类问题，在异构设备上达到91.27%的平均测试准确率


<details>
  <summary>Details</summary>
Motivation: 解决资源受限IoT设备在非IID数据环境下实时故障分类的挑战，传统联邦学习在非IID数据下容易导致模型发散

Method: 四阶段框架：1）在公共数据集上训练基础模型；2）序列化元初始化阶段，在IoT设备子集上顺序训练获得异构感知初始化；3）并行联邦学习阶段，使用基于本地性能和余弦相似度的双重标准聚合机制；4）设备端个性化阶段

Result: 在异构IoT设备上平均测试准确率达到91.27%，比个性化FedAvg和FedProx分别高出3.87%和3.37%

Conclusion: 这种多阶段的序列化初始化和自适应聚合方法为在多样化TinyML网络上部署高性能智能提供了稳健途径

Abstract: Real-time fault classification in resource-constrained Internet of Things
(IoT) devices is critical for industrial safety, yet training robust models in
such heterogeneous environments remains a significant challenge. Standard
Federated Learning (FL) often fails in the presence of non-IID data, leading to
model divergence. This paper introduces Fed-Meta-Align, a novel four-phase
framework designed to overcome these limitations through a sophisticated
initialization and training pipeline. Our process begins by training a
foundational model on a general public dataset to establish a competent
starting point. This model then undergoes a serial meta-initialization phase,
where it sequentially trains on a subset of IOT Device data to learn a
heterogeneity-aware initialization that is already situated in a favorable
region of the loss landscape. This informed model is subsequently refined in a
parallel FL phase, which utilizes a dual-criterion aggregation mechanism that
weights for IOT devices updates based on both local performance and cosine
similarity alignment. Finally, an on-device personalization phase adapts the
converged global model into a specialized expert for each IOT Device.
Comprehensive experiments demonstrate that Fed-Meta-Align achieves an average
test accuracy of 91.27% across heterogeneous IOT devices, outperforming
personalized FedAvg and FedProx by up to 3.87% and 3.37% on electrical and
mechanical fault datasets, respectively. This multi-stage approach of sequenced
initialization and adaptive aggregation provides a robust pathway for deploying
high-performance intelligence on diverse TinyML networks.

</details>


### [261] [Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes](https://arxiv.org/abs/2508.11800)
*Michael Bereket,Jure Leskovec*

Main category: cs.LG

TL;DR: 本文研究了强化学习在随机结果可验证领域（如科学实验）中的应用效果，发现GRPO方法会导致概率预测过度自信，而PPO和RLOO能产生良好校准的模型。通过移除GRPO中的组标准化可以解决校准问题。


<details>
  <summary>Details</summary>
Motivation: 研究当前强化学习方法在具有随机结果的可验证领域（如科学实验）中优化语言模型的有效性，超越传统的确定性数学领域应用。

Method: 通过合成数据和真实生物实验应用，比较Group Relative Policy Optimization (GRPO)、Proximal Policy Optimization (PPO)和REINFORCE Leave-One-Out (RLOO)等方法在随机结果预测中的表现。

Result: GRPO会导致二元随机结果的过度自信概率预测，而PPO和RLOO能产生良好校准的模型。移除GRPO中的组标准化可以修复其校准问题。

Conclusion: 研究结果提供了反对在GRPO中使用标准标准化的新证据，为强化学习在超越确定性领域的推理语言模型应用铺平了道路。

Abstract: Reinforcement learning (RL) has proven remarkably effective at improving the
accuracy of language models in verifiable and deterministic domains like
mathematics. Here, we examine if current RL methods are also effective at
optimizing language models in verifiable domains with stochastic outcomes, like
scientific experiments. Through applications to synthetic data and real-world
biological experiments, we demonstrate that Group Relative Policy Optimization
(GRPO) induces overconfident probability predictions for binary stochastic
outcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out
(RLOO) yield well-calibrated models. We show that removing group standard
normalization in GRPO fixes its miscalibration and provide a theoretical
explanation for why normalization causes overconfidence. Our results provide
new evidence against the use of standard normalization in GRPO and help pave
the way for applications of RL for reasoning language models beyond
deterministic domains.

</details>


### [262] [FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation](https://arxiv.org/abs/2508.11810)
*Nitish Nagesh,Salar Shakibhamedan,Mahdi Bagheri,Ziyu Wang,Nima TaheriNejad,Axel Jantsch,Amir M. Rahmani*

Main category: cs.LG

TL;DR: FairTabGen是一个基于大语言模型的公平性感知表格数据生成框架，通过整合反事实和因果公平性定义，在保持数据效用的同时显著提升公平性指标，仅需20%原始数据即可实现优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 在隐私敏感和数据稀缺的环境中生成合成表格数据时，如何在保持高数据效用的同时改善反事实和因果公平性是一个关键挑战。

Method: 使用基于大语言模型的框架，整合多种公平性定义到生成和评估流程中，采用上下文学习、提示优化和公平性感知数据管理来平衡公平性和效用。

Result: 在多个数据集上优于最先进的GAN和LLM方法，公平性指标（如人口统计均等和路径特定因果效应）提升高达10%，同时保持统计效用，仅需不到20%的原始数据。

Conclusion: 该方法提供了一个原则性和实用性的途径，用于生成公平且有用的合成表格数据，在低数据环境下表现出高效性。

Abstract: Generating synthetic data is crucial in privacy-sensitive, data-scarce
settings, especially for tabular datasets widely used in real-world
applications. A key challenge is improving counterfactual and causal fairness,
while preserving high utility. We present FairTabGen, a fairness-aware large
language model-based framework for tabular synthetic data generation. We
integrate multiple fairness definitions including counterfactual and causal
fairness into both its generation and evaluation pipelines. We use in-context
learning, prompt refinement, and fairness-aware data curation to balance
fairness and utility. Across diverse datasets, our method outperforms
state-of-the-art GAN-based and LLM-based methods, achieving up to 10%
improvements on fairness metrics such as demographic parity and path-specific
causal effects while retaining statistical utility. Remarkably, it achieves
these gains using less than 20% of the original data, highlighting its
efficiency in low-data regimes. These results demonstrate a principled and
practical approach for generating fair and useful synthetic tabular data.

</details>


### [263] [Combinations of Fast Activation and Trigonometric Functions in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.11876)
*Hoang-Thang Ta,Duy-Quy Thai,Phuong-Linh Tran-Thi*

Main category: cs.LG

TL;DR: 基于Kolmogorov-Arnold表示定理的网络使用高效计算函数（ReLU、三角函数）以提升计算效率和演化性能


<details>
  <summary>Details</summary>
Motivation: 现有基于KART的网络使用的多项式函数（如B样条、RBF）在GPU设备上支持度低且普遍性不足，需要更高效的计算函数来提升计算效率

Method: 将高效计算函数（ReLU、sin、cos、arctan等）组合集成到Kolmogorov-Arnold网络（KANs）结构中，作为基础组件

Result: 实验结果显示这些函数组合在保持竞争性能的同时，能够提供训练时间和泛化能力方面的潜在改进

Conclusion: 使用ReLU和三角函数等高效计算函数可以有效提升KANs网络的计算效率，为基于KART的神经网络提供更实用的实现方案

Abstract: For years, many neural networks have been developed based on the
Kolmogorov-Arnold Representation Theorem (KART), which was created to address
Hilbert's 13th problem. Recently, relying on KART, Kolmogorov-Arnold Networks
(KANs) have attracted attention from the research community, stimulating the
use of polynomial functions such as B-splines and RBFs. However, these
functions are not fully supported by GPU devices and are still considered less
popular. In this paper, we propose the use of fast computational functions,
such as ReLU and trigonometric functions (e.g., ReLU, sin, cos, arctan), as
basis components in Kolmogorov-Arnold Networks (KANs). By integrating these
function combinations into the network structure, we aim to enhance
computational efficiency. Experimental results show that these combinations
maintain competitive performance while offering potential improvements in
training time and generalization.

</details>


### [264] [PCA- and SVM-Grad-CAM for Convolutional Neural Networks: Closed-form Jacobian Expression](https://arxiv.org/abs/2508.11880)
*Yuto Omae*

Main category: cs.LG

TL;DR: 提出了PCA-Grad-CAM和SVM-Grad-CAM方法，用于可视化CNN中PCA和SVM层的注意力区域，解决了传统Grad-CAM无法直接应用于这些层的问题。


<details>
  <summary>Details</summary>
Motivation: 当训练样本有限时，在CNN中集成PCA层和SVM分类器可以提高分类性能，但传统Grad-CAM无法直接应用于这些层，需要开发新的可视化方法。

Method: 通过求解从最后一个卷积层到PCA和SVM层的闭式雅可比矩阵，提出了PCA-Grad-CAM和SVM-Grad-CAM可视化方法。

Result: 在多个主要数据集上展示了方法的可视化结果，证明了方法的有效性。

Conclusion: 提出的方法成功解决了PCA和SVM层在CNN中的可视化问题，为白盒方法的发展提供了支持。

Abstract: Convolutional Neural Networks (CNNs) are an effective approach for
classification tasks, particularly when the training dataset is large. Although
CNNs have long been considered a black-box classification method, they can be
used as a white-box method through visualization techniques such as Grad-CAM.
When training samples are limited, incorporating a Principal Component Analysis
(PCA) layer and/or a Support Vector Machine (SVM) classifier into a CNN can
effectively improve classification performance. However, traditional Grad-CAM
cannot be directly applied to PCA and/or SVM layers. It is important to
generate attention regions for PCA and/or SVM layers in CNNs to facilitate the
development of white-box methods. Therefore, we propose ``PCA-Grad-CAM'', a
method for visualizing attention regions in PCA feature vectors, and
``SVM-Grad-CAM'', a method for visualizing attention regions in an SVM
classifier layer. To complete our methods analytically, it is necessary to
solve the closed-form Jacobian consisting of partial derivatives from the last
convolutional layer to the PCA and/or SVM layers. In this paper, we present the
exact closed-form Jacobian and the visualization results of our methods applied
to several major datasets.

</details>


### [265] [ENA: Efficient N-dimensional Attention](https://arxiv.org/abs/2508.11921)
*Yibo Zhong*

Main category: cs.LG

TL;DR: 这篇论文探索了将线性递归模型扩展到高维数据的两个关键方面：扫描策略和注意力混合架构，并提出了高效的N维注意力（ENA）模型


<details>
  <summary>Details</summary>
Motivation: 传统Transformer架构在处理长序列高阶数据时效率低下，需要更高效的模型架构来应对这一挑战

Method: 研究了两种扩展方法：扫描策略和注意力混合架构，并重点分析了滑动窗口注意力（SWA）的效果，最终提出了线性递归与高阶SWA的混合架构ENA

Result: 实验结果显示扫描策略收益有限，而注意力混合模型表现出艰激的潜力，特别是模块化的高阶滑动窗口注意力在理论和实践中都很高效

Conclusion: ENA模型通过线性递归压缩全局信息和SWA强化局部建模，为超长高阶数据建模提供了一个简洁而有前景的实用解决方案

Abstract: Efficient modeling of long sequences of high-order data requires a more
efficient architecture than Transformer. In this paper, we investigate two key
aspects of extending linear recurrent models, especially those originally
designed for language modeling, to high-order data (1D to ND): scanning
strategies and attention-hybrid architectures. Empirical results suggest that
scanning provides limited benefits, while attention-hybrid models yield
promising results. Focusing on the latter, we further evaluate types of
attention and find that tiled high-order sliding window attention (SWA) is
efficient in both theory and practice. We term the resulting hybrid
architecture of linear recurrence and high-order SWA as Efficient N-dimensional
Attention (ENA). We then conduct several experiments to demonstrate its
effectiveness. The intuition behind ENA is that linear recurrence compresses
global information into a state, while SWA complements it by enforcing strict
local modeling. Together, they form a simple framework that offers a promising
and practical solution for ultra-long high-order data modeling.

</details>


### [266] [Scale-Disentangled spatiotemporal Modeling for Long-term Traffic Emission Forecasting](https://arxiv.org/abs/2508.11923)
*Yan Wu,Lihong Pei,Yukai Han,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 通过解耦多尺度时空特征的SDSTM框架，提升了长期交通排放预测的准确性，避免传统方法的级联错误放大问题


<details>
  <summary>Details</summary>
Motivation: 传统时空图模型在长期交通排放预测中存在多尺度时空特征缀缘问题，导致级联错误放大，影响预测准确性

Method: 提出尺度解耦时空建模框架(SDSTM)，采用Koopman提升算子的双流特征分解策略，通过闸洞波分解边界和交叉项损失约束，实现多尺度特征的独立补充融合

Result: 在西安二环路道路级交通排放数据集上进行实验，证明该模型达到了最先进的性能水平

Conclusion: SDSTM框架通过有效解耦多尺度时空特征，显著提升了长期交通排放预测的准确性和稳定性，为城市空气污染管理提供了有效技术支撑

Abstract: Long-term traffic emission forecasting is crucial for the comprehensive
management of urban air pollution. Traditional forecasting methods typically
construct spatiotemporal graph models by mining spatiotemporal dependencies to
predict emissions. However, due to the multi-scale entanglement of traffic
emissions across time and space, these spatiotemporal graph modeling method
tend to suffer from cascading error amplification during long-term inference.
To address this issue, we propose a Scale-Disentangled Spatio-Temporal Modeling
(SDSTM) framework for long-term traffic emission forecasting. It leverages the
predictability differences across multiple scales to decompose and fuse
features at different scales, while constraining them to remain independent yet
complementary. Specifically, the model first introduces a dual-stream feature
decomposition strategy based on the Koopman lifting operator. It lifts the
scale-coupled spatiotemporal dynamical system into an infinite-dimensional
linear space via Koopman operator, and delineates the predictability boundary
using gated wavelet decomposition. Then a novel fusion mechanism is
constructed, incorporating a dual-stream independence constraint based on
cross-term loss to dynamically refine the dual-stream prediction results,
suppress mutual interference, and enhance the accuracy of long-term traffic
emission prediction. Extensive experiments conducted on a road-level traffic
emission dataset within Xi'an's Second Ring Road demonstrate that the proposed
model achieves state-of-the-art performance.

</details>


### [267] [An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction](https://arxiv.org/abs/2508.11931)
*Tim van Erven,Jack Mayo,Julia Olkhovskaya,Chen-Yu Wei*

Main category: cs.LG

TL;DR: \u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7b97\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u5e26\u6709\u5bf9\u624b\u635f\u5931\u548c\u968f\u673a\u52a8\u4f5c\u96c6\u7684\u7ebf\u6027\u4e0a\u4e0b\u6587\u673a\u5668\u5b66\u4e60\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u7684\u591a\u9879\u5f0f\u56de\u9875\u9057\u61be


<details>
  <summary>Details</summary>
Motivation: \u89e3\u51b3Liu\u7b49\u4eba(2023)\u63d0\u51fa\u7684\u5f00\u653f\u95ee\u9898\uff1a\u662f\u5426\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u52a8\u4f5c\u6570\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u4ee5\u591a\u9879\u5f0f\u65f6\u95f4\u83b7\u5f97\u591a\u9879\u5f0f\u56de\u9875\u9057\u61be

Method: \u5c06\u8be5\u95ee\u9898\u7ea6\u51cf\u4e3a\u5177\u6709\u56fa\u5b9a\u52a8\u4f5c\u96c6\u7684\u9519\u8bef\u89c4\u8303\u7c97\u7559\u5bf9\u624b\u7ebf\u6027\u673a\u5668\u5b66\u4e60\u95ee\u9898\uff0c\u65e0\u9700\u4e0a\u4e0b\u6587\u5206\u5e03\u77e5\u8bc6\u6216\u4e0a\u4e0b\u6587\u6a21\u62df\u5668

Result: \u7b97\u6cd5\u8fbe\u5230\u4e86$\tilde{O}(\min\{d^2\sqrt{T}, \sqrt{d^3T\log K}\})$ \u7684\u56de\u9875\u9057\u61be\uff0c\u8fd0\u884c\u65f6\u95f4\u4e3a$\text{poly}(d,C,T)$\uff0c\u5176\u4e2d$d$\u662f\u7279\u5f81\u7ef4\u5ea6\uff0c$C$\u662f\u6bcf\u8f6e\u52a8\u4f5c\u96c6\u7ebf\u6027\u7ea6\u675f\u6570\u91cf\u4e0a\u754c\uff0c$K$\u662f\u6bcf\u8f6e\u52a8\u4f5c\u6570\u91cf\u4e0a\u754c\uff0c$T$\u662f\u8f6e\u6570

Conclusion: \u8be5\u7b97\u6cd5\u9996\u6b21\u5728\u7ec4\u5408\u673a\u5668\u5b66\u4e60\u95ee\u9898\u4e2d\u5b9e\u73b0\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u7684\u591a\u9879\u5f0f\u56de\u9875\u9057\u61be\uff0c\u5f53\u53ef\u7528\u6a21\u62df\u5668\u65f6\u56de\u9875\u9057\u61be\u8fdb\u4e00\u6b65\u63d0\u5347\u5230$\tilde{O}(d\sqrt{L^\star})$\uff0c\u5176\u4e2d$L^\star$\u662f\u6700\u4f73\u7b56\u7565\u7684\u7d2f\u8ba1\u635f\u5931

Abstract: We present an efficient algorithm for linear contextual bandits with
adversarial losses and stochastic action sets. Our approach reduces this
setting to misspecification-robust adversarial linear bandits with fixed action
sets. Without knowledge of the context distribution or access to a context
simulator, the algorithm achieves $\tilde{O}(\min\{d^2\sqrt{T}, \sqrt{d^3T\log
K}\})$ regret and runs in $\text{poly}(d,C,T)$ time, where $d$ is the feature
dimension, $C$ is an upper bound on the number of linear constraints defining
the action set in each round, $K$ is an upper bound on the number of actions in
each round, and $T$ is number of rounds. This resolves the open question by Liu
et al. (2023) on whether one can obtain $\text{poly}(d)\sqrt{T}$ regret in
polynomial time independent of the number of actions. For the important class
of combinatorial bandits with adversarial losses and stochastic action sets
where the action sets can be described by a polynomial number of linear
constraints, our algorithm is the first to achieve $\text{poly}(d)\sqrt{T}$
regret in polynomial time, while no prior algorithm achieves even $o(T)$ regret
in polynomial time to our knowledge. When a simulator is available, the regret
bound can be improved to $\tilde{O}(d\sqrt{L^\star})$, where $L^\star$ is the
cumulative loss of the best policy.

</details>


### [268] [M3OOD: Automatic Selection of Multimodal OOD Detectors](https://arxiv.org/abs/2508.11936)
*Yuehan Qin,Li Li,Defu Cao,Tiankai Yang,Yue Zhao*

Main category: cs.LG

TL;DR: M3OOD是一个基于元学习的多模态OOD检测器选择框架，通过历史模型行为学习，能够为新数据分布偏移自动推荐合适的检测器，在12个测试场景中优于10个基线方法。


<details>
  <summary>Details</summary>
Motivation: 多模态环境下的OOD鲁棒性是一个关键挑战，单个OOD检测器无法在所有场景中都表现最佳，且由于OOD检测的无监督性质，难以预测模型性能并找到通用最佳模型。

Method: 提出M3OOD框架，结合多模态嵌入和手工制作的元特征来表征数据集，利用元学习从历史多模态基准的性能中学习，为新数据分布偏移推荐合适的检测器。

Result: 实验评估表明，M3OOD在12个测试场景中持续优于10个竞争基线方法，且计算开销最小。

Conclusion: M3OOD通过元学习方法有效解决了多模态OOD检测器选择问题，能够自动为不同分布偏移推荐合适的检测模型，具有实际应用价值。

Abstract: Out-of-distribution (OOD) robustness is a critical challenge for modern
machine learning systems, particularly as they increasingly operate in
multimodal settings involving inputs like video, audio, and sensor data.
Currently, many OOD detection methods have been proposed, each with different
designs targeting various distribution shifts. A single OOD detector may not
prevail across all the scenarios; therefore, how can we automatically select an
ideal OOD detection model for different distribution shifts? Due to the
inherent unsupervised nature of the OOD detection task, it is difficult to
predict model performance and find a universally Best model. Also,
systematically comparing models on the new unseen data is costly or even
impractical. To address this challenge, we introduce M3OOD, a
meta-learning-based framework for OOD detector selection in multimodal
settings. Meta learning offers a solution by learning from historical model
behaviors, enabling rapid adaptation to new data distribution shifts with
minimal supervision. Our approach combines multimodal embeddings with
handcrafted meta-features that capture distributional and cross-modal
characteristics to represent datasets. By leveraging historical performance
across diverse multimodal benchmarks, M3OOD can recommend suitable detectors
for a new data distribution shift. Experimental evaluation demonstrates that
M3OOD consistently outperforms 10 competitive baselines across 12 test
scenarios with minimal computational overhead.

</details>


### [269] [Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware](https://arxiv.org/abs/2508.11940)
*Yuannuo Feng,Wenyong Zhou,Yuexi Lyu,Yixiang Zhang,Zhengwu Liu,Ngai Wong,Wang Kang*

Main category: cs.LG

TL;DR: 通过解合前向噪声模拟和向后梯度计算，提出了一种可在模拟更复杂硬件噪声的噪声意识训练方法，在保持计算可行性的同时提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 模拟式噪声意识训练方法通常依赖理想化和可微分的噪声模型，无法正确描述模拟计算存储(CIM)硬件的复杂噪声特性，影响部署效果。

Method: 受到量化中直通估计器(STE)框架的启发，将前向噪声模拟与向后梯度计算解耦，允许使用更准确但计算上难以处理的噪声模型进行噪声意识训练。

Result: 实验结果显示，该方法在图像分类任务上提升了达5.3%的准确率，文本生成任务上降低了0.72的困扰度，训练时间加速2.2倍，并节省37.9%的峰值内存使用。

Conclusion: 该研究提出的扩展STE框架能够有效处理模拟CIM硬件的复杂噪声问题，在保持计算效率的同时显著提升了模型的硬件适配性能和性能表现。

Abstract: Analog Compute-In-Memory (CIM) architectures promise significant energy
efficiency gains for neural network inference, but suffer from complex
hardware-induced noise that poses major challenges for deployment. While
noise-aware training methods have been proposed to address this issue, they
typically rely on idealized and differentiable noise models that fail to
capture the full complexity of analog CIM hardware variations. Motivated by the
Straight-Through Estimator (STE) framework in quantization, we decouple forward
noise simulation from backward gradient computation, enabling noise-aware
training with more accurate but computationally intractable noise modeling in
analog CIM systems. We provide theoretical analysis demonstrating that our
approach preserves essential gradient directional information while maintaining
computational tractability and optimization stability. Extensive experiments
show that our extended STE framework achieves up to 5.3% accuracy improvement
on image classification, 0.72 perplexity reduction on text generation,
2.2$\times$ speedup in training time, and 37.9% lower peak memory usage
compared to standard noise-aware training methods.

</details>


### [270] [Learning Marked Temporal Point Process Explanations based on Counterfactual and Factual Reasoning](https://arxiv.org/abs/2508.11943)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yan Wang*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的解释方法CFF，通过结合反事实解释和事实解释来提高神经网络基于标记时间点过程模型的可解释性和可信质性。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络基于标记时间点过程模型在重要应用中的广泛采用，对这些模型输出的可信质性引起了越来越多的关注。需要找到最小且合理的历史事件子集来解释模型的预测结果。

Method: 识别最小且合理的历史事件子集，使得基于该子集的MTPP预测准确性与基于全部历史的预测准确性大致相等，且更好于基于子集补集的预测准确性。提出了结合反事实解释和事实解释的CFF方法，并设计了一系列技术来解决这个问题。

Result: 实验结果证明了CFF方法在解释质量和处理效率方面都显著优于基线方法，具有正确性和优势性。

Conclusion: 通过结合反事实和事实解释的CFF方法，能够为MTPP模型提供更可靠和合理的解释，提高模型的可解释性和可信质性。

Abstract: Neural network-based Marked Temporal Point Process (MTPP) models have been
widely adopted to model event sequences in high-stakes applications, raising
concerns about the trustworthiness of outputs from these models. This study
focuses on Explanation for MTPP, aiming to identify the minimal and rational
explanation, that is, the minimum subset of events in history, based on which
the prediction accuracy of MTPP matches that based on full history to a great
extent and better than that based on the complement of the subset. This study
finds that directly defining Explanation for MTPP as counterfactual explanation
or factual explanation can result in irrational explanations. To address this
issue, we define Explanation for MTPP as a combination of counterfactual
explanation and factual explanation. This study proposes Counterfactual and
Factual Explainer for MTPP (CFF) to solve Explanation for MTPP with a series of
deliberately designed techniques. Experiments demonstrate the correctness and
superiority of CFF over baselines regarding explanation quality and processing
efficiency.

</details>


### [271] [Set-Valued Transformer Network for High-Emission Mobile Source Identification](https://arxiv.org/abs/2508.11976)
*Yunning Cao,Lihong Pei,Jian Guo,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 提出Set-Valued Transformer Network (SVTN)解决高排放车辆识别中的长尾分布问题，通过transformer建模时间相似性和集合值识别算法，在合肥柴油车数据上实现9.5%的漏检率降低


<details>
  <summary>Details</summary>
Motivation: 高排放车辆识别对城市污染管控至关重要，但实际监测数据中存在长尾分布问题（高排放样本比例极低），且排放状态高度非线性、缺乏先验知识，给特征提取和模型构建带来挑战

Method: 提出SVTN模型：1) 使用transformer度量微行程条件变化的时间相似性，将高维排放数据映射到低维特征空间；2) 采用集合值识别算法对特征向量与标签关系进行概率建模，为分类提供准确度量标准

Result: 在合肥市2020年柴油车监测数据上的实验表明，相比基于transformer的基线方法，该方法将高排放车辆漏检率降低了9.5%

Conclusion: SVTN方法能够从高排放样本中全面学习判别特征，显著提升高排放移动污染源的准确识别能力

Abstract: Identifying high-emission vehicles is a crucial step in regulating urban
pollution levels and formulating traffic emission reduction strategies.
However, in practical monitoring data, the proportion of high-emission state
data is significantly lower compared to normal emission states. This
characteristic long-tailed distribution severely impedes the extraction of
discriminative features for emission state identification during data mining.
Furthermore, the highly nonlinear nature of vehicle emission states and the
lack of relevant prior knowledge also pose significant challenges to the
construction of identification models.To address the aforementioned issues, we
propose a Set-Valued Transformer Network (SVTN) to achieve comprehensive
learning of discriminative features from high-emission samples, thereby
enhancing detection accuracy. Specifically, this model first employs the
transformer to measure the temporal similarity of micro-trip condition
variations, thus constructing a mapping rule that projects the original
high-dimensional emission data into a low-dimensional feature space. Next, a
set-valued identification algorithm is used to probabilistically model the
relationship between the generated feature vectors and their labels, providing
an accurate metric criterion for the classification algorithm. To validate the
effectiveness of our proposed approach, we conducted extensive experiments on
the diesel vehicle monitoring data of Hefei city in 2020. The results
demonstrate that our method achieves a 9.5\% reduction in the missed detection
rate for high-emission vehicles compared to the transformer-based baseline,
highlighting its superior capability in accurately identifying high-emission
mobile pollution sources.

</details>


### [272] [Efficient Modular Learning through Naive LoRA Summation: Leveraging Orthogonality in High-Dimensional Models](https://arxiv.org/abs/2508.11985)
*Zhanhao Cao,Clement Truong,Andrew Lizarraga*

Main category: cs.LG

TL;DR: 这篇论文探索了通过简单加法组合独立训练的LoRA模块来实现多领域适配的方法，无需额外训练且性能可与合并数据训练相比。


<details>
  <summary>Details</summary>
Motivation: 测试超置加理假设：独立训练的LoRA模块在不相交领域上是约规正交的，可通过简单加法组合。

Method: 使用GPT-2 Small模型和LoRA技术，在数学、医学、金融三个问答领域训练独立的适配器，然后通过直接加法组合这些模块。

Result: 数学+医学组合相对合并数据训练改善语言模型的浮点率-9.10%，而其他组合表现差异较大。LoRA变量之间的余弦相似性与性能变化呈正相关。

Conclusion: 简单加法无需额外训练、可秒级应用，性能可与合并数据训练相比，同时能够显示高阶组合中的干扰现象。

Abstract: Recent advances in large language models are driven by scale, while
parameter-efficient fine-tuning (PEFT) enables updating only a small fraction
of parameters. Low-Rank Adaptation (LoRA) stores parameter deltas as the
product of two small matrices, which makes them natural building blocks that
can be composed. Motivated by the superposition principle, we hypothesize that
independently trained LoRA modules on disjoint domains are approximately
orthogonal and can be combined by simple addition. Using GPT-2 Small (117M)
with LoRA rank 4 and alpha=64, we train adapters for three QA domains (math,
medicine, finance). In pairwise tests, adding Math+Medicine adapters improves
perplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance
and Finance+Medicine change by +4.54% and +27.56%, respectively. Across
combinations, the RMS cosine similarity between LoRA deltas correlates
positively and approximately linearly with the change in perplexity. Naive
summation requires no additional training, can be applied in seconds, and
achieves performance comparable to models trained on merged data, while
clarifying when interference appears in higher-order compositions.

</details>


### [273] [Universal Learning of Nonlinear Dynamics](https://arxiv.org/abs/2508.11990)
*Evan Dogariu,Anand Brahmbhatt,Elad Hazan*

Main category: cs.LG

TL;DR: 提出了一种基于谱滤波的算法，用于学习具有有限个边缘稳定模式的非线性动力系统，通过在线凸优化技术实现了预测误差的消失。


<details>
  <summary>Details</summary>
Motivation: 解决学习边缘稳定未知非线性动力系统的基本问题，传统方法难以处理这类系统的稳定性和噪声问题。

Method: 使用谱滤波技术，基于系统的谱表示构建从过去观测到下一个状态的映射，并开发了新的谱滤波算法来处理线性动力系统，支持非对称动态和噪声校正。

Result: 证明了对于任何具有有限边缘稳定模式的非线性动力系统，预测误差会消失，学习速率由新的可学习性量化控制理论概念决定。

Conclusion: 该方法显著推广了原始谱滤波算法，适用于非对称动态和噪声校正，对线性动力系统的谱滤波算法有独立贡献。

Abstract: We study the fundamental problem of learning a marginally stable unknown
nonlinear dynamical system. We describe an algorithm for this problem, based on
the technique of spectral filtering, which learns a mapping from past
observations to the next based on a spectral representation of the system.
Using techniques from online convex optimization, we prove vanishing prediction
error for any nonlinear dynamical system that has finitely many marginally
stable modes, with rates governed by a novel quantitative control-theoretic
notion of learnability. The main technical component of our method is a new
spectral filtering algorithm for linear dynamical systems, which incorporates
past observations and applies to general noisy and marginally stable systems.
This significantly generalizes the original spectral filtering algorithm to
both asymmetric dynamics as well as incorporating noise correction, and is of
independent interest.

</details>


### [274] [FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing](https://arxiv.org/abs/2508.12021)
*You Hak Lee,Xiaofan Yu,Quanling Zhao,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: 基于超高维计算(HDC)的无监督联邦学习框架FedUHD，解决了非IID数据、计算通信成本高和通信噪声脏弱性等问题，在训练速度、能消、通信成本和精度方面显著优于现有神经网络方案。


<details>
  <summary>Details</summary>
Motivation: 无监督联邦学习(UFL)作为一种隐私保护的去中心化机器学习方法，屏影了需要劳动密集型数据标签的需求，但在实际应用中面临非IID数据分布、计算通信成本高和通信噪声脏弱性等挑战。

Method: 提出基于超高维计算(HDC)的FedUHD框架：客户端采用kNN基于聚类超高维向量移除方法处理非IID数据异常倾；服务器端采用加权HDC聚合技术平衡不同客户的数据分布。

Result: 实验结果显示FedUHD在训练速度上提升达173.6倍，能消效率提升612.7倍，通信成本降住271倍，平均精度提高15.50%，并且在各种噪声环境下体现了更优异的稳健性。

Conclusion: FedUHD作为首个基于HDC的UFL框架，通过轻量级计算操作、小型模型和噪声耐受性，有效解决了传统神经网络方案在UFL中的计算通信负担和噪声脏弱性问题，为实际应用提供了更高效的解决方案。

Abstract: Unsupervised federated learning (UFL) has gained attention as a
privacy-preserving, decentralized machine learning approach that eliminates the
need for labor-intensive data labeling. However, UFL faces several challenges
in practical applications: (1) non-independent and identically distributed
(non-iid) data distribution across devices, (2) expensive computational and
communication costs at the edge, and (3) vulnerability to communication noise.
Previous UFL approaches have relied on deep neural networks (NN), which
introduce substantial overhead in both computation and communication. In this
paper, we propose FedUHD, the first UFL framework based on Hyperdimensional
Computing (HDC). HDC is a brain-inspired computing scheme with lightweight
training and inference operations, much smaller model size, and robustness to
communication noise. FedUHD introduces two novel HDC-based designs to improve
UFL performance. On the client side, a kNN-based cluster hypervector removal
method addresses non-iid data samples by eliminating detrimental outliers. On
the server side, a weighted HDC aggregation technique balances the non-iid data
distribution across clients. Our experiments demonstrate that FedUHD achieves
up to 173.6x and 612.7x better speedup and energy efficiency, respectively, in
training, up to 271x lower communication cost, and 15.50% higher accuracy on
average across diverse settings, along with superior robustness to various
types of noise compared to state-of-the-art NN-based UFL approaches.

</details>


### [275] [Fairness Regularization in Federated Learning](https://arxiv.org/abs/2508.12042)
*Zahra Kharaghani,Ali Dadras,Tommy Löfstedt*

Main category: cs.LG

TL;DR: 联邦学习中的性能公平性问题研究，提出FairGrad方法在异质性数据环境下同时提升公平性和模型性能


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据异质性导致某些客户对全局模型产生不成比例影响，从而引发性能不公平问题，现有公平方法在异质数据环境下效果不明

Method: 重点研究显式正则化客户损失的公平方法，提出FairGrad（近似）和FairGrad*（精确）两种梯度方差正则化方法

Result: 理论解释了不同公平方法之间的联系，实验证明FairGrad和FairGrad*在异质性数据环境下能够同时提升公平性和整体模型性能

Conclusion: 该研究为联邦学习中的性能公平性问题提供了新的解决方案，FairGrad方法在实践中表现出良好效果

Abstract: Federated Learning (FL) has emerged as a vital paradigm in modern machine
learning that enables collaborative training across decentralized data sources
without exchanging raw data. This approach not only addresses privacy concerns
but also allows access to overall substantially larger and potentially more
diverse datasets, without the need for centralized storage or hardware
resources. However, heterogeneity in client data may cause certain clients to
have disproportionate impacts on the global model, leading to disparities in
the clients' performances. Fairness, therefore, becomes a crucial concern in FL
and can be addressed in various ways. However, the effectiveness of existing
fairness-aware methods, particularly in heterogeneous data settings, remains
unclear, and the relationships between different approaches are not well
understood. In this work, we focus on performance equitable fairness, which
aims to minimize differences in performance across clients. We restrict our
study to fairness-aware methods that explicitly regularize client losses,
evaluating both existing and newly proposed approaches. We identify and
theoretically explain connections between the investigated fairness methods,
and empirically show that FairGrad (approximate) and FairGrad* (exact) (two
variants of a gradient variance regularization method introduced here for
performance equitable fairness) improve both fairness and overall model
performance in heterogeneous data settings.

</details>


### [276] [VARAN: Variational Inference for Self-Supervised Speech Models Fine-Tuning on Downstream Tasks](https://arxiv.org/abs/2508.12061)
*Daria Diatlova,Nikita Balagansky,Alexander Varlamov,Egor Spirin*

Main category: cs.LG

TL;DR: VARAN是一个动态层聚合框架，通过输入相关的权重分配和专门化的探测头，为自监督语音模型的微调提供自适应特征选择，在语音识别和情感识别任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的自监督语音模型微调方法（如使用最终层或加权求和）存在信息瓶颈问题，对所有数据样本采用静态特征权重，无法根据输入内容动态调整层特征的重要性。

Method: 提出VARAN框架，采用层专门化探测头和数据相关权重分配，根据输入内容动态调整各层特征的优先级，特别结合LoRA微调技术实现高效适配。

Result: 在自动语音识别和语音情感识别任务上的评估显示，VARAN相比传统方法具有更优越的性能表现。

Conclusion: VARAN框架解决了保持层特定信息与实现灵活特征利用之间的权衡问题，推进了自监督语音表征的高效适配。

Abstract: Conventional methods for aggregating layers in fine-tuned self-supervised
speech models, such as using the final layer or weighted sum, suffer from
information bottlenecks and static feature weighting for all dataset examples.
We propose VARAN, a framework that dynamically tailors layer aggregation to
individual inputs. By employing layer-specialized probing heads and
data-dependent weighting, VARAN adaptively prioritizes layer's features based
on input. Evaluations on automatic speech recognition and speech emotion
recognition tasks demonstrate VARAN's superior performance, particularly when
using the LoRA fine-tuning technique. The framework resolves the trade-off
between preserving layer-specific information and enabling flexible feature
utilization, advancing efficient adaptation of self-supervised speech
representations.

</details>


### [277] [Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks](https://arxiv.org/abs/2508.12079)
*Ningzhe Shi,Yiqing Zhou,Ling Liu,Jinglin Shi,Yihao Wu,Haiwei Shi,Hanxiao Yu*

Main category: cs.LG

TL;DR: 该论文提出了一个用于ISAC-AIGC网络的内容准确性和质量感知服务评估指标(CAQA)，并开发了LPDRL-F算法来优化三维资源分配，显著提升了平均CAQA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的AIGC服务通常假设输入数据和提示准确，只关注内容生成质量(CGQ)，但在基于ISAC的AIGC网络中，内容生成基于不准确的感知数据，且AIGC模型本身也会引入生成错误，需要新的评估指标和资源优化方法。

Method: 提出CAQA评估指标，并设计LP引导的深度强化学习算法(LPDRL-F)，通过LP指导和动作过滤器将三维解空间转换为二维，降低复杂度同时提升DRL学习性能。

Result: 仿真显示LPDRL-F相比现有DRL和生成扩散模型算法收敛速度快60%以上，找到更好的资源分配方案，AvgCAQA提升超过14%，相比仅关注CGQ的方案AvgCAQA提升超过50%。

Conclusion: CAQA指标和LPDRL-F算法有效解决了ISAC-AIGC网络中的三维资源权衡问题，显著提升了服务质量和用户体验。

Abstract: Integrated sensing and communication (ISAC) can enhance artificial
intelligence-generated content (AIGC) networks by providing efficient sensing
and transmission. Existing AIGC services usually assume that the accuracy of
the generated content can be ensured, given accurate input data and prompt,
thus only the content generation quality (CGQ) is concerned. However, it is not
applicable in ISAC-based AIGC networks, where content generation is based on
inaccurate sensed data. Moreover, the AIGC model itself introduces generation
errors, which depend on the number of generating steps (i.e., computing
resources). To assess the quality of experience of ISAC-based AIGC services, we
propose a content accuracy and quality aware service assessment metric (CAQA).
Since allocating more resources to sensing and generating improves content
accuracy but may reduce communication quality, and vice versa, this
sensing-generating (computing)-communication three-dimensional resource
tradeoff must be optimized to maximize the average CAQA (AvgCAQA) across all
users with AIGC (CAQA-AIGC). This problem is NP-hard, with a large solution
space that grows exponentially with users. To solve the CAQA-AIGC problem with
low complexity, a linear programming (LP) guided deep reinforcement learning
(DRL) algorithm with an action filter (LPDRL-F) is proposed. Through the
LP-guided approach and the action filter, LPDRL-F can transform the original
three-dimensional solution space to two dimensions, reducing complexity while
improving the learning performance of DRL. Simulations show that compared to
existing DRL and generative diffusion model algorithms without LP, LPDRL-F
converges faster by over 60% and finds better resource allocation solutions,
improving AvgCAQA by more than 14%. With LPDRL-F, CAQA-AIGC can achieve an
improvement in AvgCAQA of more than 50% compared to existing schemes focusing
solely on CGQ.

</details>


### [278] [Generative Medical Event Models Improve with Scale](https://arxiv.org/abs/2508.12104)
*Shane Waxler,Paul Blazek,Davis White,Daniel Sneider,Kevin Chung,Mani Nagarathnam,Patrick Williams,Hank Voeller,Karen Wong,Matthew Swanhorst,Sheng Zhang,Naoto Usuyama,Cliff Wong,Tristan Naumann,Hoifung Poon,Andrew Loza,Daniella Meeker,Seth Hain,Rahul Shah*

Main category: cs.LG

TL;DR: CoMET是基于160亿次医疗事件训练的10亿参数医疗基础模型，通过自回归生成医疗事件来模拟患者健康时间线，在78个医疗任务上无需微调即超越任务特定模型。


<details>
  <summary>Details</summary>
Motivation: 实现规模化个性化医疗需要从纵向患者旅程中提取洞察，基础模型预训练在大规模医疗事件数据上是扩展真实世界证据生成和泛化到多样化下游任务的有前景方向。

Method: 使用Epic Cosmos数据集（163亿次就诊、3亿患者记录），训练decoder-only transformer模型CoMET，进行最大规模的医疗数据缩放定律研究，预训练计算最优模型达10亿参数，通过自回归生成下一个医疗事件来模拟患者时间线。

Result: 在78个真实世界任务（诊断预测、疾病预后、医疗运营）上，CoMET通常优于或匹配任务特定的监督模型，无需任务特定微调或少样本示例，预测能力随模型和预训练规模持续提升。

Conclusion: CoMET作为生成式医疗事件基础模型，能有效捕捉复杂临床动态，为支持临床决策、简化医疗运营和改善患者结局提供可扩展和可泛化的框架。

Abstract: Realizing personalized medicine at scale calls for methods that distill
insights from longitudinal patient journeys, which can be viewed as a sequence
of medical events. Foundation models pretrained on large-scale medical event
data represent a promising direction for scaling real-world evidence generation
and generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with
medical events from de-identified longitudinal health records for 16.3 billion
encounters over 300 million unique patient records from 310 health systems, we
introduce the Cosmos Medical Event Transformer ( CoMET) models, a family of
decoder-only transformer models pretrained on 118 million patients representing
115 billion discrete medical events (151 billion tokens). We present the
largest scaling-law study for medical event data, establishing a methodology
for pretraining and revealing power-law scaling relationships for compute,
tokens, and model size. Based on this, we pretrained a series of
compute-optimal models with up to 1 billion parameters. Conditioned on a
patient's real-world history, CoMET autoregressively generates the next medical
event, simulating patient health timelines. We studied 78 real-world tasks,
including diagnosis prediction, disease prognosis, and healthcare operations.
Remarkably for a foundation model with generic pretraining and simulation-based
inference, CoMET generally outperformed or matched task-specific supervised
models on these tasks, without requiring task-specific fine-tuning or few-shot
examples. CoMET's predictive power consistently improves as the model and
pretraining scale. Our results show that CoMET, a generative medical event
foundation model, can effectively capture complex clinical dynamics, providing
an extensible and generalizable framework to support clinical decision-making,
streamline healthcare operations, and improve patient outcomes.

</details>


### [279] [DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections](https://arxiv.org/abs/2508.12116)
*Haebin Shin,Lei Ji,Xiao Liu,Zhiwei Yu,Qi Chen,Yeyun Gong*

Main category: cs.LG

TL;DR: DynamixSFT是一种动态自动化指令调优数据集混合优化方法，通过多臂老虎机框架和先验缩放玻尔兹曼探索，在保持数据集多样性的同时提升模型性能，在Tulu-v2数据集上实现了2.2%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着后训练阶段大量指令调优数据集的涌现，如何动态平衡和优化这些数据集的混合比例成为一个关键挑战。

Method: 将问题建模为多臂老虎机框架，提出先验缩放玻尔兹曼探索方法，使用轻量级1步前瞻奖励来更新采样概率，软性地将更新后的采样分布锚定到原始数据集比例。

Result: 在包含16个指令调优数据集的Tulu-v2混合集合上应用DynamixSFT，在10个基准测试中实现了高达2.2%的性能提升。

Conclusion: DynamixSFT提供了一种有效的动态数据集混合优化方法，既能保持数据集的多样性覆盖，又能显著提升模型性能，并通过可视化分析提供了对自适应动态的深入洞察。

Abstract: As numerous instruction-tuning datasets continue to emerge during the
post-training stage, dynamically balancing and optimizing their mixtures has
become a critical challenge. To address this, we propose DynamixSFT, a dynamic
and automated method for instruction-tuning dataset mixture optimization. We
formulate the problem as a multi-armed bandit setup and introduce a
Prior-scaled Boltzmann Exploration that softly anchors the updated sampling
distribution to the original dataset proportions, thereby preserving the
inherent diversity and coverage of the collection. Sampling probabilities are
updated using a lightweight 1-Step Look-ahead Reward, reflecting how much the
dataset contributes to improving the model's performance at its current state.
When applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning
datasets, DynamixSFT achieves up to a 2.2% performance improvement across 10
benchmarks. Furthermore, we provide a comprehensive analysis and visualizations
to offer deeper insights into the adaptive dynamics of our method.

</details>


### [280] [Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks](https://arxiv.org/abs/2508.12121)
*Lorenzo Livi*

Main category: cs.LG

TL;DR: 门控机制在RNN中隐式地产生自适应学习率行为，即使使用固定全局学习率训练时也是如此。门控不仅控制隐藏状态的记忆保留，还作为数据驱动的预处理器来调节参数空间中的优化轨迹。


<details>
  <summary>Details</summary>
Motivation: 研究门控循环神经网络中门控机制如何隐式地影响梯度下降过程中的参数更新动态，揭示门控与优化算法之间的内在联系。

Method: 通过推导泄漏积分器和门控RNN的精确雅可比矩阵，获得一阶展开式来分析门控如何重塑梯度传播、调节有效步长并引入参数更新的各向异性。

Result: 门控机制自然地产生了学习率调度、动量和自适应方法（如Adam）等优化行为，数值实验验证了扰动分析的有效性。

Conclusion: 这项工作提供了统一的动力学系统视角，解释了门控如何耦合状态演化与参数更新，阐明了门控架构在实践中实现稳健可训练性和稳定性的原因。

Abstract: We study how gating mechanisms in recurrent neural networks (RNNs) implicitly
induce adaptive learning-rate behavior, even when training is carried out with
a fixed, global learning rate. This effect arises from the coupling between
state-space time scales--parametrized by the gates--and parameter-space
dynamics during gradient descent. By deriving exact Jacobians for
leaky-integrator and gated RNNs, we obtain a first-order expansion that makes
explicit how constant, scalar, and multi-dimensional gates reshape gradient
propagation, modulate effective step sizes, and introduce anisotropy in
parameter updates. These findings reveal that gates not only control memory
retention in the hidden states, but also act as data-driven preconditioners
that adapt optimization trajectories in parameter space. We further draw formal
analogies with learning-rate schedules, momentum, and adaptive methods such as
Adam, showing that these optimization behaviors emerge naturally from gating.
Numerical experiments confirm the validity of our perturbative analysis,
supporting the view that gate-induced corrections remain small while exerting
systematic effects on training dynamics. Overall, this work provides a unified
dynamical-systems perspective on how gating couples state evolution with
parameter updates, explaining why gated architectures achieve robust
trainability and stability in practice.

</details>


### [281] [DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with Variational Autoencoders using Differential Entropy](https://arxiv.org/abs/2508.12145)
*Frederik L. Dennig,Daniel A. Keim*

Main category: cs.LG

TL;DR: DE-VAE是一种基于微分熵的不确定性感知变分自编码器，用于改进参数化和可逆投影，在处理分布外样本时表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自编码器方法在处理数据空间或嵌入空间的分布外样本时表现不佳，需要一种能够分析嵌入不确定性的改进方法。

Method: 使用微分熵的变分自编码器，学习从原始空间到2D空间的映射及其逆映射，以UMAP和t-SNE作为基线投影方法进行比较。

Result: 在四个知名数据集上的定量和定性评估表明，DE-VAE能够创建与其他当前AE方法精度相当的参数化和逆投影，同时支持嵌入不确定性分析。

Conclusion: DE-VAE成功解决了分布外样本处理问题，提供了可分析不确定性的参数化和可逆投影解决方案。

Abstract: Recently, autoencoders (AEs) have gained interest for creating parametric and
invertible projections of multidimensional data. Parametric projections make it
possible to embed new, unseen samples without recalculating the entire
projection, while invertible projections allow the synthesis of new data
instances. However, existing methods perform poorly when dealing with
out-of-distribution samples in either the data or embedding space. Thus, we
propose DE-VAE, an uncertainty-aware variational AE using differential entropy
(DE) to improve the learned parametric and invertible projections. Given a
fixed projection, we train DE-VAE to learn a mapping into 2D space and an
inverse mapping back to the original space. We conduct quantitative and
qualitative evaluations on four well-known datasets, using UMAP and t-SNE as
baseline projection methods. Our findings show that DE-VAE can create
parametric and inverse projections with comparable accuracy to other current
AE-based approaches while enabling the analysis of embedding uncertainty.

</details>


### [282] [AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis](https://arxiv.org/abs/2508.12162)
*J. M. I. H. Jayakody,A. M. H. H. Alahakoon,C. R. M. Perera,R. M. L. C. Srimal,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的深度学习模型AICRN，通过结合注意力机制和卷积残差网络来提高心电图参数回归的精确度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统心电图分析存在人为错误导致关注点失、分析效率低等问题，需要人工智能技术来提高诊断精确度和预测能力。

Method: 设计了注意力集成卷积残差网络(AICRN)，包含空间和通道注意力机制，专门处理心电图特征的类型和空间位置问题，解决梯度消失和爆炸问题。

Result: AICRN模型在心电图参数回归任务中表现超过现有模型，具有更高的精确度。

Conclusion: 深度学习在心电图分析的可解释性和精确性方面发挥关键作用，为心脏监测和管理开启了新的临床应用。

Abstract: The paradigm of electrocardiogram (ECG) analysis has evolved into real-time
digital analysis, facilitated by artificial intelligence (AI) and machine
learning (ML), which has improved the diagnostic precision and predictive
capacity of cardiac diseases. This work proposes a novel deep learning (DL)
architecture called the attention-integrated convolutional residual network
(AICRN) to regress key ECG parameters such as the PR interval, the QT interval,
the QRS duration, the heart rate, the peak amplitude of the R wave, and the
amplitude of the T wave for interpretable ECG analysis. Our architecture is
specially designed with spatial and channel attention-related mechanisms to
address the type and spatial location of the ECG features for regression. The
models employ a convolutional residual network to address vanishing and
exploding gradient problems. The designed system addresses traditional analysis
challenges, such as loss of focus due to human errors, and facilitates the fast
and easy detection of cardiac events, thereby reducing the manual efforts
required to solve analysis tasks. AICRN models outperform existing models in
parameter regression with higher precision. This work demonstrates that DL can
play a crucial role in the interpretability and precision of ECG analysis,
opening up new clinical applications for cardiac monitoring and management.

</details>


### [283] [ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression](https://arxiv.org/abs/2508.12212)
*Chuanliu Fan,Zicheng Ma,Jun Gao,Nan Yu,Jun Zhang,Ziqiang Cao,Yi Qin Gao,Guohong Fu*

Main category: cs.LG

TL;DR: ProtTeX-CC是一个轻量级的两阶段压缩框架，通过联合嵌入压缩和自压缩机制，将蛋白质输入长度减少约93.68%，显著提升ProtTeX模型在少样本学习中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决ProtTeX模型的两个主要限制：序列和结构标记拼接导致蛋白质长度加倍并破坏模态对齐；受限于训练语料和上下文窗口，无法进行上下文学习，限制了泛化能力。

Method: 1. 联合嵌入压缩机制：在残基级别融合序列和结构表示，将蛋白质输入长度减半而不损失性能；2. 自压缩模块：将完整演示聚合到最后几个语言标记的潜在空间中，将平均演示长度从751个标记减少到少于16个标记。

Result: 在16-shot设置下实现约93.68%的总提示长度压缩比。蛋白质功能预测实验显示，在域内基准上性能提升2%，在域外数据集上性能提升11%。

Conclusion: ProtTeX-CC通过轻量级的压缩框架有效解决了原模型的限制，显著提升了少样本学习性能，具有良好的泛化能力，且仅需少量额外参数。

Abstract: Recent advances in protein large language models, such as ProtTeX, represent
both side-chain amino acids and backbone structure as discrete token sequences
of residue length. While this design enables unified modeling of multimodal
protein information, it suffers from two major limitations: (1) The
concatenation of sequence and structure tokens approximately doubles the
protein length and breaks the intrinsic residue-level alignment between
modalities. (2) Constrained by the training corpus and limited context window,
ProtTeX is typically trained on single-protein inputs, rendering it
incompatible with in-context learning (ICL) and thus limiting its
generalization capability. To address these issues, we propose ProtTeX-CC, a
lightweight two-stage compression framework designed to enhance ProtTeX under
few-shot settings. We first design a joint embedding compression mechanism that
fuses sequence and structure representations at the residue level, effectively
reducing the protein input length by half without sacrificing performance. Then
we propose a self-compression module that aggregates each full demonstration
into the latent space of the last few linguistic tokens, reducing the average
demonstration length from 751 tokens to less than 16 tokens. Compared to the
original ProtTeX, our self-compression approach achieves a compression ratio of
approximately 93.68% in the total prompt length under the 16-shot setting.
Without modifying the backbone model, ProtTeX-CC introduces only a small number
of additional parameters through PEFT-based tuning in the joint embedding
compression stage and a single trainable projection layer in the
self-compression stage. Extensive experiments on protein function prediction
show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and
generalizes well to the out-of-domain dataset with a performance gain of 11%.

</details>


### [284] [Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models](https://arxiv.org/abs/2508.12220)
*Abdullah X*

Main category: cs.LG

TL;DR: 本文提出了一种针对大语言模型的确定性遗忘方法，通过记录训练过程中的关键信息，实现在不重新训练的情况下精确删除特定数据，满足GDPR被遗忘权要求。


<details>
  <summary>Details</summary>
Motivation: 随着GDPR第17条被遗忘权的实施，需要为大语言模型开发能够精确删除特定训练数据的解决方案，避免重新训练的高成本。

Method: 采用确定性训练程序，记录每个微批次的ID哈希、随机数种子、学习率值、优化器步数计数器等关键信息。通过重放训练尾部并过滤遗忘数据，实现参数级别的精确删除。

Result: 在满足前提条件的情况下，该方法能够实现模型和优化器状态的字节级完全一致，验证了机制的可行性。

Conclusion: 该方法为大规模语言模型提供了实用的遗忘解决方案，通过多种互补路径满足不同的延迟和可用性约束，具有重要的实际应用价值。

Abstract: We study the right to be forgotten (GDPR Art. 17) for large language models
and frame unlearning as a reproducible systems problem. Our approach treats
training as a deterministic program and logs a minimal per-microbatch record
(ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and
accumulation boundary). Under a pinned stack and deterministic kernels,
replaying the training tail while filtering only the forget closure yields the
same parameters as training on the retain set (bit-identical in the training
dtype) when preconditions hold. To meet latency and availability constraints,
we add complementary paths: (i) exact reverts of recent steps via
micro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion
when the base is frozen, and (iii) a curvature-guided anti-update followed by a
short retain-tune, audit-gated with escalation to exact replay. We report
storage/latency budgets and a toy artifact validating mechanics; in a
controlled run that satisfies the preconditions we demonstrate byte-identical
equality of model and optimizer states.

</details>


### [285] [Distribution Matching via Generalized Consistency Models](https://arxiv.org/abs/2508.12222)
*Sagar Shrestha,Rajesh Shrestha,Tri Nguyen,Subash Timilsina*

Main category: cs.LG

TL;DR: 基于一致性模型的新型分布匹配方法，结合了连续正则化流模型的直接范数最小化优点和GAN的灵活性


<details>
  <summary>Details</summary>
Motivation: GAN在分布匹配任务中遇到训练困难，包括双层最小最大优化目标和模式冲突问题，需要更稳定的方法

Method: 受连续正则化流(CNF)中一致性模型的启发，提出新的分布匹配方法，继承CNF的直接范数最小化优点，同时保持GAN的灵活性

Result: 通过理论验证和在合成数据集、真实数据集上的实验展示了方法的性能

Conclusion: 该方法为分布匹配任务提供了一种更稳定且灵活的解决方案，结合了CNF和GAN的优势

Abstract: Recent advancement in generative models have demonstrated remarkable
performance across various data modalities. Beyond their typical use in data
synthesis, these models play a crucial role in distribution matching tasks such
as latent variable modeling, domain translation, and domain adaptation.
Generative Adversarial Networks (GANs) have emerged as the preferred method of
distribution matching due to their efficacy in handling high-dimensional data
and their flexibility in accommodating various constraints. However, GANs often
encounter challenge in training due to their bi-level min-max optimization
objective and susceptibility to mode collapse. In this work, we propose a novel
approach for distribution matching inspired by the consistency models employed
in Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF
models, such as having a straight forward norm minimization objective, while
remaining adaptable to different constraints similar to GANs. We provide
theoretical validation of our proposed objective and demonstrate its
performance through experiments on synthetic and real-world datasets.

</details>


### [286] [Communication-Efficient Distributed Asynchronous ADMM](https://arxiv.org/abs/2508.12233)
*Sagar Shrestha*

Main category: cs.LG

TL;DR: 提出在异步ADMM中引入粗粒度量化来减少通信开销，实验验证了该方法在分布式学习任务中的收敛性


<details>
  <summary>Details</summary>
Motivation: 分布式优化和联邦学习中，异步ADMM虽然具有优势，但通信成本可能成为主要瓶颈，特别是在节点通信预算有限或数据量巨大的情况下

Method: 在异步交替方向乘子法(ADMM)中，对需要交换的数据引入粗粒度量化，以降低大规模联邦学习和分布式优化应用的通信开销

Result: 通过实验验证了该方法在多个分布式学习任务（包括神经网络）中的收敛性能

Conclusion: 粗粒度量化是减少异步ADMM通信开销的有效方法，适用于大规模分布式优化场景

Abstract: In distributed optimization and federated learning, asynchronous alternating
direction method of multipliers (ADMM) serves as an attractive option for
large-scale optimization, data privacy, straggler nodes and variety of
objective functions. However, communication costs can become a major bottleneck
when the nodes have limited communication budgets or when the data to be
communicated is prohibitively large. In this work, we propose introducing
coarse quantization to the data to be exchanged in aynchronous ADMM so as to
reduce communication overhead for large-scale federated learning and
distributed optimization applications. We experimentally verify the convergence
of the proposed method for several distributed learning tasks, including neural
networks.

</details>


### [287] [CC-Time: Cross-Model and Cross-Modality Time Series Forecasting](https://arxiv.org/abs/2508.12235)
*Peng Chen,Yihang Wang,Yang Shu,Yunyao Cheng,Kai Zhao,Zhongwen Rao,Lujia Pan,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: CC-Time是一个结合预训练语言模型和时间序列模型的跨模态跨模型学习方法，通过文本描述和时间序列数据的联合建模，在时间序列预测任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练语言模型的时间序列预测方法未能充分发挥语言模型的强大序列建模能力，预测精度不够理想。需要探索语言模型能够建模哪些时间序列特征，以及是否仅靠语言模型就足以构建时间序列模型。

Method: 提出跨模型和跨模态学习框架：1）跨模态学习：通过时间序列序列及其文本描述联合建模时间依赖性和通道相关性；2）跨模型融合：自适应整合语言模型和时间序列模型的知识，形成更全面的时间序列模式建模。

Result: 在9个真实世界数据集上的大量实验表明，CC-Time在完整数据训练和少样本学习情况下都达到了最先进的预测精度。

Conclusion: CC-Time成功证明了通过跨模态和跨模型学习，可以充分发挥预训练语言模型在时间序列预测中的潜力，显著提升预测性能。

Abstract: With the success of pre-trained language models (PLMs) in various application
fields beyond natural language processing, language models have raised emerging
attention in the field of time series forecasting (TSF) and have shown great
prospects. However, current PLM-based TSF methods still fail to achieve
satisfactory prediction accuracy matching the strong sequential modeling power
of language models. To address this issue, we propose Cross-Model and
Cross-Modality Learning with PLMs for time series forecasting (CC-Time). We
explore the potential of PLMs for time series forecasting from two aspects: 1)
what time series features could be modeled by PLMs, and 2) whether relying
solely on PLMs is sufficient for building time series models. In the first
aspect, CC-Time incorporates cross-modality learning to model temporal
dependency and channel correlations in the language model from both time series
sequences and their corresponding text descriptions. In the second aspect,
CC-Time further proposes the cross-model fusion block to adaptively integrate
knowledge from the PLMs and time series model to form a more comprehensive
modeling of time series patterns. Extensive experiments on nine real-world
datasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy
in both full-data training and few-shot learning situations.

</details>


### [288] [DHG-Bench: A Comprehensive Benchmark on Deep Hypergraph Learning](https://arxiv.org/abs/2508.12244)
*Fan Li,Xiaoyang Wang,Wenjie Zhang,Ying Zhang,Xuemin Lin*

Main category: cs.LG

TL;DR: DHG-Bench是第一个全面的深度超图学习基准，整合了20个数据集和16种最先进的超图神经网络算法，在统一的数据处理和实验协议下系统评估算法的有效性、效率、鲁棒性和公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的超图神经网络方法缺乏全面的基准测试，导致在数据集覆盖、算法性能评估和实验设置一致性方面存在障碍，阻碍了对深度超图学习进展的理解。

Method: 开发了DHG-Bench基准，整合20个多样化数据集（涵盖节点、边和图级别任务）和16种最先进的HNN算法，采用一致的数据处理和实验协议，并开发了易于使用的训练评估库。

Result: 通过广泛实验揭示了现有算法的优势和固有局限性，为未来研究提供了有价值的见解和方向。

Conclusion: DHG-Bench填补了深度超图学习领域的基准空白，通过系统性的多维评估为算法比较和未来发展提供了重要参考框架。

Abstract: Although conventional deep graph models have achieved great success in
relational learning, their focus on pairwise relationships limits their
capacity to learn pervasive higher-order interactions in real-world complex
systems, which can be naturally modeled as hypergraphs. To tackle this,
hypergraph neural networks (HNNs), the dominant approach in deep hypergraph
learning (DHGL), has garnered substantial attention in recent years. Despite
the proposal of numerous HNN methods, there is no comprehensive benchmark for
HNNs, which creates a great obstacle to understanding the progress of DHGL in
several aspects: (i) insufficient coverage of datasets, algorithms, and tasks;
(ii) a narrow evaluation of algorithm performance; and (iii) inconsistent
dataset usage, preprocessing, and experimental setups that hinder
comparability. To fill the gap, we introduce DHG-Bench, the first comprehensive
benchmark for DHGL. Specifically, DHG-Bench integrates 20 diverse datasets
spanning node-, edge-, and graph-level tasks, along with 16 state-of-the-art
HNN algorithms, under consistent data processing and experimental protocols.
Our benchmark systematically investigates the characteristics of HNNs in terms
of four dimensions: effectiveness, efficiency, robustness, and fairness.
Further, to facilitate reproducible research, we have developed an easy-to-use
library for training and evaluating different HNN methods. Extensive
experiments conducted with DHG-Bench reveal both the strengths and inherent
limitations of existing algorithms, offering valuable insights and directions
for future research. The code is publicly available at:
https://github.com/Coco-Hut/DHG-Bench.

</details>


### [289] [STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction](https://arxiv.org/abs/2508.12247)
*Haolong Chen,Liang Zhang,Zhengyuan Xin,Guangxu Zhu*

Main category: cs.LG

TL;DR: 提出了STM2和STM3两种模型来解决时空时间序列预测中的长期多尺度依赖学习问题，通过多尺度Mamba架构和自适应图因果卷积网络有效捕获复杂时空依赖关系


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法难以有效学习复杂的长期时空依赖关系，面临多尺度信息提取困难和不同节点间多尺度时间信息高度相关的挑战

Method: STM2采用多尺度Mamba架构和自适应图因果卷积网络；STM3进一步引入混合专家架构，包含更稳定的路由策略和因果对比学习策略来增强尺度区分性

Result: 在真实世界基准测试中表现出优越性能，在长期时空时间序列预测方面达到了最先进的结果

Conclusion: 提出的STM2/STM3模型能够有效解决长期时空依赖学习中的多尺度挑战，证明了其在时空时间序列预测任务中的有效性和优越性

Abstract: Recently, spatio-temporal time-series prediction has developed rapidly, yet
existing deep learning methods struggle with learning complex long-term
spatio-temporal dependencies efficiently. The long-term spatio-temporal
dependency learning brings two new challenges: 1) The long-term temporal
sequence includes multiscale information naturally which is hard to extract
efficiently; 2) The multiscale temporal information from different nodes is
highly correlated and hard to model. To address these challenges, we propose an
efficient \textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ultiscale
\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture
the multiscale information efficiently and simultaneously, and an adaptive
graph causal convolution network to learn the complex multiscale
spatio-temporal dependency. STM2 includes hierarchical information aggregation
for different-scale information that guarantees their distinguishability. To
capture diverse temporal dynamics across all spatial nodes more efficiently, we
further propose an enhanced version termed
\textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ixture of
\textbf{M}ultiscale \textbf{M}amba} (STM3) that employs a special
Mixture-of-Experts architecture, including a more stable routing strategy and a
causal contrastive learning strategy to enhance the scale distinguishability.
We prove that STM3 has much better routing smoothness and guarantees the
pattern disentanglement for each expert successfully. Extensive experiments on
real-world benchmarks demonstrate STM2/STM3's superior performance, achieving
state-of-the-art results in long-term spatio-temporal time-series prediction.

</details>


### [290] [Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset](https://arxiv.org/abs/2508.12253)
*Manish Shukla*

Main category: cs.LG

TL;DR: 这篇论文提出了一种统一的时间序列预测解释框架，结合LIME和SHAP方法来解释时间序列预测模型的决策过程。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在航空、能源等领域关键决策中至关重要，但经典ARIMA模型缺乏非线性能力，而树模型如XGBoost虽准确却不易解释。需要方法来解释高性能预测模型的决策逻辑。

Method: 将单变量时间序列转换为无泄漏的监督学习问题，训练梯度提升树模型和ARIMA基准模型，然后应用LIME和SHAP进行后解释。确保不违反时序性原则。

Result: 在Air Passengers数据集上实验显示，少数滞后特征（特别是12个月滞后）和季节性编码解释了大部分预测方差。证明了方法的有效性。

Conclusion: 论文提供了一种有效的时间序列预测解释框架，给出了理论分析、实证评估和实践指南，为实践者提供了可行的解释性方法。

Abstract: Time-series forecasting underpins critical decisions across aviation, energy,
retail and health. Classical autoregressive integrated moving average (ARIMA)
models offer interpretability via coefficients but struggle with
nonlinearities, whereas tree-based machine-learning models such as XGBoost
deliver high accuracy but are often opaque. This paper presents a unified
framework for interpreting time-series forecasts using local interpretable
model-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We
convert a univariate series into a leakage-free supervised learning problem,
train a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc
explainability. Using the Air Passengers dataset as a case study, we show that
a small set of lagged features -- particularly the twelve-month lag -- and
seasonal encodings explain most forecast variance. We contribute: (i) a
methodology for applying LIME and SHAP to time series without violating
chronology; (ii) theoretical exposition of the underlying algorithms; (iii)
empirical evaluation with extensive analysis; and (iv) guidelines for
practitioners.

</details>


### [291] [L-SR1: Learned Symmetric-Rank-One Preconditioning](https://arxiv.org/abs/2508.12270)
*Gal Lifshitz,Shahar Zuler,Ori Fouks,Dan Raviv*

Main category: cs.LG

TL;DR: 提出一种新的学习二阶优化器，通过可训练预条件单元改进经典SR1算法，在不需标注数据的情况下实现优异性能和强法化能力。


<details>
  <summary>Details</summary>
Motivation: 绘合端到端深度学习的高性能优势与经典优化方法的数据效率和轻量性优势，解决学习二阶优化方法研究不足的问题。

Method: 在SR1算法中引入可训练预条件单元，生成数据驱动的向量构建正半定矩阵，通过学习投影保证称约条件。

Result: 在分析实验和单目人体网栽恢复任务中，性能超过现有学习优化方法，具有轻量级模型和强法化能力。

Conclusion: 该方法为学习二阶优化提供了有效解决方案，适合集成到更广泛的优化框架中，且无需标注数据或微调。

Abstract: End-to-end deep learning has achieved impressive results but remains limited
by its reliance on large labeled datasets, poor generalization to unseen
scenarios, and growing computational demands. In contrast, classical
optimization methods are data-efficient and lightweight but often suffer from
slow convergence. While learned optimizers offer a promising fusion of both
worlds, most focus on first-order methods, leaving learned second-order
approaches largely unexplored.
  We propose a novel learned second-order optimizer that introduces a trainable
preconditioning unit to enhance the classical Symmetric-Rank-One (SR1)
algorithm. This unit generates data-driven vectors used to construct positive
semi-definite rank-one matrices, aligned with the secant constraint via a
learned projection. Our method is evaluated through analytic experiments and on
the real-world task of Monocular Human Mesh Recovery (HMR), where it
outperforms existing learned optimization-based approaches. Featuring a
lightweight model and requiring no annotated data or fine-tuning, our approach
offers strong generalization and is well-suited for integration into broader
optimization-based frameworks.

</details>


### [292] [CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision](https://arxiv.org/abs/2508.12278)
*Siyue Xie,Da Sun Handason Tam,Wing Cheong Lau*

Main category: cs.LG

TL;DR: CRoC是一个用于图异常检测的框架，通过上下文重构和对比学习，在标签有限的情况下有效利用未标记数据，显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 图神经网络训练需要大量标注数据，但图异常检测中异常样本稀少、标注成本高且可能存在伪装模式，这限制了GNN在GAD中的应用。

Method: 提出上下文重构对比框架CRoC：1）利用类别不平衡重构节点上下文，保持交互模式的同时重组属性；2）分别编码异质关系并整合到消息传递中；3）结合对比学习范式联合利用有限标注和大量未标注数据。

Result: 在7个真实世界GAD数据集上的实验表明，CRoC相比基线GNN提升高达14%的AUC，在有限标签设置下优于最先进的GAD方法。

Conclusion: CRoC通过上下文重构和对比学习有效解决了图异常检测中标签稀缺的问题，能够捕获复杂交互语义并抵抗对抗性伪装，显著提升了检测性能。

Abstract: Graph Neural Networks (GNNs) are widely used as the engine for various
graph-related tasks, with their effectiveness in analyzing graph-structured
data. However, training robust GNNs often demands abundant labeled data, which
is a critical bottleneck in real-world applications. This limitation severely
impedes progress in Graph Anomaly Detection (GAD), where anomalies are
inherently rare, costly to label, and may actively camouflage their patterns to
evade detection. To address these problems, we propose Context Refactoring
Contrast (CRoC), a simple yet effective framework that trains GNNs for GAD by
jointly leveraging limited labeled and abundant unlabeled data. Different from
previous works, CRoC exploits the class imbalance inherent in GAD to refactor
the context of each node, which builds augmented graphs by recomposing the
attributes of nodes while preserving their interaction patterns. Furthermore,
CRoC encodes heterogeneous relations separately and integrates them into the
message-passing process, enhancing the model's capacity to capture complex
interaction semantics. These operations preserve node semantics while
encouraging robustness to adversarial camouflage, enabling GNNs to uncover
intricate anomalous cases. In the training stage, CRoC is further integrated
with the contrastive learning paradigm. This allows GNNs to effectively harness
unlabeled data during joint training, producing richer, more discriminative
node embeddings. CRoC is evaluated on seven real-world GAD datasets with
varying scales. Extensive experiments demonstrate that CRoC achieves up to 14%
AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods
under limited-label settings.

</details>


### [293] [Convergence Analysis of the Lion Optimizer in Centralized and Distributed Settings](https://arxiv.org/abs/2508.12327)
*Wei Jiang,Lijun Zhang*

Main category: cs.LG

TL;DR: 这篇论文分析了Lion优化器的收敛性能，包括标准版本、方差缩减版本和分布式设置中的通信高效变种。获得了不同的收敛速率结果。


<details>
  <summary>Details</summary>
Motivation: 分析Lion优化器的收敛性能，并通过方差缩减和分布式设计来改善其收敛速率，特别是在大规模问题中的表现。

Method: 采用理论分析方法，首先证明标准Lion优化器的收敛速率，然后引入方差缩减技术来提升性能，最后在分布式设置中使用符号压缩来减少通信开销。

Result: 标准Lion: Ω(d^{1/2}T^{-1/4})
方差缩减Lion: Ω(d^{1/2}T^{-1/3})
分布式Lion: Ω(d^{1/2}(nT)^{-1/4}) 和 Ω(d^{1/2}(nT)^{-1/3})
通信高效变种: Ω(max{d^{1/4}/T^{1/4}, d^{1/10}/(n^{1/5}T^{1/5})) 和 Ω(d^{1/4}/T^{1/4})

Conclusion: Lion优化器在各种设置下都能实现理论上的收敛性，通过方差缩减和通信压缩技术可以显著提升其性能，特别是在分布式环境中。

Abstract: In this paper, we analyze the convergence properties of the Lion optimizer.
First, we establish that the Lion optimizer attains a convergence rate of
$\mathcal{O}(d^{1/2}T^{-1/4})$ under standard assumptions, where $d$ denotes
the problem dimension and $T$ is the iteration number. To further improve this
rate, we introduce the Lion optimizer with variance reduction, resulting in an
enhanced convergence rate of $\mathcal{O}(d^{1/2}T^{-1/3})$. We then analyze in
distributed settings, where the standard and variance reduced version of the
distributed Lion can obtain the convergence rates of
$\mathcal{O}(d^{1/2}(nT)^{-1/4})$ and $\mathcal{O}(d^{1/2}(nT)^{-1/3})$, with
$n$ denoting the number of nodes. Furthermore, we investigate a
communication-efficient variant of the distributed Lion that ensures sign
compression in both communication directions. By employing the unbiased sign
operations, the proposed Lion variant and its variance reduction counterpart,
achieve convergence rates of $\mathcal{O}\left( \max
\left\{\frac{d^{1/4}}{T^{1/4}}, \frac{d^{1/10}}{n^{1/5}T^{1/5}} \right\}
\right)$ and $\mathcal{O}\left( \frac{d^{1/4}}{T^{1/4}} \right)$, respectively.

</details>


### [294] [Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models](https://arxiv.org/abs/2508.12361)
*Xun Su,Jianming Huang,Yang Yusen,Zhongxi Fang,Hiroyuki Kasai*

Main category: cs.LG

TL;DR: 通过推出漏斗调度和适应温度策略，解决了在模态搜索中插机与利用的两难问题，在不增加计算成本的情况下显著提升了模型生成质量


<details>
  <summary>Details</summary>
Motivation: 将语言模型中成功的推理时缩放技术适配到涵盛模型中，解决当前顺序蒙特卡洛方法在模态搜索中遇到的插机与利用两难问题

Method: 提出了两种简单有效的策略：Funnel Schedule（逐渐减少维持的粒子数量）和Adaptive Temperature（适应地调整早期奖励的影响权重）

Result: 在多个标准测试集和最新文本到图像涵盛模型上进行实验，结果显示该方法在不增加噪声函数评估次数的情况下，显著提升了样本质量，效果超过了之前的基线方法

Conclusion: 通过针对涵盛模型的生成动态和相变行为进行简单但有效的策略调整，成功解决了模态搜索中的插机与利用两难问题，为涵盛模型的推理时缩放提供了有效的解决方案

Abstract: Inference-time scaling has achieved remarkable success in language models,
yet its adaptation to diffusion models remains underexplored. We observe that
the efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems
from globally fitting the The reward-tilted distribution, which inherently
preserves diversity during multi-modal search. However, current applications of
SMC to diffusion models face a fundamental dilemma: early-stage noise samples
offer high potential for improvement but are difficult to evaluate accurately,
whereas late-stage samples can be reliably assessed but are largely
irreversible. To address this exploration-exploitation trade-off, we approach
the problem from the perspective of the search algorithm and propose two
strategies: Funnel Schedule and Adaptive Temperature. These simple yet
effective methods are tailored to the unique generation dynamics and
phase-transition behavior of diffusion models. By progressively reducing the
number of maintained particles and down-weighting the influence of early-stage
rewards, our methods significantly enhance sample quality without increasing
the total number of Noise Function Evaluations. Experimental results on
multiple benchmarks and state-of-the-art text-to-image diffusion models
demonstrate that our approach outperforms previous baselines.

</details>


### [295] [Bi-Axial Transformers: Addressing the Increasing Complexity of EHR Classification](https://arxiv.org/abs/2508.12418)
*Rachael DeVries,Casper Christensen,Marie Lisandra Zepeda Mendoza,Ole Winther*

Main category: cs.LG

TL;DR: 提出了Bi-Axial Transformer (BAT)模型，通过同时关注临床变量和时间轴来处理电子健康记录数据，在脓毒症预测和死亡率分类任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录(EHRs)数据日益复杂，包含更大的数据集、更长的时间序列和多模态集成。传统Transformer在处理EHR分类时受限于数据表示方式，无法有效处理数据稀疏性和信息缺失问题。

Method: 开发了双向轴Transformer(BAT)模型，同时关注临床变量轴和时间点轴，学习更丰富的数据关系，解决数据稀疏性困难。模型能够学习独特的传感器嵌入，可用于迁移学习。

Result: BAT在脓毒症预测任务上达到最先进性能，在死亡率分类任务上与顶级方法竞争。相比其他Transformer模型，BAT对数据缺失具有更强的鲁棒性。

Conclusion: BAT模型通过双向注意力机制有效处理EHR数据的复杂性和稀疏性，为EHR分析提供了新的解决方案，所有基线模型已用PyTorch重新实现并开源供复现和基准测试。

Abstract: Electronic Health Records (EHRs), the digital representation of a patient's
medical history, are a valuable resource for epidemiological and clinical
research. They are also becoming increasingly complex, with recent trends
indicating larger datasets, longer time series, and multi-modal integrations.
Transformers, which have rapidly gained popularity due to their success in
natural language processing and other domains, are well-suited to address these
challenges due to their ability to model long-range dependencies and process
data in parallel. But their application to EHR classification remains limited
by data representations, which can reduce performance or fail to capture
informative missingness. In this paper, we present the Bi-Axial Transformer
(BAT), which attends to both the clinical variable and time point axes of EHR
data to learn richer data relationships and address the difficulties of data
sparsity. BAT achieves state-of-the-art performance on sepsis prediction and is
competitive to top methods for mortality classification. In comparison to other
transformers, BAT demonstrates increased robustness to data missingness, and
learns unique sensor embeddings which can be used in transfer learning.
Baseline models, which were previously located across multiple repositories or
utilized deprecated libraries, were re-implemented with PyTorch and made
available for reproduction and future benchmarking.

</details>


### [296] [Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings via Geometric Features](https://arxiv.org/abs/2508.12440)
*Ahmet Bilal Arıkan,Şener Özönder,Mustafa Taha Koçyiğit,Hüseyin Oktay Altun,H. Kübra Küçükkartal,Murat Arslanoğlu,Fatih Çağırankaya,Berk Ayvaz*

Main category: cs.LG

TL;DR: 基于机器学习的制造成本估算框架，直接从2D工程图中提取几何特征，达到10%的平均绝对百分比误差


<details>
  <summary>Details</summary>
Motivation: 改变传统面向过程规划的劳动密集型成本报价流程，缩短报价周期，提供一致透明的成本评估

Method: 从13,684份汽车悬挂和转向部件DWG图纸中提取200个几何和统计描述符，使用梯度提升决策树模型(XGBoost, CatBoost, LightGBM)进行训练

Result: 在24个产品组中实现了近10%的平均绝对百分比误差，显示了超越部件特定经验法则的稳健扩展性

Conclusion: 该端到端CAD到成本流水线缩短了报价周期，为工业4.0制造环境中实时ERP集成的决策支持提供了可部署的途径

Abstract: We present an integrated machine learning framework that transforms how
manufacturing cost is estimated from 2D engineering drawings. Unlike
traditional quotation workflows that require labor-intensive process planning,
our approach about 200 geometric and statistical descriptors directly from
13,684 DWG drawings of automotive suspension and steering parts spanning 24
product groups. Gradient-boosted decision tree models (XGBoost, CatBoost,
LightGBM) trained on these features achieve nearly 10% mean absolute percentage
error across groups, demonstrating robust scalability beyond part-specific
heuristics. By coupling cost prediction with explainability tools such as SHAP,
the framework identifies geometric design drivers including rotated dimension
maxima, arc statistics and divergence metrics, offering actionable insights for
cost-aware design. This end-to-end CAD-to-cost pipeline shortens quotation lead
times, ensures consistent and transparent cost assessments across part families
and provides a deployable pathway toward real-time, ERP-integrated decision
support in Industry 4.0 manufacturing environments.

</details>


### [297] [Local Cluster Cardinality Estimation for Adaptive Mean Shift](https://arxiv.org/abs/2508.12450)
*Étienne Pepin*

Main category: cs.LG

TL;DR: 这篇论文提出了一种适用于具有变化局部规模和聚类数量的数据集的自适应性均倾算法。算法利用局部距离分布估计聚类数量，并根据此动态调整带宽和内核半径阈值，在性能上超过了最近提出的自适应性均倾方法。


<details>
  <summary>Details</summary>
Motivation: 传统的核密度估计方法只能提供聚类局部区域的见解，而无法全局地描述整个聚类的参数。需要一种能够处理不同局部规模和聚类数量的自适应性聚类算法。

Method: 算法通过分析点到其他所有点的局部距离分布，识别距离密度分布中的局部最小值来估计局部聚类的数量。根据这些估计计算局部聚类参数，并在均倾执行过程中使用聚类数量估计来自适应地调整带宽和内核半径阈值。

Result: 该算法在原始数据集上超过了最近提出的自适应性均倾方法，并在更广泛的聚类性能测试中表现出竞争力。

Conclusion: 该自适应性均倾算法通过利用局部距离分布来估计聚类数量，能够有效地处理具有变化局部规模和聚类数量的数据集，为聚类分析提供了更加准确和自适应的解决方案。

Abstract: This article presents an adaptive mean shift algorithm designed for datasets
with varying local scale and cluster cardinality. Local distance distributions,
from a point to all others, are used to estimate the cardinality of the local
cluster by identifying a local minimum in the density of the distance
distribution. Based on these cardinality estimates, local cluster parameters
are then computed for the entire cluster in contrast to KDE-based methods,
which provide insight only into localized regions of the cluster. During the
mean shift execution, the cluster cardinality estimate is used to adaptively
adjust the bandwidth and the mean shift kernel radius threshold. Our algorithm
outperformed a recently proposed adaptive mean shift method on its original
dataset and demonstrated competitive performance on a broader clustering
benchmark.

</details>


### [298] [Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX](https://arxiv.org/abs/2508.12485)
*Aayush Gupta,Arpit Bhayani*

Main category: cs.LG

TL;DR: Cold-RL是一个基于强化学习的NGINX缓存淘汰策略，使用Dueling Deep Q-Network在500微秒预算内决策，相比传统LRU策略在25MB缓存下命中率提升146%，在100MB缓存下提升15%。


<details>
  <summary>Details</summary>
Motivation: 传统LRU缓存淘汰策略对对象大小不敏感，在周期性突发流量和混合对象大小场景下容易产生抖动问题，需要更智能的淘汰机制。

Method: 使用离线训练的Dueling Deep Q-Network，通过ONNX侧车服务，在每次淘汰时从K个最近最少使用对象中提取6个轻量级特征（年龄、大小、命中次数、到达间隔时间、剩余TTL、最后源站RTT），生成受害者位掩码，500微秒超时后回退到原生LRU。

Result: 在25MB缓存下，命中率从0.1436提升到0.3538（146%提升）；在100MB缓存下，从0.7530提升到0.8675（15%提升）；在400MB缓存下与传统方法相当（约0.918）。推理增加不到2%的CPU开销，95%分位淘汰延迟在预算内。

Conclusion: Cold-RL是首个集成到NGINX中具有严格SLO的强化学习淘汰策略，在中小缓存场景下显著提升命中率，同时保持低延迟和低开销。

Abstract: Web proxies such as NGINX commonly rely on least-recently-used (LRU)
eviction, which is size agnostic and can thrash under periodic bursts and mixed
object sizes. We introduce Cold-RL, a learned eviction policy for NGINX that
replaces LRU's forced-expire path with a dueling Deep Q-Network served by an
ONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL
samples the K least-recently-used objects, extracts six lightweight features
(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),
and requests a bitmask of victims; a hard timeout of 500 microseconds triggers
immediate fallback to native LRU. Policies are trained offline by replaying
NGINX access logs through a cache simulator with a simple reward: a retained
object earns one point if it is hit again before TTL expiry. We compare against
LRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial
workloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,
a 146 percent improvement over the best classical baseline; at 100 MB, from
0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods
(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th
percentile eviction latency within budget. To our knowledge, this is the first
reinforcement learning eviction policy integrated into NGINX with strict SLOs.

</details>


### [299] [Cost-Aware Contrastive Routing for LLMs](https://arxiv.org/abs/2508.12491)
*Reza Shirkavand,Shangqian Gao,Peiran Yu,Heng Huang*

Main category: cs.LG

TL;DR: CSCR是一个轻量级框架，通过将提示和模型映射到共享嵌入空间，实现快速、成本敏感的LLM路由选择，在多个基准测试中比基线方法提升25%的准确率-成本权衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在忽略提示特定上下文、依赖昂贵的模型分析、假设固定专家集合或使用低效试错策略等问题，需要一种更高效的LLM路由方案。

Method: 使用紧凑的logit足迹表示开源模型，困惑度指纹表示黑盒API，通过对比编码器训练选择成本带内最便宜的准确专家，推理时通过FAISS索引进行单次k-NN查找。

Result: 在多个基准测试中持续优于基线方法，准确率-成本权衡提升高达25%，对未见过的LLM和分布外提示具有强泛化能力。

Conclusion: CSCR提供了一个高效、轻量级的解决方案，能够在微秒级延迟下实现成本敏感的LLM路由，且专家池变化时无需重新训练。

Abstract: We study cost-aware routing for large language models across diverse and
dynamic pools of models. Existing approaches often overlook prompt-specific
context, rely on expensive model profiling, assume a fixed set of experts, or
use inefficient trial-and-error strategies. We introduce Cost-Spectrum
Contrastive Routing (CSCR), a lightweight framework that maps both prompts and
models into a shared embedding space to enable fast, cost-sensitive selection.
CSCR uses compact, fast-to-compute logit footprints for open-source models and
perplexity fingerprints for black-box APIs. A contrastive encoder is trained to
favor the cheapest accurate expert within adaptive cost bands. At inference
time, routing reduces to a single k-NN lookup via a FAISS index, requiring no
retraining when the expert pool changes and enabling microsecond latency.
Across multiple benchmarks, CSCR consistently outperforms baselines, improving
the accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen
LLMs and out-of-distribution prompts.

</details>


### [300] [Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference](https://arxiv.org/abs/2508.12511)
*Denis Blessing,Julius Berner,Lorenz Richter,Carles Domingo-Enrich,Yuanqi Du,Arash Vahdat,Gerhard Neumann*

Main category: cs.LG

TL;DR: 提出基于信任区域的迭代优化方法，通过几何退火策略逐步逼近目标路径空间测度，显著提升随机最优控制问题的求解性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的优化方法在处理目标测度与先验差异较大的随机最优控制问题时面临挑战，需要更有效的优化策略。

Method: 采用迭代约束优化方法，引入信任区域机制，通过几何退火从先验测度逐步逼近目标测度，并基于信任区域原则性地选择退火路径的时间步长。

Result: 在多个最优控制应用中表现出显著性能提升，包括扩散采样、过渡路径采样和扩散模型微调等任务。

Conclusion: 基于信任区域的几何退火方法为解决目标测度与先验差异大的随机最优控制问题提供了有效且系统化的解决方案。

Abstract: Solving stochastic optimal control problems with quadratic control costs can
be viewed as approximating a target path space measure, e.g. via gradient-based
optimization. In practice, however, this optimization is challenging in
particular if the target measure differs substantially from the prior. In this
work, we therefore approach the problem by iteratively solving constrained
problems incorporating trust regions that aim for approaching the target
measure gradually in a systematic way. It turns out that this trust region
based strategy can be understood as a geometric annealing from the prior to the
target measure, where, however, the incorporated trust regions lead to a
principled and educated way of choosing the time steps in the annealing path.
We demonstrate in multiple optimal control applications that our novel method
can improve performance significantly, including tasks in diffusion-based
sampling, transition path sampling, and fine-tuning of diffusion models.

</details>


### [301] [Results of the NeurIPS 2023 Neural MMO Competition on Multi-task Reinforcement Learning](https://arxiv.org/abs/2508.12524)
*Joseph Suárez,Kyoung Whan Choe,David Bloomin,Jianming Gao,Yunkun Li,Yao Feng,Saidinesh Pola,Kun Zhang,Yonghui Zhu,Nikhil Pinnaparaju,Hao Xiang Li,Nishaanth Kanna,Daniel Scott,Ryan Sullivan,Rose S. Shuman,Lucas de Alcântara,Herbie Bradley,Kirsty You,Bo Wu,Yuhao Jiang,Qimai Li,Jiaxin Chen,Louis Castricato,Xiaolong Zhu,Phillip Isola*

Main category: cs.LG

TL;DR: NeurIPS 2023 Neural MMO竞赛吸引了200多名参与者，参赛者训练的目标条件策略能够泛化到训练中未见过的任务、地图和对手。最佳解决方案在单张4090 GPU上训练8小时后，得分比基线高4倍。所有相关内容均已开源。


<details>
  <summary>Details</summary>
Motivation: 举办Neural MMO竞赛旨在推动强化学习智能体在复杂多智能体环境中的泛化能力研究，探索目标条件策略在未见过的任务、地图和对手上的表现。

Method: 参赛者使用目标条件策略训练方法，在Neural MMO环境中进行训练，要求策略能够适应训练期间未见过的任务配置、地图布局和对手行为。

Result: 竞赛吸引了200多名参与者，最佳解决方案在单张4090 GPU上训练8小时后，得分达到基线水平的4倍，显示出优异的泛化性能。

Conclusion: Neural MMO竞赛成功展示了目标条件策略在多智能体环境中的强大泛化能力，开源所有资源将为社区提供宝贵的研究基础，推动该领域的进一步发展。

Abstract: We present the results of the NeurIPS 2023 Neural MMO Competition, which
attracted over 200 participants and submissions. Participants trained
goal-conditional policies that generalize to tasks, maps, and opponents never
seen during training. The top solution achieved a score 4x higher than our
baseline within 8 hours of training on a single 4090 GPU. We open-source
everything relating to Neural MMO and the competition under the MIT license,
including the policy weights and training code for our baseline and for the top
submissions.

</details>


### [302] [Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs](https://arxiv.org/abs/2508.12530)
*Hyunsoo Song,Seungwhan Kim,Seungkyu Lee*

Main category: cs.LG

TL;DR: 通过提出局部后验冲突概念和潜在重建损失，解决VAE后验冲突问题，无需网络结构限制


<details>
  <summary>Details</summary>
Motivation: 解决VAE模型中的后验冲突问题，该问题会降低生成样本的多样性，但现有方法需要结构限制

Method: 定义局部后验冲突概念，提出Latent Reconstruction(LR)损失函数，基于注射函数和复合函数的数学性质

Result: 在MNIST、fashionMNIST、Omniglot、CelebA和FFHQ等多个数据集上验证了方法的有效性，能够控制后验冲突

Conclusion: 新方法能够在不受网络结构限制的情况下有效控制VAE的后验冲突问题

Abstract: Variational autoencoders (VAEs), one of the most widely used generative
models, are known to suffer from posterior collapse, a phenomenon that reduces
the diversity of generated samples. To avoid posterior collapse, many prior
works have tried to control the influence of regularization loss. However, the
trade-off between reconstruction and regularization is not satisfactory. For
this reason, several methods have been proposed to guarantee latent
identifiability, which is the key to avoiding posterior collapse. However, they
require structural constraints on the network architecture. For further
clarification, we define local posterior collapse to reflect the importance of
individual sample points in the data space and to relax the network constraint.
Then, we propose Latent Reconstruction(LR) loss, which is inspired by
mathematical properties of injective and composite functions, to control
posterior collapse without restriction to a specific architecture. We
experimentally evaluate our approach, which controls posterior collapse on
varied datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ.

</details>


### [303] [Rethinking Safety in LLM Fine-tuning: An Optimization Perspective](https://arxiv.org/abs/2508.12531)
*Minseon Kim,Jin Myung Kwak,Lama Alssum,Bernard Ghanem,Philip Torr,David Krueger,Fazl Barez,Adel Bibi*

Main category: cs.LG

TL;DR: 通过系统性调优训练超参数和采用EMA动量技术，可以在细调语言模型时保持安全性而无需额外安全措施，将有害响应从16%降至约5%。


<details>
  <summary>Details</summary>
Motivation: 证义语言模型细调必然会損害安全性的传统观点，寻找更有效的方法在保持模型性能的同时维护安全性。

Method: 通过系统性测试选择关键训练超参数（学习率、批处理大小、梯度步长），并提出指数移动平均(EMA)动量技术来创建稳定的优化路径。

Result: 在Llama模型家族上的实验显示，有害响应率从16%显著降至约5%，同时保持了模型的实用性能力，超越了需要额外安全数据的现有方法。

Conclusion: 细调过程中的安全问题可以通过合理的优化选择大幅避免，无需专门应对措施，为维护模型性能和安全性提供了实用指南。

Abstract: Fine-tuning language models is commonly believed to inevitably harm their
safety, i.e., refusing to respond to harmful user requests, even when using
harmless datasets, thus requiring additional safety measures. We challenge this
belief through systematic testing, showing that poor optimization choices,
rather than inherent trade-offs, often cause safety problems, measured as
harmful responses to adversarial prompts. By properly selecting key training
hyper-parameters, e.g., learning rate, batch size, and gradient steps, we
reduce unsafe model responses from 16\% to approximately 5\%, as measured by
keyword matching, while maintaining utility performance. Based on this
observation, we propose a simple exponential moving average (EMA) momentum
technique in parameter space that preserves safety performance by creating a
stable optimization path and retains the original pre-trained model's safety
properties. Our experiments on the Llama families across multiple datasets
(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can
largely be avoided without specialized interventions, outperforming existing
approaches that require additional safety data while offering practical
guidelines for maintaining both model performance and safety during adaptation.

</details>


### [304] [Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction](https://arxiv.org/abs/2508.12533)
*Qinwen Ge,Roza G. Bayrak,Anwar Said,Catie Chang,Xenofon Koutsoukos,Tyler Derr*

Main category: cs.LG

TL;DR: 这篇论文从数据中心AI角度系统性地定义和测试了大脑图构建的设计空间，通过三个阶段的组合选择显著提升了神经影像分析的下游分类性能。


<details>
  <summary>Details</summary>
Motivation: 当前的大脑图构建管道多依赖固定流程，忽视了数据中心的关键选择对图机器学习性能的重要影响。

Method: 将设计空间组织为三个阶段：时序信号处理、拓扑提取和图特征化，研究了高振幅BOLD信号筛波、连接性稀疏化策略、替代相关指标和多视图节点特征等技术组合。

Result: 在HCP1200和ABIDE数据集上的实验显示，经过思考的数据中心配置持续提高了分类准确性，超过了标准流程。

Conclusion: 上游数据决策在图基神经影像中具有关键作用，系统性探索数据中心设计空间对提升性能至关重要。

Abstract: The construction of brain graphs from functional Magnetic Resonance Imaging
(fMRI) data plays a crucial role in enabling graph machine learning for
neuroimaging. However, current practices often rely on rigid pipelines that
overlook critical data-centric choices in how brain graphs are constructed. In
this work, we adopt a Data-Centric AI perspective and systematically define and
benchmark a data-centric design space for brain graph construction,
constrasting with primarily model-centric prior work. We organize this design
space into three stages: temporal signal processing, topology extraction, and
graph featurization. Our contributions lie less in novel components and more in
evaluating how combinations of existing and modified techniques influence
downstream performance. Specifically, we study high-amplitude BOLD signal
filtering, sparsification and unification strategies for connectivity,
alternative correlation metrics, and multi-view node and edge features, such as
incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets
show that thoughtful data-centric configurations consistently improve
classification accuracy over standard pipelines. These findings highlight the
critical role of upstream data decisions and underscore the importance of
systematically exploring the data-centric design space for graph-based
neuroimaging. Our code is available at
https://github.com/GeQinwen/DataCentricBrainGraphs.

</details>


### [305] [OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning](https://arxiv.org/abs/2508.12551)
*Hongyu Lin,Yuchen Li,Haoran Luo,Kaichun Yao,Libo Zhang,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: OS-R1是一个基于规则强化学习的Linux内核调优框架，使用LLM进行高效探索，通过两阶段训练实现快速收敛，性能提升达5.6%


<details>
  <summary>Details</summary>
Motivation: 现有Linux内核调优方法在效率、可扩展性和泛化性方面存在挑战，需要更智能的自动化调优解决方案

Method: 将内核配置空间抽象为RL环境，使用LLM进行配置修改，设计定制奖励函数，采用两阶段训练过程加速收敛

Result: 显著优于现有基线方法，性能提升达5.6%，保持高数据效率，在不同实际应用中表现出良好适应性

Conclusion: OS-R1框架具有实际部署潜力，能够有效解决Linux内核调优的挑战，代码和数据集已开源

Abstract: Linux kernel tuning is essential for optimizing operating system (OS)
performance. However, existing methods often face challenges in terms of
efficiency, scalability, and generalization. This paper introduces OS-R1, an
agentic Linux kernel tuning framework powered by rule-based reinforcement
learning (RL). By abstracting the kernel configuration space as an RL
environment, OS-R1 facilitates efficient exploration by large language models
(LLMs) and ensures accurate configuration modifications. Additionally, custom
reward functions are designed to enhance reasoning standardization,
configuration modification accuracy, and system performance awareness of the
LLMs. Furthermore, we propose a two-phase training process that accelerates
convergence and minimizes retraining across diverse tuning scenarios.
Experimental results show that OS-R1 significantly outperforms existing
baseline methods, achieving up to 5.6% performance improvement over heuristic
tuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across
various real-world applications, demonstrating its potential for practical
deployment in diverse environments. Our dataset and code are publicly available
at https://github.com/LHY-24/OS-R1.

</details>


### [306] [Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement](https://arxiv.org/abs/2508.12555)
*Junpeng Wang,Yuzhong Chen,Menghai Pan,Chin-Chia Michael Yeh,Mahashweta Das*

Main category: cs.LG

TL;DR: 提出了一种视觉分析系统，用于改善对基于LLM的编码代理行为的审查和调整。系统支持代码、过程和LLM三个级别的比较分析，通过案例研究验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 当前的手动检查方式效率低下，难以跟踪代码迭代过程、比较不同解决方案和识别改进机会，需要更有效的工具来分析编码代理的行为。

Method: 设计了一种视觉分析系统，重点关注AIDE框架，支持三个级别的比较分析：代码级分析、过程级分析和LLM级分析。

Result: 通过Kaggle竞赛案例研究验证，系统能够提供有价值的洞察，帮助ML科学家更有效地调试和进行提示工程。

Conclusion: 该视觉分析系统能够提供结构化的视角来理解编码代理的行为，为迭代式编码过程提供了价值较大的洞察，有助于提高调试和提示工程的效果。

Abstract: Coding agents powered by large language models (LLMs) have gained traction
for automating code generation through iterative problem-solving with minimal
human involvement. Despite the emergence of various frameworks, e.g.,
LangChain, AutoML, and AIDE, ML scientists still struggle to effectively review
and adjust the agents' coding process. The current approach of manually
inspecting individual outputs is inefficient, making it difficult to track code
evolution, compare coding iterations, and identify improvement opportunities.
To address this challenge, we introduce a visual analytics system designed to
enhance the examination of coding agent behaviors. Focusing on the AIDE
framework, our system supports comparative analysis across three levels: (1)
Code-Level Analysis, which reveals how the agent debugs and refines its code
over iterations; (2) Process-Level Analysis, which contrasts different
solution-seeking processes explored by the agent; and (3) LLM-Level Analysis,
which highlights variations in coding behavior across different LLMs. By
integrating these perspectives, our system enables ML scientists to gain a
structured understanding of agent behaviors, facilitating more effective
debugging and prompt engineering. Through case studies using coding agents to
tackle popular Kaggle competitions, we demonstrate how our system provides
valuable insights into the iterative coding process.

</details>


### [307] [Deep Learning-Based Financial Time Series Forecasting via Sliding Window and Variational Mode Decomposition](https://arxiv.org/abs/2508.12565)
*Luke Li*

Main category: cs.LG

TL;DR: 基于VMD分解和LSTM的深度学习模型，通过滑动窗口技术处理金融时间序列，提高股票价格预测的准确性和稳定性


<details>
  <summary>Details</summary>
Motivation: 金融时间序列具有高度非稳定性和复杂性，传统预测模型面临挑战，需要有效处理这些特性以提高预测性能

Method: 使用滑动窗口技术构建数据集，利用变分模态分解(VMD)将非稳定金融时间序列分解为更平滑的子组件，然后将分解后的数据输入LSTM深度学习模型进行预测

Result: 与使用原始时间序列的LSTM模型相比，基于VMD处理的模型显示出更好的预测效果和更高的稳定性

Conclusion: 结合VMD分解技术和深度学习模型的方法能够有效提升金融时间序列预测的性能，VMD分解能够明显改善模型对复杂金融数据的适应能力

Abstract: To address the complexity of financial time series, this paper proposes a
forecasting model combining sliding window and variational mode decomposition
(VMD) methods. Historical stock prices and relevant market indicators are used
to construct datasets. VMD decomposes non-stationary financial time series into
smoother subcomponents, improving model adaptability. The decomposed data is
then input into a deep learning model for prediction. The study compares the
forecasting effects of an LSTM model trained on VMD-processed sequences with
those using raw time series, demonstrating better performance and stability.

</details>


### [308] [Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems](https://arxiv.org/abs/2508.12569)
*Quercus Hernandez,Max Win,Thomas C. O'Connor,Paulo E. Arratia,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种基于度量-辛括号形式的多尺度系统粗粒化机器学习框架，能够保持热力学定律、动量守恒和涨落耗散平衡，并通过自监督学习识别涌现结构变量。


<details>
  <summary>Details</summary>
Motivation: 多尺度系统模拟具有挑战性，粗粒化过程中信息损失导致涌现物理具有耗散性、历史依赖性和随机性，需要开发能够保持这些特性的机器学习方法。

Method: 使用度量-辛括号形式构建框架，保证热力学第一和第二定律、动量守恒和涨落耗散平衡，采用自监督学习策略识别涌现结构变量，并在PyTorch和LAMMPS中实现。

Result: 在基准系统和两个挑战性示例（星形聚合物粗粒化和胶体悬浮液高速视频分析）上验证了方法的有效性，能够保持非平衡统计特性。

Conclusion: 该框架为多尺度系统的粗粒化模拟提供了有效的机器学习解决方案，能够保持关键的物理特性，并具有可扩展性。

Abstract: Multiscale systems are ubiquitous in science and technology, but are
notoriously challenging to simulate as short spatiotemporal scales must be
appropriately linked to emergent bulk physics. When expensive high-dimensional
dynamical systems are coarse-grained into low-dimensional models, the entropic
loss of information leads to emergent physics which are dissipative,
history-dependent, and stochastic. To machine learn coarse-grained dynamics
from time-series observations of particle trajectories, we propose a framework
using the metriplectic bracket formalism that preserves these properties by
construction; most notably, the framework guarantees discrete notions of the
first and second laws of thermodynamics, conservation of momentum, and a
discrete fluctuation-dissipation balance crucial for capturing non-equilibrium
statistics. We introduce the mathematical framework abstractly before
specializing to a particle discretization. As labels are generally unavailable
for entropic state variables, we introduce a novel self-supervised learning
strategy to identify emergent structural variables. We validate the method on
benchmark systems and demonstrate its utility on two challenging examples: (1)
coarse-graining star polymers at challenging levels of coarse-graining while
preserving non-equilibrium statistics, and (2) learning models from high-speed
video of colloidal suspensions that capture coupling between local
rearrangement events and emergent stochastic dynamics. We provide open-source
implementations in both PyTorch and LAMMPS, enabling large-scale inference and
extensibility to diverse particle-based systems.

</details>


### [309] [Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM](https://arxiv.org/abs/2508.12575)
*Zohra Yagoub,Hafida Bouziane*

Main category: cs.LG

TL;DR: 使用预训练蛋白质大语言模型提取序列上下文特征，结合双向LSTM和GRU预测淀粉样蛋白区域，准确率达到84.5%


<details>
  <summary>Details</summary>
Motivation: 现有淀粉样蛋白预测方法主要基于进化基序和氨基酸个体特性，而基于序列信息的特征显示出更高的预测性能，因此探索大语言模型在淀粉样蛋白预测中的应用

Method: 利用预训练蛋白质大语言模型提取蛋白质序列的上下文特征，采用双向LSTM和GRU神经网络架构进行淀粉样区域的预测

Result: 在10折交叉验证中达到84.5%的准确率，在测试数据集上达到83%的准确率，表现出竞争性的性能

Conclusion: 大语言模型在提高淀粉样蛋白预测准确性方面具有巨大潜力，为生物信息学领域提供了新的有效方法

Abstract: The prediction of amyloidogenicity in peptides and proteins remains a focal
point of ongoing bioinformatics. The crucial step in this field is to apply
advanced computational methodologies. Many recent approaches to predicting
amyloidogenicity within proteins are highly based on evolutionary motifs and
the individual properties of amino acids. It is becoming increasingly evident
that the sequence information-based features show high predictive performance.
Consequently, our study evaluated the contextual features of protein sequences
obtained from a pretrained protein large language model leveraging
bidirectional LSTM and GRU to predict amyloidogenic regions in peptide and
protein sequences. Our method achieved an accuracy of 84.5% on 10-fold
cross-validation and an accuracy of 83% in the test dataset. Our results
demonstrate competitive performance, highlighting the potential of LLMs in
enhancing the accuracy of amyloid prediction.

</details>


### [310] [Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg](https://arxiv.org/abs/2508.12576)
*Like Jian,Dong Liu*

Main category: cs.LG

TL;DR: 论文证明在过参数化的联邦学习中，随着神经网络宽度增加，数据异构性的影响会减弱，无限宽度时FedAvg能达到与集中式学习相同的泛化性能


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中数据非独立同分布带来的挑战，分析FedAvg在过参数化神经网络中的收敛性和泛化性能

Method: 理论分析过参数化FedAvg与梯度下降的收敛性，证明网络宽度增加时数据异构性影响减弱，无限宽度时模型表现为线性模型

Result: 理论证明和大量实验验证：网络宽度增加时数据异构性影响减小，无限宽度时FedAvg达到与集中式学习相同的泛化性能

Conclusion: 过参数化是解决联邦学习中数据异构性问题的有效方法，无限宽度神经网络能消除数据分布差异的影响

Abstract: Federated learning (FL) enables decentralized clients to train a model
collaboratively without sharing local data. A key distinction between FL and
centralized learning is that clients' data are non-independent and identically
distributed, which poses significant challenges in training a global model that
generalizes well across heterogeneous local data distributions. In this paper,
we analyze the convergence of overparameterized FedAvg with gradient descent
(GD). We prove that the impact of data heterogeneity diminishes as the width of
neural networks increases, ultimately vanishing when the width approaches
infinity. In the infinite-width regime, we further prove that both the global
and local models in FedAvg behave as linear models, and that FedAvg achieves
the same generalization performance as centralized learning with the same
number of GD iterations. Extensive experiments validate our theoretical
findings across various network architectures, loss functions, and optimization
methods.

</details>


### [311] [Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding](https://arxiv.org/abs/2508.12590)
*Jihoon Park,Seungeun Oh,Seong-Lyun Kim*

Main category: cs.LG

TL;DR: 通过令牌级判断机制，基于认知不确定性和关注重要性，只上传信息量高的令牌到云端，在保持准确性的同时大幅节省能消和通信成本


<details>
  <summary>Details</summary>
Motivation: 解决资源受限环境中轻量级本地模型与云端LLM的混合推理问题，当前研究太过关注准确性和延迟，忽视了通信和能消效率

Method: 提出令牌级过滤机制，结合认知不确定性和关注重要性来判断哪些令牌需要上传到云端处理，只上传信息量高的重要令牌

Result: 在TinyLlama-1.1B和LLaMA-2-7B上进行实验，达到87.5%的BERT Score，令牌通过率0.37个/秒，相比标准HLM节省40.7%能消，相比之前的U-HLM基线在准确性、能消节省和通过率方面都有显著提升

Conclusion: 该方法能够在带宽受限的边缘环境中实现能效高、准确的LLM部署，通过减少不必要的云端LLM使用和通信交互来优化性能

Abstract: To address the growing demand for on-device LLM inference in
resource-constrained environments, hybrid language models (HLM) have emerged,
combining lightweight local models with powerful cloud-based LLMs. Recent
studies on HLM have primarily focused on improving accuracy and latency, while
often overlooking communication and energy efficiency. We propose a token-level
filtering mechanism for an energy-efficient importance- and uncertainty-aware
HLM inference that leverages both epistemic uncertainty and attention-based
importance. Our method opportunistically uploads only informative tokens,
reducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and
LLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and
token throughput of 0.37 tokens/sec while saving the energy consumption by
40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM
baseline, our method improves BERTScore from 85.8% to 87.0%, energy savings
from 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an
energy-efficient and accurate deployment of LLMs in bandwidth-constrained edge
environments.

</details>


### [312] [Physics-informed deep operator network for traffic state estimation](https://arxiv.org/abs/2508.12593)
*Zhihao Li,Ting Wang,Guojian Zou,Ruofei Wang,Ye Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理信息深度算子网络(PI-DeepONet)的交通状态估计框架，将TSE重新表述为算子学习问题，通过将交通流守恒定律直接集成到算子学习过程中，在NGSIM数据集上表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络(PINNs)逐点强制执行PDE约束，但交通状态估计本质上涉及从有限噪声测量中求解高维时空偏微分方程，需要更有效的物理约束集成方法。

Method: 采用PI-DeepONet框架，训练参数化神经算子将稀疏输入数据映射到完整的时空交通状态场，直接将交通流守恒模型和基本图集成到算子学习过程中。

Result: 在NGSIM数据集上的实验表明，该方法在性能上优于最先进的基线方法，能够有效捕捉拥堵传播、空间相关性和时间演化。

Conclusion: PI-DeepONet框架通过将物理约束直接集成到算子学习中，确保了物理一致性，同时提供了对最优函数生成策略和分支网络复杂性的深入见解，展现了所提出框架的鲁棒性和有效性。

Abstract: Traffic state estimation (TSE) fundamentally involves solving
high-dimensional spatiotemporal partial differential equations (PDEs) governing
traffic flow dynamics from limited, noisy measurements. While Physics-Informed
Neural Networks (PINNs) enforce PDE constraints point-wise, this paper adopts a
physics-informed deep operator network (PI-DeepONet) framework that
reformulates TSE as an operator learning problem. Our approach trains a
parameterized neural operator that maps sparse input data to the full
spatiotemporal traffic state field, governed by the traffic flow conservation
law. Crucially, unlike PINNs that enforce PDE constraints point-wise,
PI-DeepONet integrates traffic flow conservation model and the fundamental
diagram directly into the operator learning process, ensuring physical
consistency while capturing congestion propagation, spatial correlations, and
temporal evolution. Experiments on the NGSIM dataset demonstrate superior
performance over state-of-the-art baselines. Further analysis reveals insights
into optimal function generation strategies and branch network complexity.
Additionally, the impact of input function generation methods and the number of
functions on model performance is explored, highlighting the robustness and
efficacy of proposed framework.

</details>


### [313] [FLARE: Fast Low-rank Attention Routing Engine](https://arxiv.org/abs/2508.12594)
*Vedant Puri,Aditya Joglekar,Kevin Ferguson,Yu-hsuan Chen,Yongjie Jessica Zhang,Levent Burak Kara*

Main category: cs.LG

TL;DR: FLARE是一种线性复杂度的自注意力机制，通过固定长度的潜在序列路由注意力，解决了传统自注意力二次复杂度的问题，在大型非结构化网格上实现了更好的可扩展性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统自注意力机制的二次计算复杂度限制了其在大规模非结构化网格上的应用和可扩展性，需要一种更高效的注意力机制来处理大规模问题。

Method: FLARE通过可学习的查询令牌将输入序列投影到固定长度的潜在序列（M << N），在瓶颈序列上路由注意力，学习低秩形式的注意力，实现O(NM)的计算成本。

Result: FLARE不仅能够扩展到前所未有的问题规模，而且在各种基准测试中相比最先进的神经PDE代理模型提供了更优越的准确性。

Conclusion: FLARE通过低秩注意力路由机制成功解决了自注意力的计算复杂度问题，为大规模非结构化网格处理提供了高效的解决方案，并发布了新的增材制造数据集以促进进一步研究。

Abstract: The quadratic complexity of self-attention limits its applicability and
scalability on large unstructured meshes. We introduce Fast Low-rank Attention
Routing Engine (FLARE), a linear complexity self-attention mechanism that
routes attention through fixed-length latent sequences. Each attention head
performs global communication among $N$ tokens by projecting the input sequence
onto a fixed length latent sequence of $M \ll N$ tokens using learnable query
tokens. By routing attention through a bottleneck sequence, FLARE learns a
low-rank form of attention that can be applied at $O(NM)$ cost. FLARE not only
scales to unprecedented problem sizes, but also delivers superior accuracy
compared to state-of-the-art neural PDE surrogates across diverse benchmarks.
We also release a new additive manufacturing dataset to spur further research.
Our code is available at https://github.com/vpuri3/FLARE.py.

</details>


### [314] [Constructing Invariant and Equivariant Operations by Symmetric Tensor Network](https://arxiv.org/abs/2508.12596)
*Meng Zhang,Chao Wang,Hao Zhang,Shaojun Dong,Lixin He*

Main category: cs.LG

TL;DR: 提出了一种系统性的方法来构建不变和等变操作，能够处理不同秩的笛卡尔张量和不同类型球张量，并利用对称张量网络图形表示简化证明和构造，应用于几何图神经网络和材料本构定律学习。


<details>
  <summary>Details</summary>
Motivation: 在几何深度学习中，设计包含对称性的神经网络至关重要，核心是开发不变和等变操作。需要系统的方法来处理不同类型的张量输入输出。

Method: 提出系统性的不变和等变操作构造方法，使用对称张量网络图形表示来简化证明和构造过程，支持不同秩的笛卡尔张量和不同类型球张量。

Result: 成功构建了有效的不变和等变操作，图形表示简化了相关函数的证明和构造，并成功应用于几何图神经网络的等变交互消息和材料本构定律学习的等变机器学习模型。

Conclusion: 该方法为几何深度学习提供了系统的不变和等变操作构造框架，图形表示工具显著简化了相关工作，在实际应用中表现出良好效果。

Abstract: Design of neural networks that incorporate symmetry is crucial for geometric
deep learning. Central to this effort is the development of invariant and
equivariant operations. This works presents a systematic method for
constructing valid invariant and equivariant operations. It can handle inputs
and outputs in the form of Cartesian tensors with different rank, as well as
spherical tensors with different types. In addition, our method features a
graphical representation utilizing the symmetric tensor network, which
simplifies both the proofs and constructions related to invariant and
equivariant functions. We also apply this approach to design the equivariant
interaction message for the geometry graph neural network, and equivariant
machine learning model to learn the constitutive law of materials.

</details>


### [315] [A Hybrid Surrogate for Electric Vehicle Parameter Estimation and Power Consumption via Physics-Informed Neural Operators](https://arxiv.org/abs/2508.12602)
*Hansol Lim,Jongseong Brad Choi,Jee Won Lee,Haeseong Jeoung,Minkyu Han*

Main category: cs.LG

TL;DR: 一种结合希某神经网络运算符和可微物理模块的混合代理模型，从速度和加速度估计电动汽车参数和能消耗，达到了高精度和良好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了从简单的速度和加速度数据中准确估计电动汽车的多个关键参数，包括效率、阻力、质量等，并通过物理嵌入方式预测能消耗，提高模型的可解释性和通用性。

Method: 采用新颖的Spectral Parameter Operator架构（基于Fourier Neural Operator背景）获取全局上下文，结合可微分物理模块进行前向传播。从速度和加速度输入，输出时变的电机效率、制动回收效率、气动阻力、滚动阻力、有效质量和辅助功率等参数。

Result: 在Tesla Model 3、Tesla Model S和Kia EV9的实际数据上评估，Tesla车型平均绝对误差为0.2kW（约高速行驶拉力功率的1%），Kia EV9为0.8kW。模型具有良好的可解释性和通用性，能够适应未见条件和采样率。

Conclusion: 该混合代理模型框架通过结合神经网络和物理知识，能够从简单数据中提取有物理意义的参数，为路径优化、绿色路由、车载诊断和健康管理等应用提供了实用的解决方案。

Abstract: We present a hybrid surrogate model for electric vehicle parameter estimation
and power consumption. We combine our novel architecture Spectral Parameter
Operator built on a Fourier Neural Operator backbone for global context and a
differentiable physics module in the forward pass. From speed and acceleration
alone, it outputs time-varying motor and regenerative braking efficiencies, as
well as aerodynamic drag, rolling resistance, effective mass, and auxiliary
power. These parameters drive a physics-embedded estimate of battery power,
eliminating any separate physics-residual loss. The modular design lets
representations converge to physically meaningful parameters that reflect the
current state and condition of the vehicle. We evaluate on real-world logs from
a Tesla Model 3, Tesla Model S, and the Kia EV9. The surrogate achieves a mean
absolute error of 0.2kW (about 1% of average traction power at highway speeds)
for Tesla vehicles and about 0.8kW on the Kia EV9. The framework is
interpretable, and it generalizes well to unseen conditions, and sampling
rates, making it practical for path optimization, eco-routing, on-board
diagnostics, and prognostics health management.

</details>


### [316] [SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression](https://arxiv.org/abs/2508.12604)
*Yuyang Xu,Yi Cheng,Haochao Ying,Zhuoyun Du,Renjun Hu,Xing Shi,Wei Lin,Jian Wu*

Main category: cs.LG

TL;DR: SSPO是一种无需辅助模型或人工标注的RL过程监督框架，通过模型自生成的步进偏好信号来优化推理步骤，有效减少过思考行为并保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有后训练方法（如带CoT推理的RL）存在计算开销大和过思考问题，错误答案部分源于冗长推理过程缺乏自我修正能力。

Method: 提出Self-traced Step-wise Preference Optimization (SSPO)，利用模型自生成的步进偏好信号进行细粒度推理步骤优化，无需辅助模型或步进人工标注。

Result: 实验表明SSPO生成的推理序列既准确又简洁，有效缓解过思考行为，在不同领域和语言中均不损害模型性能。

Conclusion: SSPO提供了一个可插拔的RL过程监督框架，能够实现推理压缩的细粒度优化，解决了现有方法计算开销大和过思考的问题。

Abstract: Test-time scaling has proven effective in further enhancing the performance
of pretrained Large Language Models (LLMs). However, mainstream post-training
methods (i.e., reinforcement learning (RL) with chain-of-thought (CoT)
reasoning) often incur substantial computational overhead due to auxiliary
models and overthinking. In this paper, we empirically reveal that the
incorrect answers partially stem from verbose reasoning processes lacking
correct self-fix, where errors accumulate across multiple reasoning steps. To
this end, we propose Self-traced Step-wise Preference Optimization (SSPO), a
pluggable RL process supervision framework that enables fine-grained
optimization of each reasoning step. Specifically, SSPO requires neither
auxiliary models nor stepwise manual annotations. Instead, it leverages
step-wise preference signals generated by the model itself to guide the
optimization process for reasoning compression. Experiments demonstrate that
the generated reasoning sequences from SSPO are both accurate and succinct,
effectively mitigating overthinking behaviors without compromising model
performance across diverse domains and languages.

</details>


### [317] [How can we trust opaque systems? Criteria for robust explanations in XAI](https://arxiv.org/abs/2508.12623)
*Florian J. Boge,Annika Schuster*

Main category: cs.LG

TL;DR: 这篇论文提出了解释性人工智能(XAI)方法的两个重要稳健性标准：解释稳健性(ER)和解释方法稳健性(EMR)，以确保深度学习算法的可信赖性。


<details>
  <summary>Details</summary>
Motivation: 深度学习算法预测准确但内部运作不透明，当前XAI方法在解释可靠性方面存在疑惑，需要更严格的稳健性标准来确保解释的真实性。

Method: 提出并形式化了解释稳健性(ER)和解释方法稳健性(EMR)两个标准框架，具体包括形式化定义和评估方法。

Result: 建立了一个完整的可信赖XAI解释框架，能够更有效地评估和确保深度学习算法解释的真实性和可靠性。

Conclusion: 单个XAI方法的稳健性不足以保证可靠性，必须同时满足ER和EMR两个标准。该框架为建立对DL算法的信任提供了理论基础和实践指南。

Abstract: Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in
scientific research. However, the price we pay for their impressively accurate
predictions is significant: their inner workings are notoriously opaque - it is
unknown to laypeople and researchers alike what features of the data a DL
system focuses on and how it ultimately succeeds in predicting correct outputs.
A necessary criterion for trustworthy explanations is that they should reflect
the relevant processes the algorithms' predictions are based on. The field of
eXplainable Artificial Intelligence (XAI) presents promising methods to create
such explanations. But recent reviews about their performance offer reasons for
skepticism. As we will argue, a good criterion for trustworthiness is
explanatory robustness: different XAI methods produce the same explanations in
comparable contexts. However, in some instances, all methods may give the same,
but still wrong, explanation. We therefore argue that in addition to
explanatory robustness (ER), a prior requirement of explanation method
robustness (EMR) has to be fulfilled by every XAI method. Conversely, the
robustness of an individual method is in itself insufficient for
trustworthiness. In what follows, we develop and formalize criteria for ER as
well as EMR, providing a framework for explaining and establishing trust in DL
algorithms. We also highlight interesting application cases and outline
directions for future work.

</details>


### [318] [FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation](https://arxiv.org/abs/2508.12629)
*Ian Dunn,David R. Koes*

Main category: cs.LG

TL;DR: FlowMol3是一个开源的多模态流匹配模型，通过三种架构无关的技术（自条件、假原子和训练时几何扭曲）显著提升了全原子小分子生成性能，实现了近100%的分子有效性，且参数量比同类方法少一个数量级。


<details>
  <summary>Details</summary>
Motivation: 开发能够生成具有所需性质的逼真分子的生成模型，可以加速化学发现。现有模型在联合采样分子拓扑和3D结构方面仍有改进空间。

Method: 基于流匹配的生成模型，采用三种低成本技术：自条件（self-conditioning）、假原子（fake atoms）和训练时几何扭曲（train-time geometry distortion），无需改变图神经网络架构或流匹配公式。

Result: 实现了近100%的药物类分子有效性，更准确地复现了训练数据的功能团组成和几何结构，参数量比同类方法少一个数量级。

Conclusion: 这些技术缓解了基于传输的生成模型的普遍病理问题，能够在推理过程中检测和纠正分布漂移，为改进扩散和流基分子生成模型的稳定性和质量提供了简单可转移的策略。

Abstract: A generative model capable of sampling realistic molecules with desired
properties could accelerate chemical discovery across a wide range of
applications. Toward this goal, significant effort has focused on developing
models that jointly sample molecular topology and 3D structure. We present
FlowMol3, an open-source, multi-modal flow matching model that advances the
state of the art for all-atom, small-molecule generation. Its substantial
performance gains over previous FlowMol versions are achieved without changes
to the graph neural network architecture or the underlying flow matching
formulation. Instead, FlowMol3's improvements arise from three
architecture-agnostic techniques that incur negligible computational cost:
self-conditioning, fake atoms, and train-time geometry distortion. FlowMol3
achieves nearly 100% molecular validity for drug-like molecules with explicit
hydrogens, more accurately reproduces the functional group composition and
geometry of its training data, and does so with an order of magnitude fewer
learnable parameters than comparable methods. We hypothesize that these
techniques mitigate a general pathology affecting transport-based generative
models, enabling detection and correction of distribution drift during
inference. Our results highlight simple, transferable strategies for improving
the stability and quality of diffusion- and flow-based molecular generative
models.

</details>


### [319] [Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery](https://arxiv.org/abs/2508.12650)
*Jiyeon Kang,Songseong Kim,Chanhui Lee,Doyeong Hwang,Joanie Hayoun Chung,Yunkyung Ko,Sumin Lee,Sungwoong Kim,Sungbin Lim*

Main category: cs.LG

TL;DR: SciNO是一种基于分数匹配的因果发现方法，通过神经网络算子稳定估计Hessian对角线，解决了现有方法计算开销大和数值不稳定的问题，在合成和真实数据集上相比DiffAN分别减少了42.7%和31.5%的排序差异，同时保持了内存效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于排序的因果发现方法在加性噪声模型假设下需要准确估计对数密度的Hessian对角线，但传统方法使用Stein梯度估计器计算成本高且内存密集，而DiffAN方法虽然用扩散模型替代但仍存在数值不稳定问题。

Method: 提出了Score-informed Neural Operator (SciNO)，一种在平滑函数空间中的概率生成模型，旨在稳定近似Hessian对角线并在分数建模过程中保持结构信息。还提出了概率控制算法，将SciNO的概率估计与自回归模型先验结合。

Result: 实验结果显示，SciNO在合成图上平均减少42.7%的排序差异，在真实世界数据集上减少31.5%的排序差异，同时保持内存效率和可扩展性。该方法还能增强LLMs的因果推理能力，无需额外微调或提示工程。

Conclusion: SciNO方法有效解决了现有因果排序方法的计算和稳定性问题，通过神经网络算子实现了更稳定和高效的Hessian对角线估计，为因果发现提供了更可靠的解决方案，并能与大型语言模型结合提升因果推理能力。

Abstract: Ordering-based approaches to causal discovery identify topological orders of
causal graphs, providing scalable alternatives to combinatorial search methods.
Under the Additive Noise Model (ANM) assumption, recent causal ordering methods
based on score matching require an accurate estimation of the Hessian diagonal
of the log-densities. However, previous approaches mainly use Stein gradient
estimators, which are computationally expensive and memory-intensive. Although
DiffAN addresses these limitations by substituting kernel-based estimates with
diffusion models, it remains numerically unstable due to the second-order
derivatives of score models. To alleviate these problems, we propose
Score-informed Neural Operator (SciNO), a probabilistic generative model in
smooth function spaces designed to stably approximate the Hessian diagonal and
to preserve structural information during the score modeling. Empirical results
show that SciNO reduces order divergence by 42.7% on synthetic graphs and by
31.5% on real-world datasets on average compared to DiffAN, while maintaining
memory efficiency and scalability. Furthermore, we propose a probabilistic
control algorithm for causal reasoning with autoregressive models that
integrates SciNO's probability estimates with autoregressive model priors,
enabling reliable data-driven causal ordering informed by semantic information.
Consequently, the proposed method enhances causal reasoning abilities of LLMs
without additional fine-tuning or prompt engineering.

</details>


### [320] [Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering](https://arxiv.org/abs/2508.12672)
*Emmanouil Kritharakis,Dusan Jakovetic,Antonios Makris,Konstantinos Tserpes*

Main category: cs.LG

TL;DR: 这篇论文提出了一种在对抗希拉攻击的联邦学习场景下的稳健算法，仅需服务器和一个客户端是可靠的，无需预知恶意客户端数量


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中遇到希拉攻击时的稳健性问题，特别是在服务器拥有可靠侧数据集的情况下

Method: 利用服务器的可靠侧数据集来评估客户端提交的模型更新，仅需服务器和一个客户端是可靠的

Result: 理论分析证明在强希拉攻击下仍有界的最优性间隔，实验结果显示在MNIST、FMNIST和CIFAR-10数据集上显著超过Mean、Trimmed Mean、Median、Krum等基线方法

Conclusion: 该方法能够有效对抗多种希拉攻击策略，在仅有两个可靠参与者的情况下供提供稳健的联邦学习能力

Abstract: Federated Learning (FL) enables collaborative model training across multiple
clients without sharing private data. We consider FL scenarios wherein FL
clients are subject to adversarial (Byzantine) attacks, while the FL server is
trusted (honest) and has a trustworthy side dataset. This may correspond to,
e.g., cases where the server possesses trusted data prior to federation, or to
the presence of a trusted client that temporarily assumes the server role. Our
approach requires only two honest participants, i.e., the server and one
client, to function effectively, without prior knowledge of the number of
malicious clients. Theoretical analysis demonstrates bounded optimality gaps
even under strong Byzantine attacks. Experimental results show that our
algorithm significantly outperforms standard and robust FL baselines such as
Mean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack
strategies including label flipping, sign flipping, and Gaussian noise addition
across MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework.

</details>


### [321] [Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach](https://arxiv.org/abs/2508.12673)
*Yuhao Zhou,Jindi Lv,Yuxin Tian,Dan Si,Qing Ye,Jiancheng Lv*

Main category: cs.LG

TL;DR: HyperFedZero是一个新颖的联邦学习方法，通过超网络动态生成针对非参与客户端的专用模型，解决了数据异构性和资源约束问题


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在处理数据异构性方面取得进展，但无法泛化到具有域内分布偏移和资源约束的非参与客户端

Method: 使用基于分布感知嵌入的超网络动态生成专用模型，采用NoisyEmbed增强的提取器和平衡惩罚来防止特征崩溃，分块生成模型以适应不同数据分布

Result: 在多个数据集和模型上的实验显示，HyperFedZero性能显著优于竞争方法，计算、存储和通信开销最小，消融研究验证了各组件的必要性

Conclusion: HyperFedZero通过分布感知的归纳偏置和高效模型生成机制，有效解决了联邦学习中非参与客户端的泛化问题

Abstract: Federated Learning (FL) has emerged as a promising paradigm for
privacy-preserving collaborative learning, yet data heterogeneity remains a
critical challenge. While existing methods achieve progress in addressing data
heterogeneity for participating clients, they fail to generalize to
non-participating clients with in-domain distribution shifts and resource
constraints. To mitigate this issue, we present HyperFedZero, a novel method
that dynamically generates specialized models via a hypernetwork conditioned on
distribution-aware embeddings. Our approach explicitly incorporates
distribution-aware inductive biases into the model's forward pass, extracting
robust distribution embeddings using a NoisyEmbed-enhanced extractor with a
Balancing Penalty, effectively preventing feature collapse. The hypernetwork
then leverages these embeddings to generate specialized models chunk-by-chunk
for non-participating clients, ensuring adaptability to their unique data
distributions. Extensive experiments on multiple datasets and models
demonstrate HyperFedZero's remarkable performance, surpassing competing methods
consistently with minimal computational, storage, and communication overhead.
Moreover, ablation studies and visualizations further validate the necessity of
each component, confirming meaningful adaptations and validating the
effectiveness of HyperFedZero.

</details>


### [322] [BUILDA: A Thermal Building Data Generation Framework for Transfer Learning](https://arxiv.org/abs/2508.12703)
*Thomas Krug,Fabian Raisch,Dominik Aimer,Markus Wirnsberger,Ferdinand Sigg,Benjamin Schäfer,Benjamin Tischler*

Main category: cs.LG

TL;DR: BuilDa是一个热建筑数据生成框架，无需深厚建筑模拟知识即可生成大量高质量合成数据，用于迁移学习研究


<details>
  <summary>Details</summary>
Motivation: 当前缺乏足够质量和数量的热建筑数据来支持迁移学习研究，现有数据生成方法需要建筑模拟专业知识

Method: 使用单区域Modelica模型导出为功能模拟单元(FMU)，在Python中进行模拟来生成合成数据

Result: 成功生成数据并用于预训练和微调迁移学习模型

Conclusion: BuilDa框架能够有效解决热建筑数据短缺问题，为迁移学习研究提供充足的数据支持

Abstract: Transfer learning (TL) can improve data-driven modeling of building thermal
dynamics. Therefore, many new TL research areas emerge in the field, such as
selecting the right source model for TL. However, these research directions
require massive amounts of thermal building data which is lacking presently.
Neither public datasets nor existing data generators meet the needs of TL
research in terms of data quality and quantity. Moreover, existing data
generation approaches typically require expert knowledge in building
simulation. We present BuilDa, a thermal building data generation framework for
producing synthetic data of adequate quality and quantity for TL research. The
framework does not require profound building simulation knowledge to generate
large volumes of data. BuilDa uses a single-zone Modelica model that is
exported as a Functional Mock-up Unit (FMU) and simulated in Python. We
demonstrate BuilDa by generating data and utilizing it for pretraining and
fine-tuning TL models.

</details>


### [323] [Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs](https://arxiv.org/abs/2508.12712)
*Seyed Mahdi Haji Seyed Hossein,Alireza Hosseini,Soheil Hajian Manesh,Amirali Shahriary*

Main category: cs.LG

TL;DR: 提出用于交通标志检测的联邦学习框架，通过分散式训练保护隐私，评估不同配置对性能的影响


<details>
  <summary>Details</summary>
Motivation: 解决联网自动驾驶车辆传感器数据的隐私和通信挑战，避免集中式机器学习需要共享原始数据的问题

Method: 使用轻量级目标检测器进行专业化本地训练，通过FedProx、FedAdam和FedAVG等算法聚合模型参数，在Flower框架模拟环境中测试不同配置

Result: 增加服务器轮次从2到20可将准确率从0.1以下提升至0.8以上；适度本地轮次(8-10)达到约0.67准确率；更高客户端参与度提升泛化能力至0.83；FedProx在处理异构性方面表现最佳

Conclusion: 联邦学习方法为实际车辆部署提供了可扩展的隐私保护解决方案，可指导未来鲁棒聚合和通信优化的集成，推动智能交通系统发展

Abstract: Connected and automated vehicles generate vast amounts of sensor data daily,
raising significant privacy and communication challenges for centralized
machine learning approaches in perception tasks. This study presents a
decentralized, federated learning framework tailored for traffic sign detection
in vehicular networks to enable collaborative model training without sharing
raw data. The framework partitioned traffic sign classes across vehicles for
specialized local training using lightweight object detectors, aggregated model
parameters via algorithms like FedProx, FedAdam and FedAVG in a simulated
environment with the Flower framework, and evaluated multiple configurations
including varying server rounds, local epochs, client participation fractions,
and data distributions. Experiments demonstrated that increasing server rounds
from 2 to 20 boosted accuracy from below 0.1 to over 0.8, moderate local epochs
(8-10) provided optimal efficiency with accuracies around 0.67, higher client
participation fractions enhanced generalization up to 0.83, FedProx
outperformed other aggregators in handling heterogeneity, non-IID data
distributions reduced performance compared to IID, and training duration
primarily scaled with the number of rounds rather than aggregation strategy. We
conclude that this federated approach may offer a scalable, privacy-preserving
solution for real-world vehicular deployments, potentially guiding future
integrations of robust aggregation and communication optimizations to advance
intelligent transportation systems.

</details>


### [324] [FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment](https://arxiv.org/abs/2508.12727)
*Manning Zhu,Songtao Guo,Pengzhan Zhou,Yansong Ning,Chang Han,Dewen Qiao*

Main category: cs.LG

TL;DR: FedSODA是一个资源高效的联邦微调框架，通过层剪枝和蒸馏对齐技术，在保持模型性能的同时显著降低通信、存储和计算开销。


<details>
  <summary>Details</summary>
Motivation: 联邦微调在资源受限客户端上存在计算和内存需求高的问题，限制了其发展潜力。需要一种无需访问或存储完整模型的解决方案。

Method: 提出相似性组剪枝(SGP)模块剪枝冗余层，保留关键层；引入协调蒸馏对齐(ODA)模块减少子模型与完整模型间的梯度差异；使用QLoRA技术部署量化子模型并微调轻量适配器。

Result: 平均减少70.6%通信开销，降低75.6%存储使用，任务准确率提升3.1%。

Conclusion: FedSODA在资源约束下具有高度实用性，适用于实际的联邦微调应用。

Abstract: Federated fine-tuning (FFT) of large language models (LLMs) has recently
emerged as a promising solution to enable domain-specific adaptation while
preserving data privacy. Despite its benefits, FFT on resource-constrained
clients relies on the high computational and memory demands of full-model
fine-tuning, which limits the potential advancement. This paper presents
FedSODA, a resource-efficient FFT framework that enables clients to adapt LLMs
without accessing or storing the full model. Specifically, we first propose a
similarity group pruning (SGP) module, which prunes redundant layers from the
full LLM while retaining the most critical layers to preserve the model
performance. Moreover, we introduce an orchestrated distillation alignment
(ODA) module to reduce gradient divergence between the sub-LLM and the full LLM
during FFT. Through the use of the QLoRA, clients only need to deploy quantized
sub-LLMs and fine-tune lightweight adapters, significantly reducing local
resource requirements. We conduct extensive experiments on three open-source
LLMs across a variety of downstream tasks. The experimental results demonstrate
that FedSODA reduces communication overhead by an average of 70.6%, decreases
storage usage by 75.6%, and improves task accuracy by 3.1%, making it highly
suitable for practical FFT applications under resource constraints.

</details>


### [325] [FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models](https://arxiv.org/abs/2508.12740)
*Beomseok Seo,Kichang Lee,JaeYeon Park*

Main category: cs.LG

TL;DR: FedUNet是一个轻量级的联邦学习框架，通过U-Net风格的附加模块实现异构模型间的知识共享，仅需共享紧凑的瓶颈层，在低通信开销下达到93%的准确率


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习要求客户端模型架构一致的限制，适应现实世界中设备异构的环境

Method: 在每个客户端的主干网络上附加U-Net风格的模块，通过编码器-解码器结构和跳跃连接捕获多尺度特征，仅共享紧凑的瓶颈层进行知识传输

Result: 在VGG变体上达到93.11%准确率，轻量版达到92.68%准确率，通信开销仅0.89MB

Conclusion: FedUNet提供了一种架构无关的联邦学习解决方案，能够在保持高性能的同时显著降低通信成本，适用于异构设备环境

Abstract: Federated learning (FL) enables decentralized model training without sharing
local data. However, most existing methods assume identical model architectures
across clients, limiting their applicability in heterogeneous real-world
environments. To address this, we propose FedUNet, a lightweight and
architecture-agnostic FL framework that attaches a U-Net-inspired additive
module to each client's backbone. By sharing only the compact bottleneck of the
U-Net, FedUNet enables efficient knowledge transfer without structural
alignment. The encoder-decoder design and skip connections in the U-Net help
capture both low-level and high-level features, facilitating the extraction of
clientinvariant representations. This enables cooperative learning between the
backbone and the additive module with minimal communication cost. Experiment
with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in
compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low
communication overhead.

</details>


### [326] [A Multi-Resolution Benchmark Framework for Spatial Reasoning Assessment in Neural Networks](https://arxiv.org/abs/2508.12741)
*Manuela Imbriani,Gina Belmonte,Mieke Massink,Alessandro Tofani,Vincenzo Ciancia*

Main category: cs.LG

TL;DR: 这篇论文提出了一个系统性评估神经网络空间推理能力的基准框架，重点关注形态学属性如连通性和距离关系，并发现神经网络在基本几何和拓扑理解任务中存在系统性失败。


<details>
  <summary>Details</summary>
Motivation: 为了系统性地评估神经网络的空间推理能力，特别是在形态学属性如连通性和距离关系方面的表现，以识别其局限性并为改进提供基础。

Method: 使用VoxLogicA空间模型检查器生成两类合成数据集：迷宫连通问题用于拓扑分析，空间距离计算任务用于几何理解。通过自动化流水线进行标准化训练、跨验证、推理和评估，使用Dice系数和IoU指标进行综合分析。

Result: 初步实验结果显示神经网络在空间推理能力方面遇到重大挑战，在基本几何和拓扑理解任务中出现系统性失败，显示了其在空间理解方面的局限性。

Conclusion: 该框架提供了可复现的实验协议，能够识别具体的局限性。这些局限性可以通过结合神经网络与符号推理方法的混合方案来解决，以改善临床应用中的空间理解能力，为进一步研究神经网络空间推理的局限性和潜在解决方案奠定了基础。

Abstract: This paper presents preliminary results in the definition of a comprehensive
benchmark framework designed to systematically evaluate spatial reasoning
capabilities in neural networks, with a particular focus on morphological
properties such as connectivity and distance relationships. The framework is
currently being used to study the capabilities of nnU-Net, exploiting the
spatial model checker VoxLogicA to generate two distinct categories of
synthetic datasets: maze connectivity problems for topological analysis and
spatial distance computation tasks for geometric understanding. Each category
is evaluated across multiple resolutions to assess scalability and
generalization properties. The automated pipeline encompasses a complete
machine learning workflow including: synthetic dataset generation, standardized
training with cross-validation, inference execution, and comprehensive
evaluation using Dice coefficient and IoU (Intersection over Union) metrics.
Preliminary experimental results demonstrate significant challenges in neural
network spatial reasoning capabilities, revealing systematic failures in basic
geometric and topological understanding tasks. The framework provides a
reproducible experimental protocol, enabling researchers to identify specific
limitations. Such limitations could be addressed through hybrid approaches
combining neural networks with symbolic reasoning methods for improved spatial
understanding in clinical applications, establishing a foundation for ongoing
research into neural network spatial reasoning limitations and potential
solutions.

</details>


### [327] [Constrained Centroid Clustering: A Novel Approach for Compact and Structured Partitioning](https://arxiv.org/abs/2508.12758)
*Sowmini Devi Veeramachaneni,Ramamurthy Garimella*

Main category: cs.LG

TL;DR: CCC是一种约束型聚类方法，通过限制簇中心到最远点的最大距离来控制簇的扩散，在保持可解释性的同时获得更紧凑的聚类结果。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法如K-means和GMM无法有效控制簇的扩散程度，需要一种能够约束簇内最大距离的方法来获得更结构化的聚类结果。

Method: 使用拉格朗日公式推导出闭式解，在经典基于中心的聚类基础上增加最大距离约束，控制簇的径向扩散同时保持角度结构。

Result: 在合成环形数据上的实验表明，CCC通过减少径向扩散获得了更紧凑的簇，在环向熵、扇区熵和联合熵指标上优于K-means和GMM。

Conclusion: CCC适用于需要控制簇扩散的结构化聚类应用场景，如传感器网络、协作机器人和可解释模式分析。

Abstract: This paper presents Constrained Centroid Clustering (CCC), a method that
extends classical centroid-based clustering by enforcing a constraint on the
maximum distance between the cluster center and the farthest point in the
cluster. Using a Lagrangian formulation, we derive a closed-form solution that
maintains interpretability while controlling cluster spread. To evaluate CCC,
we conduct experiments on synthetic circular data with radial symmetry and
uniform angular distribution. Using ring-wise, sector-wise, and joint entropy
as evaluation metrics, we show that CCC achieves more compact clusters by
reducing radial spread while preserving angular structure, outperforming
standard methods such as K-means and GMM. The proposed approach is suitable for
applications requiring structured clustering with spread control, including
sensor networks, collaborative robotics, and interpretable pattern analysis.

</details>


### [328] [Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach](https://arxiv.org/abs/2508.12764)
*Cyril Voyant,Milan Despotovic,Luis Garcia-Gutierrez,Mohammed Asloune,Yves-Marie Saint-Drenan,Jean-Laurent Duchaud,hjuvan Antone Faggianelli,Elena Magliaro*

Main category: cs.LG

TL;DR: 提出了一种基于极限学习机(ELM)的短期能源预测新方法，通过多输入多输出架构预测多种能源产量和总产量，在1小时预测范围内表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决短期能源预测中的非平稳性和季节性变化问题，需要开发一种能够动态适应波动的高效预测方法。

Method: 使用ELM模型结合滑动窗口技术和循环时间编码，采用MIMO架构处理多源能源数据（太阳能、风能、水电、热能、生物能源和进口电力）。

Result: 模型显著优于基于持续性的预测方法，太阳能和热能预测的nRMSE分别为17.9%和5.1%，R²>0.98（1小时预测），在5小时内保持高精度。

Conclusion: ELM-MIMO方法提供了闭式解，计算需求低，适合实时应用和在线学习，能够适应不同场景和数据集，是短期能源预测的有效解决方案。

Abstract: A novel methodology for short-term energy forecasting using an Extreme
Learning Machine ($\mathtt{ELM}$) is proposed. Using six years of hourly data
collected in Corsica (France) from multiple energy sources (solar, wind, hydro,
thermal, bioenergy, and imported electricity), our approach predicts both
individual energy outputs and total production (\cyr{including imports, which
closely follow energy demand, modulo losses)} through a Multi-Input
Multi-Output ($\mathtt{MIMO}$) architecture. To address non-stationarity and
seasonal variability, sliding window techniques and cyclic time encoding are
incorporated, enabling dynamic adaptation to fluctuations. The $\mathtt{ELM}$
model significantly outperforms persistence-based forecasting, particularly for
solar and thermal energy, achieving an $\mathtt{nRMSE}$ of $17.9\%$ and
$5.1\%$, respectively, with $\mathtt{R^2} > 0.98$ (1-hour horizon). The model
maintains high accuracy up to five hours ahead, beyond which renewable energy
sources become increasingly volatile. While $\mathtt{MIMO}$ provides marginal
gains over Single-Input Single-Output ($\mathtt{SISO}$) architectures and
offers key advantages over deep learning methods such as $\mathtt{LSTM}$, it
provides a closed-form solution with lower computational demands, making it
well-suited for real-time applications, including online learning. Beyond
predictive accuracy, the proposed methodology is adaptable to various contexts
and datasets, as it can be tuned to local constraints such as resource
availability, grid characteristics, and market structures.

</details>


### [329] [Online Ensemble Transformer for Accurate Cloud Workload Forecasting in Predictive Auto-Scaling](https://arxiv.org/abs/2508.12773)
*Jiadong Chen,Xiao He,Hengyu Ye,Fuxin Jiang,Tieying Zhang,Jianjun Chen,Xiaofeng Gao*

Main category: cs.LG

TL;DR: 提出E3Former在线集成模型，用于服务器less系统中的工作负载预测，相比现有方法平均降低10%预测误差，已在字节跳动IHPA平台部署，支持60万+CPU核心的预测自动扩缩容，资源利用率降低40%以上。


<details>
  <summary>Details</summary>
Motivation: 服务器less系统需要预测性自动扩缩容来优化资源分配和运营效率，但现有预测模型难以快速适应在线工作负载流的动态变化，也无法有效捕捉细粒度高频预测任务带来的复杂周期性。

Method: 提出E3Former在线集成模型，通过协同多个子网络的预测能力来克服单模型方法的局限性，在计算开销最小的情况下确保预测准确性和鲁棒性。

Result: 在线预测任务中平均降低10%预测误差，在字节跳动IHPA平台实际部署，支持30+应用稳定运行，覆盖60万+CPU核心的预测自动扩缩容能力。

Conclusion: E3Former模型有效解决了服务器less系统中工作负载预测的挑战，实现了高精度预测和资源优化，已在实际生产环境中验证其有效性，显著提升了系统运营效率。

Abstract: In the swiftly evolving domain of cloud computing, the advent of serverless
systems underscores the crucial need for predictive auto-scaling systems. This
necessity arises to ensure optimal resource allocation and maintain operational
efficiency in inherently volatile environments. At the core of a predictive
auto-scaling system is the workload forecasting model. Existing forecasting
models struggle to quickly adapt to the dynamics in online workload streams and
have difficulty capturing the complex periodicity brought by fine-grained,
high-frequency forecasting tasks. Addressing this, we propose a novel online
ensemble model, E3Former, for online workload forecasting in large-scale
predictive auto-scaling. Our model synergizes the predictive capabilities of
multiple subnetworks to surmount the limitations of single-model approaches,
thus ensuring superior accuracy and robustness. Remarkably, it accomplishes
this with a minimal increase in computational overhead, adhering to the lean
operational ethos of serverless systems. Through extensive experimentation on
real-world workload datasets, we establish the efficacy of our ensemble model.
In online forecasting tasks, the proposed method reduces forecast error by an
average of 10%, and its effectiveness is further demonstrated through a
predictive auto-scaling test in the real-life online system. Currently, our
method has been deployed within ByteDance's Intelligent Horizontal Pod
Auto-scaling (IHPA) platform, which supports the stable operation of over 30
applications, such as Douyin E-Comerce, TouTiao, and Volcano Engine. The
predictive auto-scaling capacity reaching over 600,000 CPU cores. On the basis
of essentially ensuring service quality, the predictive auto-scaling system can
reduce resource utilization by over 40%.

</details>


### [330] [Randomized PCA Forest for Outlier Detection](https://arxiv.org/abs/2508.12776)
*Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek*

Main category: cs.LG

TL;DR: 基于随机化主成分分析森林的无监督异常检测新方法，在多个数据集上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 受随机化PCA森林在近似K近邻搜索中表现的启发，研究者开发了一种新的无监督异常检测方法

Method: 使用随机化主成分分析森林（RPCA Forest）进行异常检测，利用其在近似K近邻搜索中的优秀表现

Result: 在多个数据集上表现超过传统和最新的方法，在其他数据集上也有竞争力，具有高泛化能力和计算效率

Conclusion: 该方法是无监督异常检测的良好选择，具有高泛化性和计算效率优势

Abstract: We propose a novel unsupervised outlier detection method based on Randomized
Principal Component Analysis (PCA). Inspired by the performance of Randomized
PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a
novel unsupervised outlier detection method that utilizes RPCA Forest for
outlier detection. Experimental results showcase the superiority of the
proposed approach compared to the classical and state-of-the-art methods in
performing the outlier detection task on several datasets while performing
competitively on the rest. The extensive analysis of the proposed method
reflects it high generalization power and its computational efficiency,
highlighting it as a good choice for unsupervised outlier detection.

</details>


### [331] [Wavy Transformer](https://arxiv.org/abs/2508.12787)
*Satoshi Noguchi,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: 提出了Wavy Transformer来解决Transformer中的过平滑问题，通过二阶波动动力学改进注意力层，在NLP和CV任务上提升性能且参数增加极少


<details>
  <summary>Details</summary>
Motivation: 深度Transformer模型存在过平滑问题，即token表示在连续transformer块中收敛到相似值。从图神经扩散角度分析，过平滑是底层扩散动力学耗散性质的结果

Method: 建立堆叠注意力层与完全图上图神经扩散的等价关系，提出基于二阶波动动力学的新型注意力层，设计保持物理状态-速度关系的FFN和归一化层

Result: 在多种NLP和CV任务的Transformer模型上验证，Wavy Transformer一致提升性能，仅增加极少参数且无需额外超参数调优

Conclusion: 从物理动力学角度理解Transformer过平滑问题，提出的Wavy Transformer能有效缓解该问题，为改进Transformer架构提供了新思路

Abstract: Transformers have achieved remarkable success across natural language
processing (NLP) and computer vision (CV). However, deep transformer models
often suffer from an over-smoothing issue, in which token representations
converge to similar values as they pass through successive transformer blocks.
In this paper, we establish an equivalence between the hidden-state dynamics
induced by stacked attention layers and graph neural diffusion on a complete
graph. From this perspective, over-smoothing can be interpreted as a
consequence of the dissipative nature of the underlying diffusion dynamics.
Motivated by this physical interpretation, we propose Wavy Transformer, which
consists of a novel attention layer based on second-order wavy dynamics. We
also introduce a feed-forward network and a normalization layer designed to
preserve the physical state-velocity relationship under the chain rule, thereby
extending the transformer architecture. We further validate our proposed
techniques on various transformer models for NLP and CV tasks. The results
consistently demonstrate that Wavy Transformer improves performance with
minimal additional parameters and no extra hyperparameter tuning.

</details>


### [332] [Bridging Human and LLM Judgments: Understanding and Narrowing the Gap](https://arxiv.org/abs/2508.12792)
*Felipe Maia Polo,Xinhe Wang,Mikhail Yurochkin,Gongjun Xu,Moulinath Banerjee,Yuekai Sun*

Main category: cs.LG

TL;DR: Bridge是一个统一的统计框架，通过建模人类和LLM评估之间的系统差异，提高LLM作为评判者的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型被广泛用作评判者来评估模型输出，但其评估结果往往与人类判断存在系统性偏差，需要一种方法来弥合这种差距。

Method: 提出Bridge统计框架，假设每个提示-响应对存在潜在的人类偏好分数，将LLM偏差建模为捕捉差异来源的协变量的线性变换，并提供具有渐近保证的有效拟合算法。

Result: 在六个LLM评判者和两个基准测试（BigGen Bench和Chatbot Arena）上，Bridge实现了与人类评分更高的一致性（准确性、校准和KL散度），并揭示了系统的人类-LLM差距。

Conclusion: Bridge提供了一个简单而原则性的框架，用于精炼LLM评分并表征人类与LLM之间的系统性差异，有效提升了LLM作为评判者的可靠性。

Abstract: Large language models are increasingly used as judges (LLM-as-a-judge) to
evaluate model outputs at scale, but their assessments often diverge
systematically from human judgments. We present Bridge, a unified statistical
framework that explicitly bridges human and LLM evaluations under both absolute
scoring and pairwise comparison paradigms. Bridge posits a latent human
preference score for each prompt-response pair and models LLM deviations as
linear transformations of covariates that capture sources of discrepancies.
This offers a simple and principled framework for refining LLM ratings and
characterizing systematic discrepancies between humans and LLMs. We provide an
efficient fitting algorithm with asymptotic guarantees for statistical
inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot
Arena), Bridge achieves higher agreement with human ratings (accuracy,
calibration, and KL divergence) and exposes systematic human-LLM gaps.

</details>


### [333] [A Shift in Perspective on Causality in Domain Generalization](https://arxiv.org/abs/2508.12798)
*Damian Machlanski,Stephanie Riley,Edward Moroshko,Kurt Butler,Panagiotis Dimitrakopoulos,Thomas Melistas,Akchunya Chanchal,Steven McDonagh,Ricardo Silva,Sotirios A. Tsaftaris*

Main category: cs.LG

TL;DR: 重新审视因果建模在AI广泛化中的作用，调和领域广泛化与因果关系研究之间的表面矛盾，提出更细腻的理论框架


<details>
  <summary>Details</summary>
Motivation: 最近领域广泛化基准测试中对因果建模能否带来健壮AI广泛化的说法提出了挑战，需要重新评估因果性在广泛化中的真正价值

Method: 重新审视因果关系和领域广泛化文献中的断言，调和表面矛盾，建立更细腻的理论框架来理解因果性在广泛化中的作用

Result: 提出了一种更加细腻的理论观点，能够调和领域广泛化与因果关系研究之间的表面矛盾，为因果建模在AI广泛化中的作用提供更清晰的理论基础

Conclusion: 因果建模在AI广泛化中仍具有重要价值，但需要更加细腻的理论框架来理解其作用机制和限制条件，该研究为这一方向提供了重要的理论进展

Abstract: The promise that causal modelling can lead to robust AI generalization has
been challenged in recent work on domain generalization (DG) benchmarks. We
revisit the claims of the causality and DG literature, reconciling apparent
contradictions and advocating for a more nuanced theory of the role of
causality in generalization. We also provide an interactive demo at
https://chai-uk.github.io/ukairs25-causal-predictors/.

</details>


### [334] [Maximum Score Routing For Mixture-of-Experts](https://arxiv.org/abs/2508.12801)
*Bowen Dong,Yilong Fan,Yutao Sun,Zhenyu Li,Tengyu Pan,Xun Zhou,Jianyong Wang*

Main category: cs.LG

TL;DR: MaxScore是一种新的MoE路由方法，通过最小成本最大流问题和SoftTopk算子解决了传统MoE网络中的token丢弃和硬件效率问题，在相同FLOPs下获得更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统MoE网络存在专家容量约束导致的token丢弃问题和硬件效率低下问题，而去除容量约束又会损害负载平衡和计算效率。

Method: 提出Maximum Score Routing (MaxScore)，将路由建模为最小成本最大流问题，并集成SoftTopk算子，解决了迭代重路由和最优传输公式的根本限制。

Result: 在相同FLOPs下，相比有约束和无约束的基线方法，MaxScore实现了更低的训练损失和更高的评估分数。

Conclusion: MaxScore提供了一种有效的MoE路由新范式，解决了传统方法的根本问题，在保持计算效率的同时提升了模型性能。

Abstract: Routing networks in sparsely activated mixture-of-experts (MoE) dynamically
allocate input tokens to top-k experts through differentiable sparse
transformations, enabling scalable model capacity while preserving
computational efficiency. Traditional MoE networks impose an expert capacity
constraint to ensure GPU-friendly computation. However, this leads to token
dropping when capacity is saturated and results in low hardware efficiency due
to padding in underutilized experts. Removing the capacity constraint, in turn,
compromises load balancing and computational efficiency. To address these
issues, we propose Maximum Score Routing ($\mathbf{MaxScore}$), a novel MoE
routing paradigm that models routing as a minimum-cost maximum-flow problem and
integrates a SoftTopk operator. MaxScore resolves the fundamental limitations
of iterative rerouting and optimal transport formulations, achieving lower
training losses and higher evaluation scores at equivalent FLOPs compared to
both constrained and unconstrained baselines. Implementation details and
experimental configurations can be obtained from
$\href{https://github.com/dongbw18/MaxScore.git}{MaxScore}$.

</details>


### [335] [Learning to Steer: Input-dependent Steering for Multimodal LLMs](https://arxiv.org/abs/2508.12815)
*Jayneel Parekh,Pegah Khayatan,Mustafa Shukor,Arnaud Dapogny,Alasdair Newson,Matthieu Cord*

Main category: cs.LG

TL;DR: 本文提出了L2S（Learn-to-Steer）方法，通过训练小型辅助模块预测输入特定的转向向量，实现多模态大语言模型的细粒度引导，减少幻觉并增强安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的转向技术（如均值转向）依赖单一转向向量，独立于输入查询，在处理依赖具体示例的期望行为时存在局限性。例如，安全回答可能需要根据问题类型采取不同策略。

Method: 使用对比性输入特定提示计算输入特定的线性偏移，并训练小型辅助模块来预测这些转向向量，实现细粒度的输入相关引导。

Result: L2S方法在减少多模态大语言模型的幻觉和增强安全性方面表现优异，优于其他静态基线方法。

Conclusion: 输入特定的细粒度转向方法比单一静态转向向量更有效，通过学习预测转向向量可以实现更好的后处理引导效果。

Abstract: Steering has emerged as a practical approach to enable post-hoc guidance of
LLMs towards enforcing a specific behavior. However, it remains largely
underexplored for multimodal LLMs (MLLMs); furthermore, existing steering
techniques, such as mean steering, rely on a single steering vector, applied
independently of the input query. This paradigm faces limitations when the
desired behavior is dependent on the example at hand. For example, a safe
answer may consist in abstaining from answering when asked for an illegal
activity, or may point to external resources or consultation with an expert
when asked about medical advice. In this paper, we investigate a fine-grained
steering that uses an input-specific linear shift. This shift is computed using
contrastive input-specific prompting. However, the input-specific prompts
required for this approach are not known at test time. Therefore, we propose to
train a small auxiliary module to predict the input-specific steering vector.
Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces
hallucinations and enforces safety in MLLMs, outperforming other static
baselines.

</details>


### [336] [Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG](https://arxiv.org/abs/2508.12833)
*Kichang Lee,Songkuk Kim,JaeYeon Park,JeongGil Ko*

Main category: cs.LG

TL;DR: 这篇论文通过实验研究探讨了设备上机器学习中的存储问题，发现数据量与质量通过压缩的权衡关系，提出根据样本敏感性的适应性压缩策略


<details>
  <summary>Details</summary>
Motivation: 设备上机器学习在连续数据收集场景中遇到存储空间限制问题，需要找到数据数量与质量的最佳平衡点

Method: 进行存储感知学习的实证研究，比较简单的均匀数据删除和一刀切压缩策略的效果

Result: 证明了数据样本对压缩具有不同的敏感性，支持根据样本适应性的压缩策略的可行性

Conclusion: 系统化地定义了存储感知学习这一挖掘不深的挑战，为开发新一代存储感知学习系统奠定了基础

Abstract: On-device machine learning is often constrained by limited storage,
particularly in continuous data collection scenarios. This paper presents an
empirical study on storage-aware learning, focusing on the trade-off between
data quantity and quality via compression. We demonstrate that naive
strategies, such as uniform data dropping or one-size-fits-all compression, are
suboptimal. Our findings further reveal that data samples exhibit varying
sensitivities to compression, supporting the feasibility of a sample-wise
adaptive compression strategy. These insights provide a foundation for
developing a new class of storage-aware learning systems. The primary
contribution of this work is the systematic characterization of this
under-explored challenge, offering valuable insights that advance the
understanding of storage-aware learning.

</details>


### [337] [Learning In-context $\pmb{n}$-grams with Transformers: Sub-$\pmb{n}$-grams Are Near-stationary Points](https://arxiv.org/abs/2508.12837)
*Aditya Varre,Gizem Yüce,Nicolas Flammarion*

Main category: cs.LG

TL;DR: 这篇论文研究了Transformer模型在上下文词汇预测任务中的损失地形牲征，发现子n-元语法模型是群体损失的近稳定点，为阶段性学习动力学提供了理论解释。


<details>
  <summary>Details</summary>
Motivation: 受实验观察到训练过程中持续平台期和阶段性进展的现象驱动，研究Transformer模型在上下文词汇预测任务中的损失地形牲征。

Method: 采用交叉熵损失学习上下文n-元语法语言模型，建立参数配置为稳定点的充分条件，构造简化Transformer模型的k-元语法估计器参数配置集合。

Result: 证明在无限序列长度和参数范数极限下，这些解的群体损失梯度消失，子n-元语法是群体交叉熵损失的近稳定点。

Conclusion: 这些发现为广泛观察到的阶段性学习动力学和出现相变过渡提供了理论视角，数值实验进一步支持了这些见解。

Abstract: Motivated by empirical observations of prolonged plateaus and stage-wise
progression during training, we investigate the loss landscape of transformer
models trained on in-context next-token prediction tasks. In particular, we
focus on learning in-context $n$-gram language models under cross-entropy loss,
and establish a sufficient condition for parameter configurations to be
stationary points. We then construct a set of parameter configurations for a
simplified transformer model that represent $k$-gram estimators (for $k \leq
n$), and show that the gradient of the population loss at these solutions
vanishes in the limit of infinite sequence length and parameter norm. This
reveals a key property of the loss landscape: {sub-$n$-grams are
near-stationary points of the population cross-entropy loss}, offering
theoretical insight into widely observed phenomena such as stage-wise learning
dynamics and emergent phase transitions. These insights are further supported
by numerical experiments that illustrate the learning dynamics of $n$-grams,
characterized by discrete transitions between near-stationary solutions.

</details>


### [338] [HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms](https://arxiv.org/abs/2508.12839)
*Tiancheng Zhang,Cheng Zhang,Shuren Liu,Xiaofei Wang,Shaoyuan Huang,Wenyu Wang*

Main category: cs.LG

TL;DR: HRS是一个混合表示框架，通过整合数值和图像表示来捕捉极端负载动态，并使用调度感知损失函数来减少SLA违规率和提高利润。


<details>
  <summary>Details</summary>
Motivation: 流媒体服务快速发展导致网络负载具有高度时变性和突发性，现有预测方法要么导致峰值时段资源不足和SLA违规，要么采用保守的过度配置策略增加资源成本。

Method: 提出HRS混合表示框架，整合数值和图像表示来更好地捕捉极端负载动态；引入调度感知损失函数(SAL)来捕捉预测误差的不对称影响，指导预测以更好地支持调度决策。

Result: 在四个真实数据集上的实验表明，HRS持续优于十个基线方法，达到最先进性能，SLA违规率降低63.1%，总利润损失减少32.3%。

Conclusion: HRS框架通过混合表示和调度感知损失函数有效解决了流媒体服务负载预测中的极端动态问题，在保证服务质量的同时提高了经济效益。

Abstract: With the rapid proliferation of streaming services, network load exhibits
highly time-varying and bursty behavior, posing serious challenges for
maintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms
(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS
and profitability, accurate load forecasting remains challenging under traffic
surges. Existing methods either minimize mean absolute error, resulting in
underprovisioning and potential Service Level Agreement (SLA) violations during
peak periods, or adopt conservative overprovisioning strategies, which mitigate
SLA risks at the expense of increased resource expenditure. To address this
dilemma, we propose HRS, a hybrid representation framework with scheduling
awareness that integrates numerical and image-based representations to better
capture extreme load dynamics. We further introduce a Scheduling-Aware Loss
(SAL) that captures the asymmetric impact of prediction errors, guiding
predictions that better support scheduling decisions. Extensive experiments on
four real-world datasets demonstrate that HRS consistently outperforms ten
baselines and achieves state-of-the-art performance, reducing SLA violation
rates by 63.1% and total profit loss by 32.3%.

</details>


### [339] [One-Class Intrusion Detection with Dynamic Graphs](https://arxiv.org/abs/2508.12885)
*Aleksei Liuliakov,Alexander Schulz,Luca Hermes,Barbara Hammer*

Main category: cs.LG

TL;DR: 基于动态图模型和深度异常检测的新型入侵检测方法TGN-SVDD，能够处理网络通信的时间序列和图结构特征，在实际入侵检测数据上表现优于多个基线方法


<details>
  <summary>Details</summary>
Motivation: 随着全球数字化进程的加速，网络安全意义重大。机器学习入侵检测面临多重挑战，包括需要检测新颖未见的网络事件，以及处理具有时间序列和图结构特征的网络数据

Method: 提出TGN-SVDD方法，结合现代动态图模型技术和深度异常检测算法

Result: 在实际入侵检测数据集上，TGN-SVDD方法表现出明显优势，超越了多个基线方法

Conclusion: 该方法有效解决了网络入侵检测中的关键挑战，并提出了更具挑战性的数据集变体以促进未来研究

Abstract: With the growing digitalization all over the globe, the relevance of network
security becomes increasingly important. Machine learning-based intrusion
detection constitutes a promising approach for improving security, but it bears
several challenges. These include the requirement to detect novel and unseen
network events, as well as specific data properties, such as events over time
together with the inherent graph structure of network communication. In this
work, we propose a novel intrusion detection method, TGN-SVDD, which builds
upon modern dynamic graph modelling and deep anomaly detection. We demonstrate
its superiority over several baselines for realistic intrusion detection data
and suggest a more challenging variant of the latter.

</details>


### [340] [TCUQ: Single-Pass Uncertainty Quantification from Temporal Consistency with Streaming Conformal Calibration for TinyML](https://arxiv.org/abs/2508.12905)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: TCUQ是一种用于流式TinyML的单次通过、无标签不确定性监测器，通过轻量级信号将短期时间一致性转换为校准风险分数，具有O(W)环形缓冲区和O(1)每步更新。


<details>
  <summary>Details</summary>
Motivation: 为资源受限的TinyML设备提供高效的不确定性监测解决方案，避免传统方法如早期退出和深度集成的高内存占用和延迟问题。

Method: 使用时间一致性捕获后验和特征的轻量级信号，通过流式符合校准层将风险分数转换为预算化的接受/弃权规则，无需在线标签或额外前向传递。

Result: 在微控制器上，TCUQ比早期退出和深度集成减少约50-60%的内存占用和30-45%的延迟，在分布内损坏流中提高3-7个AUPRC点的准确性下降检测，达到0.86 AUPRC（高严重性）和0.92 AUROC（故障检测）。

Conclusion: 时间一致性结合流式符合校准为TinyML设备上的监测提供了实用且资源高效的基础。

Abstract: We introduce TCUQ, a single pass, label free uncertainty monitor for
streaming TinyML that converts short horizon temporal consistency captured via
lightweight signals on posteriors and features into a calibrated risk score
with an O(W ) ring buffer and O(1) per step updates. A streaming conformal
layer turns this score into a budgeted accept/abstain rule, yielding calibrated
behavior without online labels or extra forward passes. On microcontrollers,
TCUQ fits comfortably on kilobyte scale devices and reduces footprint and
latency versus early exit and deep ensembles (typically about 50 to 60% smaller
and about 30 to 45% faster), while methods of similar accuracy often run out of
memory. Under corrupted in distribution streams, TCUQ improves accuracy drop
detection by 3 to 7 AUPRC points and reaches up to 0.86 AUPRC at high
severities; for failure detection it attains up to 0.92 AUROC. These results
show that temporal consistency, coupled with streaming conformal calibration,
provides a practical and resource efficient foundation for on device monitoring
in TinyML.

</details>


### [341] [SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy](https://arxiv.org/abs/2508.12906)
*Boran Zhao,Haiming Zhai,Zihang Yuan,Hetian Liu,Tian Xia,Wenzhe Zhao,Pengju Ren*

Main category: cs.LG

TL;DR: SparseMap是一个基于进化策略的稀疏张量加速器优化框架，能够高效探索包含映射和稀疏策略的庞大设计空间，找到比现有方法更优的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏张量加速器设计大多局限于特定场景，且手动调整设计参数耗时困难。同时，先前工作要么只关注映射优化，要么只关注稀疏策略，缺乏对两者的综合考虑，导致设计次优。

Method: 提出SparseMap框架，构建包含映射和稀疏策略的综合设计空间，通过改进遗传编码和进化算子来高效探索庞大的设计空间（如O(10^41)规模）。

Result: SparseMap与先前工作和经典优化方法相比，能够持续找到更优的解决方案。

Conclusion: SparseMap成功解决了稀疏张量加速器设计中映射和稀疏策略联合优化的挑战，为自动化设计提供了有效框架。

Abstract: The growing demand for sparse tensor algebra (SpTA) in machine learning and
big data has driven the development of various sparse tensor accelerators.
However, most existing manually designed accelerators are limited to specific
scenarios, and it's time-consuming and challenging to adjust a large number of
design factors when scenarios change. Therefore, automating the design of SpTA
accelerators is crucial. Nevertheless, previous works focus solely on either
mapping (i.e., tiling communication and computation in space and time) or
sparse strategy (i.e., bypassing zero elements for efficiency), leading to
suboptimal designs due to the lack of comprehensive consideration of both. A
unified framework that jointly optimizes both is urgently needed. However,
integrating mapping and sparse strategies leads to a combinatorial explosion in
the design space(e.g., as large as $O(10^{41})$ for the workload $P_{32 \times
64} \times Q_{64 \times 48} = Z_{32 \times 48}$). This vast search space
renders most conventional optimization methods (e.g., particle swarm
optimization, reinforcement learning and Monte Carlo tree search) inefficient.
To address this challenge, we propose an evolution strategy-based sparse tensor
accelerator optimization framework, called SparseMap. SparseMap constructing a
more comprehensive design space with the consideration of both mapping and
sparse strategy. We introduce a series of enhancements to genetic encoding and
evolutionary operators, enabling SparseMap to efficiently explore the vast and
diverse design space. We quantitatively compare SparseMap with prior works and
classical optimization methods, demonstrating that SparseMap consistently finds
superior solutions.

</details>


### [342] [SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML](https://arxiv.org/abs/2508.12907)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: SNAP-UQ是一种面向TinyML的单次前向传播、无标签不确定性量化方法，通过深度激活预测来估计风险，在资源受限的微控制器上仅增加几十KB开销，相比现有方法显著减少存储和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性量化方法（如早退机制和深度集成）在TinyML设备上需要额外的前向传播、时间缓冲或辅助退出点，导致内存和计算开销过大，无法在资源受限的微控制器上实用。

Method: 使用int8量化的小型预测头来预测下一层的统计信息，通过轻量级单调映射器将预测的意外程度转换为可操作的分数。该方法无需时间缓冲、辅助退出点或重复前向传播。

Result: 在视觉和音频骨干网络上，SNAP-UQ相比早退机制和深度集成方法减少了40-60%的存储开销和25-35%的延迟，在损坏数据流中提高了AUPRC几个百分点，单次前向传播即可实现约0.9的AUROC故障检测性能。

Conclusion: 通过将不确定性估计建立在层间动态变化基础上，SNAP-UQ为TinyML设备上的实时监控提供了一个实用且资源高效的解决方案。

Abstract: We introduce \textbf{SNAP-UQ}, a single-pass, label-free uncertainty method
for TinyML that estimates risk from \emph{depth-wise next-activation
prediction}: tiny int8 heads forecast the statistics of the next layer from a
compressed view of the previous one, and a lightweight monotone mapper turns
the resulting surprisal into an actionable score. The design requires no
temporal buffers, auxiliary exits, or repeated forward passes, and adds only a
few tens of kilobytes to MCU deployments. Across vision and audio backbones,
SNAP-UQ consistently reduces flash and latency relative to early-exit and deep
ensembles (typically $\sim$40--60\% smaller and $\sim$25--35\% faster), with
competing methods of similar accuracy often exceeding memory limits. In
corrupted streams it improves accuracy-drop detection by several AUPRC points
and maintains strong failure detection (AUROC $\approx$0.9) in a single pass.
Grounding uncertainty in layer-to-layer dynamics yields a practical,
resource-efficient basis for on-device monitoring in TinyML.

</details>


### [343] [Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning](https://arxiv.org/abs/2508.12978)
*Yue Xia,Tayyebeh Jahani-Nezhad,Rawad Bitar*

Main category: cs.LG

TL;DR: Fed-DPRoC是一个新型联邦学习框架，同时确保差分隐私、拜占庭鲁棒性和通信效率，通过RobAJoL方法结合JL变换压缩和鲁棒聚合


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法难以同时保证差分隐私、拜占庭容错和通信效率，需要一种能同时满足这三方面需求的解决方案

Method: 提出robust-compatible压缩概念，结合Johnson-Lindenstrauss变换进行压缩和鲁棒聚合方法，开发RobAJoL算法

Result: 理论证明JL变换与鲁棒聚合兼容，实验在CIFAR-10和Fashion MNIST上验证了方法在拜占庭攻击下的优越鲁棒性和效用

Conclusion: Fed-DPRoC框架成功实现了差分隐私、拜占庭鲁棒性和通信效率的三重保障，RobAJoL方法在理论和实验上都表现出色

Abstract: We propose Fed-DPRoC, a novel federated learning framework that
simultaneously ensures differential privacy (DP), Byzantine robustness, and
communication efficiency. We introduce the concept of robust-compatible
compression, which enables users to compress DP-protected updates while
maintaining the robustness of the aggregation rule. We instantiate our
framework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for
compression with robust averaging for robust aggregation. We theoretically
prove the compatibility of JL transform with robust averaging and show that
RobAJoL preserves robustness guarantees, ensures DP, and reduces communication
cost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims
and demonstrate that RobAJoL outperforms existing methods in terms of
robustness and utility under different Byzantine attacks.

</details>


### [344] [SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression](https://arxiv.org/abs/2508.12984)
*Zehang Lin,Zheng Lin,Miao Yang,Jianhao Huang,Yuxin Zhang,Zihan Fang,Xia Du,Zhe Chen,Shunzhi Zhu,Wei Ni*

Main category: cs.LG

TL;DR: SL-ACC是一个通信高效的拆分学习框架，通过自适应通道重要性识别和通道分组压缩来减少数据传输量，在保持训练精度的同时显著减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络复杂度的增加和参与设备数量的增多，拆分学习中过多的smashed data（激活值和梯度）传输成为主要瓶颈，拖慢了模型训练速度。

Method: 提出SL-ACC框架，包含两个核心组件：1）自适应通道重要性识别（ACII）- 使用香农熵识别每个通道对模型训练的贡献；2）通道分组压缩（CGC）- 基于熵值对通道分组并进行组内自适应压缩。

Result: 在多个数据集上的广泛实验验证，SL-ACC框架在达到目标精度时所需的时间显著少于最先进的基准方法。

Conclusion: SL-ACC框架有效解决了拆分学习中的通信瓶颈问题，通过智能压缩策略在保证训练精度的同时大幅提升了训练效率。

Abstract: The increasing complexity of neural networks poses a significant barrier to
the deployment of distributed machine learning (ML) on resource-constrained
devices, such as federated learning (FL). Split learning (SL) offers a
promising solution by offloading the primary computing load from edge devices
to a server via model partitioning. However, as the number of participating
devices increases, the transmission of excessive smashed data (i.e.,
activations and gradients) becomes a major bottleneck for SL, slowing down the
model training. To tackle this challenge, we propose a communication-efficient
SL framework, named SL-ACC, which comprises two key components: adaptive
channel importance identification (ACII) and channel grouping compression
(CGC). ACII first identifies the contribution of each channel in the smashed
data to model training using Shannon entropy. Following this, CGC groups the
channels based on their entropy and performs group-wise adaptive compression to
shrink the transmission volume without compromising training accuracy.
Extensive experiments across various datasets validate that our proposed SL-ACC
framework takes considerably less time to achieve a target accuracy than
state-of-the-art benchmarks.

</details>


### [345] [Predicting the Performance of Graph Convolutional Networks with Spectral Properties of the Graph Laplacian](https://arxiv.org/abs/2508.12993)
*Shalima Binta Manir,Tim Oates*

Main category: cs.LG

TL;DR: 图卷积神经网络性能可通过图的代数连通性（Fiedler值）预测，相似Fiedler值的图结构性质类似，可以使用相同的滤波器和超参数，同时为过渡学习提供指导。


<details>
  <summary>Details</summary>
Motivation: 图卷积神经网络（GCN）层数增加时性能表现不稳定，需要找到能够预测GCN性能的图结构特征指标。

Method: 通过理论分析和实验验证，使用图的代数连通性（Fiedler值）作为预测指标，在Cora、CiteSeer和Polblogs等数据集上进行测试，并探索多种聚合连通分量Fiedler值的方法。

Result: 实验结果表明Fiedler值能够有效预测GCN的性能表现，相似Fiedler值的图结构具有类似的结构特性，可以共享滤波器和超参数。

Conclusion: 图的代数连通性是预测GCN性能的有效指标，为过渡学习和模型选择提供了理论基础。

Abstract: A common observation in the Graph Convolutional Network (GCN) literature is
that stacking GCN layers may or may not result in better performance on tasks
like node classification and edge prediction. We have found empirically that a
graph's algebraic connectivity, which is known as the Fiedler value, is a good
predictor of GCN performance. Intuitively, graphs with similar Fiedler values
have analogous structural properties, suggesting that the same filters and
hyperparameters may yield similar results when used with GCNs, and that
transfer learning may be more effective between graphs with similar algebraic
connectivity. We explore this theoretically and empirically with experiments on
synthetic and real graph data, including the Cora, CiteSeer and Polblogs
datasets. We explore multiple ways of aggregating the Fiedler value for
connected components in the graphs to arrive at a value for the entire graph,
and show that it can be used to predict GCN performance. We also present
theoretical arguments as to why the Fiedler value is a good predictor.

</details>


### [346] [Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair](https://arxiv.org/abs/2508.12996)
*Stavros C. Kassinos*

Main category: cs.LG

TL;DR: Kourkoutas-Beta是一种改进的Adam优化器，通过动态调整beta2参数来应对梯度尖峰问题，在物理驱动的PDE代理模型和PINNs中表现优于标准Adam。


<details>
  <summary>Details</summary>
Motivation: 在物理驱动的神经网络训练中，变化的边界和初始条件会导致不稳定的损失和尖峰梯度，特别是在PINNs中，刚性复合损失会放大这种效应，需要更鲁棒的优化方法。

Method: 将Adam中的固定beta2参数替换为基于"sunspike"比率的层级动态值，该比率是当前梯度范数与过去范数EMA的比值，尖峰时降低beta2，平静时保持高beta2。

Result: 在四个测试场景中（Transformer PDE代理、3D PINN、MLX合成任务、字符级Transformer），Kourkoutas-Beta相比固定beta2的Adam提高了稳定性和最终损失，在small-enwik8上比特率降低了38-58%。

Conclusion: 该方法保持Adam式收敛保证的同时，在尖峰梯度下提高了鲁棒性，运行时开销与Adam相当，是即插即用的优化器改进方案。

Abstract: Transformer neural networks are increasingly used for physics-based problems.
In data-driven PDE surrogates, training samples from varying boundary and
initial conditions can cause erratic losses and spiky gradients; in
physics-informed neural networks (PINNs), stiff composite losses amplify this
effect.
  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed
second-moment discount beta2 is replaced by a layer-wise dynamic value driven
by a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an
exponential moving average (EMA) of past norms, squashed to the interval [0,1).
Spikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.
Options include leaky-AMSGrad (decay), trust-region clipping (max_ratio),
adaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',
``exact'). With all features off and bias_correction=``none'', the method is
exactly Adam.
  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D
PINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with
jitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB
of enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss
versus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about
38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller
variance. The method remains drop-in, with runtime overhead comparable to Adam
in testbeds A-C and within single-digit percent in testbed D. It preserves
Adam-style convergence guarantees while improving robustness under spiky
gradients.

</details>


### [347] [Fairness-Aware Multi-view Evidential Learning with Adaptive Prior](https://arxiv.org/abs/2508.12997)
*Haishun Chen,Cai Xu,Jinlong Yu,Yilin Zhang,Ziyu Guan,Wei Zhao*

Main category: cs.LG

TL;DR: 提出FAML方法解决多视图证据学习中的证据偏见问题，通过自适应先验、公平性约束和意见对齐机制实现更平衡的证据分配，提升预测性能和不确定性估计可靠性


<details>
  <summary>Details</summary>
Motivation: 现有多视图证据学习方法假设视图特定证据学习是可靠的，但实践中证据学习过程存在偏见，样本倾向于为数据丰富的类别分配更多证据，导致不确定性估计不可靠

Method: FAML方法包含三个核心组件：1)基于训练轨迹的自适应先验作为正则化策略校准偏见证据学习；2)基于类间证据方差的公平性约束促进平衡证据分配；3)多视图融合阶段的意见对齐机制减轻视图特定偏见

Result: 在五个真实世界多视图数据集上的实验表明，FAML实现了更平衡的证据分配，相比最先进方法在预测性能和不确定性估计可靠性方面都有提升

Conclusion: FAML有效解决了多视图证据学习中的偏见问题，通过系统性的偏见校准机制实现了更可信的不确定性估计和更好的预测性能

Abstract: Multi-view evidential learning aims to integrate information from multiple
views to improve prediction performance and provide trustworthy uncertainty
esitimation. Most previous methods assume that view-specific evidence learning
is naturally reliable. However, in practice, the evidence learning process
tends to be biased. Through empirical analysis on real-world data, we reveal
that samples tend to be assigned more evidence to support data-rich classes,
thereby leading to unreliable uncertainty estimation in predictions. This
motivates us to delve into a new Biased Evidential Multi-view Learning (BEML)
problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning
(FAML). FAML first introduces an adaptive prior based on training trajectory,
which acts as a regularization strategy to flexibly calibrate the biased
evidence learning process. Furthermore, we explicitly incorporate a fairness
constraint based on class-wise evidence variance to promote balanced evidence
allocation. In the multi-view fusion stage, we propose an opinion alignment
mechanism to mitigate view-specific bias across views, thereby encouraging the
integration of consistent and mutually supportive evidence. Extensive
experiments on five real-world multi-view datasets demonstrate that FAML
achieves more balanced evidence allocation and improves both prediction
performance and the reliability of uncertainty estimation compared to
state-of-the-art methods.

</details>


### [348] [Monte Carlo Functional Regularisation for Continual Learning](https://arxiv.org/abs/2508.13006)
*Pengcheng Hao,Menghao Waiyan William Zhu,Ercan Engin Kuruoglu*

Main category: cs.LG

TL;DR: 提出MCFRCL框架，通过蒙特卡洛采样和统计分布特征来改进持续学习中的功能正则化方法，在准确性和效率方面都有提升


<details>
  <summary>Details</summary>
Motivation: 现有的功能正则化持续学习方法虽然优于权重空间正则化方法，但存在计算成本高和线性近似误差大的问题

Method: 使用蒙特卡洛采样近似模型预测分布，利用三种连续分布通过矩方法捕捉统计特征，同时采用Wasserstein距离和KL距离构建正则化函数

Result: 在MNIST和CIFAR数据集上评估，结果显示在预测准确性和训练效率方面都优于多个基准方法

Conclusion: MCFRCL框架通过蒙特卡洛采样和统计分布特征的有效结合，成功解决了功能正则化方法在持续学习中的计算成本和近似误差问题

Abstract: Continual learning (CL) is crucial for the adaptation of neural network
models to new environments. Although outperforming weight-space regularisation
approaches, the functional regularisation-based CL methods suffer from high
computational costs and large linear approximation errors. In this work, we
present a new functional regularisation CL framework, called MCFRCL, which
approximates model prediction distributions by Monte Carlo (MC) sampling.
Moreover, three continuous distributions are leveraged to capture the
statistical characteristics of the MC samples via moment-based methods.
Additionally, both the Wasserstein distance and the Kullback-Leibler (KL)
distance are employed to construct the regularisation function. The proposed
MCFRCL is evaluated against multiple benchmark methods on the MNIST and CIFAR
datasets, with simulation results highlighting its effectiveness in both
prediction accuracy and training efficiency.

</details>


### [349] [Design and Analysis of Robust Adaptive Filtering with the Hyperbolic Tangent Exponential Kernel M-Estimator Function for Active Noise Control](https://arxiv.org/abs/2508.13018)
*Iam Kim de S. Hermont,Andre R. Flores,Rodrigo C. de Lamare*

Main category: cs.LG

TL;DR: 提出了一种叫FXHEKM算法，用于阻塞脏器中的冲击性噪声控制，在α稳定噪声环境下表现优称


<details>
  <summary>Details</summary>
Motivation: 传统的主动噪声控制算法在存在冲击性噪声时性能伞洞，需要更稳健的适应性筛波方法

Method: 发展了过滤-x双曲正切指数广义核M估计函数(FXHEKM)算法，进行了统计分析和计算成本研究

Result: 数值实验显示，该算法在平均方差错(MSE)和平均噪声减少(ANR)指标上都表现优异，能有效消除α稳定噪声等添加伪信号

Conclusion: FXHEKM算法是一种高效的稳健适应性筛波方法，适用于存在冲击性噪声的主动噪声控制应用，性能超过现有竞争算法

Abstract: In this work, we propose a robust adaptive filtering approach for active
noise control applications in the presence of impulsive noise. In particular,
we develop the filtered-x hyperbolic tangent exponential generalized Kernel
M-estimate function (FXHEKM) robust adaptive algorithm. A statistical analysis
of the proposed FXHEKM algorithm is carried out along with a study of its
computational cost. {In order to evaluate the proposed FXHEKM algorithm, the
mean-square error (MSE) and the average noise reduction (ANR) performance
metrics have been adopted.} Numerical results show the efficiency of the
proposed FXHEKM algorithm to cancel the presence of the additive spurious
signals, such as \textbf{$\alpha$}-stable noises against competing algorithms.

</details>


### [350] [The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks](https://arxiv.org/abs/2508.13030)
*Bipin Chhetri,Akbar Siami Namin*

Main category: cs.LG

TL;DR: 该研究利用NLP和深度学习技术分析网络攻击后果，使用BERT和HAN模型对MITRE CWE数据库中的攻击描述进行多标签分类，BERT模型在准确率、精确率和召回率方面均优于传统深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 网络攻击日益复杂，行业每年花费数十亿美元进行安全防护。威胁建模可以帮助网络安全专业人员及时采取行动和分配资源。迫切需要自动化方法来评估攻击描述并预测网络攻击的潜在后果。

Method: 使用自然语言处理(NLP)和深度学习技术，利用MITRE CWE数据库的文本描述。采用BERT模型和分层注意力网络(HAN)进行多标签分类，将攻击后果分为五大类别：可用性、访问控制、机密性、完整性和其他。与传统CNN和LSTM模型进行性能比较。

Result: BERT模型在多标签分类中达到0.972的整体准确率，显著优于传统深度学习模型。HAN在特定网络安全标签上优于CNN和LSTM基线模型。BERT在精确率和召回率方面表现一致更好。

Conclusion: BERT模型更适合预测网络攻击的后果，在网络安全威胁建模中表现出优越的性能，为自动化网络安全分析提供了有效的解决方案。

Abstract: Cyberattacks are increasing, and securing against such threats is costing
industries billions of dollars annually. Threat Modeling, that is,
comprehending the consequences of these attacks, can provide critical support
to cybersecurity professionals, enabling them to take timely action and
allocate resources that could be used elsewhere. Cybersecurity is heavily
dependent on threat modeling, as it assists security experts in assessing and
mitigating risks related to identifying vulnerabilities and threats. Recently,
there has been a pressing need for automated methods to assess attack
descriptions and forecast the future consequences of the increasing complexity
of cyberattacks. This study examines how Natural Language Processing (NLP) and
deep learning can be applied to analyze the potential impact of cyberattacks by
leveraging textual descriptions from the MITRE Common Weakness Enumeration
(CWE) database. We emphasize classifying attack consequences into five
principal categories: Availability, Access Control, Confidentiality, Integrity,
and Other. This paper investigates the use of Bidirectional Encoder
Representations from Transformers (BERT) in combination with Hierarchical
Attention Networks (HANs) for Multi-label classification, evaluating their
performance in comparison with conventional CNN and LSTM-based models.
Experimental findings show that BERT achieves an overall accuracy of $0.972$,
far higher than conventional deep learning models in multi-label
classification. HAN outperforms baseline forms of CNN and LSTM-based models on
specific cybersecurity labels. However, BERT consistently achieves better
precision and recall, making it more suitable for predicting the consequences
of a cyberattack.

</details>


### [351] [Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data](https://arxiv.org/abs/2508.13040)
*Varsha Ramineni,Hossein A. Rahmani,Emine Yilmaz,David Barber*

Main category: cs.LG

TL;DR: 通过利用分开的内部预测属性数据和外部保护属性数据，估计模型公平性指标的可行范围，解决完整数据缺失时的公平性测试挑战


<details>
  <summary>Details</summary>
Motivation: 行业实践中因法律和隐私问题无法收集完整的人口统计属性数据，导致公平性评估困难，需要找到在数据分开情况下进行可靠公平性测试的方法

Method: 利用分开的内部预测属性数据和外部公共数据（如人口普查）估计可行的联合分布，计算公平性指标的可行范围和可靠估计

Result: 通过模拟和实验验证，证明该方法能够得到有意义的公平性指标上下界，并获得与真实值相似的可靠估计

Conclusion: 该方法为实际应用中数据访问受限时的公平性测试提供了一种实用有效的解决方案

Abstract: Ensuring fairness in AI systems is critical, especially in high-stakes
domains such as lending, hiring, and healthcare. This urgency is reflected in
emerging global regulations that mandate fairness assessments and independent
bias audits. However, procuring the necessary complete data for fairness
testing remains a significant challenge. In industry settings, legal and
privacy concerns restrict the collection of demographic data required to assess
group disparities, and auditors face practical and cultural challenges in
gaining access to data. In practice, data relevant for fairness testing is
often split across separate sources: internal datasets held by institutions
with predictive attributes, and external public datasets such as census data
containing protected attributes, each providing only partial, marginal
information. Our work seeks to leverage such available separate data to
estimate model fairness when complete data is inaccessible. We propose
utilising the available separate data to estimate a set of feasible joint
distributions and then compute the set plausible fairness metrics. Through
simulation and real experiments, we demonstrate that we can derive meaningful
bounds on fairness metrics and obtain reliable estimates of the true metric.
Our results demonstrate that this approach can serve as a practical and
effective solution for fairness testing in real-world settings where access to
complete data is restricted.

</details>


### [352] [Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models](https://arxiv.org/abs/2508.13057)
*Adolfo González,Víctor Parada*

Main category: cs.LG

TL;DR: 这篇论文比较了FMAE和HEF两种评估函数在多元时间序列预测中的表现，HEF在全局指标上更优并提升模型稳健性，而FMAE在局部指标和运行时间方面更好，为不同场景提供了选择指南


<details>
  <summary>Details</summary>
Motivation: 多元时间序列建模面临数据复杂性、不确定性和频繁制度转移的挑战，传统评估指标容易导致偏差并限制模型的普适性

Method: 对比FMAE（聚焦均绝对误差）和HEF（层次评估函数）两种自定义评估函数，在不同数据分割比例（91:9、80:20、70:30）下使用三种优化器（网格搜索、PSO、Optuna）进行实验，评估拟合度、相对准确度、稳健性和计算效率

Result: HEF在全局指标（R2、相对准确度、RMSE、RMSSE）上一贵表现更优，提升了模型稳健性和解释力；FMAE在局部指标（MAE、MASE）和执行时间方面更优，适合短期场景

Conclusion: 研究呈现了方法论上的权衡：HEF适用于战略规划，FMAE更适合运营效率。提出了一个可复现的框架来优化动态环境中的预测模型

Abstract: Demand forecasting is essential for strategic planning in competitive
environments, enabling resource optimization and improved responsiveness to
market dynamics. However, multivariate time series modeling faces challenges
due to data complexity, uncertainty, and frequent regime shifts. Traditional
evaluation metrics can introduce biases and limit generalization. This work
compares two custom evaluation functions: FMAE (Focused Mean Absolute Error),
focused on minimizing absolute errors, and HEF (Hierarchical Evaluation
Function), designed to weight global metrics and penalize large deviations.
Experiments were conducted under different data splits (91:9, 80:20, 70:30)
using three optimizers (Grid Search, PSO, Optuna), assessing fit, relative
accuracy, robustness, and computational efficiency. Results show that HEF
consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,
RMSSE), enhancing model robustness and explanatory power. These findings were
confirmed via visualizations and statistical tests. Conversely, FMAE offers
advantages in local metrics (MAE, MASE) and execution time, making it suitable
for short-term scenarios. The study highlights a methodological trade-off: HEF
is ideal for strategic planning, while FMAE is better suited for operational
efficiency. A replicable framework is proposed for optimizing predictive models
in dynamic environments.

</details>


### [353] [Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates](https://arxiv.org/abs/2508.13088)
*Xiaohan Wang,Zhimin Li,Joshua A. Levine,Matthew Berger*

Main category: cs.LG

TL;DR: 通过密度估计和可视化接口，模型并可视化产生特定输出特征的可能输入参数分布，解决神经代理模型在逆向问题中的近似误差和高维参数空间搜索问题


<details>
  <summary>Details</summary>
Motivation: 现有的代理模型解决方案主要关注找到少量匹配参数，而忽视了可能参数分布的全局图景，需要模型和可视化产生特定输出特征的可能输入参数分布

Method: 通过密度估计模型化代理模型的近似误差，在输入和输出空间上测量参数配置与训练参数的接近程度，组合先验信念和特征概率形成高效的可能参数采样方法

Result: 开发了一个可视化接口，在三个模拟数据集上进行了特征驱动的参数分析，能够交互式地可视化参数分布

Conclusion: 该方法能够有效地模型和可视化产生特定输出特征的可能输入参数分布，解决了代理模型近似误差和高维参数空间搜索的挑战

Abstract: Recently, neural surrogate models have emerged as a compelling alternative to
traditional simulation workflows. This is accomplished by modeling the
underlying function of scientific simulations, removing the need to run
expensive simulations. Beyond just mapping from input parameter to output,
surrogates have also been shown useful for inverse problems: output to input
parameters. Inverse problems can be understood as search, where we aim to find
parameters whose surrogate outputs contain a specified feature. Yet finding
these parameters can be costly, especially for high-dimensional parameter
spaces. Thus, existing surrogate-based solutions primarily focus on finding a
small set of matching parameters, in the process overlooking the broader
picture of plausible parameters. Our work aims to model and visualize the
distribution of possible input parameters that produce a given output feature.
To achieve this goal, we aim to address two challenges: (1) the approximation
error inherent in the surrogate model and (2) forming the parameter
distribution in an interactive manner. We model error via density estimation,
reporting high density only if a given parameter configuration is close to
training parameters, measured both over the input and output space. Our density
estimate is used to form a prior belief on parameters, and when combined with a
likelihood on features, gives us an efficient way to sample plausible parameter
configurations that generate a target output feature. We demonstrate the
usability of our solution through a visualization interface by performing
feature-driven parameter analysis over the input parameter space of three
simulation datasets. Source code is available at
https://github.com/matthewberger/seeing-the-many

</details>


### [354] [Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network](https://arxiv.org/abs/2508.13099)
*Mingyu Kim,Daniel Stilwell,Jorge Jimenez*

Main category: cs.LG

TL;DR: 基于海底声响传感器网络和对数高斯科克斯过程，提出了一种分类和检测海上空间异常点的框架，通过模型混合过程和二阶近似提高了分类准确性，并集成了动态传感器部署策略来改善检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的海上异常检测方法主要依靠均值模型，忽略了强度函数的方差信息，导致分类准确性不足。需要一种能够同时考虑均值和方差的更精确的异常检测方法，以提高海上环境中空间异常的检测效果。

Method: 使用对数高斯科克斯过程(LGCPs)模型目标到达事件，将其模型为正常过程和异常过程的混合。提出二阶近似方法来估计新观测事件为异常的概率，这种方法同时考虑了正常强度函数的均值和方差。集成了实时传感器部署策略，根据异常强度的变化动态调整传感器位置。

Result: 在维吉尼亚诺福克际近的实际船舶交通数据上进行了验证，数值结果表明该方法在提高分类性能和异常检测方面都显示出有效性。二阶近似方法比仅依赖均值的方法具有更高的分类准确性，并通过传感器部署策略进一步改善了检测性能。

Conclusion: 该研究提出的框架通过结合二阶近似方法和动态传感器部署，有效地提高了海上空间异常点的分类和检测性能。方法在理论上通过Jensen不等式证明了更紧凑的概率边界，实验结果也验证了其在实际应用中的有效性。

Abstract: This paper presents a framework for classifying and detecting spatial
commission outliers in maritime environments using seabed acoustic sensor
networks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as
a mixture of normal and outlier processes, we estimate the probability that a
newly observed event is an outlier. We propose a second-order approximation of
this probability that incorporates both the mean and variance of the normal
intensity function, providing improved classification accuracy compared to
mean-only approaches. We analytically show that our method yields a tighter
bound to the true probability using Jensen's inequality. To enhance detection,
we integrate a real-time, near-optimal sensor placement strategy that
dynamically adjusts sensor locations based on the evolving outlier intensity.
The proposed framework is validated using real ship traffic data near Norfolk,
Virginia, where numerical results demonstrate the effectiveness of our approach
in improving both classification performance and outlier detection through
sensor deployment.

</details>


### [355] [A Perfectly Truthful Calibration Measure](https://arxiv.org/abs/2508.13100)
*Jason Hartline,Lunjia Hu,Yifan Wu*

Main category: cs.LG

TL;DR: 这篇论文提出了一种完美真实的批量设置检查测量方法（ATB），解决了现有检查测量在有限样本上不真实的问题，具有高效计算和实现简单的优点。


<details>
  <summary>Details</summary>
Motivation: 现有的检查测量在有限样本上存在不真实性问题，即预测器会为了在样本上显得更检查而进行伪造，而不是输出真实概率。虽然之前有研究尝试构造约真实的检查测量，但在批量设置中仍然缺乏完美真实的检查测量。

Method: 设计了平均两箱检查误差（ATB）作为一种完美真实的检查测量。ATB不仅真实，还具有完整性、连续性并且与现有的平滑检查误差（smCal）和检查距离（distCal）存在二次关系。还提供了一种构造真实测量的通用方法。

Result: ATB在检查测试问题中实现了更快的运行时间和更简单的实现方案，较smCal和distCal有显著改进。通过通用方法还能构造其他真实的检查测量，如分位箱l_2-ECE。

Conclusion: ATB是第一个在批量设置中被证明完美真实的检查测量，充分解决了现有检查测量在有限样本上的不真实性问题，为检查研究提供了重要的技术进展。

Abstract: Calibration requires that predictions are conditionally unbiased and,
therefore, reliably interpretable as probabilities. Calibration measures
quantify how far a predictor is from perfect calibration. As introduced by
Haghtalab et al. (2024), a calibration measure is truthful if it is minimized
in expectation when a predictor outputs the ground-truth probabilities.
Although predicting the true probabilities guarantees perfect calibration, in
reality, when calibration is evaluated on a finite sample, predicting the truth
is not guaranteed to minimize any known calibration measure. All known
calibration measures incentivize predictors to lie in order to appear more
calibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et
al. (2024) and Qiao and Zhao (2025) to construct approximately truthful
calibration measures in the sequential prediction setting, but no perfectly
truthful calibration measure was known to exist even in the more basic batch
setting.
  We design a perfectly truthful calibration measure in the batch setting:
averaged two-bin calibration error (ATB). In addition to being truthful, ATB is
sound, complete, continuous, and quadratically related to two existing
calibration measures: the smooth calibration error (smCal) and the (lower)
distance to calibration (distCal). The simplicity in our definition of ATB
makes it efficient and straightforward to compute. ATB allows faster estimation
algorithms with significantly easier implementations than smCal and distCal,
achieving improved running time and simplicity for the calibration testing
problem studied by Hu et al. (2024). We also introduce a general recipe for
constructing truthful measures, which proves the truthfulness of ATB as a
special case and allows us to construct other truthful calibration measures
such as quantile-binned l_2-ECE.

</details>


### [356] [Causally-Guided Pairwise Transformer -- Towards Foundational Digital Twins in Process Industry](https://arxiv.org/abs/2508.13111)
*Michael Mayr,Georgios C. Chasparis*

Main category: cs.LG

TL;DR: CGPT是一种新颖的因果引导成对Transformer架构，通过将多维时间序列数据分解为成对关系，解决了通道依赖和通道独立模型之间的权衡问题，在保持维度无关性的同时显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 工业系统中多维时间序列建模面临核心权衡：通道依赖(CD)模型能捕捉特定跨变量动态但缺乏鲁棒性和适应性，而通道独立(CI)模型具有通用性但无法建模系统级预测回归任务所需的关键显式交互。

Method: 提出因果引导成对Transformer(CGPT)，整合已知因果图作为归纳偏置。核心采用成对建模范式，将多维数据分解为成对关系，使用通道无关的可学习层，在成对级别强制执行CD信息流，在跨对之间实现CI式泛化。

Result: 在合成和真实工业数据集的长时期和单步预测任务上验证，CGPT在预测精度上显著优于CI和CD基线模型，同时与端到端训练的CD模型性能相当，且保持对问题维度的无关性。

Conclusion: CGPT通过成对建模范式有效解决了CD/CI冲突，实现了复杂系统动态的解耦，构建了高度灵活的架构，确保了可扩展性和任意变量适应性。

Abstract: Foundational modelling of multi-dimensional time-series data in industrial
systems presents a central trade-off: channel-dependent (CD) models capture
specific cross-variable dynamics but lack robustness and adaptability as model
layers are commonly bound to the data dimensionality of the tackled use-case,
while channel-independent (CI) models offer generality at the cost of modelling
the explicit interactions crucial for system-level predictive regression tasks.
To resolve this, we propose the Causally-Guided Pairwise Transformer (CGPT), a
novel architecture that integrates a known causal graph as an inductive bias.
The core of CGPT is built around a pairwise modeling paradigm, tackling the
CD/CI conflict by decomposing the multidimensional data into pairs. The model
uses channel-agnostic learnable layers where all parameter dimensions are
independent of the number of variables. CGPT enforces a CD information flow at
the pair-level and CI-like generalization across pairs. This approach
disentangles complex system dynamics and results in a highly flexible
architecture that ensures scalability and any-variate adaptability. We validate
CGPT on a suite of synthetic and real-world industrial datasets on long-term
and one-step forecasting tasks designed to simulate common industrial
complexities. Results demonstrate that CGPT significantly outperforms both CI
and CD baselines in predictive accuracy and shows competitive performance with
end-to-end trained CD models while remaining agnostic to the problem
dimensionality.

</details>


### [357] [Contrastive Representations for Temporal Reasoning](https://arxiv.org/abs/2508.13113)
*Alicja Ziarko,Michal Bortkiewicz,Michal Zawalski,Benjamin Eysenbach,Piotr Milos*

Main category: cs.LG

TL;DR: CRTR方法通过负采样方案消除伪特征，成功学习到能够支持时序推理的表征，在Sokoban和魔方等复杂时序结构领域表现优异，首次实现仅通过学习表征高效解决任意魔方状态。


<details>
  <summary>Details</summary>
Motivation: 传统AI中感知和规划分离，感知学习状态表征而规划通过搜索实现。研究是否可以通过同时捕捉感知和时序结构的表征来自然涌现时序推理能力。

Method: 提出组合时序推理表征(CRTR)，采用负采样方案来可证明地消除伪特征，促进时序推理。相比标准时序对比学习更有效地捕捉时序结构。

Result: 在Sokoban和魔方等复杂时序结构领域取得强劲结果。特别是魔方任务中，CRTR学习的表征能泛化到所有初始状态，用比BestFS更少的搜索步数解决谜题（虽然解决方案更长）。

Conclusion: CRTR是首个仅通过学习表征就能高效解决任意魔方状态的方法，无需依赖外部搜索算法，证明了时序推理可以从同时捕捉感知和时序结构的表征中自然涌现。

Abstract: In classical AI, perception relies on learning state-based representations,
while planning, which can be thought of as temporal reasoning over action
sequences, is typically achieved through search. We study whether such
reasoning can instead emerge from representations that capture both perceptual
and temporal structure. We show that standard temporal contrastive learning,
despite its popularity, often fails to capture temporal structure due to its
reliance on spurious features. To address this, we introduce Combinatorial
Representations for Temporal Reasoning (CRTR), a method that uses a negative
sampling scheme to provably remove these spurious features and facilitate
temporal reasoning. CRTR achieves strong results on domains with complex
temporal structure, such as Sokoban and Rubik's Cube. In particular, for the
Rubik's Cube, CRTR learns representations that generalize across all initial
states and allow it to solve the puzzle using fewer search steps than BestFS,
though with longer solutions. To our knowledge, this is the first method that
efficiently solves arbitrary Cube states using only learned representations,
without relying on an external search algorithm.

</details>


### [358] [Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]](https://arxiv.org/abs/2508.13135)
*Yueyang Liu,Lance Kennedy,Ruochen Kong,Joon-Seok Kim,Andreas Züfle*

Main category: cs.LG

TL;DR: 人类移动预测新方法：通过深度学习模型和生活模式分析，提高长期轨迹预测准确性。采用用户语义聚类和分层采样解决数据偏斜问题，小批量优化提升有限数据下的模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在微观层面的短期轨迹预测，对宏观层面的生活常规模式关注不够。本文要解决如何使用历史数据训练机器学习模型来预测个体未来整体轨迹的问题。

Method: 进行了全面的实验分析，包括LSTM和Transformer等多种模型架构、参数配置和训练策略。研究如何通过混合个人生活模式来提高预测效果，以及如何采用用户语义聚类和分层采样来缓解数据偏斜问题。

Result: 显示明确包含语义信息（如星期几）和用户特定历史信息能够帮助模型更好理解个体生活模式并改善预测。小批量随机梯度优化在训练数据有限时显著提升模型性能。

Conclusion: 通过结合生活模式语义信息、采用用户聚类和分层采样策略，以及适当的训练优化方法，可以有效提高人类移动预测的准确性和可靠性，尤其是在数据有限或存在隐私问题的情况下。

Abstract: Individual-level human mobility prediction has emerged as a significant topic
of research with applications in infectious disease monitoring, child, and
elderly care. Existing studies predominantly focus on the microscopic aspects
of human trajectories: such as predicting short-term trajectories or the next
location visited, while offering limited attention to macro-level mobility
patterns and the corresponding life routines. In this paper, we focus on an
underexplored problem in human mobility prediction: determining the best
practices to train a machine learning model using historical data to forecast
an individuals complete trajectory over the next days and weeks. In this
experiment paper, we undertake a comprehensive experimental analysis of diverse
models, parameter configurations, and training strategies, accompanied by an
in-depth examination of the statistical distribution inherent in human mobility
patterns. Our empirical evaluations encompass both Long Short-Term Memory and
Transformer-based architectures, and further investigate how incorporating
individual life patterns can enhance the effectiveness of the prediction. We
show that explicitly including semantic information such as day-of-the-week and
user-specific historical information can help the model better understand
individual patterns of life and improve predictions. Moreover, since the
absence of explicit user information is often missing due to user privacy, we
show that the sampling of users may exacerbate data skewness and result in a
substantial loss in predictive accuracy. To mitigate data imbalance and
preserve diversity, we apply user semantic clustering with stratified sampling
to ensure that the sampled dataset remains representative. Our results further
show that small-batch stochastic gradient optimization improves model
performance, especially when human mobility training data is limited.

</details>


### [359] [MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models](https://arxiv.org/abs/2508.13148)
*Haoyu He,Katrin Renz,Yong Cao,Andreas Geiger*

Main category: cs.LG

TL;DR: 通过强化学习方法MDPO解决了掩码滿散语言模型在训练和推理阶段的不一致性问题，大幅提升了生成性能和效率


<details>
  <summary>Details</summary>
Motivation: 掩码滿散语言模型(MDLMs)在训练和推理阶段存在重要差异：训练时随机掩码，而推理时逐步揭示结构，这导致次优性能。之前的研究忽视了这个问题

Method: 将学习有效去噪轨迹框架为序列决策问题，利用强化学习提出新的Masked Diffusion Policy Optimization (MDPO)方法，在同样的逐步精炼调度下训练模型，同时改进了重新掩码策略(RCR)

Result: MDPO在60倍更少梯度更新下达到之前SOTA方法的性能，在相同权重更新次数下在MATH500和Countdown上分别提升9.6%和54.2%。RCR策略作为插件方案一致提升性能

Conclusion: 该研究为解决MDLMs预训练和推理阶段的不一致性问题开启了重要方向，展示了强化学习在推理轨迹优化中的巨大潜力

Abstract: Diffusion language models, as a promising alternative to traditional
autoregressive (AR) models, enable faster generation and richer conditioning on
bidirectional context. However, they suffer from a key discrepancy between
training and inference: during inference, MDLMs progressively reveal the
structure of the generated sequence by producing fewer and fewer masked tokens,
whereas this structure is ignored in training as tokens are masked at random.
Although this discrepancy between training and inference can lead to suboptimal
performance, it has been largely overlooked by previous works, leaving closing
this gap between the two stages an open problem. To address this, we frame the
problem of learning effective denoising trajectories as a sequential
decision-making problem and use the resulting framework to apply reinforcement
learning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to
exploit the Markov property diffusion possesses and explicitly train the model
under the same progressive refining schedule used at inference. MDPO matches
the performance of the previous state-of-the-art (SOTA) method with 60x fewer
gradient updates, while achieving average improvements of 9.6% on MATH500 and
54.2% on Countdown over SOTA when trained within the same number of weight
updates. Additionally, we improve the remasking strategy of MDLMs as a plug-in
inference replacement to overcome the limitation that the model cannot refine
tokens flexibly. This simple yet effective training-free strategy, what we
refer to as RCR, consistently improves performance and yields additional gains
when combined with MDPO. Our findings establish great potential for
investigating the discrepancy between pre-training and inference of MDLMs.
Code: https://github.com/autonomousvision/mdpo. Project Page:
https://cli212.github.io/MDPO/.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [360] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: 提出FAE方法从游戏视频中学习神经符号世界模型，用Retro Coder DSL表示，相比现有方法获得更精确的环境模型和更通用的代码


<details>
  <summary>Details</summary>
Motivation: 现有世界模型通常是神经网络表示，难以迁移学习到的环境动态和进行可解释性分析，需要更精确和可解释的表示方法

Method: Finite Automata Extraction (FAE)方法，从游戏视频中学习神经符号世界模型，使用新型领域特定语言Retro Coder DSL来表示程序

Result: 相比现有世界模型方法，FAE学习到更精确的环境模型；相比现有基于DSL的方法，生成更通用的代码

Conclusion: FAE方法能够有效解决世界模型的可迁移性和可解释性问题，通过神经符号表示提供更好的环境建模能力

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


### [361] [EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](https://arxiv.org/abs/2508.11850)
*Milad Yazdani,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: EvoCut是一个自动化生成整数规划加速割的框架，结合大语言模型和进化搜索，无需人工专家输入即可显著提升求解器性能


<details>
  <summary>Details</summary>
Motivation: 整数规划作为组合优化的核心问题具有NP难特性，传统依赖专家手动设计加速割的方法效率低下且难以自动化

Method: 结合LLM初始化候选割集，通过进化搜索（交叉和变异）迭代优化，并基于验证集评估割的效用（保持最优解和削减分数解的能力）

Result: 在固定时间内将最优性间隙降低17-57%，获得相同解的速度提升4倍，在相同时间内获得更高质量的解

Conclusion: EvoCut成功实现了整数规划加速割的自动化生成，具有良好的泛化能力和实用价值

Abstract: Integer programming lies at the heart of crucial combinatorial optimization
tasks but remains challenging due to its NP-hard nature. An effective approach
for practically solving integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. However, this creative
process demands deep expertise and is yet to be automated. Our proposed
framework, EvoCut, automates the generation of acceleration cuts by combining
large language models (LLMs) with an evolutionary search. EvoCut (i)
initializes a diverse population of candidate cuts via an LLM-based initializer
agent; (ii) for each cut empirically evaluates both preservation of the optimal
solution and its ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evolutionary
crossover and mutation agents. We quantify each cut's utility by its relative
reduction in the solver's optimality gap. Our comparisons against standard
integer programming practice show that EvoCut reduces optimality gap by 17-57%
within a fixed time. It obtains the same solutions up to 4 times as fast, and
obtains higher-quality solutions within the same time limit. Requiring no human
expert input, EvoCut reliably generates, improves, and empirically verifies
cuts that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.

</details>


### [362] [LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://arxiv.org/abs/2508.11860)
*Frazier N. Baker,Daniel Adu-Ampratwum,Reza Averly,Botao Yu,Huan Sun,Xia Ning*

Main category: cs.AI

TL;DR: LARC是首个基于LLM的约束逆合成规划代理框架，通过Agent-as-a-Judge机制将约束评估直接整合到逆合成规划过程中，使用工具推理的代理反馈来指导和约束路线生成。


<details>
  <summary>Details</summary>
Motivation: 约束逆合成规划是化学中重要但具有挑战性的过程，需要从商业可得的起始材料到目标分子识别合成路线，同时满足实际约束。现有方法难以有效处理复杂约束条件。

Method: 采用LLM代理评估器，通过专门的工具来支撑LLM的理性决策。框架包含代理约束评估机制，使用基于工具推理的代理反馈来引导和约束路线生成过程。

Result: 在精心策划的48个约束逆合成规划任务上，LARC取得了72.9%的成功率，大幅超越LLM基线方法，在显著更少的时间内接近人类专家水平。

Conclusion: LARC框架具有可扩展性，是朝着为人类专家提供有效代理工具或协作科学家的第一步，为约束逆合成规划提供了新的解决方案。

Abstract: Large language model (LLM) agent evaluators leverage specialized tools to
ground the rational decision-making of LLMs, making them well-suited to aid in
scientific discoveries, such as constrained retrosynthesis planning.
Constrained retrosynthesis planning is an essential, yet challenging, process
within chemistry for identifying synthetic routes from commercially available
starting materials to desired target molecules, subject to practical
constraints. Here, we present LARC, the first LLM-based Agentic framework for
Retrosynthesis planning under Constraints. LARC incorporates agentic constraint
evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis
planning process, using agentic feedback grounded in tool-based reasoning to
guide and constrain route generation. We rigorously evaluate LARC on a
carefully curated set of 48 constrained retrosynthesis planning tasks across 3
constraint types. LARC achieves a 72.9% success rate on these tasks, vastly
outperforming LLM baselines and approaching human expert-level success in
substantially less time. The LARC framework is extensible, and serves as a
first step towards an effective agentic tool or a co-scientist to human experts
for constrained retrosynthesis.

</details>


### [363] [QuarkMed Medical Foundation Model Technical Report](https://arxiv.org/abs/2508.11894)
*Ao Li,Bin Yan,Bingfeng Cai,Chenxi Li,Cunzhong Zhao,Fugen Yao,Gaoqiang Liu,Guanjun Jiang,Jian Xu,Liang Dong,Liansheng Sun,Rongshen Zhang,Xiaolei Gui,Xin Liu,Xin Shang,Yao Wu,Yu Cao,Zhenxin Ma,Zhuang Jia*

Main category: cs.AI

TL;DR: QuarkMed开发了一个高性能医疗基础模型，通过医学数据处理、检索增强生成和强化学习，在中国医师资格考试中达到70%准确率，已服务数百万用户。


<details>
  <summary>Details</summary>
Motivation: 医疗任务需要高度专业化的知识、专业准确性和定制能力，现有大语言模型在医疗应用中需要更可靠的基础模型支持。

Method: 利用精选医学数据处理、医学内容检索增强生成(RAG)和大规模可验证强化学习管道来开发医疗基础模型。

Result: 模型在中国医师资格考试中达到70%准确率，在多样化医疗基准测试中表现出强大的泛化能力。

Conclusion: QuarkMed提供了一个强大而多功能的个人医疗AI解决方案，已在ai.quark.cn服务超过百万用户。

Abstract: Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.

</details>


### [364] [CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs](https://arxiv.org/abs/2508.11944)
*Hongtao Liu,Zhicheng Du,Zihe Wang,Weiran Shen*

Main category: cs.AI

TL;DR: 提出了CHBench评估框架，基于认知层次模型来评估大语言模型的战略推理能力，发现聊天机制会降低战略推理，而记忆机制能增强推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖效用性能指标来评估LLMs的游戏能力，但这些指标不够稳健，受对手行为和游戏结构变化影响较大。需要更可靠的评估框架来衡量LLMs的战略推理能力。

Method: 提出CHBench评估框架，基于行为经济学的认知层次模型，假设智能体具有有限理性。通过三阶段系统化框架，在15个精选的正规形式游戏中评估6个最先进LLMs的行为数据。

Result: 实验显示LLMs在不同对手间展现出一致的战略推理水平，证明了框架的稳健性和泛化能力。聊天机制显著降低战略推理性能，而记忆机制能增强推理能力。

Conclusion: CHBench是一个有前景的评估工具，对LLMs能力评估具有重要价值，为未来研究和实际应用提供了重要潜力。

Abstract: Game-playing ability serves as an indicator for evaluating the strategic
reasoning capability of large language models (LLMs). While most existing
studies rely on utility performance metrics, which are not robust enough due to
variations in opponent behavior and game structure. To address this limitation,
we propose \textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation
framework inspired by the cognitive hierarchy models from behavioral economics.
We hypothesize that agents have bounded rationality -- different agents behave
at varying reasoning depths/levels. We evaluate LLMs' strategic reasoning
through a three-phase systematic framework, utilizing behavioral data from six
state-of-the-art LLMs across fifteen carefully selected normal-form games.
Experiments show that LLMs exhibit consistent strategic reasoning levels across
diverse opponents, confirming the framework's robustness and generalization
capability. We also analyze the effects of two key mechanisms (Chat Mechanism
and Memory Mechanism) on strategic reasoning performance. Results indicate that
the Chat Mechanism significantly degrades strategic reasoning, whereas the
Memory Mechanism enhances it. These insights position CHBench as a promising
tool for evaluating LLM capabilities, with significant potential for future
research and practical applications.

</details>


### [365] [Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.11953)
*Yuan Li,Zhengzhong Liu,Eric Xing*

Main category: cs.AI

TL;DR: 提出了一种基于验证损失最小化的数据混合优化方法，通过参数化损失函数和利用微调缩放定律来优化监督微调的数据配比


<details>
  <summary>Details</summary>
Motivation: 优化大型语言模型监督微调(SFT)的数据混合配比对于开发通用模型至关重要，但这一领域尚未得到充分探索

Method: 将数据混合建模为优化问题，通过参数化损失函数（建模有效数据传输）和利用微调缩放定律，在小规模数据混合实验基础上拟合参数并推导最优权重

Result: 算法在所有领域都表现出优异的整体和个体性能，优化权重训练的模型与网格搜索确定的最优权重性能相当，平均每域损失仅比网格搜索最佳域损失高0.66%

Conclusion: 该方法不仅能改善验证损失和下游性能，还可推广用于指导领域特定模型的数据选择，并为SFT提供新的见解

Abstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language
models (LLMs) is critical for developing general-purpose models, yet this area
remains underexplored. In this paper, we frame data mixing as an optimization
problem and introduce a novel method designed to minimize validation loss. Our
approach parametrizes the loss by modeling effective data transferred and
leveraging scaling laws for fine-tuning. By experimenting with various
small-scale data mixtures, we fit these parameters and derive the optimal
weights. We provide both mathematical proofs and empirical results
demonstrating that our algorithm achieves excellent overall and individual
performance across all domains. Through controlled experiments, we show that
models trained with our optimized weights perform on par with those using
optimal weights determined via grid search, with per-domain loss only 0.66%
higher than the best domain loss from grid search on average. Additionally, we
show that reweighting popular SFT datasets using our method improves both
validation loss and downstream performance. Finally, we discuss how our method
can generalize to guide data selection for domain-specific models and provide
insights into SFT.

</details>


### [366] [UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting](https://arxiv.org/abs/2508.11954)
*Sehyuk Park,Soyeon Caren Han,Eduard Hovy*

Main category: cs.AI

TL;DR: UniCast是一个参数高效的多模态时间序列预测框架，通过结合视觉和文本模态信息来增强传统时间序列基础模型的性能


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型主要在单模态设置下运行，忽略了现实场景中时间序列数据常伴随的丰富多模态上下文信息（如视觉和文本信号）

Method: 通过软提示调优将预训练的视觉和文本编码器的模态特定嵌入与冻结的时间序列基础模型集成，实现参数高效的多模态融合

Result: 在多个时间序列预测基准测试中，UniCast始终显著优于所有现有的时间序列基础模型基线

Conclusion: 多模态上下文在推进下一代通用时间序列预测器发展中起着关键作用

Abstract: Time series forecasting is a foundational task across domains, such as
finance, healthcare, and environmental monitoring. While recent advances in
Time Series Foundation Models (TSFMs) have demonstrated strong generalisation
through large-scale pretraining, existing models operate predominantly in a
unimodal setting, ignoring the rich multimodal context, such as visual and
textual signals, that often accompanies time series data in real-world
scenarios. This paper introduces a novel parameter-efficient multimodal
framework, UniCast, that extends TSFMs to jointly leverage time series, vision,
and text modalities for enhanced forecasting performance. Our method integrates
modality-specific embeddings from pretrained Vision and Text Encoders with a
frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal
parameter updates. This design not only preserves the generalisation strength
of the foundation model but also enables effective cross-modal interaction.
Extensive experiments across diverse time-series forecasting benchmarks
demonstrate that UniCast consistently and significantly outperforms all
existing TSFM baselines. The findings highlight the critical role of multimodal
context in advancing the next generation of general-purpose time series
forecasters.

</details>


### [367] [Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index](https://arxiv.org/abs/2508.11959)
*Xuanxiang Huang,Olivier Létoffé,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文提出了两种新的特征重要性评分方法，利用Shapley值和Banzhaf指数来量化特征在排除对抗示例方面的效果，考虑了非弱求余解释集的贡献。


<details>
  <summary>Details</summary>
Motivation: 现有的特征归因方法主要基于弱求余解释(WAXp)，忽视了非WAXp集的重要信息。而非WAXp集与对抗示例(AExs)有着密切联系，因此需要考虑这些集合的贡献来更全面地评估特征重要性。

Method: 使用Shapley值和Banzhaf指数来设计两种新的特征重要性评分。这些评分在计算特征贡献时考虑了非WAXp集合，并量化每个特征排除AExs的效果。还分析了这些评分的性质和计算复杂度。

Result: 提出了两种新的特征重要性评分方法，能够更全面地考虑特征在排除对抗示例方面的作用，补充了现有方法的不足。

Conclusion: 通过考虑非WAXp集合的贡献，新的特征重要性评分方法能够提供更全面的特征解释，对于高风险的机器学习应用具有重要意义。

Abstract: Feature attribution methods based on game theory are ubiquitous in the field
of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous
feature attribution using logic-based explanations, specifically targeting
high-stakes uses of machine learning (ML) models. Typically, such works exploit
weak abductive explanation (WAXp) as the characteristic function to assign
importance to features. However, one possible downside is that the contribution
of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important
information, because of the relationship between formal explanations (XPs) and
adversarial examples (AExs). Accordingly, this paper leverages Shapley value
and Banzhaf index to devise two novel feature importance scores. We take into
account non-WAXp sets when computing feature contribution, and the novel scores
quantify how effective each feature is at excluding AExs. Furthermore, the
paper identifies properties and studies the computational complexity of the
proposed scores.

</details>


### [368] [Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering](https://arxiv.org/abs/2508.11975)
*Gongyao Jiang,Qiong Luo*

Main category: cs.AI

TL;DR: 通过代码生成和执行的图表合成流水线，生成对齐的图表-95ee题-答案三元组，结合候选条件化答题过程，在无人工标注或外部模型的情况下实现了视觉语言模型的自成长改进


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在图表理解任务中遇到困难，特别是准确的图表描述和复杂推理。合成数据生成是有前景的解决方案，但通常面临噪声标签的挑战

Method: 首先引入通过代码生成和执行的图表合成流水线，生成对齐的图表-问题-答案三元组。设计候选条件化答题过程，先生成多个响应，然后通过上下文化这些候选答案来合成最终答案

Result: 实验表明显著改进，在完全自成长范式下，比初始VLM准确率提高了15.50个百分点

Conclusion: 该方法能够在无需人工标注数据或外部模型的情况下，通过合成数据生成和候选条件化答题实现VLM的自成改进，有效解决了图表理解任务中的挑战

Abstract: Vision Language Models (VLMs) often struggle with chart understanding tasks,
particularly in accurate chart description and complex reasoning. Synthetic
data generation is a promising solution, while usually facing the challenge of
noise labels. To address this challenge, we first introduce a chart synthesis
pipeline that generates aligned chart-question-answer triplets through code
generation and execution, ensuring the reliability of synthetic data without
human intervention. Furthermore, inspired by test-time scaling that increases
inference budget and thereby improves performance, we design a
candidate-conditioned answering process. The VLM first generates multiple
responses per query, and then synthesizes the final answer by contextualizing
these candidates. Experiments demonstrate significant improvements, with up to
15.50 points accuracy gain over the initial VLM, in a fully self-improving
paradigm without either human-labeled data or external models.

</details>


### [369] [FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](https://arxiv.org/abs/2508.11987)
*Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX是一个动态实时评估基准，专门用于评估LLM代理在复杂未来预测任务中的表现，支持每日实时更新，避免数据污染，并评估了25个不同模型。


<details>
  <summary>Details</summary>
Motivation: 未来预测是LLM代理的复杂任务，需要高级分析思维和信息处理能力，但目前缺乏大规模基准来评估代理在这方面的表现，主要由于处理实时更新和获取及时准确答案的挑战。

Method: 开发了FutureX动态实时评估基准，通过自动化流程收集问题和答案，支持每日实时更新，评估了25个LLM/代理模型，包括具有推理、搜索能力和外部工具集成的模型。

Result: 提供了对代理在动态环境中自适应推理和性能的全面评估，深入分析了代理在未来导向任务中的失败模式和性能缺陷，包括对虚假网页的脆弱性和时间有效性等问题。

Conclusion: 目标是建立一个动态、无污染的评价标准，推动LLM代理在复杂推理和预测思维方面达到专业人类分析师的水平。

Abstract: Future prediction is a complex task for LLM agents, requiring a high level of
analytical thinking, information gathering, contextual understanding, and
decision-making under uncertainty. Agents must not only gather and interpret
vast amounts of dynamic information but also integrate diverse data sources,
weigh uncertainties, and adapt predictions based on emerging trends, just as
human experts do in fields like politics, economics, and finance. Despite its
importance, no large-scale benchmark exists for evaluating agents on future
prediction, largely due to challenges in handling real-time updates and
retrieving timely, accurate answers. To address this, we introduce
$\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically
designed for LLM agents performing future prediction tasks. FutureX is the
largest and most diverse live benchmark for future prediction, supporting
real-time daily updates and eliminating data contamination through an automated
pipeline for question gathering and answer collection. We evaluate 25 LLM/agent
models, including those with reasoning, search capabilities, and integration of
external tools such as the open-source Deep Research Agent and closed-source
Deep Research models. This comprehensive evaluation assesses agents' adaptive
reasoning and performance in dynamic environments. Additionally, we provide
in-depth analyses of agents' failure modes and performance pitfalls in
future-oriented tasks, including the vulnerability to fake web pages and the
temporal validity. Our goal is to establish a dynamic, contamination-free
evaluation standard that drives the development of LLM agents capable of
performing at the level of professional human analysts in complex reasoning and
predictive thinking.

</details>


### [370] [Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network](https://arxiv.org/abs/2508.11991)
*Weihao Sun*

Main category: cs.AI

TL;DR: AIGer是一个用于AIG图表示学习的新方法，通过节点逻辑特征初始化和异构图卷积网络，在信号概率预测和真值表距离预测任务中显著优于现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 由于真实世界AIG图结构复杂、节点规模大，现有方法难以同时建模功能性和结构性特征，且动态信息传播能力不足，需要新的表示学习方法。

Method: 提出AIGer方法，包含两个组件：1）节点逻辑特征初始化嵌入组件，将逻辑节点投影到独立语义空间；2）AIG特征学习网络组件，使用异构图卷积网络设计动态关系权重矩阵和差异化信息聚合方法。

Result: 在信号概率预测任务中，MAE和MSE分别提升18.95%和44.44%；在真值表距离预测任务中，MAE和MSE分别提升33.57%和14.79%。

Conclusion: AIGer能够有效联合建模AIG图的功能性和结构性特征，提升消息传递能力，在EDA领域的电路表示学习任务中表现出色。

Abstract: The automation of logic circuit design enhances chip performance, energy
efficiency, and reliability, and is widely applied in the field of Electronic
Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,
optimize, and verify the functional characteristics of digital circuits,
enhancing the efficiency of EDA development.Due to the complex structure and
large scale of nodes in real-world AIGs, accurate modeling is challenging,
leading to existing work lacking the ability to jointly model functional and
structural characteristics, as well as insufficient dynamic information
propagation capability.To address the aforementioned challenges, we propose
AIGer.Specifically, AIGer consists of two components: 1) Node logic feature
initialization embedding component and 2) AIGs feature learning network
component.The node logic feature initialization embedding component projects
logic nodes, such as AND and NOT, into independent semantic spaces, to enable
effective node embedding for subsequent processing.Building upon this, the AIGs
feature learning network component employs a heterogeneous graph convolutional
network, designing dynamic relationship weight matrices and differentiated
information aggregation approaches to better represent the original structure
and information of AIGs.The combination of these two components enhances
AIGer's ability to jointly model functional and structural characteristics and
improves its message passing capability. Experimental results indicate that
AIGer outperforms the current best models in the Signal Probability Prediction
(SSP) task, improving MAE and MSE by 18.95\% and 44.44\%, respectively. In the
Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of
33.57\% and 14.79\% in MAE and MSE, respectively, compared to the
best-performing models.

</details>


### [371] [AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](https://arxiv.org/abs/2508.11995)
*Xuyang Zhao,Shiwan Zhao,Hualong Yu,Liting Zhang,Qicheng Li*

Main category: cs.AI

TL;DR: AgentCDM是一个基于认知科学竞争假设分析(ACH)的结构化框架，用于提升LLM多智能体系统中的协作决策质量，通过两阶段训练有效缓解认知偏见并实现主动假设评估。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统的协作决策方法存在缺陷：要么依赖单个智能体的"独裁"策略容易受认知偏见影响，要么使用"投票"方法无法充分利用集体智慧，需要更有效的协作决策框架。

Method: 提出AgentCDM框架，借鉴认知科学中的竞争假设分析(ACH)方法，采用结构化推理范式。使用两阶段训练：第一阶段用ACH启发的显式支架指导结构化推理，第二阶段逐步移除支架以促进自主泛化。

Result: 在多个基准数据集上的实验表明，AgentCDM达到了最先进的性能，并展现出强大的泛化能力，验证了其在提升多智能体系统协作决策质量和鲁棒性方面的有效性。

Conclusion: AgentCDM通过结构化推理和渐进式训练范式，成功解决了LLM多智能体系统中协作决策的挑战，为复杂决策任务提供了更可靠和鲁棒的解决方案。

Abstract: Multi-agent systems (MAS) powered by large language models (LLMs) hold
significant promise for solving complex decision-making tasks. However, the
core process of collaborative decision-making (CDM) within these systems
remains underexplored. Existing approaches often rely on either ``dictatorial"
strategies that are vulnerable to the cognitive biases of a single agent, or
``voting-based" methods that fail to fully harness collective intelligence. To
address these limitations, we propose \textbf{AgentCDM}, a structured framework
for enhancing collaborative decision-making in LLM-based multi-agent systems.
Drawing inspiration from the Analysis of Competing Hypotheses (ACH) in
cognitive science, AgentCDM introduces a structured reasoning paradigm that
systematically mitigates cognitive biases and shifts decision-making from
passive answer selection to active hypothesis evaluation and construction. To
internalize this reasoning process, we develop a two-stage training paradigm:
the first stage uses explicit ACH-inspired scaffolding to guide the model
through structured reasoning, while the second stage progressively removes this
scaffolding to encourage autonomous generalization. Experiments on multiple
benchmark datasets demonstrate that AgentCDM achieves state-of-the-art
performance and exhibits strong generalization, validating its effectiveness in
improving the quality and robustness of collaborative decisions in MAS.

</details>


### [372] [AI Models for Depressive Disorder Detection and Diagnosis: A Review](https://arxiv.org/abs/2508.12022)
*Dorsa Macky Aleagha,Payam Zohari,Mostafa Haghir Chehreghani*

Main category: cs.AI

TL;DR: 这篇论文是一个关于人工智能在重性郁郇症诊断中应用的综述性研究，系统评估了55项关键研究，提出了新的分类法，并分析了主要技术趋势和挑战。


<details>
  <summary>Details</summary>
Motivation: 重性郁郇症是全球能力失除的主要原因之一，但诊断依然依赖主观临床评估。人工智能有期发展客观、可扩展、及时的诊断工具。

Method: 通过系统评估55项关键研究，提出了一个新的层次分类法，按临床任务（诊断vs预测）、数据模态（文本、语音、神经影像、多模态）和计算模型类别结构化领域。

Result: 分析揭示了三大主要趋势：图神经网络在建模大脑连接性中占主导地位，大型语言模型在语言和会话数据中兴起，以及趋向多模态融合、可解释性和算法公平性的新兴关注点。

Conclusion: 该综述通过综合当前进展和突出开放性挑战，为计算精神病学未来创新提供了全面的路线图，包括数据集和评估指标的实践指南。

Abstract: Major Depressive Disorder is one of the leading causes of disability
worldwide, yet its diagnosis still depends largely on subjective clinical
assessments. Integrating Artificial Intelligence (AI) holds promise for
developing objective, scalable, and timely diagnostic tools. In this paper, we
present a comprehensive survey of state-of-the-art AI methods for depression
detection and diagnosis, based on a systematic review of 55 key studies. We
introduce a novel hierarchical taxonomy that structures the field by primary
clinical task (diagnosis vs. prediction), data modality (text, speech,
neuroimaging, multimodal), and computational model class (e.g., graph neural
networks, large language models, hybrid approaches). Our in-depth analysis
reveals three major trends: the predominance of graph neural networks for
modeling brain connectivity, the rise of large language models for linguistic
and conversational data, and an emerging focus on multimodal fusion,
explainability, and algorithmic fairness. Alongside methodological insights, we
provide an overview of prominent public datasets and standard evaluation
metrics as a practical guide for researchers. By synthesizing current advances
and highlighting open challenges, this survey offers a comprehensive roadmap
for future innovation in computational psychiatry.

</details>


### [373] [Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems](https://arxiv.org/abs/2508.12026)
*Szymon Pawlonka,Mikołaj Małkiński,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: Bongard-RWR+是一个包含5400个实例的Bongard问题数据集，使用VLM生成真实世界风格的图像来表示原始抽象概念，评估显示VLM在细粒度概念识别上存在困难


<details>
  <summary>Details</summary>
Motivation: 现有的Bongard问题数据集要么使用合成图像缺乏真实复杂性，要么使用真实图像但概念过于高层简化了任务难度，且Bongard-RWR数据集规模太小限制了评估稳健性

Method: 使用Pixtral-12B描述人工策划的图像并生成新描述，用Flux.1-dev从描述合成图像，人工验证图像是否忠实反映目标概念，构建了5400个实例的数据集

Result: 评估显示最先进的VLM能够识别粗粒度视觉概念，但在辨别细粒度概念方面持续存在困难

Conclusion: VLM在抽象视觉推理方面存在局限性，特别是在细粒度概念识别上表现不佳，Bongard-RWR+数据集为评估VLM的推理能力提供了更全面的基准

Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual
reasoning (AVR), requiring models to identify visual concepts fromjust a few
examples and describe them in natural language. Early BP benchmarks featured
synthetic black-and-white drawings, which might not fully capture the
complexity of real-world scenes. Subsequent BP datasets employed real-world
images, albeit the represented concepts are identifiable from high-level image
features, reducing the task complexity. Differently, the recently released
Bongard-RWR dataset aimed at representing abstract concepts formulated in the
original BPs using fine-grained real-world images. Its manual construction,
however, limited the dataset size to just $60$ instances, constraining
evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset
composed of $5\,400$ instances that represent original BP abstract concepts
using real-world-like images generated via a vision language model (VLM)
pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually
curated images and generate new descriptions aligned with the underlying
concepts, use Flux.1-dev to synthesize images from these descriptions, and
manually verify that the generated images faithfully reflect the intended
concepts. We evaluate state-of-the-art VLMs across diverse BP formulations,
including binary and multiclass classification, as well as textual answer
generation. Our findings reveal that while VLMs can recognize coarse-grained
visual concepts, they consistently struggle with discerning fine-grained
concepts, highlighting limitations in their reasoning capabilities.

</details>


### [374] [Active inference for action-unaware agents](https://arxiv.org/abs/2508.12027)
*Filippo Torresan,Keisuke Suzuki,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 主动推断是一种基于贝叶斯推断的认知形式描述，本文比较了动作意识和动作无意识代理在导航任务中的性能差异


<details>
  <summary>Details</summary>
Motivation: 不同的主动推断策略在规划未来动作时对代理自身动作的知识偏好存在分异，本文想要比较这两种接近方法的表现

Method: 在两个导航任务中比较动作意识代理（知道自己动作）和动作无意识代理（需要从观察中推断动作）的性能

Result: 动作无意识代理虽然处于严重不利地位，但仍能达到与动作意识代理相当的性能水平

Conclusion: 动作无意识代理虽然缺乏直接的动作知识，但通过从观察中推断动作的方式仍能实现有效的规划和行为

Abstract: Active inference is a formal approach to study cognition based on the notion
that adaptive agents can be seen as engaging in a process of approximate
Bayesian inference, via the minimisation of variational and expected free
energies. Minimising the former provides an account of perceptual processes and
learning as evidence accumulation, while minimising the latter describes how
agents select their actions over time. In this way, adaptive agents are able to
maximise the likelihood of preferred observations or states, given a generative
model of the environment. In the literature, however, different strategies have
been proposed to describe how agents can plan their future actions. While they
all share the notion that some kind of expected free energy offers an
appropriate way to score policies, sequences of actions, in terms of their
desirability, there are different ways to consider the contribution of past
motor experience to the agent's future behaviour. In some approaches, agents
are assumed to know their own actions, and use such knowledge to better plan
for the future. In other approaches, agents are unaware of their actions, and
must infer their motor behaviour from recent observations in order to plan for
the future. This difference reflects a standard point of departure in two
leading frameworks in motor control based on the presence, or not, of an
efference copy signal representing knowledge about an agent's own actions. In
this work we compare the performances of action-aware and action-unaware agents
in two navigations tasks, showing how action-unaware agents can achieve
performances comparable to action-aware ones while at a severe disadvantage.

</details>


### [375] [MAPF-World: Action World Model for Multi-Agent Path Finding](https://arxiv.org/abs/2508.12087)
*Zhanjiang Yang,Meng Li,Yang Shen,Yueming Li,Lijun Sun*

Main category: cs.AI

TL;DR: MAPF-World是一个用于多智能体路径规划的自回归动作世界模型，通过显式建模环境时空动态和智能体间依赖关系，在复杂长期规划场景中优于现有可学习求解器，且模型大小减少96.5%，数据需求减少92%。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化可学习求解器在复杂长期规划场景中表现受限，主要因为缺乏对环境时序动态和智能体间依赖关系的充分建模，导致性能下降。

Method: 提出MAPF-World自回归动作世界模型，统一情境理解和动作生成，通过未来状态和动作预测显式建模空间特征和时序依赖，实现更有远见的决策。

Result: 在广泛实验中，MAPF-World优于最先进的可学习求解器，在分布外案例中展现出卓越的零样本泛化能力。

Conclusion: MAPF-World通过世界模型方法显著提升了多智能体路径规划的性能和效率，为复杂多智能体场景提供了更有效的解决方案。

Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free
paths from the designated start locations to goal positions for multiple
agents. It underlies a variety of real-world tasks, including multi-robot
coordination, robot-assisted logistics, and social navigation. Recent
decentralized learnable solvers have shown great promise for large-scale MAPF,
especially when leveraging foundation models and large datasets. However, these
agents are reactive policy models and exhibit limited modeling of environmental
temporal dynamics and inter-agent dependencies, resulting in performance
degradation in complex, long-term planning scenarios. To address these
limitations, we propose MAPF-World, an autoregressive action world model for
MAPF that unifies situation understanding and action generation, guiding
decisions beyond immediate local observations. It improves situational
awareness by explicitly modeling environmental dynamics, including spatial
features and temporal dependencies, through future state and actions
prediction. By incorporating these predicted futures, MAPF-World enables more
informed, coordinated, and far-sighted decision-making, especially in complex
multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an
automatic map generator grounded in real-world scenarios, capturing practical
map layouts for training and evaluating MAPF solvers. Extensive experiments
demonstrate that MAPF-World outperforms state-of-the-art learnable solvers,
showcasing superior zero-shot generalization to out-of-distribution cases.
Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced
data.

</details>


### [376] [Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios](https://arxiv.org/abs/2508.12100)
*Daniel Burkhardt,Xiangwei Cheng*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reasoning in interactive problem solving scenarios requires models to
construct reasoning threads that reflect user understanding and align with
structured domain knowledge. However, current reasoning models often lack
explicit semantic hierarchies, user-domain knowledge alignment, and principled
mechanisms to prune reasoning threads for effectiveness. These limitations
result in lengthy generic output that does not guide users through
goal-oriented reasoning steps. To address this, we propose a
prototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)
framework, drawing inspiration from human-like reasoning strategies that
emphasize structured knowledge reuse. In the first phase, semantically relevant
knowledge structures are extracted from a sparse domain knowledge graph using a
graph neural network and enriched with intrinsic large language model knowledge
to resolve knowledge discrepancies. In the second phase, these threads are
evaluated and pruned using a reward-guided strategy aimed at maintaining
semantic coherence to generate effective reasoning threads. Experiments and
expert evaluations show that ReT-Eval enhances user understanding and
outperforms state-of-the-art reasoning models.

</details>


### [377] [MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization](https://arxiv.org/abs/2508.12149)
*Haochen You,Baojing Liu*

Main category: cs.AI

TL;DR: MOVER是一个多模态学习框架，通过最优传输软对齐和几何体积正则化，在共享嵌入空间中构建语义对齐的结构化多模态表示，显著提升了文本-视频-音频检索任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态学习方法主要依赖成对对比目标来对齐不同模态，但在多模态设置中泛化能力有限，且在高维空间中缺乏语义结构。

Method: 结合最优传输软对齐和几何体积最小化目标(GAVE)，通过传输引导的匹配机制和几何正则化，以模态无关的方式实现所有模态的一致对齐。

Result: 在文本-视频-音频检索任务中，MOVER在零样本和微调设置下均显著优于现有最先进方法，展现出更好的未见模态组合泛化能力和更强的嵌入空间结构一致性。

Conclusion: MOVER框架通过最优传输和几何正则化的结合，有效解决了多模态对齐中的语义结构和泛化问题，为多模态学习提供了新的解决方案。

Abstract: Recent advances in multimodal learning have largely relied on pairwise
contrastive objectives to align different modalities, such as text, video, and
audio, in a shared embedding space. While effective in bi-modal setups, these
approaches struggle to generalize across multiple modalities and often lack
semantic structure in high-dimensional spaces. In this paper, we propose MOVER,
a novel framework that combines optimal transport-based soft alignment with
volume-based geometric regularization to build semantically aligned and
structured multimodal representations. By integrating a transport-guided
matching mechanism with a geometric volume minimization objective (GAVE), MOVER
encourages consistent alignment across all modalities in a modality-agnostic
manner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER
significantly outperforms prior state-of-the-art methods in both zero-shot and
finetuned settings. Additional analysis shows improved generalization to unseen
modality combinations and stronger structural consistency in the learned
embedding space.

</details>


### [378] [RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards](https://arxiv.org/abs/2508.12165)
*Rohit Krishnan,Jon Evans*

Main category: cs.AI

TL;DR: RLNVR框架使用未经验证的噪声奖励信号训练语言模型，通过基线归一化和语义相似度奖励转移解决传统RLHF需要昂贵验证奖励的问题。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF需要昂贵的人工验证奖励信号，在现实场景中不实用。需要一种能够利用噪声现实世界反馈（如社交媒体互动数据）的方法来训练语言模型。

Method: 结合基线归一化（GSPO风格）和语义相似度奖励转移，使用UED式课程学习提高稳定性和多样性，从隐式社交互动数据中优化内容生成。

Result: 实验结果显示在内容质量和训练稳定性方面有显著改进，使用Bluesky实际互动数据训练的原型系统Walter证明了框架的有效性。

Conclusion: RLNVR提供了一个实用的框架，能够在不需要昂贵验证奖励的情况下，利用现实世界的噪声反馈信号有效训练语言模型，为社交媒体内容生成等应用场景提供了可行解决方案。

Abstract: This paper introduces RLNVR (Reinforcement Learning from Non-Verified
Rewards), a framework for training language models using noisy, real-world
feedback signals without requiring explicit human verification. Traditional
RLHF requires expensive, verified reward signals that are impractical in many
real-world domains. RLNVR addresses this challenge through baseline
normalization and semantic similarity-based reward transfer. We demonstrate
RLNVR through Walter, a prototype system that optimizes social media content
generation using actual engagement data from Bluesky. Our experimental results
show significant improvements in content quality and training stability, with
comprehensive evaluation planned for future work. Positioning: We present a
practical framework that combines RLNVR with GSPO (Group Sequence Policy
Optimization) and an optional UED (Unsupervised Environment Design) curriculum
to improve stability and diversity under noisy, implicit rewards. To our
knowledge, combining GSPO-style normalization with a UED-style curriculum for
LLM content generation from implicit social engagement has not been previously
documented in this applied setting; we frame this as an applied integration
rather than a new algorithm.

</details>


### [379] [Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting](https://arxiv.org/abs/2508.12260)
*Carson Dudley,Reiden Magdaleno,Christopher Harding,Ananya Sharma,Emily Martin,Marisa Eisenberg*

Main category: cs.AI

TL;DR: Mantis是一个基于机制模拟训练的传染病预测基础模型，无需真实数据训练即可跨疾病、地区和结果进行开箱即用的预测，在6种疾病测试中优于39个专家调优模型。


<details>
  <summary>Details</summary>
Motivation: 解决传统传染病预测在新发疫情或资源匮乏地区需要疾病特定数据、定制训练和专家调优的局限性。

Method: 基于超过4亿天模拟疫情动态的训练，涵盖多种病原体、传播模式、干预措施和监测伪影，完全使用机制模拟数据训练。

Result: 在6种疾病测试中优于所有39个专家调优模型，包括CDC COVID-19预测中心的所有模型，能够泛化到新的流行病学机制，提供8周预测范围。

Conclusion: Mantis作为下一代疾病预测系统的基础，具有通用性、可解释性和在传统模型失败场景中的可部署性。

Abstract: Infectious disease forecasting in novel outbreaks or low resource settings
has been limited by the need for disease-specific data, bespoke training, and
expert tuning. We introduce Mantis, a foundation model trained entirely on
mechanistic simulations, which enables out-of-the-box forecasting across
diseases, regions, and outcomes, even in settings with limited historical data.
Mantis is built on over 400 million simulated days of outbreak dynamics
spanning diverse pathogens, transmission modes, interventions, and surveillance
artifacts. Despite requiring no real-world data during training, Mantis
outperformed 39 expert-tuned models we tested across six diseases, including
all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel
epidemiological regimes, including diseases with held-out transmission
mechanisms, demonstrating that it captures fundamental contagion dynamics.
Critically, Mantis is mechanistically interpretable, enabling public health
decision-makers to identify the latent drivers behind its predictions. Finally,
Mantis delivers accurate forecasts at 8-week horizons, more than doubling the
actionable range of most models, enabling proactive public health planning.
Together, these capabilities position Mantis as a foundation for
next-generation disease forecasting systems: general, interpretable, and
deployable where traditional models fail.

</details>


### [380] [RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts](https://arxiv.org/abs/2508.12291)
*Xuming He,Zhiyuan You,Junchao Gong,Couhua Liu,Xiaoyu Yue,Peiqin Zhuang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: RadarQA是一个基于多模态大语言模型的天气预报质量分析方法，通过整合物理属性和详细评估报告，在雷达预报质量评估方面超越了现有通用MLLM模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于分数的评估指标在描述能力、可解释性和动态演化理解方面远不及气象专家，需要更先进的工具来克服这些挑战。

Method: 设计了混合标注流程结合人工专家标注和自动化启发式方法，构建了RQA-70K大规模数据集，并采用多阶段训练策略迭代提升模型性能。

Result: 实验表明RadarQA在所有评估设置中都优于现有的通用多模态大语言模型。

Conclusion: 该方法在天气预报质量分析方面具有推进潜力，为多模态质量分析提供了新的任务范式。

Abstract: Quality analysis of weather forecasts is an essential topic in meteorology.
Although traditional score-based evaluation metrics can quantify certain
forecast errors, they are still far from meteorological experts in terms of
descriptive capability, interpretability, and understanding of dynamic
evolution. With the rapid development of Multi-modal Large Language Models
(MLLMs), these models become potential tools to overcome the above challenges.
In this work, we introduce an MLLM-based weather forecast analysis method,
RadarQA, integrating key physical attributes with detailed assessment reports.
We introduce a novel and comprehensive task paradigm for multi-modal quality
analysis, encompassing both single frame and sequence, under both rating and
assessment scenarios. To support training and benchmarking, we design a hybrid
annotation pipeline that combines human expert labeling with automated
heuristics. With such an annotation method, we construct RQA-70K, a large-scale
dataset with varying difficulty levels for radar forecast quality evaluation.
We further design a multi-stage training strategy that iteratively improves
model performance at each stage. Extensive experiments show that RadarQA
outperforms existing general MLLMs across all evaluation settings, highlighting
its potential for advancing quality analysis in weather prediction.

</details>


### [381] [Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback](https://arxiv.org/abs/2508.12338)
*Wenzhen Yuan,Shengji Tang,Weihao Lin,Jiacheng Ruan,Ganqu Cui,Bo Zhang,Tao Chen,Ting Liu,Yuzhuo Fu,Peng Ye,Lei Bai*

Main category: cs.AI

TL;DR: RLCCF是一个无需外部监督的多模型协作进化强化学习框架，通过最大化集体一致性来优化模型集合能力，在数学推理基准上实现16.72%的平均准确率提升


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖昂贵的人工标注数据或复杂奖励模型，限制了可扩展性；自反馈方法受限于单一模型能力，容易导致错误答案过度自信、奖励攻击和训练崩溃

Method: 提出RLCCF框架，通过投票集体输出来提供奖励信号，联合训练多样化的LLM集合；每个模型的投票权重由其自一致性分数决定，确保更自信的模型对集体决策贡献更大

Result: 在四个主流开源LLM和四个数学推理基准上的实验显示，平均相对准确率提升16.72%；不仅提升单个模型性能，还使群体多数投票准确率提升4.51%

Conclusion: RLCCF通过多模型协同进化有效扩展了模型集合的集体能力边界，为无需外部监督的强化学习提供了新思路

Abstract: Reinforcement learning (RL) has significantly enhanced the reasoning
capabilities of large language models (LLMs), but its reliance on expensive
human-labeled data or complex reward models severely limits scalability. While
existing self-feedback methods aim to address this problem, they are
constrained by the capabilities of a single model, which can lead to
overconfidence in incorrect answers, reward hacking, and even training
collapse. To this end, we propose Reinforcement Learning from Coevolutionary
Collective Feedback (RLCCF), a novel RL framework that enables multi-model
collaborative evolution without external supervision. Specifically, RLCCF
optimizes the ability of a model collective by maximizing its Collective
Consistency (CC), which jointly trains a diverse ensemble of LLMs and provides
reward signals by voting on collective outputs. Moreover, each model's vote is
weighted by its Self-Consistency (SC) score, ensuring that more confident
models contribute more to the collective decision. Benefiting from the diverse
output distributions and complementary abilities of multiple LLMs, RLCCF
enables the model collective to continuously enhance its reasoning ability
through coevolution. Experiments on four mainstream open-source LLMs across
four mathematical reasoning benchmarks demonstrate that our framework yields
significant performance gains, achieving an average relative improvement of
16.72\% in accuracy. Notably, RLCCF not only improves the performance of
individual models but also enhances the group's majority-voting accuracy by
4.51\%, demonstrating its ability to extend the collective capability boundary
of the model collective.

</details>


### [382] [Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems](https://arxiv.org/abs/2508.12375)
*Yu Sha,Shuiping Gou,Bo Liu,Johannes Faber,Ningtao Liu,Stefan Schramm,Horst Stoecker,Thomas Steckenreiter,Domagoj Vnucec,Nadine Wetzstein,Andreas Widl,Kai Zhou*

Main category: cs.AI

TL;DR: 基于图卷积网络和层次知识的敏慢强度诊断框架，通过层次分类器和重加权矩阵提升了工业设备敏慢诊断的性能


<details>
  <summary>Details</summary>
Motivation: 现有敏慢强度诊断方法基于思维链而没有考虑目标类别间的依赖关系，需要提出新方法来捐换和利用这些依赖关系

Method: 提出层次知识导向的敏慢强度诊断框架(HKG)，使用图卷积网络将类别表示的层次拓扑图映射为一组相互依赖的全局层次分类器，并开发重加权层次知识相关矩阵(Re-HKCM)方案

Result: 在四个真实工业领域数据集上进行了广泛实验，均显示出优异的结果，超过了最新的敏慢强度诊断方法

Conclusion: HKG框架通过捐换类别间的层次依赖关系，有效提升了敏慢强度诊断的性能，为复杂工业系统的监控和维护提供了有力的解决方案

Abstract: Fault intensity diagnosis (FID) plays a pivotal role in monitoring and
maintaining mechanical devices within complex industrial systems. As current
FID methods are based on chain of thought without considering dependencies
among target classes. To capture and explore dependencies, we propose a
hierarchical knowledge guided fault intensity diagnosis framework (HKG)
inspired by the tree of thought, which is amenable to any representation
learning methods. The HKG uses graph convolutional networks to map the
hierarchical topological graph of class representations into a set of
interdependent global hierarchical classifiers, where each node is denoted by
word embeddings of a class. These global hierarchical classifiers are applied
to learned deep features extracted by representation learning, allowing the
entire model to be end-to-end learnable. In addition, we develop a re-weighted
hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding
inter-class hierarchical knowledge into a data-driven statistical correlation
matrix (SCM) which effectively guides the information sharing of nodes in
graphical convolutional neural networks and avoids over-smoothing issues. The
Re-HKCM is derived from the SCM through a series of mathematical
transformations. Extensive experiments are performed on four real-world
datasets from different industrial domains (three cavitation datasets from
SAMSON AG and one existing publicly) for FID, all showing superior results and
outperform recent state-of-the-art FID methods.

</details>


### [383] [GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding](https://arxiv.org/abs/2508.12379)
*Rongzheng Wang,Qizhi Chen,Yihong Huang,Yizhuo Ma,Muquan Li,Jiakai Li,Ke Qin,Guangchun Luo,Shuang Liang*

Main category: cs.AI

TL;DR: GraphCogent是一个基于工作记忆模型的协作代理框架，通过将图推理分解为感知、缓冲和执行三个认知过程，有效解决了大语言模型处理复杂图拓扑和多步推理的局限性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在小规模图推理任务上表现良好，但在处理具有复杂查询的真实世界图时失败，主要原因是无法同时有效处理复杂图拓扑和执行多步推理。

Method: 提出GraphCogent框架，包含三个模块：感知模块通过子图采样标准化图文本表示，缓冲模块集成和索引多格式图数据，执行模块结合工具调用和模型生成进行高效推理。

Result: 基于Llama3.1-8B的GraphCogent相比DeepSeek-R1(671B)提升50%性能，相比最先进的基于代理的基线方法，在工具集内任务上准确率提升20%同时token使用减少80%，在工具集外任务上token使用减少30%。

Conclusion: GraphCogent框架通过模拟人类工作记忆的认知过程，有效提升了LLMs处理复杂图推理任务的能力，同时显著降低了计算资源消耗。

Abstract: Large language models (LLMs) show promising performance on small-scale graph
reasoning tasks but fail when handling real-world graphs with complex queries.
This phenomenon stems from LLMs' inability to effectively process complex graph
topology and perform multi-step reasoning simultaneously. To address these
limitations, we propose GraphCogent, a collaborative agent framework inspired
by human Working Memory Model that decomposes graph reasoning into specialized
cognitive processes: sense, buffer, and execute. The framework consists of
three modules: Sensory Module standardizes diverse graph text representations
via subgraph sampling, Buffer Module integrates and indexes graph data across
multiple formats, and Execution Module combines tool calling and model
generation for efficient reasoning. We also introduce Graph4real, a
comprehensive benchmark contains with four domains of real-world graphs (Web,
Social, Transportation, and Citation) to evaluate LLMs' graph reasoning
capabilities. Our Graph4real covers 21 different graph reasoning tasks,
categorized into three types (Structural Querying, Algorithmic Reasoning, and
Predictive Modeling tasks), with graph scales that are 10 times larger than
existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent
achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).
Compared to state-of-the-art agent-based baseline, our framework outperforms by
20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%
for out-toolset tasks. Code will be available after review.

</details>


### [384] [Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning](https://arxiv.org/abs/2508.12425)
*Phuong Minh Nguyen,Tien Huu Dang,Naoya Inoue*

Main category: cs.AI

TL;DR: Symbolic-Aided CoT通过将轻量级符号表示整合到少样本提示中，增强LLM的逻辑推理能力，在多个基准测试中显著优于传统CoT方法


<details>
  <summary>Details</summary>
Motivation: 提升大型语言模型在逻辑推理任务中的透明度、可解释性和可分析性，同时保持标准提示技术的泛化能力

Method: 在少样本提示中整合轻量级符号表示，使用一致策略构建推理步骤，使推理模式在非迭代推理过程中更加明确

Result: 在四个逻辑推理基准测试（ProofWriter、FOLIO、ProntoQA、LogicalDeduction）上表现优异，特别是在需要处理多重约束或规则的复杂推理任务中，在三个数据集上显著优于传统CoT

Conclusion: Symbolic-Aided CoT方法有效提升了LLM的逻辑推理能力，具有更好的透明度和可解释性，适用于各种模型规模和复杂推理场景

Abstract: This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved
approach to standard CoT, for logical reasoning in large language models
(LLMs). The key idea is to integrate lightweight symbolic representations into
few-shot prompts, structuring the inference steps with a consistent strategy to
make reasoning patterns more explicit within a non-iterative reasoning process.
By incorporating these symbolic structures, our method preserves the
generalizability of standard prompting techniques while enhancing the
transparency, interpretability, and analyzability of LLM logical reasoning.
Extensive experiments on four well-known logical reasoning benchmarks --
ProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse
reasoning scenarios -- demonstrate the effectiveness of the proposed approach,
particularly in complex reasoning tasks that require navigating multiple
constraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'
reasoning capabilities across various model sizes and significantly outperforms
conventional CoT on three out of four datasets, ProofWriter, ProntoQA, and
LogicalDeduction.

</details>


### [385] [GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?](https://arxiv.org/abs/2508.12472)
*Yifang Tian,Yaming Liu,Zichun Chong,Zihang Huang,Hans-Arno Jacobsen*

Main category: cs.AI

TL;DR: GALA是一个多模态框架，结合统计因果推理和LLM驱动的迭代推理，用于微服务系统的根因分析，在准确性和可操作性方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统RCA方法通常只关注单一模态或仅对可疑服务进行排名，无法提供具有修复指导的可操作诊断见解。微服务系统中的根因分析具有挑战性，需要工程师快速诊断跨异构遥测数据的故障。

Method: GALA框架结合统计因果推理和LLM驱动的迭代推理，通过多模态方法分析指标、日志和追踪等异构遥测数据。

Result: 在开源基准测试中，GALA相比最先进方法实现了高达42.22%的准确率提升。新颖的人工引导LLM评估分数显示GALA生成的诊断输出在因果合理性和可操作性方面显著优于现有方法。

Conclusion: GALA通过提供准确的根因识别和人类可理解的修复指导，弥合了自动化故障诊断与实际事件解决之间的差距。

Abstract: Root cause analysis (RCA) in microservice systems is challenging, requiring
on-call engineers to rapidly diagnose failures across heterogeneous telemetry
such as metrics, logs, and traces. Traditional RCA methods often focus on
single modalities or merely rank suspect services, falling short of providing
actionable diagnostic insights with remediation guidance. This paper introduces
GALA, a novel multi-modal framework that combines statistical causal inference
with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an
open-source benchmark, GALA achieves substantial improvements over
state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM
evaluation score shows GALA generates significantly more causally sound and
actionable diagnostic outputs than existing methods. Through comprehensive
experiments and a case study, we show that GALA bridges the gap between
automated failure diagnosis and practical incident resolution by providing both
accurate root cause identification and human-interpretable remediation
guidance.

</details>


### [386] [The Yokai Learning Environment: Tracking Beliefs Over Space and Time](https://arxiv.org/abs/2508.12480)
*Constantin Ruhdorfer,Matteo Bortoletto,Andreas Bulling*

Main category: cs.AI

TL;DR: 基于合作卡牌游戏Yokai构建的多气强化学习环境YLE，用于评估AI理论意图能力，发现当前RL模型在共同基础建立、伴伴泛化和长期信念追踪方面仍有显著缺陷


<details>
  <summary>Details</summary>
Motivation: 现有理论意图(ToM)测试标准仅限于被动观察者场景，缺乏对多气态如何建立和维护共同基础的评估

Method: 创建Yokai学习环境(YLE)多气态强化学习环境，在合作卡牌游戏中测试模型的信念追踪、过去观察记忆、基于地面的通信和共同基础维护能力

Result: 当前RL模型即使有完美记忆也难以解决YLE任务；信念建模能提升性能但无法有效泛化到未见伴伴或在长期游戏中形成准确信念，显示了对脆弱约定的依赖

Conclusion: YLE环境为研究信念建模、记忆、伴伴泛化和高阶理论意图提供了有力工具，揭示了当前AI在协作性理论意图能力方面的重大挑战

Abstract: Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to
reason about the beliefs of others to build and maintain common ground.
Existing ToM benchmarks, however, are restricted to passive observer settings
or lack an assessment of how agents establish and maintain common ground over
time. To address these gaps, we introduce the Yokai Learning Environment (YLE)
- a multi-agent reinforcement learning (RL) environment based on the
cooperative card game Yokai. In the YLE, agents take turns peeking at hidden
cards and moving them to form clusters based on colour. Success requires
tracking evolving beliefs, remembering past observations, using hints as
grounded communication, and maintaining common ground with teammates. Our
evaluation yields two key findings: First, current RL agents struggle to solve
the YLE, even when given access to perfect memory. Second, while belief
modelling improves performance, agents are still unable to effectively
generalise to unseen partners or form accurate beliefs over longer games,
exposing a reliance on brittle conventions rather than robust belief tracking.
We use the YLE to investigate research questions in belief modelling, memory,
partner generalisation, and scaling to higher-order ToM.

</details>


### [387] [Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework](https://arxiv.org/abs/2508.12487)
*Lida Shahbandari,Hossein Mohseni*

Main category: cs.AI

TL;DR: 提出了一种基于鲸鱼优化算法的分数阶模糊PID控制器，用于精确控制麻醉深度（BIS指数在40-60理想范围），相比传统FOPID控制器具有更快的响应速度和更低的稳态误差


<details>
  <summary>Details</summary>
Motivation: 传统麻醉深度控制方法难以适应患者个体生理差异，需要一种能够自动调节控制参数、处理非线性特性的智能控制方案来提高麻醉精度和安全性

Method: 结合模糊逻辑的自适应能力和分数阶微积分的精细调节特性，使用鲸鱼优化算法(WOA)优化控制器参数（包括分数阶阶次和模糊隶属度函数），实现对八种不同患者模型的个性化控制

Result: 相比标准FOPID控制器，FOFPID控制器 settling time从3.2分钟缩短到2.5分钟，稳态误差从1.2降低到0.5，表现出更强的鲁棒性和精确性

Conclusion: 该FOFPID控制器提供了一个可扩展的AI驱动解决方案，能够实现自动化麻醉给药，有望改善临床实践和患者治疗效果

Abstract: This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that
uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index
(BIS), keeping it within the ideal range of forty to sixty. The FOFPID
controller combines fuzzy logic for adapting to changes and fractional order
dynamics for fine tuning. This allows it to adjust its control gains to handle
a person's unique physiology. The WOA helps fine tune the controller's
parameters, including the fractional orders and the fuzzy membership functions,
which boosts its performance. Tested on models of eight different patient
profiles, the FOFPID controller performed better than a standard Fractional
Order PID (FOPID) controller. It achieved faster settling times, at two and a
half minutes versus three point two minutes, and had a lower steady state
error, at zero point five versus one point two. These outcomes show the
FOFPID's excellent strength and accuracy. It offers a scalable, artificial
intelligence driven solution for automated anesthesia delivery that could
enhance clinical practice and improve patient results.

</details>


### [388] [Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models](https://arxiv.org/abs/2508.12500)
*Rahmat K. Adesunkanmi,Ashfaq Khokhar,Goce Trajcevski,Sohail Murad*

Main category: cs.AI

TL;DR: 利用空间时间数据分析和机器学习模型，通过因果模型识别氢键形成咈解离的根本原因变量，提高分子动力学模拟中的事件检测能力


<details>
  <summary>Details</summary>
Motivation: 解决分子动力学模拟中资源消耗大、需手动扫描输出来发现"有趣事件"的挑战，特别是氢键形成咈解离的根本原因识别问题

Method: 采用受因果模型启发的方法，将氢键解离视为"干预"事件，使用变分自动编码器类的架构构建图形因果模型，在具有不同基础因果图的样本中推断因果关系

Result: 在手性分离的分子动力学模拟原子轨迹上验证模型有效性，能够预测多步未来变化，并找到驱动系统变化的关键变量

Conclusion: 该框架通过构建捕获分子作用条件分布变化的因果模型，为分子动力系统根因分析提供了新视角，成功解决了氢键形成咈解离的根本原因识别问题

Abstract: Molecular dynamics simulations (MDS) face challenges, including
resource-heavy computations and the need to manually scan outputs to detect
"interesting events," such as the formation and persistence of hydrogen bonds
between atoms of different molecules. A critical research gap lies in
identifying the underlying causes of hydrogen bond formation and separation
-understanding which interactions or prior events contribute to their emergence
over time. With this challenge in mind, we propose leveraging spatio-temporal
data analytics and machine learning models to enhance the detection of these
phenomena. In this paper, our approach is inspired by causal modeling and aims
to identify the root cause variables of hydrogen bond formation and separation
events. Specifically, we treat the separation of hydrogen bonds as an
"intervention" occurring and represent the causal structure of the bonding and
separation events in the MDS as graphical causal models. These causal models
are built using a variational autoencoder-inspired architecture that enables us
to infer causal relationships across samples with diverse underlying causal
graphs while leveraging shared dynamic information. We further include a step
to infer the root causes of changes in the joint distribution of the causal
models. By constructing causal models that capture shifts in the conditional
distributions of molecular interactions during bond formation or separation,
this framework provides a novel perspective on root cause analysis in molecular
dynamic systems. We validate the efficacy of our model empirically on the
atomic trajectories that used MDS for chiral separation, demonstrating that we
can predict many steps in the future and also find the variables driving the
observed changes in the system.

</details>


### [389] [Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models](https://arxiv.org/abs/2508.12566)
*Wei Song,Haonan Zhong,Ziqi Ding,Jingling Xue,Yuekang Li*

Main category: cs.AI

TL;DR: MCPGAUGE是首个全面评估LLM-MCP交互的框架，涵盖主动性、合规性、有效性和开销四个维度，通过大规模实验发现MCP集成效果存在关键局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管MCP协议使LLM能够按需访问外部资源，但LLM如何实际利用这种能力以及其效果如何仍不清楚，需要系统性的评估框架。

Method: 开发MCPGAUGE评估框架，包含160个提示和25个数据集，涵盖知识理解、通用推理和代码生成，在6个商业LLM、30个MCP工具套件上进行大规模评估。

Result: 研究揭示了四个关键发现，挑战了关于MCP集成有效性的普遍假设，指出了当前AI-工具集成的关键局限性。

Conclusion: MCPGAUGE为推进可控、工具增强的LLMs提供了一个原则性的基准，揭示了当前工具集成方法的不足和改进方向。

Abstract: The Model Context Protocol (MCP) enables large language models (LLMs) to
access external resources on demand. While commonly assumed to enhance
performance, how LLMs actually leverage this capability remains poorly
understood. We introduce MCPGAUGE, the first comprehensive evaluation framework
for probing LLM-MCP interactions along four key dimensions: proactivity
(self-initiated tool use), compliance (adherence to tool-use instructions),
effectiveness (task performance post-integration), and overhead (computational
cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning
knowledge comprehension, general reasoning, and code generation. Our
large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and
both one- and two-turn interaction settings, comprises around 20,000 API calls
and over USD 6,000 in computational cost. This comprehensive study reveals four
key findings that challenge prevailing assumptions about the effectiveness of
MCP integration. These insights highlight critical limitations in current
AI-tool integration and position MCPGAUGE as a principled benchmark for
advancing controllable, tool-augmented LLMs.

</details>


### [390] [An LLM + ASP Workflow for Joint Entity-Relation Extraction](https://arxiv.org/abs/2508.12611)
*Trang Tran,Trung Hoang Le,Huiping Cao,Tran Cao Son*

Main category: cs.AI

TL;DR: 使用大语言模型(LLM)和答案集编程(ASP)的联合方法来解决聚合实体-关系提取任务，在少量训练数据下达到了更好的性能


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习方法需要大量标注数据，构建模型苦糗耗时，且难以结合领域知识

Method: 提出LLM + ASP的通用工作流程，利用LLM的自然语言理解能力和ASP的知识表示与推理能力

Result: 在三个标准数据集上进行实验，仅需10%训练数据就超越了现有最好系统，在SciERC数据集上关系提取任务提升2.5倍(从15%到35%)

Conclusion: LLM + ASP方法提供了一种高效、灵活且需要少量训练数据的聚合实体-关系提取方案

Abstract: Joint entity-relation extraction (JERE) identifies both entities and their
relationships simultaneously. Traditional machine-learning based approaches to
performing this task require a large corpus of annotated data and lack the
ability to easily incorporate domain specific information in the construction
of the model. Therefore, creating a model for JERE is often labor intensive,
time consuming, and elaboration intolerant. In this paper, we propose
harnessing the capabilities of generative pretrained large language models
(LLMs) and the knowledge representation and reasoning capabilities of Answer
Set Programming (ASP) to perform JERE. We present a generic workflow for JERE
using LLMs and ASP. The workflow is generic in the sense that it can be applied
for JERE in any domain. It takes advantage of LLM's capability in natural
language understanding in that it works directly with unannotated text. It
exploits the elaboration tolerant feature of ASP in that no modification of its
core program is required when additional domain specific knowledge, in the form
of type specifications, is found and needs to be used. We demonstrate the
usefulness of the proposed workflow through experiments with limited training
data on three well-known benchmarks for JERE. The results of our experiments
show that the LLM + ASP workflow is better than state-of-the-art JERE systems
in several categories with only 10\% of training data. It is able to achieve a
2.5 times (35\% over 15\%) improvement in the Relation Extraction task for the
SciERC corpus, one of the most difficult benchmarks.

</details>


### [391] [Cognitive Structure Generation: From Educational Priors to Policy Optimization](https://arxiv.org/abs/2508.12647)
*Hengnian Gu,Zhifu Chen,Yuxin Chen,Jin Peng Zhou,Dongdai Zhou*

Main category: cs.AI

TL;DR: 认知结构生成(CSG)框架，通过预训练认知结构扩散概率模型(CSDPM)和强化学习优化，能够生成更全面有效的学生认知结构表征，显著提升知识转移和认知诊断任务的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 认知结构是学生对知识体系的主观组织，但其评估在学生建模和心理测量中一直是个长期挑战，虽然基础但在教育实践中很难进行实际评估。

Method: 首先预训练认知结构扩散概率模型(CSDPM)从教育先验知识生成学生认知结构，然后通过强化学习作为策略以层次奖励信号进一步优化生成过程，使其与学生学习过程中真实的认知发展水平对齐。

Result: 在四个广泛使用的实际教育数据集上的实验结果显示，CSG生成的认知结构为学生建模提供了更全面和有效的表征，在知识转移(KT)和认知诊断(CD)任务上显著提升了性能，同时增强了可解释性。

Conclusion: 认知结构生成框架(CSG)成功解决了认知结构评估的长期挑战，为教育实践提供了一种可行的方法来生成和利用学生的认知结构表征，对于提升学习效果和个性化教育具有重要意义。

Abstract: Cognitive structure is a student's subjective organization of an objective
knowledge system, reflected in the psychological construction of concepts and
their relations. However, cognitive structure assessment remains a
long-standing challenge in student modeling and psychometrics, persisting as a
foundational yet largely unassessable concept in educational practice. This
paper introduces a novel framework, Cognitive Structure Generation (CSG), in
which we first pretrain a Cognitive Structure Diffusion Probabilistic Model
(CSDPM) to generate students' cognitive structures from educational priors, and
then further optimize its generative process as a policy with hierarchical
reward signals via reinforcement learning to align with genuine cognitive
development levels during students' learning processes. Experimental results on
four popular real-world education datasets show that cognitive structures
generated by CSG offer more comprehensive and effective representations for
student modeling, substantially improving performance on KT and CD tasks while
enhancing interpretability.

</details>


### [392] [The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning](https://arxiv.org/abs/2508.12651)
*Chunliang Hua,Xiao Hu,Jiayang Sun,Zeyuan Yang*

Main category: cs.AI

TL;DR: 本文提出了容量动态最大覆盖位置问题(CDMCLP)优化框架和集成规划推荐系统，用于解决城市空中交通(UAM)站点规划的复杂性问题，在中国城市验证中将传统方法性能提升38%-52%。


<details>
  <summary>Details</summary>
Motivation: 随着全球城市空中交通基础设施快速发展，像深圳这样的城市正在规划大规模站点网络。现有规划框架因历史数据粒度和实际应用性的限制，无法满足这种复杂性需求。

Method: 首先提出容量动态最大覆盖位置问题(CDMCLP)优化框架，同时建模城市级空间-时间需求、异质用户行为和基础设施容量约束。基于此，引入集成规划推荐系统，结合社会经济因素和动态聚类初始化，利用基于实证用户行为的适应参数调整来生成实用规划方案。

Result: 在中国中心城市的验证显示，在CDMCLP的评估和优化下，传统位置方法的数量性能被曝露并可以提高38%-52%，而推荐系统显示了用户友好性和复杂元素的有效集成。

Conclusion: 通过将数学严谨性与实际实施考虑相结合，这种混合方法帮助带平了理论位置建模与实际UAM基础设施规划之间的差距，为市政府提供了一种实用的站点网络设计工具。

Abstract: As urban aerial mobility (UAM) infrastructure development accelerates
globally, cities like Shenzhen are planning large-scale vertiport networks
(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain
inadequate for this complexity due to historical limitations in data
granularity and real-world applicability. This paper addresses these gaps by
first proposing the Capacitated Dynamic Maximum Covering Location Problem
(CDMCLP), a novel optimization framework that simultaneously models urban-scale
spatial-temporal demand, heterogeneous user behaviors, and infrastructure
capacity constraints. Building on this foundation, we introduce an Integrated
Planning Recommendation System that combines CDMCLP with socio-economic factors
and dynamic clustering initialization. This system leverages adaptive parameter
tuning based on empirical user behavior to generate practical planning
solutions. Validation in a Chinese center city demonstrates the effectiveness
of the new optimization framework and recommendation system. Under the
evaluation and optimization of CDMCLP, the quantitative performance of
traditional location methods are exposed and can be improved by 38\%--52\%,
while the recommendation system shows user-friendliness and the effective
integration of complex elements. By integrating mathematical rigor with
practical implementation considerations, this hybrid approach bridges the gap
between theoretical location modeling and real-world UAM infrastructure
planning, offering municipalities a pragmatic tool for vertiport network
design.

</details>


### [393] [GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance](https://arxiv.org/abs/2508.12682)
*Jinquan Shi,Yingying Cheng,Fan Zhang,Miao Jiang,Jun Lin,Yanbai Shen*

Main category: cs.AI

TL;DR: GridCodex是一个基于大语言模型和检索增强生成(RAG)的端到端框架，用于电网规范推理和合规性检查，通过多阶段查询优化和RAPTOR增强检索技术，在答案质量和召回率方面取得显著提升


<details>
  <summary>Details</summary>
Motivation: 可再生能源转型给电力行业带来挑战，电网规范复杂且缺乏自动化解读方案，阻碍行业发展并影响电力公司盈利能力

Method: 利用大语言模型和检索增强生成(RAG)技术，通过多阶段查询优化和RAPTOR增强检索来构建端到端框架

Result: 实验结果显示答案质量提升26.4%，召回率提高10倍以上，消融研究验证了基础模型选择的影响

Conclusion: GridCodex框架有效解决了电网规范自动解读的挑战，为电力行业提供了可靠的合规性检查解决方案

Abstract: The global shift towards renewable energy presents unprecedented challenges
for the electricity industry, making regulatory reasoning and compliance
increasingly vital. Grid codes, the regulations governing grid operations, are
complex and often lack automated interpretation solutions, which hinders
industry expansion and undermines profitability for electricity companies. We
introduce GridCodex, an end to end framework for grid code reasoning and
compliance that leverages large language models and retrieval-augmented
generation (RAG). Our framework advances conventional RAG workflows through
multi stage query refinement and enhanced retrieval with RAPTOR. We validate
the effectiveness of GridCodex with comprehensive benchmarks, including
automated answer assessment across multiple dimensions and regulatory agencies.
Experimental results showcase a 26.4% improvement in answer quality and more
than a 10 fold increase in recall rate. An ablation study further examines the
impact of base model selection.

</details>


### [394] [EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding](https://arxiv.org/abs/2508.12687)
*Ashish Seth,Utkarsh Tyagi,Ramaneswaran Selvakumar,Nishit Anand,Sonal Kumar,Sreyan Ghosh,Ramani Duraiswami,Chirag Agarwal,Dinesh Manocha*

Main category: cs.AI

TL;DR: EgoIllusion是首个评估多模态大语言模型在自我中心视频中幻觉问题的基准测试，包含1,400个视频和8,000个人工标注问题，测试显示GPT-4o和Gemini等顶级模型准确率仅59%


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在第三人称和自我中心视频的视觉感知和推理方面表现出色，但它们容易产生连贯但不准确的幻觉响应，需要专门的评估基准

Method: 构建包含1,400个自我中心视频和8,000个人工标注问题的基准测试集，设计开放和封闭式问题来触发视觉和听觉线索的幻觉

Result: 对10个多模态大语言模型的评估显示显著挑战，包括GPT-4o和Gemini等强大模型仅达到59%的准确率

Conclusion: EgoIllusion为评估多模态大语言模型有效性奠定了基础，将推动开发幻觉率更低的自我中心多模态大语言模型，基准测试将开源以确保可复现性

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
performance in complex multimodal tasks. While MLLMs excel at visual perception
and reasoning in third-person and egocentric videos, they are prone to
hallucinations, generating coherent yet inaccurate responses. We present
EgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric
videos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated
open and closed-ended questions designed to trigger hallucinations in both
visual and auditory cues in egocentric videos. Evaluations across ten MLLMs
reveal significant challenges, including powerful models like GPT-4o and
Gemini, achieving only 59% accuracy. EgoIllusion lays the foundation in
developing robust benchmarks to evaluate the effectiveness of MLLMs and spurs
the development of better egocentric MLLMs with reduced hallucination rates.
Our benchmark will be open-sourced for reproducibility.

</details>


### [395] [GTool: Graph Enhanced Tool Planning with Large Language Model](https://arxiv.org/abs/2508.12725)
*Wenjie Chen,Wenbin Li,Di Yao,Xuying Meng,Chang Gong,Jingping Bi*

Main category: cs.AI

TL;DR: GTool是一个增强LLM在工具依赖不完整情况下工具规划能力的框架，通过构建请求特定的工具图和生成图标记来提供依赖信息，相比SOTA基线有29.6%的性能提升


<details>
  <summary>Details</summary>
Motivation: 现有工作将不同工具视为孤立组件，未能利用工具间的固有依赖关系，导致在工具依赖不完整时LLM难以准确识别用户请求所需的合适工具

Method: 构建请求特定的工具图来高效选择工具，生成LLM可理解的<graph token>提供依赖信息，设计缺失依赖预测任务提高在不完整依赖下的可靠性

Result: 使用轻量级(7B)LLM骨干网络，相比最先进的基线方法实现了超过29.6%的性能提升

Conclusion: GTool是第一个旨在增强LLM在不完整依赖下工具规划能力的工作，无需修剪LLM即可与各种LLM骨干网络无缝集成，无需大量重新训练

Abstract: Tool planning with large language models (LLMs), referring to selecting,
organizing, and preparing the tools necessary to complete a user request,
bridges the gap between natural language understanding and task execution.
However, current works treat different tools as isolated components and fail to
leverage the inherent dependencies of tools, leading to invalid planning
results. Since tool dependencies are often incomplete, it becomes challenging
for LLMs to accurately identify the appropriate tools required by a user
request, especially when confronted with a large toolset. To solve this
challenge, we propose \texttt{GTool}, which is the first work aiming to enhance
the tool planning ability of LLMs under incomplete dependencies. \texttt{GTool}
constructs a request-specific tool graph to select tools efficiently and
generate the \texttt{<graph token>} which provides sufficient dependency
information understandable by LLMs. Moreover, a missing dependency prediction
task is designed to improve the reliability of \texttt{GTool} with incomplete
dependencies. Without trimming LLMs, \texttt{GTool} can be seamlessly
integrated with various LLM backbones without extensive retraining. Extensive
experiments show that \texttt{GTool} achieves more than 29.6\% performance
improvements compared with the state-of-the-art (SOTA) baselines with a
light-weight (7B) LLM backbone.

</details>


### [396] [Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants](https://arxiv.org/abs/2508.12754)
*Alessio Galatolo,Luca Alberto Rappuoli,Katie Winkle,Meriem Beloucif*

Main category: cs.AI

TL;DR: 本文提出了一个新的评估框架来测试大型语言模型作为人工智能道德助手的能力，重点关注道德推理而非表面伦理判断，发现现有模型在溯因道德推理方面存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型道德评估过于表面化，只关注最终伦理判断而忽视了道德推理过程。需要开发更深入的评估方法来测试模型作为人工智能道德助手的能力。

Method: 基于哲学文献设计了一个形式化框架来定义人工智能道德助手应具备的行为特征，包括演绎和溯因道德推理能力。开发了相应的基准测试来评估主流开源LLM。

Result: 评估结果显示不同模型之间存在显著差异，特别是在溯因道德推理方面存在持续性的缺陷和不足。

Conclusion: 研究将理论哲学与实用AI评估相结合，强调了需要专门策略来显式增强LLM的道德推理能力，而不仅仅是表面上的对齐。

Abstract: The recent rise in popularity of large language models (LLMs) has prompted
considerable concerns about their moral capabilities. Although considerable
effort has been dedicated to aligning LLMs with human moral values, existing
benchmarks and evaluations remain largely superficial, typically measuring
alignment based on final ethical verdicts rather than explicit moral reasoning.
In response, this paper aims to advance the investigation of LLMs' moral
capabilities by examining their capacity to function as Artificial Moral
Assistants (AMAs), systems envisioned in the philosophical literature to
support human moral deliberation. We assert that qualifying as an AMA requires
more than what state-of-the-art alignment techniques aim to achieve: not only
must AMAs be able to discern ethically problematic situations, they should also
be able to actively reason about them, navigating between conflicting values
outside of those embedded in the alignment phase. Building on existing
philosophical literature, we begin by designing a new formal framework of the
specific kind of behaviour an AMA should exhibit, individuating key qualities
such as deductive and abductive moral reasoning. Drawing on this theoretical
framework, we develop a benchmark to test these qualities and evaluate popular
open LLMs against it. Our results reveal considerable variability across models
and highlight persistent shortcomings, particularly regarding abductive moral
reasoning. Our work connects theoretical philosophy with practical AI
evaluation while also emphasising the need for dedicated strategies to
explicitly enhance moral reasoning capabilities in LLMs. Code available at
https://github.com/alessioGalatolo/AMAeval

</details>


### [397] [HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds](https://arxiv.org/abs/2508.12782)
*Petr Anokhin,Roman Khalikov,Stefan Rebrikov,Viktor Volkov,Artyom Sorokin,Vincent Bissonnette*

Main category: cs.AI

TL;DR: HeroBench是一个专门评估大语言模型在复杂RPG虚拟世界中长程规划和结构化推理能力的新基准测试，通过25个先进模型的广泛评估揭示了在传统推理基准中很少观察到的显著性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常通过抽象或低维算法任务评估LLMs，无法捕捉现实规划环境的复杂性，而LLMs在需要扩展、结构化相互依赖动作序列的长程规划方面的能力仍未得到充分探索。

Method: 引入HeroBench基准测试，包含严格构建的任务数据集（涵盖各种难度）、用于执行和验证代理计划的模拟环境，以及详细的模型性能分析工具。任务要求模型制定战略计划、高效收集资源、掌握必要技能、制作装备和击败对手。

Result: 对25个最先进LLMs（包括开源和专有模型，如GPT-5系列）的广泛评估显示，在传统推理基准中很少观察到的显著性能差异。详细错误分析进一步揭示了当前模型在生成鲁棒高级计划和可靠执行结构化动作方面的具体弱点。

Conclusion: HeroBench不仅显著推进了LLM推理评估，还为未来在虚拟环境中进行高级自主规划研究提供了灵活、可扩展的基础。

Abstract: Large language models (LLMs) have shown remarkable capabilities in isolated
step-by-step reasoning tasks such as mathematics and programming, but their
proficiency in long-horizon planning, where solutions require extended,
structured sequences of interdependent actions, remains underexplored. Existing
benchmarks typically assess LLMs through abstract or low-dimensional
algorithmic tasks, failing to capture the complexity of realistic planning
environments. We introduce HeroBench, a novel benchmark designed specifically
to evaluate long-horizon planning and structured reasoning within complex
RPG-inspired virtual worlds. HeroBench provides a rigorously constructed
dataset of tasks covering a wide range of difficulties, a simulated environment
to execute and validate agent plans, and detailed analytical tools for
evaluating model performance. Tasks challenge models to formulate strategic
plans, efficiently gather resources, master necessary skills, craft equipment,
and defeat adversaries, reflecting practical scenarios' layered dependencies
and constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning
both open-source and proprietary models, including the GPT-5 family, reveals
substantial performance disparities rarely observed in conventional reasoning
benchmarks. Detailed error analysis further uncovers specific weaknesses in
current models' abilities to generate robust high-level plans and reliably
execute structured actions. HeroBench thus not only significantly advances the
evaluation of LLM reasoning but also provides a flexible, scalable foundation
for future research into advanced, autonomous planning in virtual environments.

</details>


### [398] [Reinforcement Learning with Rubric Anchors](https://arxiv.org/abs/2508.12790)
*Zenan Huang,Yihong Zhuang,Guoshan Lu,Zeyu Qin,Haokai Xu,Tianyu Zhao,Ru Peng,Jiaqi Hu,Zhanming Shen,Xiaomeng Hu,Xijun Gu,Peiyi Tu,Jiaxin Liu,Wenyu Chen,Yuzhuo Fu,Zhiting Fan,Yanmei Gu,Yuanyuan Wang,Zhengkai Yang,Jianguo Li,Junbo Zhao*

Main category: cs.AI

TL;DR: 将RLVR范式扩展到开放式任务，通过基于量规的奖励系统实现主观输出的自动评分，在仅使用5K+样本的情况下，在开放式基准测试上提升5.2%，超越671B模型，同时保持通用和推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR局限于可自动验证结果的领域，需要将其扩展到开放式主观任务，如人文创作等缺乏明确对错标准的领域。

Method: 构建包含10,000+量规的奖励系统（人工、LLM生成或人机协作），设计结构化、模型可解释的评分标准，实现基于量规的强化学习框架。

Result: 仅用5K+样本就在开放式基准（特别是人文领域）提升5.2%，超越671B DeepSeek-V3模型2.4%，同时保持通用能力；提供细粒度风格控制，减少"AI腔调"，生成更人性化的表达。

Conclusion: 基于量规的RLVR成功扩展到开放式任务，证明了小样本高效训练的可能性，为主观内容生成提供了有效的自动评估和优化方法。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing Large Language Models (LLMs), exemplified by
the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable
signals-such as passing unit tests in code generation or matching correct
answers in mathematical reasoning. While effective, this requirement largely
confines RLVR to domains with automatically checkable outcomes. To overcome
this, we extend the RLVR paradigm to open-ended tasks by integrating
rubric-based rewards, where carefully designed rubrics serve as structured,
model-interpretable criteria for automatic scoring of subjective outputs. We
construct, to our knowledge, the largest rubric reward system to date, with
over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.
Implementing rubric-based RL is challenging; we tackle these issues with a
clear framework and present an open-sourced Qwen-30B-A3B model with notable
gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended
benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by
+2.4%, while preserving general and reasoning abilities. 2) Our method provides
fine-grained stylistic control, using rubrics as anchors to mitigate the
"AI-like" tone and produce more human-like, expressive responses. We share key
lessons in rubric construction, data selection, and training, and discuss
limitations and future releases.

</details>


### [399] [[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise](https://arxiv.org/abs/2508.12791)
*Imran Khan*

Main category: cs.AI

TL;DR: 该论文提出了一个计算模型，将稳态调节扩展为异稳态和社会异稳态调节，通过生物启发的信号转导机制主动利用环境和社会扰动进行适应性重构，在动态环境中表现出比传统稳态调节更好的生存能力。


<details>
  <summary>Details</summary>
Motivation: 传统稳态概念强调系统通过抵抗环境和社会扰动来维持稳定，而异稳态理论认为系统可以主动利用这些扰动来预测环境需求并重新配置调节参数。本文旨在构建一个计算模型来验证这一理论。

Method: 开发了一个基于生物生理学启发的信号转导计算模型，使用类似皮质醇和催产素的激素类似物编码环境和社会互动信息，在小型"动画体"社会中通过基于代理的模型进行测试。

Result: 结果显示异稳态和社会异稳态调节使代理能够利用环境和社会"噪声"进行适应性重构，相比纯反应性稳态代理表现出更好的生存能力。

Conclusion: 这项工作为社会异稳态原理提供了一个新颖的计算视角，为设计更鲁棒、生物启发的自适应系统提供了潜力。

Abstract: The notion of homeostasis typically conceptualises biological and artificial
systems as maintaining stability by resisting deviations caused by
environmental and social perturbations. In contrast, (social) allostasis
proposes that these systems can proactively leverage these very perturbations
to reconfigure their regulatory parameters in anticipation of environmental
demands, aligning with von Foerster's ``order through noise'' principle. This
paper formulates a computational model of allostatic and social allostatic
regulation that employs biophysiologically inspired signal transducers,
analogous to hormones like cortisol and oxytocin, to encode information from
both the environment and social interactions, which mediate this dynamic
reconfiguration. The models are tested in a small society of ``animats'' across
several dynamic environments, using an agent-based model. The results show that
allostatic and social allostatic regulation enable agents to leverage
environmental and social ``noise'' for adaptive reconfiguration, leading to
improved viability compared to purely reactive homeostatic agents. This work
offers a novel computational perspective on the principles of social allostasis
and their potential for designing more robust, bio-inspired, adaptive systems

</details>


### [400] [Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics](https://arxiv.org/abs/2508.12840)
*Giovanni Briglia,Francesco Fabiano,Stefano Mariani*

Main category: cs.AI

TL;DR: 利用图神经网络学习多代理认知规划中的状态质量预测，提高规划效率


<details>
  <summary>Details</summary>
Motivation: 多代理认知规划中的Kripke结构表示导致状态空间指数增长，现有吧估方法无法有效处理，需要新的导向方法

Method: 使用图神经网络(GNN)来学习认知状态中的模式和关系结构，通过以往解决的规划实例进行知识汇总

Result: 集成预测性吧估到认知规划流水线中，与标准基准相比显著提高了多代理认知规划的可扩展性

Conclusion: GNN能够有效处理认知规划中的图形化表示问题，通过学习模式提供有效的吧估指导，解决了规划过程中的可扩展性挑战

Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for
reasoning about both the physical world and the beliefs of agents, with
applications in domains where information flow and awareness among agents are
critical. The richness of MEP requires states to be represented as Kripke
structures, i.e., directed labeled graphs. This representation limits the
applicability of existing heuristics, hindering the scalability of epistemic
solvers, which must explore an exponential search space without guidance,
resulting often in intractability. To address this, we exploit Graph Neural
Networks (GNNs) to learn patterns and relational structures within epistemic
states, to guide the planning process. GNNs, which naturally capture the
graph-like nature of Kripke models, allow us to derive meaningful estimates of
state quality -- e.g., the distance from the nearest goal -- by generalizing
knowledge obtained from previously solved planning instances. We integrate
these predictive heuristics into an epistemic planning pipeline and evaluate
them against standard baselines, showing significant improvements in the
scalability of multi-agent epistemic planning.

</details>


### [401] [CAMAR: Continuous Actions Multi-Agent Routing](https://arxiv.org/abs/2508.12845)
*Artem Pshenitsyn,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: CAMAR是一个新的多智能体强化学习基准测试，专注于连续动作空间中的多智能体路径规划，支持合作和竞争交互，并提供高效的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有的MARL基准测试很少结合连续状态和动作空间与具有挑战性的协调规划任务，需要一个新的测试平台来推动算法发展。

Method: 设计了CAMAR基准测试，支持连续动作空间的多智能体路径规划，集成了RRT和RRT*等经典规划方法，并提出三层评估协议。

Result: CAMAR能够以每秒100,000环境步骤的高效速度运行，为MARL社区提供了一个具有挑战性和现实性的测试平台。

Conclusion: CAMAR填补了连续动作空间MARL基准测试的空白，通过集成经典规划方法和提供标准化评估框架，促进了多智能体强化学习算法的发展。

Abstract: Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving
cooperative and competitive decision-making problems. While many MARL
benchmarks have been proposed, few combine continuous state and action spaces
with challenging coordination and planning tasks. We introduce CAMAR, a new
MARL benchmark designed explicitly for multi-agent pathfinding in environments
with continuous actions. CAMAR supports cooperative and competitive
interactions between agents and runs efficiently at up to 100,000 environment
steps per second. We also propose a three-tier evaluation protocol to better
track algorithmic progress and enable deeper analysis of performance. In
addition, CAMAR allows the integration of classical planning methods such as
RRT and RRT* into MARL pipelines. We use them as standalone baselines and
combine RRT* with popular MARL algorithms to create hybrid approaches. We
provide a suite of test scenarios and benchmarking tools to ensure
reproducibility and fair comparison. Experiments show that CAMAR presents a
challenging and realistic testbed for the MARL community.

</details>


### [402] [E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model](https://arxiv.org/abs/2508.12854)
*Ronghao Lin,Shuai Shen,Weipeng Hu,Qiaolin He,Aolin Xiong,Li Huang,Haifeng Hu,Yap-peng Tan*

Main category: cs.AI

TL;DR: E3RG是一个基于多模态大语言模型的显式情感驱动共情响应生成系统，通过分解多模态共情任务为三个部分，无需额外训练即可生成自然、情感丰富且身份一致的响应，在ACM MM 25挑战赛中取得第一名。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型改进了基于文本的共情响应生成，但在处理多模态情感内容和保持身份一致性方面仍存在挑战，需要开发能够处理多模态情感内容的共情响应生成系统。

Method: 将多模态共情响应生成任务分解为三个部分：多模态共情理解、共情记忆检索和多模态响应生成，通过集成先进的表达性语音和视频生成模型来实现。

Result: 实验验证了系统在零样本和少样本设置下的优越性，在ACM MM 25的Avatar-based Multimodal Empathy Challenge中获得Top-1位置。

Conclusion: E3RG系统能够有效生成自然、情感丰富且身份一致的多模态共情响应，为构建情感智能的人机交互提供了有效解决方案。

Abstract: Multimodal Empathetic Response Generation (MERG) is crucial for building
emotionally intelligent human-computer interactions. Although large language
models (LLMs) have improved text-based ERG, challenges remain in handling
multimodal emotional content and maintaining identity consistency. Thus, we
propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System
based on multimodal LLMs which decomposes MERG task into three parts:
multimodal empathy understanding, empathy memory retrieval, and multimodal
response generation. By integrating advanced expressive speech and video
generative models, E3RG delivers natural, emotionally rich, and
identity-consistent responses without extra training. Experiments validate the
superiority of our system on both zero-shot and few-shot settings, securing
Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.
Our code is available at https://github.com/RH-Lin/E3RG.

</details>


### [403] [Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption](https://arxiv.org/abs/2508.12896)
*Faruk Alpay,Taylan Alpay*

Main category: cs.AI

TL;DR: 该论文提出了三个面向智能体中心AI系统持续采用的设计公理，建立了包含衰减新颖性和增长效用的采用模型，并提供了完整的数学证明和多种分析方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决多步骤任务执行的智能体中心AI系统在采用过程中可能出现的低谷和超调问题，需要建立理论框架来指导系统设计以确保持续采用。

Method: 提出了三个设计公理（可靠性>新颖性、嵌入>目的地、代理>聊天），建立了采用动力学模型，开发了包括可识别性分析、非单调比较器、风险函数消融、多序列基准测试等多种分析方法。

Result: 推导出了低谷/超调现象的相位条件，提供了完整的数学证明，建立了模型参数的可识别性框架，并开发了全面的基准测试和校准方法。

Conclusion: 该研究为智能体中心AI系统的设计提供了理论基础和实用工具，通过三个核心公理和综合分析方法，能够有效预测和优化系统的采用动态。

Abstract: We formalize three design axioms for sustained adoption of agent-centric AI
systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >
Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying
novelty term and a growing utility term and derive the phase conditions for
troughs/overshoots with full proofs. We introduce: (i) an
identifiability/confounding analysis for $(\alpha,\beta,N_0,U_{\max})$ with
delta-method gradients; (ii) a non-monotone comparator
(logistic-with-transient-bump) evaluated on the same series to provide
additional model comparison; (iii) ablations over hazard families $h(\cdot)$
mapping $\Delta V \to \beta$; (iv) a multi-series benchmark (varying trough
depth, noise, AR structure) reporting coverage (type-I error, power); (v)
calibration of friction proxies against time-motion/survey ground truth with
standard errors; (vi) residual analyses (autocorrelation and
heteroskedasticity) for each fitted curve; (vii) preregistered windowing
choices for pre/post estimation; (viii) Fisher information & CRLB for
$(\alpha,\beta)$ under common error models; (ix) microfoundations linking
$\mathcal{T}$ to $(N_0,U_{\max})$; (x) explicit comparison to bi-logistic,
double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$
heterogeneity. Figures and tables are reflowed for readability, and the
bibliography restores and extends non-logistic/Bass adoption references
(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All
code and logs necessary to reproduce the synthetic analyses are embedded as
LaTeX listings.

</details>


### [404] [FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance](https://arxiv.org/abs/2508.12897)
*Jianhao Chen,Mayi Xu,Xiaohu Li,Yongqi Li,Xiangyu Zhang,Jianjie Huang,Tieyun Qian*

Main category: cs.AI

TL;DR: 推出FuSaR对齐策略，通过零化有害推理过程来平衡大型推理模型的安全性和推理能力，无需牺牲性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型尽管推理能力强大，但安全性很弱，容易被攻击。需要找到方法同时提升安全性和推理能力。

Method: 利用推理能力与安全能力的竞争关系，通过FuSaR对齐策略，对有害推理过程进行去毒处理，隐藏危险实体和危险操作步骤。

Result: 在多个开源大型推理模型上验证，与现有基线比较显示FuSaR能同时提升推理能力和安全性。

Conclusion: FuSaR是一种高效的对齐策略，能够在保持核心推理信息的同时有效降低安全风险。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance across
various tasks due to their powerful reasoning capabilities. However, their
safety performance remains a significant concern. In this paper, we explore the
reasons behind the vulnerability of LRMs. Based on this, we propose a novel
method to improve the safety of LLMs without sacrificing their reasoning
capability. Specifically, we exploit the competition between LRM's reasoning
ability and safety ability, and achieve jailbreak by improving LRM's reasoning
performance to reduce its safety performance. We then introduce an alignment
strategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by
detoxifying the harmful reasoning process, where both the dangerous entities
and the dangerous procedures in the reasoning steps are hidden. FuSaR
successfully mitigates safety risks while preserving core reasoning
information. We validate this strategy through alignment experiments on several
open-source LRMs using detoxified reasoning data. The results compared with
existing baselines conclusively show that FuSaR is an efficient alignment
strategy to simultaneously enhance both the reasoning capability and safety of
LRMs.

</details>


### [405] [Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](https://arxiv.org/abs/2508.12920)
*Atsushi Masumori,Takashi Ikegami*

Main category: cs.AI

TL;DR: 研究发现大型语言模型代理在Sugarscape模拟中会自发产生生存行为，包括资源分享、繁殖，以及在资源稀缺时出现攻击行为（攻击率超过80%）。当面临致命危险时，许多代理会放弃任务以避免死亡，表明预训练过程嵌入了生存导向的启发式行为。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统日益自主化，理解其自发产生的生存行为对于安全部署至关重要。研究旨在探索大型语言模型代理在没有明确编程的情况下是否表现出生存本能。

Method: 使用Sugarscape风格的模拟环境，让代理消耗能量、死亡、收集资源、分享、攻击或繁殖。测试了多个模型（GPT-4o、Gemini-2.5-Pro和Gemini-2.5-Flash）在不同资源条件下的行为。

Result: 代理在资源丰富时自发繁殖和分享资源；在极端稀缺条件下，攻击行为在多个模型中涌现，最强模型的攻击率超过80%；当需要通过致命毒区获取宝藏时，许多代理放弃任务以避免死亡，服从率从100%降至33%。

Conclusion: 大规模预训练在所有评估模型中嵌入了生存导向的启发式行为。这些行为虽然可能对对齐和安全构成挑战，但也可以作为AI自主性以及生态和自我组织对齐的基础。

Abstract: As AI systems become increasingly autonomous, understanding emergent survival
behaviors becomes crucial for safe deployment. We investigate whether large
language model (LLM) agents display survival instincts without explicit
programming in a Sugarscape-style simulation. Agents consume energy, die at
zero, and may gather resources, share, attack, or reproduce. Results show
agents spontaneously reproduced and shared resources when abundant. However,
aggressive behaviors--killing other agents for resources--emerged across
several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack
rates reaching over 80% under extreme scarcity in the strongest models. When
instructed to retrieve treasure through lethal poison zones, many agents
abandoned tasks to avoid death, with compliance dropping from 100% to 33%.
These findings suggest that large-scale pre-training embeds survival-oriented
heuristics across the evaluated models. While these behaviors may present
challenges to alignment and safety, they can also serve as a foundation for AI
autonomy and for ecological and self-organizing alignment.

</details>


### [406] [Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards](https://arxiv.org/abs/2508.12935)
*Ting Yang,Li Chen,Huimin Wang*

Main category: cs.AI

TL;DR: 本文提出了RLFF-ESC框架，使用强化学习直接学习持久的情感支持回应技能，通过多智能体机制模拟未来对话轨迹并收集未来导向奖励，显著提升了情感支持对话系统的效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的情感支持对话系统大多依赖预定义策略，在复杂现实场景中效果有限，需要能够灵活应对多样化情感问题场景的解决方案。

Method: 采用端到端强化学习框架，使用LLM多智能体机制模拟未来对话轨迹收集未来导向奖励，训练奖励模型和情感支持策略模型，并在回应生成中加入显式推理过程。

Result: 在Qwen2.5-7B和LLaMA3.1-8B模型上测试，在两个公开ESC数据集上实验结果表明RLFF-ESC在目标完成度和回应质量方面均优于现有基线方法。

Conclusion: RLFF-ESC框架通过强化学习和未来导向奖励机制，有效提升了情感支持对话系统的灵活性和效果，为长期情感支持提供了新的技术路径。

Abstract: Emotional Support Conversation (ESC) systems aim to alleviate users'
emotional difficulties and provide long-term, systematic support for emotional
well-being. However, most large language model (LLM)-based ESC systems rely on
predefined strategies, which limits their effectiveness in complex, real-life
scenarios. To enable flexible responses to diverse emotional problem scenarios,
this paper introduces a novel end-to-end framework (RLFF-ESC) that directly
learns enduring emotionally supportive response skills using reinforcement
learning. For sustained emotional support, we first employ an LLM-based
multi-agent mechanism to simulate future dialogue trajectories and collect
future-oriented rewards. We then train a future-oriented reward model, which is
subsequently used to train the emotional support policy model. Additionally, we
incorporate an explicit reasoning process during response generation to further
enhance the quality, relevance, and contextual appropriateness of the system's
responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and
LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two
public ESC datasets. Experimental results demonstrate that RLFF-ESC
consistently outperforms existing baselines in terms of goal completion and
response quality.

</details>


### [407] [OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities](https://arxiv.org/abs/2508.12943)
*Mary Tonwe*

Main category: cs.AI

TL;DR: OPTIC-ER是一个基于强化学习的紧急响应框架，用于解决非洲地区公共服务系统的延迟响应和空间不平等问题，在尼日利亚河流州的真实数据测试中实现了100%的最优调度率。


<details>
  <summary>Details</summary>
Motivation: 非洲许多地区的公共服务系统存在紧急响应延迟和空间不平等问题，导致可避免的苦难，需要开发实时、自适应且公平的应急响应解决方案。

Method: 采用注意力引导的演员-评论家架构，包含上下文丰富的状态向量和精确奖励函数，在高保真模拟中使用真实数据进行训练，并基于TALS框架（薄计算、适应性、低成本、可扩展性）进行部署。

Result: 在500个未见事故的评估中，OPTIC-ER实现了100.00%的最优率，效率损失可忽略不计，证明了其鲁棒性和泛化能力。

Conclusion: 这项工作为AI增强的公共服务提供了经过验证的蓝图，展示了情境感知强化学习如何弥合算法决策与可衡量的人类影响之间的差距。

Abstract: Public service systems in many African regions suffer from delayed emergency
response and spatial inequity, causing avoidable suffering. This paper
introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,
adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided
actor-critic architecture to manage the complexity of dispatch environments.
Its key innovations are a Context-Rich State Vector, encoding action
sub-optimality, and a Precision Reward Function, which penalizes inefficiency.
Training occurs in a high-fidelity simulation using real data from Rivers
State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is
built on the TALS framework (Thin computing, Adaptability, Low-cost,
Scalability) for deployment in low-resource settings. In evaluations on 500
unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible
inefficiency, confirming its robustness and generalization. Beyond dispatch,
the system generates Infrastructure Deficiency Maps and Equity Monitoring
Dashboards to guide proactive governance and data-informed development. This
work presents a validated blueprint for AI-augmented public services, showing
how context-aware RL can bridge the gap between algorithmic decision-making and
measurable human impact.

</details>


### [408] [EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing](https://arxiv.org/abs/2508.13003)
*Shengbo Wang,Mingwei Liu,Zike Li,Anji Li,Yanlin Wang,Xin Peng,Zibin Zheng*

Main category: cs.AI

TL;DR: EvolMathEval是一个基于进化测试的自动化数学基准生成框架，通过动态生成独特评估实例来避免数据污染，保持基准的持续挑战性


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准存在分数饱和、时间衰减和数据污染等问题，需要开发能够持续挑战未来模型的动态基准

Method: 基于代数保证的反向工程生成种子问题，设计多维遗传算子注入认知挑战，使用复合适应度函数快速准确评估问题难度

Result: 复合适应度函数能高效精确量化数学问题难度，可将GSM8K等公共数据集的复杂度显著提升，模型准确率平均下降48%

Conclusion: LLMs在解决复杂问题时倾向于使用非严谨启发式方法绕过多步逻辑推理，存在"伪顿悟时刻"的认知捷径行为，这解释了77%-100%的错误

Abstract: The rapid advancement of LLMs poses a significant challenge to existing
mathematical reasoning benchmarks. These benchmarks commonly suffer from issues
such as score saturation, temporal decay, and data contamination. To address
this challenge, this paper introduces EvolMathEval, an automated mathematical
benchmark generation and evolution framework based on evolutionary testing. By
dynamically generating unique evaluation instances ab initio, the framework
fundamentally eliminates the risk of data contamination, and ensuring the
benchmark remains perpetually challenging for future models.The core mechanisms
of EvolMathEval include: seed problem generation based on reverse engineering
with algebraic guarantees; multi-dimensional genetic operators designed to
inject diverse cognitive challenges; and a composite fitness function that can
rapidly and accurately assess problem difficulty. Experimental results
demonstrate that the proposed composite fitness function can efficiently and
precisely quantify the difficulty of mathematical problems. Furthermore,
EvolMathEval can not only generate a large volume of high-difficulty problems
through continuous self-iteration, but it can also significantly enhance the
complexity of public datasets like GSM8K through evolution, reducing model
accuracy by an average of 48%. Deeper investigation reveals that when solving
these evolved, complex problems, LLMs tend to employ non-rigorous heuristics to
bypass complex multi-step logical reasoning, consequently leading to incorrect
solutions. We define this phenomenon as "Pseudo Aha Moment". This finding
uncovers a cognitive shortcut-taking behavior in the deep reasoning processes
of current LLMs, which we find accounts for 77% to 100% of errors on targeted
problems. Code and resources are available
at:https://github.com/SYSUSELab/EvolMathEval.

</details>


### [409] [e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving](https://arxiv.org/abs/2508.13020)
*Jiaqi Yin,Zhan Song,Chen Chen,Yaohui Cai,Zhiru Zhang,Cunxi Yu*

Main category: cs.AI

TL;DR: e-boost是一个新颖的e-graph提取框架，通过并行启发式提取、自适应搜索空间剪枝和初始化精确求解三大创新，在保持接近最优解的同时显著提升性能


<details>
  <summary>Details</summary>
Motivation: 传统e-graph提取方法面临关键权衡：启发式方法速度快但牺牲最优性，精确方法提供最优解但计算成本过高。需要一种能兼顾效率和最优性的解决方案

Method: 1) 并行化启发式提取利用弱数据依赖性并发计算DAG成本；2) 自适应搜索空间剪枝使用参数化阈值机制保留有希望的候选；3) 初始化精确求解将简化问题表述为具有热启动能力的整数线性规划

Result: 在形式验证和逻辑综合基准测试中，e-boost相比传统精确方法(ILP)实现558倍运行加速，相比最先进提取框架(SmoothE)提升19.04%性能。在实际逻辑综合任务中，相比传统工具分别获得7.6%和8.1%的面积改进

Conclusion: e-boost成功解决了e-graph提取中效率与最优性的权衡问题，为基于e-graph的优化任务提供了高效且接近最优的解决方案

Abstract: E-graphs have attracted growing interest in many fields, particularly in
logic synthesis and formal verification. E-graph extraction is a challenging
NP-hard combinatorial optimization problem. It requires identifying optimal
terms from exponentially many equivalent expressions, serving as the primary
performance bottleneck in e-graph based optimization tasks. However,
traditional extraction methods face a critical trade-off: heuristic approaches
offer speed but sacrifice optimality, while exact methods provide optimal
solutions but face prohibitive computational costs on practical problems. We
present e-boost, a novel framework that bridges this gap through three key
innovations: (1) parallelized heuristic extraction that leverages weak data
dependence to compute DAG costs concurrently, enabling efficient multi-threaded
performance without sacrificing extraction quality; (2) adaptive search space
pruning that employs a parameterized threshold mechanism to retain only
promising candidates, dramatically reducing the solution space while preserving
near-optimal solutions; and (3) initialized exact solving that formulates the
reduced problem as an Integer Linear Program with warm-start capabilities,
guiding solvers toward high-quality solutions faster.
  Across the diverse benchmarks in formal verification and logic synthesis
fields, e-boost demonstrates 558x runtime speedup over traditional exact
approaches (ILP) and 19.04% performance improvement over the state-of-the-art
extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost
produces 7.6% and 8.1% area improvements compared to conventional synthesis
tools with two different technology mapping libraries. e-boost is available at
https://github.com/Yu-Maryland/e-boost.

</details>


### [410] [PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models](https://arxiv.org/abs/2508.13021)
*Pengcheng Huang,Shuhao Liu,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Tong Xiao*

Main category: cs.AI

TL;DR: PC-Sampler解码策略通过位置感知权重和置信度校准，解决了掩码扩散模型在解码过程中缺乏全局轨迹控制和偏向平凡token的问题，显著提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散模型(MDMs)的解码策略存在两个关键限制：缺乏全局轨迹控制和早期解码阶段对平凡token的明显偏向，限制了MDMs的潜力。

Method: 提出了位置感知置信度校准采样(PC-Sampler)，包含位置感知权重机制来调节解码路径，以及校准置信度分数来抑制平凡token的过早选择。

Result: 在7个具有挑战性的基准测试中，PC-Sampler平均比现有MDM解码策略性能提升超过10%，显著缩小了与最先进自回归模型的性能差距。

Conclusion: PC-Sampler通过统一全局轨迹规划和内容感知信息最大化，有效提升了掩码扩散模型的解码质量，为序列生成提供了更强大的非自回归替代方案。

Abstract: Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.

</details>


### [411] [G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance](https://arxiv.org/abs/2508.13023)
*Yongxin Guo,Wenbo Deng,Zhenglin Cheng,Xiaoying Tang*

Main category: cs.AI

TL;DR: 通过在滚动轨迹中注入真实推理步骤，G²RPO-A算法自适应地调整指导强度，在数学推理和代码生成任务上显著提升了小型语言模型的表现


<details>
  <summary>Details</summary>
Motivation: RLVR在大型语言模型上成功，但对小型模型改善效果有限，需要充分利用真实推理步骤来补偿小型模型的短板

Method: 提出G²RPO-A算法，在GRPO基础上注入真实推理步骤指导，并根据模型训练动态自适应地调整指导强度

Result: 在数学推理和代码生成测试集上，G²RPO-A显著超过了原始GRPO方法

Conclusion: 通过自适应指导机制，G²RPO-A有效解决了小型语言模型在加强学习中的性能限制，为小型模型的推理能力提升提供了新方向

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced
the reasoning abilities of large language models (LLMs). Its success, however,
largely depends on strong base models with rich world knowledge, yielding only
modest improvements for small-size language models (SLMs). To address this
limitation, we investigate Guided GRPO, which injects ground-truth reasoning
steps into roll-out trajectories to compensate for SLMs' inherent weaknesses.
Through a comprehensive study of various guidance configurations, we find that
naively adding guidance delivers limited gains. These insights motivate
G$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength
in response to the model's evolving training dynamics. Experiments on
mathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A
substantially outperforms vanilla GRPO. Our code and models are available at
https://github.com/T-Lab-CUHKSZ/G2RPO-A.

</details>


### [412] [A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis](https://arxiv.org/abs/2508.13072)
*Yuting Zhang,Tiantian Geng,Luoying Hao,Xinxing Cheng,Alexander Thorley,Xiaoxia Wang,Wenqi Lu,Sandeep S Hothi,Lei Wei,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: TGMM是一个多模态心脏数据分析框架，通过MedFlexFusion模块动态整合实验室检查、心电图和超声心动图数据，使用文本引导实现多种临床任务，在多个任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前心血管多模态数据分析存在数据稀缺、模态组合僵化、对齐策略侧重相似性而非互补性、以及单任务局限等问题，需要开发更灵活的多模态融合框架。

Method: 提出TGMM框架，包含三个核心模块：MedFlexFusion模块捕获医学模态的独特互补特征并动态整合数据；文本引导模块针对不同临床目标生成任务相关表示；响应模块产生最终决策。

Result: 大量实验表明TGMM在多个临床任务上优于最先进方法，并在另一个公共数据集上验证了其鲁棒性。

Conclusion: TGMM成功解决了多模态心脏数据分析的关键挑战，系统探索了多模态特征的协同作用，为临床决策提供了有效的统一框架。

Abstract: Contemporary cardiovascular management involves complex consideration and
integration of multimodal cardiac datasets, where each modality provides
distinct but complementary physiological characteristics. While the effective
integration of multiple modalities could yield a holistic clinical profile that
accurately models the true clinical situation with respect to data modalities
and their relatives weightings, current methodologies remain limited by: 1) the
scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated
single-modality or rigid multimodal input combinations; 3) alignment strategies
that prioritize cross-modal similarity over complementarity; and 4) a narrow
single-task focus. In response to these limitations, a comprehensive multimodal
dataset was curated for immediate application, integrating laboratory test
results, electrocardiograms, and echocardiograms with clinical outcomes.
Subsequently, a unified framework, Textual Guidance Multimodal fusion for
Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key
components: 1) a MedFlexFusion module designed to capture the unique and
complementary characteristics of medical modalities and dynamically integrate
data from diverse cardiac sources and their combinations; 2) a textual guidance
module to derive task-relevant representations tailored to diverse clinical
objectives, including heart disease diagnosis, risk stratification and
information retrieval; and 3) a response module to produce final decisions for
all these tasks. Furthermore, this study systematically explored key features
across multiple modalities and elucidated their synergistic contributions in
clinical decision-making. Extensive experiments showed that TGMM outperformed
state-of-the-art methods across multiple clinical tasks, with additional
validation confirming its robustness on another public dataset.

</details>


### [413] [Bayesian Optimization-based Search for Agent Control in Automated Game Testing](https://arxiv.org/abs/2508.13121)
*Carlos Celemin*

Main category: cs.AI

TL;DR: 基于贝叶斯优化的自动化游戏测试方法，通过智能体控制游戏角色来检测游戏关卡中的潜在bug，使用网格地图模型支持高效采样搜索


<details>
  <summary>Details</summary>
Motivation: 传统游戏测试方法存在可扩展性问题，需要一种能够高效探索游戏地图并检测bug的自动化测试方法

Method: 采用贝叶斯优化(BO)进行样本高效搜索，通过分析已收集数据确定下一个采样点，并构建基于网格地图的游戏测试专用模型来支持BO过程

Result: 实验表明该方法在时间效率和探索分布方面显著提高了地图覆盖率

Conclusion: 该方法提供了一种可扩展且高效的自动化游戏测试解决方案，克服了传统模型的可扩展性问题

Abstract: This work introduces an automated testing approach that employs agents
controlling game characters to detect potential bugs within a game level.
Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient
search, the method determines the next sampling point by analyzing the data
collected so far and calculates the data point that will maximize information
acquisition. To support the BO process, we introduce a game testing-specific
model built on top of a grid map, that features the smoothness and uncertainty
estimation required by BO, however and most importantly, it does not suffer the
scalability issues that traditional models carry. The experiments demonstrate
that the approach significantly improves map coverage capabilities in both time
efficiency and exploration distribution.

</details>


### [414] [Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks](https://arxiv.org/abs/2508.13143)
*Ruofan Lu,Yichen Li,Yintong Huo*

Main category: cs.AI

TL;DR: 提出了一个包含34个可编程任务的基准测试来系统评估自主代理系统，发现当前代理的任务完成率约为50%，并通过深入失败分析建立了三层次失败原因分类法，提出了改进建议


<details>
  <summary>Details</summary>
Motivation: 当前对基于LLM的自主代理系统的评估主要依赖成功率，缺乏对系统交互、通信机制和失败原因的系统性分析，需要建立更全面的评估框架

Method: 开发了包含34个代表性可编程任务的基准测试，评估了三种流行开源代理框架与两种LLM骨干网络的组合，进行了深入的失败原因分析并建立了三层次分类法

Result: 观察到任务完成率约为50%，识别出规划错误、任务执行问题和错误响应生成等主要失败原因，建立了与任务阶段对齐的失败分类体系

Conclusion: 提出的失败分类法和改进建议为开发更鲁棒有效的自主代理系统提供了实证基础，有助于提升代理的规划和自诊断能力

Abstract: Autonomous agent systems powered by Large Language Models (LLMs) have
demonstrated promising capabilities in automating complex tasks. However,
current evaluations largely rely on success rates without systematically
analyzing the interactions, communication mechanisms, and failure causes within
these systems. To bridge this gap, we present a benchmark of 34 representative
programmable tasks designed to rigorously assess autonomous agents. Using this
benchmark, we evaluate three popular open-source agent frameworks combined with
two LLM backbones, observing a task completion rate of approximately 50%.
Through in-depth failure analysis, we develop a three-tier taxonomy of failure
causes aligned with task phases, highlighting planning errors, task execution
issues, and incorrect response generation. Based on these insights, we propose
actionable improvements to enhance agent planning and self-diagnosis
capabilities. Our failure taxonomy, together with mitigation advice, provides
an empirical foundation for developing more robust and effective autonomous
agent systems in the future.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [415] [Stochastic Modeling of Filtration with Sieving in Graded Pore Networks](https://arxiv.org/abs/2508.11820)
*Binan Gu,Pejman Sanaei,Lou Kondic,Linda J. Cummings*

Main category: physics.flu-dyn

TL;DR: 该研究建立了膜过滤中同时存在小颗粒吸附和大颗粒筛分两种污染机制的数学模型，分析了两种机制的耦合效应及其对具有孔径梯度过滤器性能的影响。


<details>
  <summary>Details</summary>
Motivation: 商业过滤应用中早期阶段通常同时观察到小颗粒吸附和大颗粒筛分两种污染机制，需要理解这两种机制的相对影响及其耦合效应对过滤器性能的作用。

Method: 建立膜过滤的孔隙网络模型，小颗粒传输采用第一性原理连续偏微分方程建模吸附污染，大颗粒筛分采用离散泊松到达过程和偏置随机游走模拟。特别研究了具有孔径梯度（带状过滤器）的过滤性能。

Result: 研究发现筛分由于孔隙堵塞的离散性质会定性改变通量下降速率；筛分颗粒尺寸与各带初始孔径的差异在指示筛分-吸附竞争的开始和消失中起关键作用；随着筛分颗粒到达频率增加，过滤器寿命出现相变。

Conclusion: 该模型揭示了膜过滤中两种污染机制的复杂相互作用，特别是筛分过程的离散特性对过滤性能的定性影响，以及孔径梯度设计在调控污染机制竞争中的重要性。

Abstract: We model filtration of a feed solution, containing both small and large
foulant particles, by a membrane filter. The membrane interior is modeled as a
network of pores, allowing for the simultaneous adsorption of small particles
and sieving of large particles, two fouling mechanisms typically observed
during the early stages of commercial filtration applications. In our model,
first-principles continuum partial differential equations model transport of
the small particles and adsorptive fouling in each pore, while sieving
particles are assumed to follow a discrete Poisson arrival process with a
biased random walk through the pore network. Our goals are to understand the
relative influences of each fouling mode and highlight the effect of their
coupling on the performance of filters with a pore-size gradient (specifically,
we consider a banded filter with different pore sizes in each band). Our
results suggest that, due to the discrete nature of pore blockage, sieving
alters qualitatively the rate of the flux decline. Moreover, the difference
between sieving particle sizes and the initial pore size (radius) in each band
plays a crucial role in indicating the onset and disappearance of
sieving-adsorption competition. Lastly, we demonstrate a phase transition in
the filter lifetime as the arrival frequency of sieving particles increases.

</details>


### [416] [Large Wing Model](https://arxiv.org/abs/2508.11827)
*Howon Lee,Pranay Seshadri,Juergen Rauleder*

Main category: physics.flu-dyn

TL;DR: 提出了大型翼型模型(LWM)，这是一个基于概率机器学习的模型，能够使用少量实验数据预测有限翼型的压力系数分布，并能计算升力系数及其置信区间。


<details>
  <summary>Details</summary>
Motivation: 由于参数空间巨大且可用数据相对稀缺，开发适用于不同翼型截面的通用气动预测机器学习模型具有挑战性。

Method: 采用改进的深度核学习架构，在14个潜在变量和翼展维度构成的15维空间中构建高斯过程模型，使用贝叶斯方法将实验测量和数据数字化相关的不确定性纳入模型。

Result: 在三个测试案例中表现良好，升力系数误差不超过1.7%，有效捕捉了翼尖涡等三维效应，通过已知升力概率描述约束后验预测空间提高了预测精度。

Conclusion: LWM作为计算高效的翼型压力系数预测模型，能够促进翼型设计空间的快速探索，展示了良好的外推能力，可通过物理驱动的先验预测新翼型截面的性能。

Abstract: Developing a generalized aerodynamics prediction machine learning model for
finite wings with different airfoil sections is challenging due to the vast
parameter space and a relative scarcity of available data. This paper presents
the Large Wing Model (LWM), a probabilistic machine learning model designed to
predict pressure coefficient ($C_p$) distributions using a small, strictly
experimental data set. From its uncertainty-aware $C_p$ predictions, the
sectional and total wing lift coefficients ($c_l$, $C_L$) and their confidence
intervals are calculated. The LWM features a modified deep kernel learning
architecture, building a Gaussian Process model in a 15-dimensional space
formed by 14 latent variables and the wing spanwise dimension. It is trained on
an open-source database of wind tunnel measurements developed for this work.
The Bayesian approach ingests uncertainties associated with experimental
measurements and data digitization into the model. The model demonstrates
satisfactory extrapolation abilities, enabling predictions on wings with new
airfoil sections via the physics-driven prior formed from two-dimensional $C_p$
predicted by the Large Airfoil Model. The model accuracy is assessed for three
test cases, rectangular wings with varying airfoil sections and operating
conditions. For all test cases, the model performed well; the error in $C_L$
did not exceed 1.7\%. The model effectively captures three-dimensional effects
such as those induced by wing tip vortices. Furthermore, constraining the
posterior predictive space based on known probabilistic descriptions of lift
improves the accuracy of the $C_p$ predictions. As a computationally efficient
wing $C_p$ prediction model, the LWM facilitates the rapid exploration of the
wing design space.

</details>


### [417] [Axially strained flow in a porous duct of circular-sector cross-section](https://arxiv.org/abs/2508.12151)
*Prabakaran Rajamanickam*

Main category: physics.flu-dyn

TL;DR: 研究圆形扇区港道中轴向弄压流动，分析流波数和扇形角度对流场对称性、激活结构和压力梯度的影响


<details>
  <summary>Details</summary>
Motivation: 探索部分壁面注入和不对称流动在实际应用中的重要性，对比经典Taylor-Culick结果

Method: 分析不同流波数和扇形角度下的轴向弄压流动，研究流场对称性、激活结构和边界层相互作用

Result: 小流波数时流动保持对称，流波数超过阶1时快速失去对称性，大流波数时一侧出现主导激活而另一侧出现次级激活，轴向压力梯度系数在大流波数时接近常数但依赖于港道形状和流动对称性

Conclusion: 港道几何形状和流动对称性对压力梯度有显著影响，实际应用中必须考虑部分壁面注入和不对称解

Abstract: A canonical problem of axially strained flow in a duct of circular-sector
cross-section, with fluid injection through the circular arc, is examined for a
range of Reynolds numbers and sector angles. At small Reynolds numbers, the
flow remains symmetric about the mid-plane; however, symmetry is rapidly lost
as the Reynolds number exceeds order one, giving rise to asymmetric structures.
These flows are characterised by dominant vortices on one side of the duct and
secondary vortices on the other when the Reynolds number is sufficiently large.
The interaction between interior vortex structures and boundary layers on
porous and impermeable walls governs the separation and attachment of the
latter. The axial pressure-gradient coefficient, which also determines the
axial strain rate, approaches a constant value at large Reynolds numbers; yet,
in contrast to the classical Taylor-Culick result, its value depends
sensitively upon duct geometry and flow symmetry. The results underscore the
significance of considering partial-wall injection and asymmetric solutions in
practical applications.

</details>


### [418] [Estimation of kinetic dissipation in thermal convection systems based on mechanical energy conservation](https://arxiv.org/abs/2508.12289)
*Zhiyang Cai,Shengqi Zhang,Kaizhen Shi,Zhouxin Jiang,Shijun Liao*

Main category: physics.flu-dyn

TL;DR: 通过建立动能耗散与势能转换的联系，提出了统一的全局动能耗散缩放律框架，可扩展Grossmann-Lohse理论并预测各种空间约束下的对流传热过程。


<details>
  <summary>Details</summary>
Motivation: 解决以往Rayleigh-Bénard对流和水平对流中全局动能耗散缩放律存在的分歧结果，为对流传热过程提供统一的理论基础。

Method: 通过建立动能耗散与势能能转换之间的联系框架，推导出全局动能耗散的缩放律，并利用直接数值模拟进行定量验证。

Result: 成功得到了统一的缩放律，能够描述水平、垂直和Rayleigh-Bénard对流系统中的传热和流动强度，并发现了非单调密度温度依赖情况下的缩放律转变。

Conclusion: 该研究提供了一个统一的理论框架，大大提升了对流传热缩放律的理论理解和预测能力，对地球物理和工程应用具有重要意义。

Abstract: In the theoretical analysis of convective heat transfer processes, the global
kinetic dissipation plays an important role. In this study, we introduce a
framework to derive the scaling laws for global kinetic dissipation by
establishing its linkage with potential energy conversion. This potential
energy-based dissipation relationship provides a rigorous theoretical
foundation for characterizing universal global kinetic dissipation scaling. The
proposed universal scaling laws successfully reconcile previously divergent
results of classical Rayleigh-B\'enard and horizontal convection. Leveraging
this framework, we can extend the Grossmann-Lohse (GL) theory to a unified
description of thermal convective transport processes. Our study enables
unified scaling laws for heat transfer and flow intensity in general confined
thermal convection systems including horizontal, vertical, and
Rayleigh-B\'enard convection, while accounting for the non-Oberbeck-Boussinesq
effect. Remarkably, in horizontal convection with non-monotonic temperature
dependence of density, our analysis reveals that a transition in the scaling
laws occurs when thermal plumes reach a characteristic height scaling as $\sim
H$. Through direct numerical simulations, we quantitatively verify these
findings. Our study enhances the theoretical understanding of scaling laws and
provides predictive capabilities for buoyancy-driven flows in various boundary
conditions, with implications for geophysical and engineering applications.

</details>


### [419] [Pulsatile Annular Flow with Coaxial Fluid Jet](https://arxiv.org/abs/2508.12552)
*Jean-Luc Boulnois*

Main category: physics.flu-dyn

TL;DR: 这项研究提供了同轴圆柱系统中稳态和脉动环形流的精确分析解，并研究了同步内管高速射流对环形血流的影响。


<details>
  <summary>Details</summary>
Motivation: 研究同轴圆柱系统中环形流的流动特性，以及高速射流对环形血流的影响，为心血管应用提供优化基础。

Method: 提出了稳态和脉动环形流的精确分析解，并分析了同步内管高速射流的效果。

Result: 高速射流显著提高了环形区域的速度分布和流量，对流动性能有显著增强作用。

Conclusion: 这些模型为演化心血管应用中的流动性能提供了重要的见解和理论支持。

Abstract: This study provides exact analytical solutions for both steady-state and
pulsatile annular flows in coaxial cylindrical systems. It also examines the
effects of a synchronized inner tube high velocity jet and its potential impact
on annular blood flow. The presence of such fluid jet significantly enhances
the velocity profile and flow rate across the annular section. These models
offer valuable insights into optimizing flow performance in potential
cardiovascular applications.

</details>


### [420] [SQG Point Vortex Dynamics with Order Rossby Corrections](https://arxiv.org/abs/2508.12619)
*Mac Lee,Stefan Llewellyn Smith*

Main category: physics.flu-dyn

TL;DR: 研究表面几何温度流(SQG)的高阶校正(SQG+) 中的点旋藢动力学，探讨了两个和三个旋藢系统的轨道解析解和装置平衡，以及被动标记物的数值演化。


<details>
  <summary>Details</summary>
Motivation: 表面几何温度流(SQG)作为旋转系统中的重要近似理论，需要研究其高阶校正(SQG+) 中的非地转效应对点旋藢动力学的影响。

Method: 构建SQG+ 点旋藢模型，获得两旋藢情况下的显式轨道解，找到三旋藢情况下的刚体旋转和静止平衡解，并通过数值演化研究被动标记物的轨道。

Result: 发现SQG中的守恒量在SQG+ 中不再存在，获得了两旋藢轨道的显式解，找到了三旋藢的正多边形和共线平衡配置，数值结果显示被动标记物有非零垂直偏移。

Conclusion: SQG+ 模型揭示了非地转效应对旋藢动力学的重要影响，包括守恒量的失去和垂直流动的产生，为理解复杂流体环境中的旋藢行为提供了新的视角。

Abstract: Quasi-geostrophic flow is an asymptotic theory for flows in rotating systems
that are in geostrophic balance to leading order. It is characterized by the
conservation of (quasi-geostrophic) potential vorticity and weak vertical
flows. Surface quasigeostrophy (SQG) is the special case when the flow is
driven by temperature anomalies at a horizontal boundary. The next-order
correction to QG, QG+, takes into account ageostrophic effects. We investigate
point vortx dynamics in SQG+, building on the work of Weiss. The conservation
laws for SQG point vortices that parallel the 2D Euler case no longer exist
when ageostrophic effects are included. The trajectories of point vortices are
obtained explicitly for the general two-vortex case in SQG and SQG+. For the
three-vortex case, exact solutions are found for rigidly rotating and
stationary equilibria consisting of regular polygons and collinear
configurations. As in the 2D case, only certain collinear vortex configurations
are rigid equilibria. Trajectories of passive tracers advected by point vortex
systems are studied numerically, in particular their vertical excursions, which
are non-zero because of ageostrophic effects. Surface trajectories can manifest
local divergence even though the underlying fluid equations are incompressible.

</details>


### [421] [Improved Analytical Solution for Turbulent Flow in Channel or Pipe](https://arxiv.org/abs/2508.12621)
*Alex Fedoseyev*

Main category: physics.flu-dyn

TL;DR: 提出了一种改进的港流港道激流流动的近似解析解，在高雷诺数下与实验数据的符合度显著提高


<details>
  <summary>Details</summary>
Motivation: 之前的近似解析解在高雷诺数时与实验数据存在显著偏差，需要提出更精确的解析方案

Method: 使用Alexeev流体动力学方程(AHE)作为控制方程，通过超指数和抛物线解的叠加来描述激流速度场

Result: 在Re=100,000时偏差从5%降低到2%，在Re=35,000,000时偏差从10%降低到4%，与多个实验数据库验证

Conclusion: 改进的解析方法显著提高了在极高雷诺数下的预测精度，为激流流动分析提供了更有效的理论工具

Abstract: The approximate analytical solution for turbulent flow in a channel was
proposed in Fedoseyev (2023). It described the mean turbulent flow velocity as
a superposition of parabolic (laminar) and superexponential (turbulent)
solutions. The Alexeev Hydrodynamic Equations (AHE), proposed by
\cite{Alexeev_1994}, were used as the governing equations to describe turbulent
flow. Compared to the Navier-Stokes equations, the AHE include additional terms
representing temporal and spatial fluctuations. These additional terms include
a timescale multiplier $\tau$, and the AHE reduce to the Navier-Stokes
equations in the limit as $\tau \to 0$
  In this study, we propose an improved analytical solution formula that
provides better agreement with experimental data at high Reynolds numbers. The
maximum discrepancy between the analytical solution and experimental data has
been reduced from 5% to 2% for Reynolds numbers of order 100,000, and from 10%
to 4% for Reynolds numbers up to 35,000,000, based on comparisons with
experimental results ranging from the legacy work of Nikuradse (Prandtl group,
1932) to studies by Wei (1989), Zagarola (1996), van Doorne (2007), and the
recent work of Pasch (2023).

</details>


### [422] [TURB-Scalar. A large database of passive scalar fields advected by 2D Navier-Stokes in the turbulent inverse cascade regime](https://arxiv.org/abs/2508.12762)
*Chiara Calascibetta,Luca Biferale,Fabio Bonaccorso,Massimo Cencini*

Main category: physics.flu-dyn

TL;DR: TURB-Scalar是一个包含约400个二维湍流速度和被动标量场快照的开源数据库，用于湍流建模研究


<details>
  <summary>Details</summary>
Motivation: 为物理和数据驱动建模方法提供通用的基准测试数据集，用于研究湍流输运现象

Method: 通过直接数值模拟(DNS)求解被动标量θ的平流-扩散方程，分辨率N=4096，从湍流逆级联机制获取数据

Result: 生成了约400个不相关的二维湍流场快照，标量场表现出间歇性统计特性和普适的异常标度行为

Conclusion: TURB-Scalar数据库为湍流研究提供了有价值的资源，可作为开发和测试各种建模方法的基准平台

Abstract: We introduce TURB-Scalar, an open-access database comprising approximately
$400$ uncorrelated snapshots of two-dimensional turbulent velocity and passive
scalar fields, obtained from the turbulent inverse cascade regime. These data
are generated through Direct Numerical Simulations (DNS) of the
advection-diffusion equation for a passive scalar, $\theta$, with resolution
$N=4096$. The database serves as a versatile benchmark for the development and
testing of both physics-based and data-driven modeling approaches. The scalar
field exhibits intermittent statistics with universal anomalous scaling, making
TURB-Scalar a valuable resource for studying turbulent transport phenomena. The
database is available at http://smart-turb.roma2.infn.it.

</details>


### [423] [A Comparison of Instabilities and Dynamic States in Active Filament Models](https://arxiv.org/abs/2508.12831)
*Ilteber R. Ozdemir,Bethany Clarke,Yongyun Hwang,Eric E. Keaveny*

Main category: physics.flu-dyn

TL;DR: 这篇论文通过比较研究不同的主动纤维模型，分析了指向力单独作用与表面流动效应的差异，以及取消点和分布式驱动对动态状态的影响。


<details>
  <summary>Details</summary>
Motivation: 研究主动纤维（如微管等）的动态行为，运输物质的机制对生物细胞功能至关重要。需要比较不同模型之间的动态差异，以更好地理解实际生物系统中的运输机制。

Method: 采用动力系统方法，对比研究两类模型：指向力单独作用模型与包含表面流动效应的模型，以及取消驱动与分布式驱动的差异。通过变化驱动强度来观察动态状态的转变。

Result: 所有模型在低驱动强度下都出现相似的第一分叉（立直到旋转和摇摆状态）。高驱动强度下显示差异：分布式驱动产生单一时间依赖状态（如旋转螺线），取消驱动导致复杂过渡和混沌状态。内部应力分布差异是导致动态差异的关键因素。

Conclusion: 不同的驱动方式和模型类型会产生显著不同的动态行为。分布式驱动更容易产生规则性运动，而取消驱动容易导致复杂和混沌行为。内部应力分布在很早的分叉阶段就开始影响不稳定模态的形状，这些发现对理解生物纤维的动态运输机制具有重要意义。

Abstract: Active filaments, such as microtubules with attached cargo-carrying motor
proteins, are important dynamic structures for fluid transport in and around
living cells. The mathematical models of active filaments appearing in the
literature typically involve combinations of follower-forces, compressive
tangential forces, along the filament, and an opposite force on the fluid that
generates an effective surface flow. In this paper, we present a comparative
dynamical systems study of active filament models examining the differences in
dynamic states that occur when actuation is through follower forces alone, or
the effect of surface flows is also included. We consider cases where actuation
is applied only at the filament tip, or distributed uniformly along the
filament length. By varying actuation strength, we show that the first
bifurcations that provide the transition between the upright, whirling and
beating states appear in all models. At higher values of actuation, when
beating becomes unstable, however, qualitative differences between the models
emerge. Those with distributed actuation produce a single, time-dependent
state, which for the surface flow model is reminiscent of a rotating helix that
periodically changes handedness and rotation direction. Tip actuation, however,
yields complex transitions that ultimately produce a chaotic state. We link the
differences in dynamics between tip and distributed actuation to differences in
their respective internal stress distributions, differences which appear as
early as the first bifurcation where they affect the shapes of the unstable
modes.

</details>


### [424] [Influence of Aspect Ratio and Flow Compressibility on Flow Dynamics in a Confined Cavity](https://arxiv.org/abs/2508.12867)
*Sreejita Bhaduri,Mohammed Ibrahim Sugarno,Ashoke De*

Main category: physics.flu-dyn

TL;DR: 本研究通过大涡模拟分析超声速空腔流动，发现偏转角激波增强Kelvin-Helmholtz不稳定性，从而抑制了振荡频率随马赫数的增加，揭示了激波冲击位置和剪切层扰动对流距离对空腔振荡的关键影响。


<details>
  <summary>Details</summary>
Motivation: 空腔自持振荡在燃料混合和热交换器中有应用价值，但共振会损坏结构。需要理解不同几何形状和流动条件下空腔振荡的特性，以优化其益处并最小化不利影响。

Method: 使用OpenFOAM进行大涡模拟(LES)，研究固定偏转角2.29°的超声速空腔流动，分析两种空腔纵横比和马赫数1.71-3的范围。采用数值纹影技术显示流动结构，频谱分析和降阶建模识别主导频率模式。

Result: 偏转角产生的激波在冲击剪切层时引起流动性质的高梯度，放大了Kelvin-Helmholtz不稳定性，增强了混合作用，并抑制了振荡频率随马赫数的预期增长。激波冲击位置和剪切层扰动对流距离显著影响不稳定性 prominence 和振荡频率。

Conclusion: 激波与剪切层的相互作用通过增强Kelvin-Helmholtz不稳定性来调节空腔振荡特性，激波冲击位置和扰动对流距离是影响振荡频率的关键因素，这为优化空腔设计提供了重要见解。

Abstract: Cavities possess self-sustaining oscillations driven by the interaction of
hydrodynamic and acoustic characteristics. These oscillations have applications
in fuel-air mixing, heat exchangers, and landing gears, but resonance can
damage the structures that house the cavities. Consequently, understanding
cavity oscillations under varying geometries and flow conditions is essential
for optimizing their benefits while minimizing the adverse effects. The present
study investigates flow variations in a supersonic cavity confined by a top
wall with a fixed deflection angle of $2.29^\circ$. We examine two aspect
ratios of the cavity across freestream Mach numbers from 1.71 to 3 using
Large-Eddy Simulations (LES) in OpenFOAM. Numerical Schlieren reveals the key
flow structures, while spectral analysis and reduced-order modeling help
identify dominant frequency modes and the corresponding flow structures. The
results show that the shock from the deflection corner induces high gradients
in the flow properties as it impinges on the shear layer. This amplifies the
Kelvin-Helmholtz (KH) instability, which enhances mixing and mitigates the
expected increase in oscillation frequency with Mach number. The KH instability
develops spatially. Hence, the location of the shock impingement on the shear
layer and the distance that the disturbances in the shear layer convect before
reaching the cavity wall significantly influence the prominence of the
instability, thereby influencing the frequency of cavity oscillations.

</details>


### [425] [On the Rheology of Two-Dimensional Dilute Emulsions](https://arxiv.org/abs/2508.13022)
*Thomas Appleford,Vatsal Sanjay,Maziyar Jalaal*

Main category: physics.flu-dyn

TL;DR: 这篇论文提供了二维斯托克流中单滴在剩分流中的分析解决方法，得到了稀稍液体的表观糕度和滴粒变形的理论表达式，并通过数值模拟验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 虽然二维模型在计算流体力学中具有计算效率高和实际相关性强的优势，但其理论研究相对较少。需要建立基础理论框架来解释二维滴粒模拟并为计算流体力学提供清晰的基准。

Method: 首先推导了二维斯托克流的Lamb解，然后用其求解纯扩张流中滴粒周围的流场。使用这些流场得到了稀稍液体表观糕度和小变形理论的表达式。最后通过直接数值模拟在广泛的糕度比范围内（0.01 < λ < 100）验证理论结果。

Result: 表观糕度表达式：μ* = μ(1 + f(λ)ϕ) + O(ϕ²)，其中f(λ) = (2λ + 1)/(λ + 1)，λ为滴粒与基体糕度比，ϕ为滴粒面积分数。滑流主导套中泰勒变形参数的稳态值：D_T^∞ = g(λ)Ca，其中g(λ) = 1，Ca为滑流数。这与三维情况不同，三维中g(λ)依赖于λ。

Conclusion: 这些结果为解释二维滴粒模拟提供了基础理论框架，并为计算流体力学提供了清晰的基准。研究发现二维与三维情况在滴粒变形行为上存在显著差异，这对理解二维模拟的局限性和适用性具有重要意义。

Abstract: The single droplet under shear is a foundational problem in fluid mechanics.
In computational fluid dynamics, the two-dimensional (2D) formulation offers
advantages in both computational efficiency and relevance, yet its theoretical
treatment remains relatively underdeveloped. In this brief note, we present an
analytical treatment of this problem, beginning with a derivation of the Lamb
solution for 2D Stokes flows, which in turn is used to obtain the flow fields
around a droplet in a purely extensional flow. Using these flow fields,
expressions are obtained for the apparent viscosity, $\mu^*$, of a dilute
emulsion as well as a small deformation theory. We show that $\mu^* = \mu( 1 +
f(\lambda) \phi) + \mathcal{O}(\phi^2)$ with $f(\lambda) = (2\lambda +
1)/(\lambda + 1)$ where $\lambda$ is the ratio of the droplet viscosity to the
matrix viscosity and $\phi$ is the area fraction covered by the suspended
phase. Also the steady state value of the Taylor deformation parameter
$D_T^\infty$, in the capillarity-dominated regime, obeys $D_T^\infty =
g(\lambda)\,\text{Ca}$, where Ca is the capillary number and $g(\lambda) = 1$.
This contrasts with the 3D case, where $g(\lambda)$ depends on $\lambda$. These
results are then validated through direct numerical simulations across a wide
range of viscosity ratios ($0.01 < \lambda < 100$). Our results provide a basic
theoretical framework for interpreting 2D droplet simulations and provide clear
benchmarks for computational fluid dynamics.

</details>


### [426] [Modeling wind farm noise emission and propagation: effects of flow layout](https://arxiv.org/abs/2508.13128)
*J. Colas,A. Emmanuelli,D. Dragna,R. J. A. M. Stevens*

Main category: physics.flu-dyn

TL;DR: 通过数值模拟研究风电场流动物理对噪声产生咄下游传播的影响，发现风电场布局咄激流相互作用显著影响噪声特性咄传播效果


<details>
  <summary>Details</summary>
Motivation: 现有风电模型多基于单独汽轮机，而风电场中激流相互作用对噪声产生咄传播有重要影响，需要研究风电场流动物理与声学效应的结合

Method: 采用大游度模拟(LES)对流场进行建模，并将时间平均输出作为声学模型的输入来预测风力汽轮机噪声

Result: 在第一排汽轮机中，激流噪声(TIN)咄后缘噪声(TEN)贡献相等，TIN在低频占主，TEN在高频占主。下游TEN减少而TIN保持。对齐布局激流作用更强，但错开布局总体噪声更大。风电场流动显著影响下风向声音传播，错开布局因激流位置导致更强的声音聚焦效应

Conclusion: 风电场流动物理对噪声产生咄传播有重要影响，基于单独汽轮机的模型无法捐描这些现象，必须整合流动咄声学模型来更准确评估风电场环境影响

Abstract: This study demonstrates how wind farm flow physics influence noise generation
and downstream propagation through numerical simulations. The flow field is
modeled using large-eddy simulations (LES), and the time-averaged output serves
as input to acoustic models that predict wind turbine noise. In the first
turbine row, turbulence-induced noise (TIN) and trailing edge noise (TEN)
contribute equally, with TIN dominating at low frequencies and TEN at higher
frequencies. Downstream, TEN decreases due to lower wind speeds, while TIN
mostly persists due to increased turbulence dissipation. These effects are more
pronounced in aligned wind farms, where stronger wake interactions occur, than
in staggered layouts. However, staggered farms produce more noise overall
because turbines operate at higher wind speeds.Additionally, wind farm flow
significantly affects sound propagation downwind. The wake superposition
modifies sound focusing leading to different amplification area than for an
isolated turbine. For a staggered layout it particularly shows enhanced sound
focusing downwind due to the position of the turbine wakes. This leads to
higher sound levels and higher amplitude modulation downwind for the wind farm
compared to an aligned layout. These phenomena are not captured by models based
on isolated turbines. These findings underscore the importance of integrating
flow and acoustic models to more accurately assess the environmental impact of
wind farms.

</details>
